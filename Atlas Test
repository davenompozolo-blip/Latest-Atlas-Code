#!/usr/bin/env python3
"""
ATLAS TERMINAL v9.1 COMPLETE - FULL COMBINED EDITION
ALL v8.8 Features + Valuation House Module

COMPLETE FEATURE SET:
‚úÖ Phoenix Parser (Portfolio reconstruction)
‚úÖ Portfolio Home (Enhanced holdings)
‚úÖ Market Watch (Global markets)
‚úÖ Risk Analysis (8+ WORLD-CLASS visualizations)
‚úÖ Performance Suite (Interactive analytics)
‚úÖ Portfolio Deep Dive (Attribution & sector rotation)
‚úÖ Multi-Factor Analysis (Factor exposure & attribution)
‚úÖ Valuation House (FCFF/FCFE DCF engine)

This is the COMPLETE unified codebase with EVERYTHING!
"""

import os
import subprocess
import sys
import time
from pathlib import Path

print("="*80)
print("üî• ATLAS TERMINAL v9.1 COMPLETE - FULL COMBINED EDITION")
print("   ALL v8.8 Features + Valuation House")
print("="*80)

# ============================================================================
# INSTALL DEPENDENCIES
# ============================================================================
print("\nüì¶ Installing dependencies...")
packages = [
    "streamlit", "yfinance", "plotly", "pandas", "numpy",
    "scipy", "pyngrok", "openpyxl", "xlrd", "xlsxwriter",
    "lxml", "html5lib", "networkx", "scikit-learn", "seaborn",
    "pandas-datareader", "statsmodels"
]

for pkg in packages:
    try:
        subprocess.check_call(
            [sys.executable, "-m", "pip", "install", pkg, "-q"],
            stdout=subprocess.DEVNULL,
            stderr=subprocess.DEVNULL
        )
    except:
        pass

print("‚úÖ Dependencies installed!")

# ============================================================================
# NGROK SETUP
# ============================================================================
print("\nüì° Setting up ngrok tunnel...")
from pyngrok import ngrok

ngrok.set_auth_token("3560NW1Q6pfr5LKXYCFxvt6JnAI_39PX8PaW3aGqhTTr2yo2M")

# ============================================================================
# WRITE COMPLETE COMBINED APP CODE
# ============================================================================
print("\nüìù Creating ATLAS Terminal v9.1 COMPLETE...")
print("   ‚ú® ALL v8.8 Features")
print("   ‚ú® Valuation House Module")
print("   ‚ú® 150+ Features Total")

app_code = r'''
"""
ATLAS TERMINAL v9.1 COMPLETE - FULL COMBINED EDITION
The Ultimate Portfolio Analytics + Valuation Platform
"""

import pickle
import warnings
import re
import time
import io
import json
import random
from datetime import datetime, timedelta, date
from pathlib import Path
from collections import Counter, defaultdict
import numpy as np
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import streamlit as st
import yfinance as yf
from scipy import stats
from scipy.optimize import minimize
import networkx as nx
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA
from sklearn.linear_model import LinearRegression

warnings.filterwarnings("ignore")

# ============================================================================
# HELPER FUNCTIONS FOR VALIDATION
# ============================================================================
def is_valid_series(series):
    """Safely check if a pandas Series has valid data"""
    return series is not None and isinstance(series, pd.Series) and not series.empty

def is_valid_dataframe(df):
    """Safely check if a pandas DataFrame has valid data"""
    return df is not None and isinstance(df, pd.DataFrame) and not df.empty

# ============================================================================
# PAGE CONFIG
# ============================================================================
st.set_page_config(
    page_title="ATLAS Terminal v9.1 COMPLETE",
    page_icon="üî•",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ============================================================================
# PROFESSIONAL THEME SYSTEM
# ============================================================================

COLORS = {
    "background": "#000000",
    "card_background": "#0a1929",
    "card_background_alt": "#050f17",
    "neon_blue": "#00d4ff",
    "electric_blue": "#0080ff",
    "teal": "#00ffcc",
    "cyan": "#00ffff",
    "success": "#00ff88",
    "warning": "#ffaa00",
    "danger": "#ff0044",
    "info": "#00d4ff",
    "purple": "#b794f6",
    "pink": "#ff00ff",
    "orange": "#ff6b00",
    "chart_primary": "#00d4ff",
    "chart_secondary": "#0080ff",
    "chart_accent": "#00ffcc",
    "chart_grid": "#1a3a52",
    "text_primary": "#ffffff",
    "text_secondary": "#b0c4de",
    "text_muted": "#6c8ca8",
    "border": "#00d4ff",
    "shadow": "rgba(0, 212, 255, 0.3)",
    "shadow_strong": "rgba(0, 212, 255, 0.6)",
    "gain_bg": "rgba(0, 255, 136, 0.15)",
    "gain_text": "#00ff88",
    "loss_bg": "rgba(255, 0, 68, 0.15)",
    "loss_text": "#ff0044",
}

# ============================================================================
# ENHANCED CSS
# ============================================================================
st.markdown(f"""
<style>
    @import url('https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&family=JetBrains+Mono:wght@400;600&display=swap');

    * {{
        font-family: 'Inter', 'Segoe UI', sans-serif !important;
    }}

    .main {{
        background: linear-gradient(135deg, #000000 0%, #0a1929 100%);
        color: {COLORS['text_primary']};
    }}

    h1 {{
        background: linear-gradient(90deg, #00d4ff, #00ff88, #00d4ff);
        background-clip: text;
        -webkit-background-clip: text;
        -webkit-text-fill-color: transparent;
        text-shadow: 0 0 40px rgba(0,212,255,0.8);
        font-family: 'Inter', sans-serif !important;
        font-weight: 700 !important;
        font-size: 3.5em !important;
        text-align: center;
        animation: glow 2s ease-in-out infinite alternate;
    }}

    @keyframes glow {{
        from {{ text-shadow: 0 0 20px rgba(0,212,255,0.5); }}
        to {{ text-shadow: 0 0 30px rgba(0,212,255,1), 0 0 40px rgba(0,255,136,0.5); }}
    }}

    div[data-testid="stMetric"] {{
        background: linear-gradient(135deg, {COLORS['card_background']} 0%, {COLORS['card_background_alt']} 100%);
        border: 2px solid {COLORS['neon_blue']};
        border-radius: 12px;
        padding: 20px;
        box-shadow: 0 0 30px {COLORS['shadow']};
        transition: all 0.3s ease;
    }}

    div[data-testid="stMetric"]:hover {{
        transform: translateY(-5px) scale(1.02);
        box-shadow: 0 10px 40px {COLORS['shadow_strong']};
    }}
    
    .stSlider {{
        padding: 10px 0px;
    }}
</style>
""", unsafe_allow_html=True)

# ============================================================================
# CONSTANTS & CONFIG
# ============================================================================
CACHE_DIR = Path.home() / ".atlas_cache"
CACHE_DIR.mkdir(exist_ok=True)
PORTFOLIO_CACHE = CACHE_DIR / "portfolio.pkl"
TRADE_HISTORY_CACHE = CACHE_DIR / "trade_history.pkl"
ACCOUNT_HISTORY_CACHE = CACHE_DIR / "account_history.pkl"

RISK_FREE_RATE = 0.045
MARKET_RETURN = 0.10

# ETF sectors
ETF_SECTORS = {
    "QQQ": "Technology", "XLK": "Technology", "VGT": "Technology",
    "XLF": "Financial Services", "KRE": "Financial Services",
    "XLV": "Healthcare", "IBB": "Healthcare", "XBI": "Healthcare",
    "XLE": "Energy", "XOP": "Energy", "USO": "Energy",
    "XLB": "Basic Materials", "GDX": "Basic Materials",
    "XLY": "Consumer Cyclical", "XLP": "Consumer Defensive",
    "XLI": "Industrials", "IYT": "Industrials",
    "VNQ": "Real Estate", "XLRE": "Real Estate",
    "XLU": "Utilities",
    "SPY": "Broad Market", "VOO": "Broad Market", "VTI": "Broad Market"
}

# Global Market Indices
GLOBAL_INDICES = {
    "^GSPC": {"name": "S&P 500", "region": "US"},
    "^NDX": {"name": "Nasdaq 100", "region": "US"},
    "^DJI": {"name": "Dow Jones", "region": "US"},
    "^RUT": {"name": "Russell 2000", "region": "US"},
    "^FTSE": {"name": "FTSE 100", "region": "UK"},
    "^GDAXI": {"name": "DAX", "region": "Germany"},
}

# Commodities
COMMODITIES = {
    "GC=F": {"name": "Gold", "category": "Precious Metals"},
    "SI=F": {"name": "Silver", "category": "Precious Metals"},
    "CL=F": {"name": "Crude Oil WTI", "category": "Energy"},
    "NG=F": {"name": "Natural Gas", "category": "Energy"},
}

# Popular ETFs
POPULAR_ETFS = {
    "XLK": {"name": "Technology Select", "category": "Sector"},
    "XLF": {"name": "Financial Select", "category": "Sector"},
    "XLV": {"name": "Health Care Select", "category": "Sector"},
    "ARKK": {"name": "ARK Innovation", "category": "Thematic"},
}

# Factor definitions
FACTOR_DEFINITIONS = {
    "Market": {"description": "Market risk premium", "benchmark": "SPY"},
    "Size": {"description": "Small cap minus large cap", "benchmark": "IWM"},
    "Value": {"description": "Value minus growth", "benchmark": "IWD"},
    "Momentum": {"description": "Winners minus losers", "benchmark": "MTUM"},
}

# ============================================================================
# HELPER FUNCTIONS
# ============================================================================

def format_percentage(value, decimals=2):
    if pd.isna(value) or value is None:
        return "N/A"
    return f"{value:.{decimals}f}%"

def format_currency(value):
    if pd.isna(value) or value is None:
        return "N/A"
    return f"${value:,.2f}"

def format_large_number(value):
    """Format large numbers with B/M/K suffix"""
    if pd.isna(value) or value is None:
        return "N/A"
    if abs(value) >= 1e9:
        return f"${value/1e9:.2f}B"
    elif abs(value) >= 1e6:
        return f"${value/1e6:.2f}M"
    elif abs(value) >= 1e3:
        return f"${value/1e3:.2f}K"
    return f"${value:.2f}"

def add_arrow_indicator(value):
    try:
        val = float(str(value).replace('%', '').replace('$', '').replace(',', ''))
        if val > 0:
            return f"‚ñ≤ {value}"
        elif val < 0:
            return f"‚ñº {value}"
        return f"‚îÄ {value}"
    except:
        return value

# ============================================================================
# DATA FUNCTIONS
# ============================================================================

def save_portfolio_data(data):
    with open(PORTFOLIO_CACHE, "wb") as f:
        pickle.dump(data, f)

def load_portfolio_data():
    if PORTFOLIO_CACHE.exists():
        with open(PORTFOLIO_CACHE, "rb") as f:
            return pickle.load(f)
    return []

def save_trade_history(df):
    with open(TRADE_HISTORY_CACHE, "wb") as f:
        pickle.dump(df, f)

def load_trade_history():
    if TRADE_HISTORY_CACHE.exists():
        with open(TRADE_HISTORY_CACHE, "rb") as f:
            return pickle.load(f)
    return None

def save_account_history(df):
    with open(ACCOUNT_HISTORY_CACHE, "wb") as f:
        pickle.dump(df, f)

def load_account_history():
    if ACCOUNT_HISTORY_CACHE.exists():
        with open(ACCOUNT_HISTORY_CACHE, "rb") as f:
            return pickle.load(f)
    return None

@st.cache_data(ttl=300)
def fetch_market_data(ticker):
    try:
        stock = yf.Ticker(ticker)
        info = stock.info
        hist = stock.history(period="5d")
        if hist.empty:
            return None

        current_price = hist['Close'].iloc[-1]
        prev_close = hist['Close'].iloc[-2] if len(hist) > 1 else current_price
        daily_change = current_price - prev_close
        daily_change_pct = (daily_change / prev_close * 100) if prev_close else 0

        company_name = info.get('longName', info.get('shortName', ticker))

        return {
            "price": current_price,
            "daily_change": daily_change,
            "daily_change_pct": daily_change_pct,
            "company_name": company_name,
            "sector": info.get('sector', 'Unknown'),
            "beta": info.get('beta', None),
        }
    except:
        return None

def is_option_ticker(ticker):
    if len(ticker) <= 6:
        return False
    has_year = any(str(y) in ticker for y in range(2020, 2030))
    has_strike = any(c.isdigit() for c in ticker[6:])
    has_type = ticker[-1] in ['C', 'P'] or 'C' in ticker[6:] or 'P' in ticker[6:]
    return has_year and has_strike and has_type

def classify_ticker_sector(ticker, default_sector):
    if pd.notna(default_sector) and default_sector != "Unknown":
        return default_sector
    if ticker in ETF_SECTORS:
        return ETF_SECTORS[ticker]
    return "Other"

@st.cache_data(ttl=600)
def fetch_historical_data(ticker, start_date, end_date):
    try:
        stock = yf.Ticker(ticker)
        hist = stock.history(start=start_date, end=end_date)
        if not hist.empty:
            return hist
    except:
        pass
    return None

# ============================================================================
# VALUATION HOUSE - DATA FETCHING
# ============================================================================

@st.cache_data(ttl=3600)
def fetch_company_financials(ticker):
    """Fetch comprehensive financial data for valuation"""
    try:
        stock = yf.Ticker(ticker)
        info = stock.info
        
        company_data = {
            'ticker': ticker,
            'name': info.get('longName', ticker),
            'sector': info.get('sector', 'Unknown'),
            'industry': info.get('industry', 'Unknown'),
            'current_price': info.get('currentPrice', 0),
            'market_cap': info.get('marketCap', 0),
            'shares_outstanding': info.get('sharesOutstanding', 0),
            'beta': info.get('beta', 1.0),
            'forward_pe': info.get('forwardPE'),
            'trailing_pe': info.get('trailingPE'),
        }
        
        income_stmt = stock.income_stmt
        balance_sheet = stock.balance_sheet
        cash_flow = stock.cash_flow
        
        financials = {}
        
        if not income_stmt.empty:
            latest_col = income_stmt.columns[0]
            
            financials['revenue'] = income_stmt.loc['Total Revenue', latest_col] if 'Total Revenue' in income_stmt.index else 0
            financials['ebit'] = income_stmt.loc['EBIT', latest_col] if 'EBIT' in income_stmt.index else 0
            financials['net_income'] = income_stmt.loc['Net Income', latest_col] if 'Net Income' in income_stmt.index else 0
            financials['tax_expense'] = income_stmt.loc['Tax Provision', latest_col] if 'Tax Provision' in income_stmt.index else 0
            
            if financials['ebit'] != 0:
                financials['tax_rate'] = abs(financials['tax_expense'] / financials['ebit'])
            else:
                financials['tax_rate'] = 0.21
                
        if not balance_sheet.empty:
            latest_col = balance_sheet.columns[0]
            
            financials['total_debt'] = balance_sheet.loc['Total Debt', latest_col] if 'Total Debt' in balance_sheet.index else 0
            financials['cash'] = balance_sheet.loc['Cash And Cash Equivalents', latest_col] if 'Cash And Cash Equivalents' in balance_sheet.index else 0
            financials['total_equity'] = balance_sheet.loc['Total Equity Gross Minority Interest', latest_col] if 'Total Equity Gross Minority Interest' in balance_sheet.index else 0
            
        if not cash_flow.empty:
            latest_col = cash_flow.columns[0]
            
            financials['capex'] = abs(cash_flow.loc['Capital Expenditure', latest_col]) if 'Capital Expenditure' in cash_flow.index else 0
            financials['depreciation'] = cash_flow.loc['Depreciation And Amortization', latest_col] if 'Depreciation And Amortization' in cash_flow.index else 0
            financials['operating_cf'] = cash_flow.loc['Operating Cash Flow', latest_col] if 'Operating Cash Flow' in cash_flow.index else 0
        
        financials['change_wc'] = 0
        
        return {
            'company': company_data,
            'financials': financials,
            'success': True
        }
        
    except Exception as e:
        return {
            'success': False,
            'error': str(e)
        }

# ============================================================================
# VALUATION HOUSE - DCF CALCULATIONS
# ============================================================================

def calculate_wacc(cost_equity, cost_debt, tax_rate, debt, equity):
    """Calculate Weighted Average Cost of Capital"""
    total_value = debt + equity
    if total_value == 0:
        return cost_equity
    
    weight_equity = equity / total_value
    weight_debt = debt / total_value
    
    wacc = (cost_equity * weight_equity) + (cost_debt * (1 - tax_rate) * weight_debt)
    return wacc

def calculate_cost_of_equity(risk_free_rate, beta, market_risk_premium):
    """Calculate Cost of Equity using CAPM"""
    return risk_free_rate + (beta * market_risk_premium)

def calculate_terminal_value(final_fcf, discount_rate, terminal_growth):
    """Calculate Terminal Value using Gordon Growth Model"""
    if discount_rate <= terminal_growth:
        return 0
    return final_fcf * (1 + terminal_growth) / (discount_rate - terminal_growth)

def project_fcff(base_ebit, revenue_growth, ebit_margin, tax_rate, depreciation, 
                 capex, change_wc, forecast_years):
    """Project Free Cash Flow to Firm"""
    projections = []
    
    current_ebit = base_ebit
    
    for year in range(1, forecast_years + 1):
        current_ebit = current_ebit * (1 + revenue_growth)
        nopat = current_ebit * (1 - tax_rate)
        fcff = nopat + depreciation - capex - change_wc
        
        projections.append({
            'year': year,
            'ebit': current_ebit,
            'nopat': nopat,
            'depreciation': depreciation,
            'capex': capex,
            'change_wc': change_wc,
            'fcff': fcff
        })
    
    return projections

def project_fcfe(base_net_income, revenue_growth, tax_rate, depreciation,
                 capex, change_wc, net_borrowing, forecast_years):
    """Project Free Cash Flow to Equity"""
    projections = []
    
    current_ni = base_net_income
    
    for year in range(1, forecast_years + 1):
        current_ni = current_ni * (1 + revenue_growth)
        fcfe = current_ni + depreciation - capex - change_wc + net_borrowing
        
        projections.append({
            'year': year,
            'net_income': current_ni,
            'depreciation': depreciation,
            'capex': capex,
            'change_wc': change_wc,
            'net_borrowing': net_borrowing,
            'fcfe': fcfe
        })
    
    return projections

def calculate_dcf_value(projections, discount_rate, terminal_value, shares_outstanding, 
                       net_debt=0, method='FCFF'):
    """Calculate DCF valuation"""
    pv_cash_flows = []
    total_pv = 0
    
    for proj in projections:
        year = proj['year']
        cf = proj['fcff'] if method == 'FCFF' else proj['fcfe']
        pv = cf / ((1 + discount_rate) ** year)
        pv_cash_flows.append(pv)
        total_pv += pv
    
    pv_terminal = terminal_value / ((1 + discount_rate) ** len(projections))
    
    enterprise_value = total_pv + pv_terminal
    
    if method == 'FCFF':
        equity_value = enterprise_value - net_debt
    else:
        equity_value = enterprise_value
    
    intrinsic_value_per_share = equity_value / shares_outstanding if shares_outstanding > 0 else 0
    
    return {
        'pv_cash_flows': pv_cash_flows,
        'total_pv_cash_flows': total_pv,
        'terminal_value': terminal_value,
        'pv_terminal': pv_terminal,
        'enterprise_value': enterprise_value,
        'equity_value': equity_value,
        'intrinsic_value_per_share': intrinsic_value_per_share
    }

# ============================================================================
# VALUATION HOUSE - VISUALIZATIONS
# ============================================================================

def create_dcf_waterfall(dcf_results, method='FCFF'):
    """Create waterfall chart showing DCF buildup"""
    
    categories = ['PV of Cash Flows', 'PV of Terminal Value']
    values = [dcf_results['total_pv_cash_flows'], dcf_results['pv_terminal']]
    
    if method == 'FCFF':
        categories.append('Enterprise Value')
        categories.append('Less: Net Debt')
        categories.append('Equity Value')
        values.append(dcf_results['enterprise_value'])
        values.append(-dcf_results.get('net_debt', 0))
        values.append(dcf_results['equity_value'])
    
    fig = go.Figure(go.Waterfall(
        name="DCF Buildup",
        orientation="v",
        x=categories,
        y=values,
        connector={"line": {"color": COLORS['neon_blue']}},
        decreasing={"marker": {"color": COLORS['danger']}},
        increasing={"marker": {"color": COLORS['success']}},
    ))
    
    fig.update_layout(
        title=f"üíé {method} Valuation Buildup",
        yaxis_title="Value ($)",
        height=500,
        paper_bgcolor=COLORS['background'],
        plot_bgcolor=COLORS['card_background'],
        font=dict(color=COLORS['text_primary'])
    )
    
    return fig

def create_cash_flow_chart(projections, method='FCFF'):
    """Create bar chart of projected cash flows"""
    
    cf_key = 'fcff' if method == 'FCFF' else 'fcfe'
    
    years = [proj['year'] for proj in projections]
    cash_flows = [proj[cf_key] for proj in projections]
    
    fig = go.Figure()
    
    fig.add_trace(go.Bar(
        x=years,
        y=cash_flows,
        marker_color=COLORS['electric_blue'],
        name=method
    ))
    
    fig.update_layout(
        title=f"üìä Projected {method} by Year",
        xaxis_title="Year",
        yaxis_title=f"{method} ($)",
        height=400,
        paper_bgcolor=COLORS['background'],
        plot_bgcolor=COLORS['card_background'],
        font=dict(color=COLORS['text_primary'])
    )
    
    return fig

def create_sensitivity_table(base_price, base_discount, base_terminal):
    """Create sensitivity analysis table"""
    
    discount_rates = np.linspace(base_discount - 0.02, base_discount + 0.02, 5)
    terminal_growth_rates = np.linspace(base_terminal - 0.01, base_terminal + 0.01, 5)
    
    sensitivity_matrix = []
    for tr in terminal_growth_rates:
        row = []
        for dr in discount_rates:
            adjustment = (1 - (dr - base_discount)) * (1 + (tr - base_terminal))
            value = base_price * adjustment
            row.append(value)
        sensitivity_matrix.append(row)
    
    fig = go.Figure(data=go.Heatmap(
        z=sensitivity_matrix,
        x=[f"{dr:.1%}" for dr in discount_rates],
        y=[f"{tg:.1%}" for tg in terminal_growth_rates],
        colorscale='RdYlGn',
        text=[[f"${v:.2f}" for v in row] for row in sensitivity_matrix],
        texttemplate='%{text}',
        textfont={"size": 10},
        colorbar=dict(title="Price")
    ))
    
    fig.update_layout(
        title="üó∫Ô∏è Portfolio Heatmap",
        height=700,
        paper_bgcolor=COLORS['background'],
        font=dict(color=COLORS['text_primary'])
    )
    
    return fig

def create_sector_rotation_heatmap(df, start_date, end_date):
    """Sector rotation heatmap"""
    sector_returns = {}
    
    for _, row in df.iterrows():
        ticker = row['Ticker']
        sector = row['Sector']
        
        hist_data = fetch_historical_data(ticker, start_date, end_date)
        if hist_data is not None and len(hist_data) > 30:
            monthly_data = hist_data['Close'].resample('M').last()
            monthly_returns = monthly_data.pct_change() * 100
            
            if sector not in sector_returns:
                sector_returns[sector] = []
            
            sector_returns[sector].append(monthly_returns)
    
    if not sector_returns:
        return None
    
    sector_avg = {}
    for sector, returns_list in sector_returns.items():
        combined = pd.concat(returns_list, axis=1).mean(axis=1)
        sector_avg[sector] = combined
    
    sectors = list(sector_avg.keys())
    months = sector_avg[sectors[0]].index
    
    matrix = []
    for sector in sectors:
        matrix.append(sector_avg[sector].values)
    
    fig = go.Figure(data=go.Heatmap(
        z=matrix,
        x=[m.strftime('%b %Y') for m in months],
        y=sectors,
        colorscale='RdYlGn',
        zmid=0,
        text=np.round(matrix, 1),
        texttemplate='%{text}%',
        textfont={"size": 11},
        colorbar=dict(title="Return %")
    ))
    
    fig.update_layout(
        title="üîÑ Sector Rotation Heatmap",
        xaxis_title="Month",
        yaxis_title="Sector",
        height=500,
        paper_bgcolor=COLORS['background'],
        plot_bgcolor=COLORS['card_background'],
        font=dict(color=COLORS['text_primary'])
    )
    
    return fig

def create_holdings_attribution_waterfall(df):
    """Holdings attribution waterfall"""

    # Step 1: Get top 10 contributors
    top_contributors = df.nlargest(10, 'Total Gain/Loss üéØ Sensitivity Analysis')

    # Step 2: Create your plot (example using Plotly)
    fig = px.bar(
        top_contributors,
        x='SomeXAxisColumn',  # replace with actual column
        y='Total Gain/Loss üéØ Sensitivity Analysis',
        title="üéØ Sensitivity Analysis"
    )

    # Step 3: Update layout
    fig.update_layout(
        xaxis_title="Discount Rate",
        yaxis_title="Terminal Growth Rate",
        height=400,
        paper_bgcolor=COLORS['background'],
        plot_bgcolor=COLORS['card_background'],
        font=dict(color=COLORS['text_primary'])
    )

    return fig


# ============================================================================
# PHOENIX PARSER
# ============================================================================

def parse_trade_history_file(uploaded_file):
    try:
        df = pd.read_html(uploaded_file)[0]
        required_cols = ['Date', 'Symbol', 'Trade Type', 'Quantity', 'Price']
        if not all(col in df.columns for col in required_cols):
            return None
        df['Price'] = df['Price'].astype(str).str.replace('$', '').str.replace(',', '').astype(float)
        df['Date'] = pd.to_datetime(df['Date'])
        df = df.sort_values('Date')
        return df
    except:
        return None

def parse_account_history_file(uploaded_file):
    try:
        df = pd.read_html(uploaded_file)[0]
        df['Date'] = pd.to_datetime(df['Date'])
        df = df.sort_values('Date')
        return df
    except:
        return None

def calculate_portfolio_from_trades(trade_df):
    holdings = {}
    for _, row in trade_df.iterrows():
        symbol = row['Symbol']
        trade_type = row['Trade Type']
        quantity = row['Quantity']
        price = row['Price']

        if is_option_ticker(symbol):
            continue

        if symbol not in holdings:
            holdings[symbol] = {'total_shares': 0, 'total_cost': 0, 'trades': []}

        is_buy = 'Buy' in trade_type

        if is_buy:
            holdings[symbol]['total_shares'] += quantity
            holdings[symbol]['total_cost'] += (quantity * price)
            holdings[symbol]['trades'].append({'type': 'BUY', 'quantity': quantity, 'price': price})
        else:
            remaining_to_sell = quantity
            for trade in holdings[symbol]['trades']:
                if trade['type'] == 'BUY' and remaining_to_sell > 0:
                    if trade['quantity'] <= remaining_to_sell:
                        holdings[symbol]['total_cost'] -= (trade['quantity'] * trade['price'])
                        holdings[symbol]['total_shares'] -= trade['quantity']
                        remaining_to_sell -= trade['quantity']
                        trade['quantity'] = 0
                    else:
                        holdings[symbol]['total_cost'] -= (remaining_to_sell * trade['price'])
                        holdings[symbol]['total_shares'] -= remaining_to_sell
                        trade['quantity'] -= remaining_to_sell
                        remaining_to_sell = 0

    portfolio_data = []
    for symbol, data in holdings.items():
        if data['total_shares'] > 0:
            avg_cost = data['total_cost'] / data['total_shares']
            portfolio_data.append({
                'Ticker': symbol,
                'Shares': data['total_shares'],
                'Avg Cost': avg_cost
            })

    if not portfolio_data:
        return pd.DataFrame(columns=['Ticker', 'Shares', 'Avg Cost'])
    return pd.DataFrame(portfolio_data).sort_values('Ticker')

# ============================================================================
# ENHANCED HOLDINGS TABLE
# ============================================================================

def create_enhanced_holdings_table(df):
    enhanced_df = df.copy()

    for idx, row in enhanced_df.iterrows():
        ticker = row['Ticker']
        market_data = fetch_market_data(ticker)

        if market_data:
            enhanced_df.at[idx, 'Asset Name'] = market_data['company_name']
            enhanced_df.at[idx, 'Current Price'] = market_data['price']
            enhanced_df.at[idx, 'Daily Change'] = market_data['daily_change']
            enhanced_df.at[idx, 'Daily Change %'] = market_data['daily_change_pct']
            enhanced_df.at[idx, 'Beta'] = market_data.get('beta', 'N/A')
            base_sector = market_data.get('sector', 'Unknown')
            enhanced_df.at[idx, 'Sector'] = classify_ticker_sector(ticker, base_sector)
        else:
            enhanced_df.at[idx, 'Asset Name'] = ticker
            enhanced_df.at[idx, 'Sector'] = 'Other'

    enhanced_df['Sector'] = enhanced_df['Sector'].fillna('Other')
    enhanced_df['Shares'] = enhanced_df['Shares'].round(0).astype(int)

    enhanced_df['Total Cost'] = enhanced_df['Shares'] * enhanced_df['Avg Cost']
    enhanced_df['Total Value'] = enhanced_df['Shares'] * enhanced_df['Current Price']
    enhanced_df['Total Gain/Loss' ] = enhanced_df['Total Value'] - enhanced_df['Total Cost']
    enhanced_df['Total Gain/Loss %'] = ((enhanced_df['Current Price'] - enhanced_df['Avg Cost']) / enhanced_df['Avg Cost']) * 100
    enhanced_df['Daily P&L' ] = enhanced_df['Shares'] * enhanced_df['Daily Change']

    total_value = enhanced_df['Total Value'].sum()
    enhanced_df['Weight %'] = (enhanced_df['Total Value'] / total_value * 100) if total_value > 0 else 0

    return enhanced_df

def style_holdings_dataframe(df):
    display_df = df[[
        'Ticker', 'Asset Name', 'Shares', 'Avg Cost', 'Current Price',
        'Daily Change %', 'Weight %', 'Daily P&L' 
        'Total Gain/Loss' , 'Total Gain/Loss %', 'Beta'
    ]].copy()

    pct_cols = ['Daily Change %', 'Weight %', 'Total Gain/Loss %']
    for col in pct_cols:
        display_df[col] = display_df[col].apply(lambda x: format_percentage(x))

    currency_cols = ['Avg Cost', 'Current Price', 'Daily P&L' , 'Total Gain/Loss' ]
    for col in currency_cols:
        display_df[col] = display_df[col].apply(format_currency)

    display_df['Daily Change %'] = display_df['Daily Change %'].apply(add_arrow_indicator)
    display_df['Total Gain/Loss %'] = display_df['Total Gain/Loss %'].apply(add_arrow_indicator)

    return display_df

# ============================================================================
# RISK METRICS (v8.8 COMPLETE)
# ============================================================================

def calculate_sharpe_ratio(returns, risk_free_rate=RISK_FREE_RATE):
    if not is_valid_series(returns) or len(returns) < 2:
        return None
    total_return = (1 + returns).prod() - 1
    n_years = len(returns) / 252
    annualized_return = (1 + total_return) ** (1/n_years) - 1 if n_years > 0 else 0
    annualized_vol = returns.std() * np.sqrt(252)
    sharpe = (annualized_return - risk_free_rate) / annualized_vol if annualized_vol > 0 else 0
    return sharpe

def calculate_sortino_ratio(returns, risk_free_rate=RISK_FREE_RATE):
    if not is_valid_series(returns) or len(returns) < 2:
        return None
    total_return = (1 + returns).prod() - 1
    n_years = len(returns) / 252
    annualized_return = (1 + total_return) ** (1/n_years) - 1 if n_years > 0 else 0
    downside_returns = returns[returns < 0]
    if len(downside_returns) < 2:
        return None
    downside_std = downside_returns.std() * np.sqrt(252)
    sortino = (annualized_return - risk_free_rate) / downside_std if downside_std > 0 else 0
    return sortino

def calculate_calmar_ratio(returns, risk_free_rate=RISK_FREE_RATE):
    if not is_valid_series(returns) or len(returns) < 2:
        return None
    total_return = (1 + returns).prod() - 1
    n_years = len(returns) / 252
    annualized_return = (1 + total_return) ** (1/n_years) - 1 if n_years > 0 else 0
    max_dd = abs(calculate_max_drawdown(returns))
    if max_dd == 0:
        return 0
    return (annualized_return - risk_free_rate) / (max_dd / 100)

def calculate_information_ratio(portfolio_returns, benchmark_returns):
    if not is_valid_series(portfolio_returns) or not is_valid_series(benchmark_returns):
        return None
    if len(portfolio_returns) < 2 or len(benchmark_returns) < 2:
        return None
    common_dates = portfolio_returns.index.intersection(benchmark_returns.index)
    portfolio_returns = portfolio_returns.loc[common_dates]
    benchmark_returns = benchmark_returns.loc[common_dates]
    excess_returns = portfolio_returns - benchmark_returns
    if len(excess_returns) < 2:
        return None
    total_excess = (1 + excess_returns).prod() - 1
    n_years = len(excess_returns) / 252
    annualized_excess = (1 + total_excess) ** (1/n_years) - 1 if n_years > 0 else 0
    tracking_error = excess_returns.std() * np.sqrt(252)
    info_ratio = annualized_excess / tracking_error if tracking_error > 0 else 0
    return info_ratio

def calculate_var(returns, confidence=0.95):
    if not is_valid_series(returns) or len(returns) < 2:
        return None
    var = np.percentile(returns, (1 - confidence) * 100)
    return var * 100

def calculate_cvar(returns, confidence=0.95):
    if not is_valid_series(returns) or len(returns) < 2:
        return None
    var = np.percentile(returns, (1 - confidence) * 100)
    cvar = returns[returns <= var].mean()
    return cvar * 100

def calculate_max_drawdown(returns):
    if not is_valid_series(returns) or len(returns) < 2:
        return None
    cumulative = (1 + returns).cumprod()
    running_max = cumulative.expanding().max()
    drawdown = (cumulative - running_max) / running_max
    return drawdown.min() * 100

@st.cache_data(ttl=600)
def calculate_portfolio_returns(df, start_date, end_date):
    try:
        valid_positions = []
        for _, row in df.iterrows():
            if not is_option_ticker(row['Ticker']):
                valid_positions.append(row)
        
        if not valid_positions:
            return None
        
        valid_df = pd.DataFrame(valid_positions)
        all_data = {}
        
        for _, row in valid_df.iterrows():
            ticker = row['Ticker']
            data = fetch_historical_data(ticker, start_date, end_date)
            if data is not None and len(data) > 0:
                all_data[ticker] = data
        
        if not all_data:
            return None
        
        common_dates = None
        for ticker, data in all_data.items():
            dates = set(data.index)
            common_dates = dates if common_dates is None else common_dates.intersection(dates)
        
        common_dates = sorted(list(common_dates))
        if len(common_dates) < 2:
            return None
        
        portfolio_values = []
        for date in common_dates:
            daily_value = 0
            for _, row in valid_df.iterrows():
                ticker = row['Ticker']
                if ticker in all_data:
                    try:
                        price = all_data[ticker].loc[date, 'Close']
                        daily_value += price * row['Shares']
                    except KeyError:
                        continue
            portfolio_values.append(daily_value)
        
        portfolio_series = pd.Series(portfolio_values, index=common_dates)
        returns = portfolio_series.pct_change().dropna()
        return returns
    except:
        return None

@st.cache_data(ttl=600)
def calculate_benchmark_returns(benchmark_ticker, start_date, end_date):
    try:
        data = fetch_historical_data(benchmark_ticker, start_date, end_date)
        if data is None or data.empty:
            return None
        returns = data['Close'].pct_change().dropna()
        return returns
    except:
        return None

# ============================================================================
# WORLD-CLASS VISUALIZATIONS (v8.8 COMPLETE)
# ============================================================================

def create_rolling_metrics_chart(returns, window=60):
    """Rolling metrics visualization"""
    if not is_valid_series(returns) or len(returns) < window:
        return None
    
    rolling_vol = returns.rolling(window).std() * np.sqrt(252) * 100
    rolling_sharpe = (returns.rolling(window).mean() * 252 - RISK_FREE_RATE) / (returns.rolling(window).std() * np.sqrt(252))
    
    fig = make_subplots(
        rows=2, cols=1,
        subplot_titles=('Rolling Volatility (60-Day)', 'Rolling Sharpe Ratio (60-Day)'),
        vertical_spacing=0.15
    )
    
    fig.add_trace(
        go.Scatter(
            x=rolling_vol.index,
            y=rolling_vol.values,
            fill='tozeroy',
            fillcolor='rgba(255, 0, 68, 0.2)',
            line=dict(color=COLORS['danger'], width=2),
            name='Volatility'
        ),
        row=1, col=1
    )
    
    fig.add_trace(
        go.Scatter(
            x=rolling_sharpe.index,
            y=rolling_sharpe.values,
            fill='tozeroy',
            fillcolor='rgba(0, 212, 255, 0.2)',
            line=dict(color=COLORS['neon_blue'], width=2),
            name='Sharpe Ratio'
        ),
        row=2, col=1
    )
    
    fig.add_hline(y=0, line_dash="dash", line_color=COLORS['text_muted'], row=2, col=1)
    
    fig.update_layout(
        height=600,
        showlegend=False,
        title_text="üìä Rolling Risk Metrics",
        paper_bgcolor=COLORS['background'],
        plot_bgcolor=COLORS['card_background'],
        font=dict(color=COLORS['text_primary'])
    )
    
    return fig

def create_underwater_plot(returns):
    """Underwater drawdown plot"""
    if not is_valid_series(returns) or len(returns) < 2:
        return None
    
    cumulative = (1 + returns).cumprod()
    running_max = cumulative.expanding().max()
    drawdown = ((cumulative - running_max) / running_max) * 100
    
    fig = go.Figure()
    
    fig.add_trace(go.Scatter(
        x=drawdown.index,
        y=drawdown.values,
        fill='tozeroy',
        fillcolor='rgba(255, 0, 68, 0.3)',
        line=dict(color=COLORS['danger'], width=2),
        name='Drawdown'
    ))
    
    fig.add_hline(y=0, line_dash="solid", line_color=COLORS['text_primary'], line_width=1)
    
    max_dd_idx = drawdown.idxmin()
    max_dd_val = drawdown.min()
    
    fig.add_annotation(
        x=max_dd_idx,
        y=max_dd_val,
        text=f"Max DD: {max_dd_val:.2f}%",
        showarrow=True,
        arrowhead=2,
        arrowcolor=COLORS['danger'],
        ax=0,
        ay=-40,
        bgcolor=COLORS['card_background'],
        bordercolor=COLORS['danger'],
        borderwidth=2
    )
    
    fig.update_layout(
        title="üåä Underwater Plot",
        xaxis_title="Date",
        yaxis_title="Drawdown (%)",
        height=500,
        paper_bgcolor=COLORS['background'],
        plot_bgcolor=COLORS['card_background'],
        font=dict(color=COLORS['text_primary'])
    )
    
    return fig

def create_var_waterfall(returns):
    """VaR/CVaR waterfall chart"""
    if not is_valid_series(returns) or len(returns) < 2:
        return None
    
    var_90 = calculate_var(returns, 0.90)
    var_95 = calculate_var(returns, 0.95)
    var_99 = calculate_var(returns, 0.99)
    cvar_95 = calculate_cvar(returns, 0.95)
    
    categories = ['VaR 90%', 'VaR 95%', 'VaR 99%', 'CVaR 95%']
    values = [var_90, var_95, var_99, cvar_95]
    
    colors_list = [COLORS['warning'], COLORS['orange'], COLORS['danger'], COLORS['danger']]
    
    fig = go.Figure()
    
    fig.add_trace(go.Bar(
        x=categories,
        y=values,
        marker=dict(
            color=colors_list,
            line=dict(color=COLORS['border'], width=2)
        ),
        text=[f"{v:.2f}%" for v in values],
        textposition='outside'
    ))
    
    fig.update_layout(
        title="‚ö†Ô∏è Value at Risk Waterfall",
        xaxis_title="Risk Measure",
        yaxis_title="Expected Loss (%)",
        height=500,
        paper_bgcolor=COLORS['background'],
        plot_bgcolor=COLORS['card_background'],
        font=dict(color=COLORS['text_primary'])
    )
    
    return fig

def create_risk_contribution_sunburst(df):
    """Risk contribution sunburst"""
    risk_data = []
    
    for _, row in df.iterrows():
        ticker = row['Ticker']
        weight = row['Weight %']
        sector = row['Sector']
        
        hist_data = fetch_historical_data(ticker, datetime.now() - timedelta(days=365), datetime.now())
        if hist_data is not None and len(hist_data) > 30:
            returns = hist_data['Close'].pct_change().dropna()
            vol = returns.std() * np.sqrt(252) * 100
            risk_contribution = weight * vol
            
            risk_data.append({
                'Ticker': ticker,
                'Sector': sector,
                'Weight': weight,
                'Volatility': vol,
                'Risk Contribution': risk_contribution
            })
    
    if not risk_data:
        return None
    
    risk_df = pd.DataFrame(risk_data)
    
    fig = px.sunburst(
        risk_df,
        path=['Sector', 'Ticker'],
        values='Risk Contribution',
        color='Volatility',
        color_continuous_scale='RdYlGn_r',
        title="‚òÄÔ∏è Risk Contribution Sunburst"
    )
    
    fig.update_layout(
        height=600,
        paper_bgcolor=COLORS['background'],
        font=dict(color=COLORS['text_primary'])
    )
    
    return fig

def create_risk_reward_plot(df):
    """Risk-reward scatter plot"""
    risk_reward_data = []
    
    for _, row in df.iterrows():
        ticker = row['Ticker']
        hist_data = fetch_historical_data(ticker, datetime.now() - timedelta(days=365), datetime.now())
        
        if hist_data is not None and len(hist_data) > 30:
            returns = hist_data['Close'].pct_change().dropna()
            annual_return = ((1 + returns.mean()) ** 252 - 1) * 100
            annual_vol = returns.std() * np.sqrt(252) * 100
            
            risk_reward_data.append({
                'Ticker': ticker,
                'Asset Name': row['Asset Name'],
                'Return': annual_return,
                'Risk': annual_vol,
                'Weight': row['Weight %'],
                'Sector': row['Sector']
            })
    
    if not risk_reward_data:
        return None
    
    rr_df = pd.DataFrame(risk_reward_data)
    
    fig = px.scatter(
        rr_df,
        x='Risk',
        y='Return',
        size='Weight',
        color='Sector',
        text='Ticker',
        hover_data=['Asset Name'],
        color_discrete_sequence=px.colors.qualitative.Set3
    )
    
    fig.update_traces(
        textposition='top center',
        marker=dict(line=dict(width=2, color=COLORS['border']))
    )
    
    fig.update_layout(
        title="üìà Risk-Reward Analysis",
        xaxis_title="Risk (Annual Volatility %)",
        yaxis_title="Expected Return (Annual %)",
        height=500,
        paper_bgcolor=COLORS['background'],
        plot_bgcolor=COLORS['card_background'],
        font=dict(color=COLORS['text_primary'])
    )
    
    return fig

def create_efficient_frontier(df):
    """FIXED BROADCASTING ERROR - Efficient Frontier"""
    returns_data = {}
    expected_returns = []
    volatilities = []
    tickers = []
    
    for _, row in df.iterrows():
        ticker = row['Ticker']
        hist_data = fetch_historical_data(ticker, datetime.now() - timedelta(days=365), datetime.now())
        
        if hist_data is not None and len(hist_data) > 30:
            returns = hist_data['Close'].pct_change().dropna()
            annual_return = ((1 + returns.mean()) ** 252 - 1)
            annual_vol = returns.std() * np.sqrt(252)
            
            expected_returns.append(annual_return)
            volatilities.append(annual_vol)
            tickers.append(ticker)
            returns_data[ticker] = returns
    
    if len(expected_returns) < 2:
        return None
    
    returns_df = pd.DataFrame(returns_data)
    cov_matrix = returns_df.cov() * 252
    
    num_portfolios = 5000
    results = np.zeros((3, num_portfolios))
    
    np.random.seed(42)
    
    for i in range(num_portfolios):
        weights = np.random.random(len(tickers))
        weights /= np.sum(weights)
        
        portfolio_return = np.sum(weights * np.array(expected_returns))
        portfolio_vol = np.sqrt(np.dot(weights.T, np.dot(cov_matrix, weights)))
        sharpe = (portfolio_return - RISK_FREE_RATE) / portfolio_vol if portfolio_vol > 0 else 0
        
        results[0, i] = portfolio_return * 100
        results[1, i] = portfolio_vol * 100
        results[2, i] = sharpe
    
    fig = go.Figure()
    
    fig.add_trace(go.Scatter(
        x=results[1],
        y=results[0],
        mode='markers',
        marker=dict(
            size=5,
            color=results[2],
            colorscale='Viridis',
            showscale=True,
            colorbar=dict(title="Sharpe Ratio")
        ),
        name='Efficient Frontier'
    ))
    
    # FIXED: Properly align weights and returns
    current_weights = df[df['Ticker'].isin(tickers)]['Weight %'].values / 100
    aligned_returns = np.array(expected_returns[:len(current_weights)])
    aligned_cov = cov_matrix.iloc[:len(current_weights), :len(current_weights)]
    
    current_return = np.sum(current_weights * aligned_returns) * 100
    current_vol = np.sqrt(np.dot(current_weights.T, np.dot(aligned_cov, current_weights))) * 100
    
    fig.add_trace(go.Scatter(
        x=[current_vol],
        y=[current_return],
        mode='markers',
        marker=dict(size=20, color=COLORS['danger'], symbol='star'),
        name='Current Portfolio'
    ))
    
    fig.update_layout(
        title="üìä Efficient Frontier",
        xaxis_title="Risk (Volatility %)",
        yaxis_title="Return %",
        height=600,
        paper_bgcolor=COLORS['background'],
        plot_bgcolor=COLORS['card_background'],
        font=dict(color=COLORS['text_primary'])
    )
    
    return fig

def create_risk_parity_analysis(df):
    """Risk parity analysis"""
    risk_contributions = []
    
    for _, row in df.iterrows():
        ticker = row['Ticker']
        weight = row['Weight %'] / 100
        
        hist_data = fetch_historical_data(ticker, datetime.now() - timedelta(days=365), datetime.now())
        if hist_data is not None and len(hist_data) > 30:
            returns = hist_data['Close'].pct_change().dropna()
            vol = returns.std() * np.sqrt(252)
            risk_contribution = weight * vol
            
            risk_contributions.append({
                'Ticker': ticker,
                'Weight %': row['Weight %'],
                'Volatility': vol * 100,
                'Risk Contribution': risk_contribution * 100
            })
    
    if not risk_contributions:
        return None
    
    rc_df = pd.DataFrame(risk_contributions)
    total_risk = rc_df['Risk Contribution'].sum()
    rc_df['Risk %'] = (rc_df['Risk Contribution'] / total_risk) * 100
    
    fig = go.Figure()
    
    fig.add_trace(go.Bar(
        name='Weight %',
        x=rc_df['Ticker'],
        y=rc_df['Weight %'],
        marker_color=COLORS['electric_blue']
    ))
    
    fig.add_trace(go.Bar(
        name='Risk Contribution %',
        x=rc_df['Ticker'],
        y=rc_df['Risk %'],
        marker_color=COLORS['danger']
    ))
    
    fig.update_layout(
        title="‚öñÔ∏è Risk Parity Analysis",
        xaxis_title="Asset",
        yaxis_title="Percentage",
        barmode='group',
        height=500,
        paper_bgcolor=COLORS['background'],
        plot_bgcolor=COLORS['card_background'],
        font=dict(color=COLORS['text_primary'])
    )
    
    return fig

def create_correlation_network(df, start_date, end_date):
    """Correlation network graph"""
    returns_data = {}
    
    for _, row in df.iterrows():
        ticker = row['Ticker']
        hist_data = fetch_historical_data(ticker, start_date, end_date)
        if hist_data is not None and len(hist_data) > 30:
            returns_data[ticker] = hist_data['Close'].pct_change().dropna()
    
    if len(returns_data) < 2:
        return None
    
    returns_df = pd.DataFrame(returns_data)
    corr_matrix = returns_df.corr()
    
    fig = go.Figure()
    
    G = nx.Graph()
    for ticker in corr_matrix.columns:
        G.add_node(ticker)
    
    threshold = 0.5
    for i, ticker1 in enumerate(corr_matrix.columns):
        for j, ticker2 in enumerate(corr_matrix.columns):
            if i < j:
                corr = corr_matrix.iloc[i, j]
                if abs(corr) > threshold:
                    G.add_edge(ticker1, ticker2, weight=abs(corr))
    
    pos = nx.spring_layout(G)
    
    for edge in G.edges():
        x0, y0 = pos[edge[0]]
        x1, y1 = pos[edge[1]]
        weight = G[edge[0]][edge[1]]['weight']
        
        fig.add_trace(go.Scatter(
            x=[x0, x1],
            y=[y0, y1],
            mode='lines',
            line=dict(width=weight*5, color=COLORS['electric_blue']),
            opacity=0.5,
            showlegend=False
        ))
    
    node_x = []
    node_y = []
    node_text = []
    
    for node in G.nodes():
        x, y = pos[node]
        node_x.append(x)
        node_y.append(y)
        node_text.append(node)
    
    fig.add_trace(go.Scatter(
        x=node_x,
        y=node_y,
        mode='markers+text',
        text=node_text,
        textposition='top center',
        marker=dict(
            size=20,
            color=COLORS['neon_blue'],
            line=dict(width=2, color=COLORS['border'])
        ),
        showlegend=False
    ))
    
    fig.update_layout(
        title="üîó Correlation Network",
        showlegend=False,
        height=600,
        paper_bgcolor=COLORS['background'],
        plot_bgcolor=COLORS['card_background'],
        font=dict(color=COLORS['text_primary']),
        xaxis=dict(showgrid=False, zeroline=False, showticklabels=False),
        yaxis=dict(showgrid=False, zeroline=False, showticklabels=False)
    )
    
    return fig

def run_monte_carlo_simulation(returns, initial_value=100000, days=252, simulations=1000):
    """Monte Carlo simulation"""
    if not is_valid_series(returns) or len(returns) < 30:
        return None
    
    daily_return = returns.mean()
    daily_vol = returns.std()
    
    simulation_results = []
    
    for _ in range(simulations):
        prices = [initial_value]
        for _ in range(days):
            price = prices[-1] * (1 + np.random.normal(daily_return, daily_vol))
            prices.append(price)
        simulation_results.append(prices)
    
    return np.array(simulation_results)

def create_monte_carlo_chart(simulation_results, initial_value=100000):
    """Monte Carlo visualization"""
    if simulation_results is None:
        return None, None
    
    fig = go.Figure()
    
    for i in range(min(100, len(simulation_results))):
        fig.add_trace(go.Scatter(
            y=simulation_results[i],
            mode='lines',
            line=dict(width=0.5, color=COLORS['electric_blue']),
            opacity=0.1,
            showlegend=False
        ))
    
    percentiles = [5, 25, 50, 75, 95]
    colors_pct = [COLORS['danger'], COLORS['warning'], COLORS['info'], 
                  COLORS['teal'], COLORS['success']]
    
    for p, color in zip(percentiles, colors_pct):
        values = np.percentile(simulation_results, p, axis=0)
        fig.add_trace(go.Scatter(
            y=values,
            mode='lines',
            line=dict(width=3, color=color),
            name=f'{p}th Percentile'
        ))
    
    fig.update_layout(
        title="üé≤ Monte Carlo Simulation",
        xaxis_title="Trading Days",
        yaxis_title="Portfolio Value ($)",
        height=500,
        paper_bgcolor=COLORS['background'],
        plot_bgcolor=COLORS['card_background'],
        font=dict(color=COLORS['text_primary'])
    )
    
    final_values = simulation_results[:, -1]
    stats = {
        'mean': np.mean(final_values),
        'median': np.median(final_values),
        'percentile_5': np.percentile(final_values, 5),
        'percentile_95': np.percentile(final_values, 95),
        'prob_profit': (final_values > initial_value).mean() * 100,
        'prob_loss_10': (final_values < initial_value * 0.9).mean() * 100,
        'prob_gain_20': (final_values > initial_value * 1.2).mean() * 100
    }
    
    return fig, stats

# ============================================================================
# PORTFOLIO DEEP DIVE VISUALIZATIONS (v8.8)
# ============================================================================

def create_portfolio_heatmap(df):
    """Portfolio treemap"""
    df_viz = df[['Ticker', 'Asset Name', 'Weight %', 'Total Gain/Loss %', 'Sector']].copy()
    df_viz['Sector'] = df_viz['Sector'].fillna('Other')
    df_viz = df_viz.dropna()
    
    if df_viz.empty:
        return None
    
    fig = px.treemap(
        df_viz,
        path=[px.Constant("Portfolio"), 'Sector', 'Ticker'],
        values='Weight %',
        color='Total Gain/Loss %',
        color_continuous_scale='RdYlGn',
        color_continuous_midpoint=0,
        hover_data={'Asset Name': True, 'Total Gain/Loss %': ':.2f'}
    )
    
   # Step 1: Extract data from DataFrame
tickers = top_contributors['Ticker'].tolist()
contributions = top_contributors['Total Gain/Loss üéØ Sensitivity Analysis'].tolist()

# Step 2: Create the figure (example using Plotly)
fig = go.Figure(go.Bar(
    x=tickers,
    y=contributions,
    marker_color='green'
))

# Step 3: Update layout
fig.update_layout(
    title="üéØ Sensitivity Analysis",
    xaxis_title="Discount Rate",
    yaxis_title="Terminal Growth Rate",
    height=400,
    paper_bgcolor=COLORS['background'],
    plot_bgcolor=COLORS['card_background'],
    font=dict(color=COLORS['text_primary'])
)

# Step 4: Return figure
return fig


# ============================================================================
# PHOENIX PARSER
# ============================================================================

def parse_trade_history_file(uploaded_file):
    try:
        df = pd.read_html(uploaded_file)[0]
        required_cols = ['Date', 'Symbol', 'Trade Type', 'Quantity', 'Price']
        if not all(col in df.columns for col in required_cols):
            return None
        df['Price'] = df['Price'].astype(str).str.replace('$', '').str.replace(',', '').astype(float)
        df['Date'] = pd.to_datetime(df['Date'])
        df = df.sort_values('Date')
        return df
    except:
        return None

def parse_account_history_file(uploaded_file):
    try:
        df = pd.read_html(uploaded_file)[0]
        df['Date'] = pd.to_datetime(df['Date'])
        df = df.sort_values('Date')
        return df
    except:
        return None

def calculate_portfolio_from_trades(trade_df):
    holdings = {}
    for _, row in trade_df.iterrows():
        symbol = row['Symbol']
        trade_type = row['Trade Type']
        quantity = row['Quantity']
        price = row['Price']

        if is_option_ticker(symbol):
            continue

        if symbol not in holdings:
            holdings[symbol] = {'total_shares': 0, 'total_cost': 0, 'trades': []}

        is_buy = 'Buy' in trade_type

        if is_buy:
            holdings[symbol]['total_shares'] += quantity
            holdings[symbol]['total_cost'] += (quantity * price)
            holdings[symbol]['trades'].append({'type': 'BUY', 'quantity': quantity, 'price': price})
        else:
            remaining_to_sell = quantity
            for trade in holdings[symbol]['trades']:
                if trade['type'] == 'BUY' and remaining_to_sell > 0:
                    if trade['quantity'] <= remaining_to_sell:
                        holdings[symbol]['total_cost'] -= (trade['quantity'] * trade['price'])
                        holdings[symbol]['total_shares'] -= trade['quantity']
                        remaining_to_sell -= trade['quantity']
                        trade['quantity'] = 0
                    else:
                        holdings[symbol]['total_cost'] -= (remaining_to_sell * trade['price'])
                        holdings[symbol]['total_shares'] -= remaining_to_sell
                        trade['quantity'] -= remaining_to_sell
                        remaining_to_sell = 0

    portfolio_data = []
    for symbol, data in holdings.items():
        if data['total_shares'] > 0:
            avg_cost = data['total_cost'] / data['total_shares']
            portfolio_data.append({
                'Ticker': symbol,
                'Shares': data['total_shares'],
                'Avg Cost': avg_cost
            })

    if not portfolio_data:
        return pd.DataFrame(columns=['Ticker', 'Shares', 'Avg Cost'])
    return pd.DataFrame(portfolio_data).sort_values('Ticker')

# ============================================================================
# ENHANCED HOLDINGS TABLE
# ============================================================================

def create_enhanced_holdings_table(df):
    enhanced_df = df.copy()

    for idx, row in enhanced_df.iterrows():
        ticker = row['Ticker']
        market_data = fetch_market_data(ticker)

        if market_data:
            enhanced_df.at[idx, 'Asset Name'] = market_data['company_name']
            enhanced_df.at[idx, 'Current Price'] = market_data['price']
            enhanced_df.at[idx, 'Daily Change'] = market_data['daily_change']
            enhanced_df.at[idx, 'Daily Change %'] = market_data['daily_change_pct']
            enhanced_df.at[idx, 'Beta'] = market_data.get('beta', 'N/A')
            base_sector = market_data.get('sector', 'Unknown')
            enhanced_df.at[idx, 'Sector'] = classify_ticker_sector(ticker, base_sector)
        else:
            enhanced_df.at[idx, 'Asset Name'] = ticker
            enhanced_df.at[idx, 'Sector'] = 'Other'

    enhanced_df['Sector'] = enhanced_df['Sector'].fillna('Other')
    enhanced_df['Shares'] = enhanced_df['Shares'].round(0).astype(int)

    enhanced_df['Total Cost'] = enhanced_df['Shares'] * enhanced_df['Avg Cost']
    enhanced_df['Total Value'] = enhanced_df['Shares'] * enhanced_df['Current Price']
    enhanced_df['Total Gain/Loss' ] = enhanced_df['Total Value'] - enhanced_df['Total Cost']
    enhanced_df['Total Gain/Loss %'] = ((enhanced_df['Current Price'] - enhanced_df['Avg Cost']) / enhanced_df['Avg Cost']) * 100
    enhanced_df['Daily P&L' ] = enhanced_df['Shares'] * enhanced_df['Daily Change']

    total_value = enhanced_df['Total Value'].sum()
    enhanced_df['Weight %'] = (enhanced_df['Total Value'] / total_value * 100) if total_value > 0 else 0

    return enhanced_df

def style_holdings_dataframe(df):
    display_df = df[[
        'Ticker', 'Asset Name', 'Shares', 'Avg Cost', 'Current Price',
        'Daily Change %', 'Weight %', 'Daily P&L' 
        'Total Gain/Loss' , 'Total Gain/Loss %', 'Beta'
    ]].copy()

    pct_cols = ['Daily Change %', 'Weight %', 'Total Gain/Loss %']
    for col in pct_cols:
        display_df[col] = display_df[col].apply(lambda x: format_percentage(x))

    currency_cols = ['Avg Cost', 'Current Price', 'Daily P&L' , 'Total Gain/Loss' ]
    for col in currency_cols:
        display_df[col] = display_df[col].apply(format_currency)

    display_df['Daily Change %'] = display_df['Daily Change %'].apply(add_arrow_indicator)
    display_df['Total Gain/Loss %'] = display_df['Total Gain/Loss %'].apply(add_arrow_indicator)

    return display_df

# ============================================================================
# RISK METRICS (v8.8 COMPLETE)
# ============================================================================

def calculate_sharpe_ratio(returns, risk_free_rate=RISK_FREE_RATE):
    if not is_valid_series(returns) or len(returns) < 2:
        return None
    total_return = (1 + returns).prod() - 1
    n_years = len(returns) / 252
    annualized_return = (1 + total_return) ** (1/n_years) - 1 if n_years > 0 else 0
    annualized_vol = returns.std() * np.sqrt(252)
    sharpe = (annualized_return - risk_free_rate) / annualized_vol if annualized_vol > 0 else 0
    return sharpe

def calculate_sortino_ratio(returns, risk_free_rate=RISK_FREE_RATE):
    if not is_valid_series(returns) or len(returns) < 2:
        return None
    total_return = (1 + returns).prod() - 1
    n_years = len(returns) / 252
    annualized_return = (1 + total_return) ** (1/n_years) - 1 if n_years > 0 else 0
    downside_returns = returns[returns < 0]
    if len(downside_returns) < 2:
        return None
    downside_std = downside_returns.std() * np.sqrt(252)
    sortino = (annualized_return - risk_free_rate) / downside_std if downside_std > 0 else 0
    return sortino

def calculate_calmar_ratio(returns, risk_free_rate=RISK_FREE_RATE):
    if not is_valid_series(returns) or len(returns) < 2:
        return None
    total_return = (1 + returns).prod() - 1
    n_years = len(returns) / 252
    annualized_return = (1 + total_return) ** (1/n_years) - 1 if n_years > 0 else 0
    max_dd = abs(calculate_max_drawdown(returns))
    if max_dd == 0:
        return 0
    return (annualized_return - risk_free_rate) / (max_dd / 100)

def calculate_information_ratio(portfolio_returns, benchmark_returns):
    if not is_valid_series(portfolio_returns) or not is_valid_series(benchmark_returns):
        return None
    if len(portfolio_returns) < 2 or len(benchmark_returns) < 2:
        return None
    common_dates = portfolio_returns.index.intersection(benchmark_returns.index)
    portfolio_returns = portfolio_returns.loc[common_dates]
    benchmark_returns = benchmark_returns.loc[common_dates]
    excess_returns = portfolio_returns - benchmark_returns
    if len(excess_returns) < 2:
        return None
    total_excess = (1 + excess_returns).prod() - 1
    n_years = len(excess_returns) / 252
    annualized_excess = (1 + total_excess) ** (1/n_years) - 1 if n_years > 0 else 0
    tracking_error = excess_returns.std() * np.sqrt(252)
    info_ratio = annualized_excess / tracking_error if tracking_error > 0 else 0
    return info_ratio

def calculate_var(returns, confidence=0.95):
    if not is_valid_series(returns) or len(returns) < 2:
        return None
    var = np.percentile(returns, (1 - confidence) * 100)
    return var * 100

def calculate_cvar(returns, confidence=0.95):
    if not is_valid_series(returns) or len(returns) < 2:
        return None
    var = np.percentile(returns, (1 - confidence) * 100)
    cvar = returns[returns <= var].mean()
    return cvar * 100

def calculate_max_drawdown(returns):
    if not is_valid_series(returns) or len(returns) < 2:
        return None
    cumulative = (1 + returns).cumprod()
    running_max = cumulative.expanding().max()
    drawdown = (cumulative - running_max) / running_max
    return drawdown.min() * 100

@st.cache_data(ttl=600)
def calculate_portfolio_returns(df, start_date, end_date):
    try:
        valid_positions = []
        for _, row in df.iterrows():
            if not is_option_ticker(row['Ticker']):
                valid_positions.append(row)
        
        if not valid_positions:
            return None
        
        valid_df = pd.DataFrame(valid_positions)
        all_data = {}
        
        for _, row in valid_df.iterrows():
            ticker = row['Ticker']
            data = fetch_historical_data(ticker, start_date, end_date)
            if data is not None and len(data) > 0:
                all_data[ticker] = data
        
        if not all_data:
            return None
        
        common_dates = None
        for ticker, data in all_data.items():
            dates = set(data.index)
            common_dates = dates if common_dates is None else common_dates.intersection(dates)
        
        common_dates = sorted(list(common_dates))
        if len(common_dates) < 2:
            return None
        
        portfolio_values = []
        for date in common_dates:
            daily_value = 0
            for _, row in valid_df.iterrows():
                ticker = row['Ticker']
                if ticker in all_data:
                    try:
                        price = all_data[ticker].loc[date, 'Close']
                        daily_value += price * row['Shares']
                    except KeyError:
                        continue
            portfolio_values.append(daily_value)
        
        portfolio_series = pd.Series(portfolio_values, index=common_dates)
        returns = portfolio_series.pct_change().dropna()
        return returns
    except:
        return None

@st.cache_data(ttl=600)
def calculate_benchmark_returns(benchmark_ticker, start_date, end_date):
    try:
        data = fetch_historical_data(benchmark_ticker, start_date, end_date)
        if data is None or data.empty:
            return None
        returns = data['Close'].pct_change().dropna()
        return returns
    except:
        return None

# ============================================================================
# WORLD-CLASS VISUALIZATIONS (v8.8 COMPLETE)
# ============================================================================

def create_rolling_metrics_chart(returns, window=60):
    """Rolling metrics visualization"""
    if not is_valid_series(returns) or len(returns) < window:
        return None
    
    rolling_vol = returns.rolling(window).std() * np.sqrt(252) * 100
    rolling_sharpe = (returns.rolling(window).mean() * 252 - RISK_FREE_RATE) / (returns.rolling(window).std() * np.sqrt(252))
    
    fig = make_subplots(
        rows=2, cols=1,
        subplot_titles=('Rolling Volatility (60-Day)', 'Rolling Sharpe Ratio (60-Day)'),
        vertical_spacing=0.15
    )
    
    fig.add_trace(
        go.Scatter(
            x=rolling_vol.index,
            y=rolling_vol.values,
            fill='tozeroy',
            fillcolor='rgba(255, 0, 68, 0.2)',
            line=dict(color=COLORS['danger'], width=2),
            name='Volatility'
        ),
        row=1, col=1
    )
    
    fig.add_trace(
        go.Scatter(
            x=rolling_sharpe.index,
            y=rolling_sharpe.values,
            fill='tozeroy',
            fillcolor='rgba(0, 212, 255, 0.2)',
            line=dict(color=COLORS['neon_blue'], width=2),
            name='Sharpe Ratio'
        ),
        row=2, col=1
    )
    
    fig.add_hline(y=0, line_dash="dash", line_color=COLORS['text_muted'], row=2, col=1)
    
    fig.update_layout(
        height=600,
        showlegend=False,
        title_text="üìä Rolling Risk Metrics",
        paper_bgcolor=COLORS['background'],
        plot_bgcolor=COLORS['card_background'],
        font=dict(color=COLORS['text_primary'])
    )
    
    return fig

def create_underwater_plot(returns):
    """Underwater drawdown plot"""
    if not is_valid_series(returns) or len(returns) < 2:
        return None
    
    cumulative = (1 + returns).cumprod()
    running_max = cumulative.expanding().max()
    drawdown = ((cumulative - running_max) / running_max) * 100
    
    fig = go.Figure()
    
    fig.add_trace(go.Scatter(
        x=drawdown.index,
        y=drawdown.values,
        fill='tozeroy',
        fillcolor='rgba(255, 0, 68, 0.3)',
        line=dict(color=COLORS['danger'], width=2),
        name='Drawdown'
    ))
    
    fig.add_hline(y=0, line_dash="solid", line_color=COLORS['text_primary'], line_width=1)
    
    max_dd_idx = drawdown.idxmin()
    max_dd_val = drawdown.min()
    
    fig.add_annotation(
        x=max_dd_idx,
        y=max_dd_val,
        text=f"Max DD: {max_dd_val:.2f}%",
        showarrow=True,
        arrowhead=2,
        arrowcolor=COLORS['danger'],
        ax=0,
        ay=-40,
        bgcolor=COLORS['card_background'],
        bordercolor=COLORS['danger'],
        borderwidth=2
    )
    
    fig.update_layout(
        title="üåä Underwater Plot",
        xaxis_title="Date",
        yaxis_title="Drawdown (%)",
        height=500,
        paper_bgcolor=COLORS['background'],
        plot_bgcolor=COLORS['card_background'],
        font=dict(color=COLORS['text_primary'])
    )
    
    return fig

def create_var_waterfall(returns):
    """VaR/CVaR waterfall chart"""
    if not is_valid_series(returns) or len(returns) < 2:
        return None
    
    var_90 = calculate_var(returns, 0.90)
    var_95 = calculate_var(returns, 0.95)
    var_99 = calculate_var(returns, 0.99)
    cvar_95 = calculate_cvar(returns, 0.95)
    
    categories = ['VaR 90%', 'VaR 95%', 'VaR 99%', 'CVaR 95%']
    values = [var_90, var_95, var_99, cvar_95]
    
    colors_list = [COLORS['warning'], COLORS['orange'], COLORS['danger'], COLORS['danger']]
    
    fig = go.Figure()
    
    fig.add_trace(go.Bar(
        x=categories,
        y=values,
        marker=dict(
            color=colors_list,
            line=dict(color=COLORS['border'], width=2)
        ),
        text=[f"{v:.2f}%" for v in values],
        textposition='outside'
    ))
    
    fig.update_layout(
        title="‚ö†Ô∏è Value at Risk Waterfall",
        xaxis_title="Risk Measure",
        yaxis_title="Expected Loss (%)",
        height=500,
        paper_bgcolor=COLORS['background'],
        plot_bgcolor=COLORS['card_background'],
        font=dict(color=COLORS['text_primary'])
    )
    
    return fig

def create_risk_contribution_sunburst(df):
    """Risk contribution sunburst"""
    risk_data = []
    
    for _, row in df.iterrows():
        ticker = row['Ticker']
        weight = row['Weight %']
        sector = row['Sector']
        
        hist_data = fetch_historical_data(ticker, datetime.now() - timedelta(days=365), datetime.now())
        if hist_data is not None and len(hist_data) > 30:
            returns = hist_data['Close'].pct_change().dropna()
            vol = returns.std() * np.sqrt(252) * 100
            risk_contribution = weight * vol
            
            risk_data.append({
                'Ticker': ticker,
                'Sector': sector,
                'Weight': weight,
                'Volatility': vol,
                'Risk Contribution': risk_contribution
            })
    
    if not risk_data:
        return None
    
    risk_df = pd.DataFrame(risk_data)
    
    fig = px.sunburst(
        risk_df,
        path=['Sector', 'Ticker'],
        values='Risk Contribution',
        color='Volatility',
        color_continuous_scale='RdYlGn_r',
        title="‚òÄÔ∏è Risk Contribution Sunburst"
    )
    
    fig.update_layout(
        height=600,
        paper_bgcolor=COLORS['background'],
        font=dict(color=COLORS['text_primary'])
    )
    
    return fig

def create_risk_reward_plot(df):
    """Risk-reward scatter plot"""
    risk_reward_data = []
    
    for _, row in df.iterrows():
        ticker = row['Ticker']
        hist_data = fetch_historical_data(ticker, datetime.now() - timedelta(days=365), datetime.now())
        
        if hist_data is not None and len(hist_data) > 30:
            returns = hist_data['Close'].pct_change().dropna()
            annual_return = ((1 + returns.mean()) ** 252 - 1) * 100
            annual_vol = returns.std() * np.sqrt(252) * 100
            
            risk_reward_data.append({
                'Ticker': ticker,
                'Asset Name': row['Asset Name'],
                'Return': annual_return,
                'Risk': annual_vol,
                'Weight': row['Weight %'],
                'Sector': row['Sector']
            })
    
    if not risk_reward_data:
        return None
    
    rr_df = pd.DataFrame(risk_reward_data)
    
    fig = px.scatter(
        rr_df,
        x='Risk',
        y='Return',
        size='Weight',
        color='Sector',
        text='Ticker',
        hover_data=['Asset Name'],
        color_discrete_sequence=px.colors.qualitative.Set3
    )
    
    fig.update_traces(
        textposition='top center',
        marker=dict(line=dict(width=2, color=COLORS['border']))
    )
    
    fig.update_layout(
        title="üìà Risk-Reward Analysis",
        xaxis_title="Risk (Annual Volatility %)",
        yaxis_title="Expected Return (Annual %)",
        height=500,
        paper_bgcolor=COLORS['background'],
        plot_bgcolor=COLORS['card_background'],
        font=dict(color=COLORS['text_primary'])
    )
    
    return fig

def create_efficient_frontier(df):
    """FIXED BROADCASTING ERROR - Efficient Frontier"""
    returns_data = {}
    expected_returns = []
    volatilities = []
    tickers = []
    
    for _, row in df.iterrows():
        ticker = row['Ticker']
        hist_data = fetch_historical_data(ticker, datetime.now() - timedelta(days=365), datetime.now())
        
        if hist_data is not None and len(hist_data) > 30:
            returns = hist_data['Close'].pct_change().dropna()
            annual_return = ((1 + returns.mean()) ** 252 - 1)
            annual_vol = returns.std() * np.sqrt(252)
            
            expected_returns.append(annual_return)
            volatilities.append(annual_vol)
            tickers.append(ticker)
            returns_data[ticker] = returns
    
    if len(expected_returns) < 2:
        return None
    
    returns_df = pd.DataFrame(returns_data)
    cov_matrix = returns_df.cov() * 252
    
    num_portfolios = 5000
    results = np.zeros((3, num_portfolios))
    
    np.random.seed(42)
    
    for i in range(num_portfolios):
        weights = np.random.random(len(tickers))
        weights /= np.sum(weights)
        
        portfolio_return = np.sum(weights * np.array(expected_returns))
        portfolio_vol = np.sqrt(np.dot(weights.T, np.dot(cov_matrix, weights)))
        sharpe = (portfolio_return - RISK_FREE_RATE) / portfolio_vol if portfolio_vol > 0 else 0
        
        results[0, i] = portfolio_return * 100
        results[1, i] = portfolio_vol * 100
        results[2, i] = sharpe
    
    fig = go.Figure()
    
    fig.add_trace(go.Scatter(
        x=results[1],
        y=results[0],
        mode='markers',
        marker=dict(
            size=5,
            color=results[2],
            colorscale='Viridis',
            showscale=True,
            colorbar=dict(title="Sharpe Ratio")
        ),
        name='Efficient Frontier'
    ))
    
    # FIXED: Properly align weights and returns
    current_weights = df[df['Ticker'].isin(tickers)]['Weight %'].values / 100
    aligned_returns = np.array(expected_returns[:len(current_weights)])
    aligned_cov = cov_matrix.iloc[:len(current_weights), :len(current_weights)]
    
    current_return = np.sum(current_weights * aligned_returns) * 100
    current_vol = np.sqrt(np.dot(current_weights.T, np.dot(aligned_cov, current_weights))) * 100
    
    fig.add_trace(go.Scatter(
        x=[current_vol],
        y=[current_return],
        mode='markers',
        marker=dict(size=20, color=COLORS['danger'], symbol='star'),
        name='Current Portfolio'
    ))
    
    fig.update_layout(
        title="üìä Efficient Frontier",
        xaxis_title="Risk (Volatility %)",
        yaxis_title="Return %",
        height=600,
        paper_bgcolor=COLORS['background'],
        plot_bgcolor=COLORS['card_background'],
        font=dict(color=COLORS['text_primary'])
    )
    
    return fig

def create_risk_parity_analysis(df):
    """Risk parity analysis"""
    risk_contributions = []
    
    for _, row in df.iterrows():
        ticker = row['Ticker']
        weight = row['Weight %'] / 100
        
        hist_data = fetch_historical_data(ticker, datetime.now() - timedelta(days=365), datetime.now())
        if hist_data is not None and len(hist_data) > 30:
            returns = hist_data['Close'].pct_change().dropna()
            vol = returns.std() * np.sqrt(252)
            risk_contribution = weight * vol
            
            risk_contributions.append({
                'Ticker': ticker,
                'Weight %': row['Weight %'],
                'Volatility': vol * 100,
                'Risk Contribution': risk_contribution * 100
            })
    
    if not risk_contributions:
        return None
    
    rc_df = pd.DataFrame(risk_contributions)
    total_risk = rc_df['Risk Contribution'].sum()
    rc_df['Risk %'] = (rc_df['Risk Contribution'] / total_risk) * 100
    
    fig = go.Figure()
    
    fig.add_trace(go.Bar(
        name='Weight %',
        x=rc_df['Ticker'],
        y=rc_df['Weight %'],
        marker_color=COLORS['electric_blue']
    ))
    
    fig.add_trace(go.Bar(
        name='Risk Contribution %',
        x=rc_df['Ticker'],
        y=rc_df['Risk %'],
        marker_color=COLORS['danger']
    ))
    
    fig.update_layout(
        title="‚öñÔ∏è Risk Parity Analysis",
        xaxis_title="Asset",
        yaxis_title="Percentage",
        barmode='group',
        height=500,
        paper_bgcolor=COLORS['background'],
        plot_bgcolor=COLORS['card_background'],
        font=dict(color=COLORS['text_primary'])
    )
    
    return fig

def create_correlation_network(df, start_date, end_date):
    """Correlation network graph"""
    returns_data = {}
    
    for _, row in df.iterrows():
        ticker = row['Ticker']
        hist_data = fetch_historical_data(ticker, start_date, end_date)
        if hist_data is not None and len(hist_data) > 30:
            returns_data[ticker] = hist_data['Close'].pct_change().dropna()
    
    if len(returns_data) < 2:
        return None
    
    returns_df = pd.DataFrame(returns_data)
    corr_matrix = returns_df.corr()
    
    fig = go.Figure()
    
    G = nx.Graph()
    for ticker in corr_matrix.columns:
        G.add_node(ticker)
    
    threshold = 0.5
    for i, ticker1 in enumerate(corr_matrix.columns):
        for j, ticker2 in enumerate(corr_matrix.columns):
            if i < j:
                corr = corr_matrix.iloc[i, j]
                if abs(corr) > threshold:
                    G.add_edge(ticker1, ticker2, weight=abs(corr))
    
    pos = nx.spring_layout(G)
    
    for edge in G.edges():
        x0, y0 = pos[edge[0]]
        x1, y1 = pos[edge[1]]
        weight = G[edge[0]][edge[1]]['weight']
        
        fig.add_trace(go.Scatter(
            x=[x0, x1],
            y=[y0, y1],
            mode='lines',
            line=dict(width=weight*5, color=COLORS['electric_blue']),
            opacity=0.5,
            showlegend=False
        ))
    
    node_x = []
    node_y = []
    node_text = []
    
    for node in G.nodes():
        x, y = pos[node]
        node_x.append(x)
        node_y.append(y)
        node_text.append(node)
    
    fig.add_trace(go.Scatter(
        x=node_x,
        y=node_y,
        mode='markers+text',
        text=node_text,
        textposition='top center',
        marker=dict(
            size=20,
            color=COLORS['neon_blue'],
            line=dict(width=2, color=COLORS['border'])
        ),
        showlegend=False
    ))
    
    fig.update_layout(
        title="üîó Correlation Network",
        showlegend=False,
        height=600,
        paper_bgcolor=COLORS['background'],
        plot_bgcolor=COLORS['card_background'],
        font=dict(color=COLORS['text_primary']),
        xaxis=dict(showgrid=False, zeroline=False, showticklabels=False),
        yaxis=dict(showgrid=False, zeroline=False, showticklabels=False)
    )
    
    return fig

def run_monte_carlo_simulation(returns, initial_value=100000, days=252, simulations=1000):
    """Monte Carlo simulation"""
    if not is_valid_series(returns) or len(returns) < 30:
        return None
    
    daily_return = returns.mean()
    daily_vol = returns.std()
    
    simulation_results = []
    
    for _ in range(simulations):
        prices = [initial_value]
        for _ in range(days):
            price = prices[-1] * (1 + np.random.normal(daily_return, daily_vol))
            prices.append(price)
        simulation_results.append(prices)
    
    return np.array(simulation_results)

def create_monte_carlo_chart(simulation_results, initial_value=100000):
    """Monte Carlo visualization"""
    if simulation_results is None:
        return None, None
    
    fig = go.Figure()
    
    for i in range(min(100, len(simulation_results))):
        fig.add_trace(go.Scatter(
            y=simulation_results[i],
            mode='lines',
            line=dict(width=0.5, color=COLORS['electric_blue']),
            opacity=0.1,
            showlegend=False
        ))
    
    percentiles = [5, 25, 50, 75, 95]
    colors_pct = [COLORS['danger'], COLORS['warning'], COLORS['info'], 
                  COLORS['teal'], COLORS['success']]
    
    for p, color in zip(percentiles, colors_pct):
        values = np.percentile(simulation_results, p, axis=0)
        fig.add_trace(go.Scatter(
            y=values,
            mode='lines',
            line=dict(width=3, color=color),
            name=f'{p}th Percentile'
        ))
    
    def run_monte_carlo(df):
    fig = go.Figure()

    # Add traces here...
    
    fig.update_layout(
        title="üé≤ Monte Carlo Simulation",
        xaxis_title="Trading Days",
        yaxis_title="Portfolio Value ($)",
        height=500,
        paper_bgcolor=COLORS['background'],
        plot_bgcolor=COLORS['card_background'],
        font=dict(color=COLORS['text_primary'])
    )

    return fig

    
    final_values = simulation_results[:, -1]
    stats = {
        'mean': np.mean(final_values),
        'median': np.median(final_values),
        'percentile_5': np.percentile(final_values, 5),
        'percentile_95': np.percentile(final_values, 95),
        'prob_profit': (final_values > initial_value).mean() * 100,
        'prob_loss_10': (final_values < initial_value * 0.9).mean() * 100,
        'prob_gain_20': (final_values > initial_value * 1.2).mean() * 100
    }
    
    return fig, stats

# ============================================================================
# PORTFOLIO DEEP DIVE VISUALIZATIONS (v8.8)
# ============================================================================

def create_portfolio_heatmap(df):
    """Portfolio treemap"""
    df_viz = df[['Ticker', 'Asset Name', 'Weight %', 'Total Gain/Loss %', 'Sector']].copy()
    df_viz['Sector'] = df_viz['Sector'].fillna('Other')
    df_viz = df_viz.dropna()
    
    if df_viz.empty:
        return None
    
   # Create a treemap figure
fig = px.treemap(
    df_viz,
    path=[px.Constant("Portfolio"), 'Sector', 'Ticker'],
    values='Weight %',
    color='Total Gain/Loss %',
    color_continuous_scale='RdYlGn',
    color_continuous_midpoint=0,
    hover_data={'Asset Name': True, 'Total Gain/Loss %': ':.2f'}
)

# Optional: update layout if needed
fig.update_layout(
    title="Portfolio Treemap",
    paper_bgcolor=COLORS['background'],
    plot_bgcolor=COLORS['card_background'],
    font=dict(color=COLORS['text_primary'])
)

# Extract data for waterfall
tickers = top_contributors['Ticker'].tolist()
contributions = top_contributors['Total Gain/Loss üéØ Sensitivity Analysis'].tolist()

# Create a waterfall figure
fig_waterfall = go.Figure()

fig_waterfall.add_trace(go.Waterfall(
    name="Attribution",
    orientation="v",
    x=tickers,
    y=contributions,
    connector={"line": {"color": COLORS['neon_blue']}},
    decreasing={"marker": {"color": COLORS['danger']}},
    increasing={"marker": {"color": COLORS['success']}},
    totals={"marker": {"color": COLORS['electric_blue']}}
))

    
    fig.update_layout(
        title="üíß Holdings Attribution Waterfall",
        xaxis_title="Ticker",
        yaxis_title="Contribution ($)",
        height=500,
        paper_bgcolor=COLORS['background'],
        plot_bgcolor=COLORS['card_background'],
        font=dict(color=COLORS['text_primary'])
    )
    
    return fig

def create_concentration_gauge(df):
    """Concentration gauge"""
    top_5_weight = df.nlargest(5, 'Weight %')['Weight %'].sum()
    
    fig = go.Figure(go.Indicator(
        mode="gauge+number+delta",
        value=top_5_weight,
        title={'text': "Top 5 Concentration"},
        delta={'reference': 50, 'increasing': {'color': COLORS['warning']}},
        gauge={
            'axis': {'range': [None, 100]},
            'bar': {'color': COLORS['neon_blue']},
            'steps': [
                {'range': [0, 30], 'color': COLORS['success']},
                {'range': [30, 50], 'color': COLORS['warning']},
                {'range': [50, 100], 'color': COLORS['danger']}
            ],
            'threshold': {
                'line': {'color': "red", 'width': 4},
                'thickness': 0.75,
                'value': 70
            }
        }
    ))
    
    fig.update_layout(
        height=400,
        paper_bgcolor=COLORS['background'],
        font=dict(color=COLORS['text_primary'])
    )
    
    return fig

# ============================================================================
# MULTI-FACTOR ANALYSIS (v8.8)
# ============================================================================

@st.cache_data(ttl=3600)
def calculate_factor_exposures(df, start_date, end_date):
    """Calculate factor exposures using regression"""
    try:
        portfolio_returns = calculate_portfolio_returns(df, start_date, end_date)
        if not is_valid_series(portfolio_returns):
            return None
        
        factor_returns = {}
        for factor_name, factor_info in FACTOR_DEFINITIONS.items():
            benchmark = factor_info['benchmark']
            returns = calculate_benchmark_returns(benchmark, start_date, end_date)
            if is_valid_series(returns):
                factor_returns[factor_name] = returns
        
        if not factor_returns:
            return None
        
        common_dates = portfolio_returns.index
        for factor_name in factor_returns:
            common_dates = common_dates.intersection(factor_returns[factor_name].index)
        
        X = pd.DataFrame({name: returns.loc[common_dates] for name, returns in factor_returns.items()})
        y = portfolio_returns.loc[common_dates]
        
        X['Alpha'] = 1
        
        model = LinearRegression()
        model.fit(X, y)
        
        exposures = pd.Series(model.coef_, index=X.columns)
        r_squared = model.score(X, y)
        predicted_returns = model.predict(X)
        
        asset_exposures = {}
        for _, row in df.iterrows():
            ticker = row['Ticker']
            ticker_returns = calculate_benchmark_returns(ticker, start_date, end_date)
            if is_valid_series(ticker_returns):
                ticker_aligned = ticker_returns.loc[common_dates]
                
                asset_model = LinearRegression()
                asset_model.fit(X, ticker_aligned)
                
                asset_exposures[ticker] = pd.Series(asset_model.coef_, index=X.columns)
        
        return {
            'exposures': exposures,
            'r_squared': r_squared,
            'factor_returns': X,
            'portfolio_returns': y,
            'predicted_returns': predicted_returns,
            'asset_exposures': asset_exposures
        }
    except:
        return None

def create_factor_momentum_chart(factor_data):
    """Factor momentum chart"""
    if factor_data is None or 'factor_returns' not in factor_data:
        return None
    
    factor_returns = factor_data['factor_returns']
    
    fig = go.Figure()
    
    colors = [COLORS['neon_blue'], COLORS['electric_blue'], COLORS['teal'], 
              COLORS['success'], COLORS['purple'], COLORS['pink']]
    
    for idx, factor in enumerate(FACTOR_DEFINITIONS.keys()):
        if factor in factor_returns.columns:
            cumulative = (1 + factor_returns[factor]).cumprod() - 1
            fig.add_trace(go.Scatter(
                x=cumulative.index,
                y=cumulative.values * 100,
                mode='lines',
                name=factor,
                line=dict(width=2, color=colors[idx % len(colors)])
            ))
    
    fig.update_layout(
        title="üìà Factor Momentum",
        xaxis_title="Date",
        yaxis_title="Cumulative Return (%)",
        height=600,
        hovermode='x unified',
        legend=dict(x=0.02, y=0.98),
        paper_bgcolor=COLORS['background'],
        plot_bgcolor=COLORS['card_background'],
        font=dict(color=COLORS['text_primary'])
    )
    
    return fig

def create_factor_exposure_radar(exposures):
    """Factor exposure radar"""
    if exposures is None or 'exposures' not in exposures:
        return None
    
    exp = exposures['exposures']
    factors = [f for f in FACTOR_DEFINITIONS.keys() if f in exp.index]
    values = [exp[f] for f in factors]
    
    max_abs = max([abs(v) for v in values])
    normalized = [(v / max_abs) * 100 if max_abs > 0 else 0 for v in values]
    
    fig = go.Figure()
    
    fig.add_trace(go.Scatterpolar(
        r=normalized,
        theta=factors,
        fill='toself',
        fillcolor='rgba(0, 212, 255, 0.2)',
        line=dict(color=COLORS['neon_blue'], width=2),
        name='Factor Exposure'
    ))
    
    fig.update_layout(
        polar=dict(
            radialaxis=dict(
                visible=True,
                range=[0, 100],
                color=COLORS['text_secondary']
            ),
            bgcolor=COLORS['card_background']
        ),
        title="üéØ Factor Exposure Radar",
        height=550,
        paper_bgcolor=COLORS['background'],
        font=dict(color=COLORS['text_primary'])
    )
    
    return fig

def create_factor_attribution_table(exposures, df):
    """Factor attribution table"""
    if exposures is None or 'asset_exposures' not in exposures:
        return None, None, None
    
    attribution_data = []
    
    for ticker, asset_exp in exposures['asset_exposures'].items():
        asset_row = df[df['Ticker'] == ticker]
        if asset_row.empty:
            continue
        
        weight = asset_row['Weight %'].values[0] / 100
        sector = asset_row['Sector'].values[0]
        
        for factor in FACTOR_DEFINITIONS.keys():
            if factor in asset_exp:
                contribution = weight * asset_exp[factor]
                attribution_data.append({
                    'Ticker': ticker,
                    'Sector': sector,
                    'Factor': factor,
                    'Weight': weight * 100,
                    'Factor Beta': asset_exp[factor],
                    'Contribution': contribution
                })
    
    if not attribution_data:
        return None, None, None
    
    attr_df = pd.DataFrame(attribution_data)
    
    factor_summary = attr_df.groupby('Factor').agg({
        'Contribution': 'sum'
    }).reset_index()
    factor_summary.columns = ['Factor', 'Total Contribution']
    
    sector_summary = attr_df.groupby(['Sector', 'Factor']).agg({
        'Contribution': 'sum'
    }).reset_index()
    
    return attr_df, factor_summary, sector_summary

# ============================================================================
# PERFORMANCE METRICS (v8.8)
# ============================================================================

def calculate_performance_metrics(df, portfolio_returns, benchmark_returns):
    """Calculate comprehensive performance metrics"""
    if not is_valid_series(portfolio_returns):
        return None
    
    total_return = (1 + portfolio_returns).prod() - 1
    n_years = len(portfolio_returns) / 252
    annualized_return = (1 + total_return) ** (1/n_years) - 1 if n_years > 0 else 0
    annualized_vol = portfolio_returns.std() * np.sqrt(252)
    
    sharpe = calculate_sharpe_ratio(portfolio_returns)
    sortino = calculate_sortino_ratio(portfolio_returns)
    calmar = calculate_calmar_ratio(portfolio_returns)
    
    info_ratio = calculate_information_ratio(portfolio_returns, benchmark_returns)
    
    var_95 = calculate_var(portfolio_returns, 0.95)
    cvar_95 = calculate_cvar(portfolio_returns, 0.95)
    max_dd = calculate_max_drawdown(portfolio_returns)
    
    winning_days = (portfolio_returns > 0).sum()
    losing_days = (portfolio_returns < 0).sum()
    win_rate = winning_days / (winning_days + losing_days) * 100 if (winning_days + losing_days) > 0 else 0
    
    avg_win = portfolio_returns[portfolio_returns > 0].mean() * 100 if winning_days > 0 else 0
    avg_loss = portfolio_returns[portfolio_returns < 0].mean() * 100 if losing_days > 0 else 0
    
    best_day = portfolio_returns.max() * 100
    worst_day = portfolio_returns.min() * 100
    
    return {
        'Total Return': total_return * 100,
        'Annualized Return': annualized_return * 100,
        'Annualized Volatility': annualized_vol * 100,
        'Sharpe Ratio': sharpe,
        'Sortino Ratio': sortino,
        'Calmar Ratio': calmar,
        'Information Ratio': info_ratio,
        'VaR (95%)': var_95,
        'CVaR (95%)': cvar_95,
        'Max Drawdown': max_dd,
        'Win Rate': win_rate,
        'Avg Win': avg_win,
        'Avg Loss': avg_loss,
        'Best Day': best_day,
        'Worst Day': worst_day,
        'Winning Days': winning_days,
        'Losing Days': losing_days
    }

def create_performance_dashboard(metrics):
    """Performance dashboard with 4 charts"""
    fig = make_subplots(
        rows=2, cols=2,
        subplot_titles=('Returns Distribution', 'Risk Metrics', 
                       'Win/Loss Analysis', 'Risk-Adjusted Returns'),
        specs=[[{'type': 'bar'}, {'type': 'scatter'}],
               [{'type': 'pie'}, {'type': 'bar'}]]
    )
    
    fig.add_trace(
        go.Bar(x=['Total', 'Annualized'], 
               y=[metrics['Total Return'], metrics['Annualized Return']],
               marker_color=[COLORS['success'], COLORS['electric_blue']]),
        row=1, col=1
    )
    
    fig.add_trace(
        go.Scatter(x=['Volatility', 'VaR', 'CVaR', 'Max DD'],
                  y=[metrics['Annualized Volatility'], abs(metrics['VaR (95%)']), 
                     abs(metrics['CVaR (95%)']), abs(metrics['Max Drawdown'])],
                  mode='markers+lines',
                  marker=dict(size=15, color=COLORS['danger'])),
        row=1, col=2
    )
    
    fig.add_trace(
        go.Pie(labels=['Winning Days', 'Losing Days'],
               values=[metrics['Winning Days'], metrics['Losing Days']],
               marker=dict(colors=[COLORS['success'], COLORS['danger']])),
        row=2, col=1
    )
    
    fig.add_trace(
        go.Bar(x=['Sharpe', 'Sortino', 'Calmar', 'Info'],
               y=[metrics['Sharpe Ratio'], metrics['Sortino Ratio'], 
                  metrics['Calmar Ratio'], metrics['Information Ratio']],
               marker_color=COLORS['purple']),
        row=2, col=2
    )
    
    fig.update_layout(
        height=700,
        showlegend=False,
        title_text="üìä Performance Dashboard",
        paper_bgcolor=COLORS['background'],
        plot_bgcolor=COLORS['card_background'],
        font=dict(color=COLORS['text_primary'])
    )
    
    return fig

# ============================================================================
# INTERACTIVE CHARTS
# ============================================================================

@st.cache_data(ttl=600)
def fetch_ticker_performance(ticker, start_date, end_date):
    try:
        data = fetch_historical_data(ticker, start_date, end_date)
        if data is not None and not data.empty:
            returns = data['Close'].pct_change().fillna(0)
            cumulative = (1 + returns).cumprod() - 1
            return cumulative * 100, data
        return None, None
    except:
        return None, None

def create_interactive_performance_chart(tickers, start_date, end_date):
    """Interactive performance chart"""
    fig = go.Figure()
    
    colors = [COLORS['neon_blue'], COLORS['electric_blue'], COLORS['teal'], 
              COLORS['success'], COLORS['warning'], COLORS['danger'],
              COLORS['purple'], COLORS['pink'], COLORS['orange']]
    
    for idx, ticker in enumerate(tickers):
        cumulative, data = fetch_ticker_performance(ticker, start_date, end_date)
        if cumulative is not None:
            fig.add_trace(go.Scatter(
                x=cumulative.index,
                y=cumulative.values,
                mode='lines',
                name=ticker,
                line=dict(width=2.5, color=colors[idx % len(colors)])
            ))
    
    if not fig.data:
        return None
    
    fig.update_layout(
        title="üìà Interactive Performance Comparison",
        xaxis_title="Date",
        yaxis_title="Cumulative Return (%)",
        height=600,
        hovermode='x unified',
        legend=dict(x=0.01, y=0.99),
        paper_bgcolor=COLORS['background'],
        plot_bgcolor=COLORS['card_background'],
        font=dict(color=COLORS['text_primary'])
    )
    
    fig.add_hline(y=0, line_dash="dash", line_color=COLORS['text_muted'], line_width=1)
    
    return fig

# ============================================================================
# MARKET WATCH
# ============================================================================

@st.cache_data(ttl=300)
def fetch_market_watch_data(tickers_dict):
    market_data = []
    
    for ticker, info in tickers_dict.items():
        try:
            stock = yf.Ticker(ticker)
            hist = stock.history(period="5d")
            
            if not hist.empty:
                current = hist['Close'].iloc[-1]
                prev = hist['Close'].iloc[-2] if len(hist) > 1 else current
                change = ((current - prev) / prev) * 100
                
                five_day = ((current / hist['Close'].iloc[0]) - 1) * 100 if len(hist) >= 5 else 0
                
                volume = hist['Volume'].iloc[-1]
                avg_volume = hist['Volume'].mean()
                
                market_data.append({
                    'Symbol': ticker,
                    'Name': info.get('name', ticker),
                    'Category': info.get('category', info.get('region', '')),
                    'Last': current,
                    'Change %': change,
                    '5D %': five_day,
                    'Volume': volume,
                    'Avg Volume': avg_volume,
                    'Vol/Avg': volume / avg_volume if avg_volume > 0 else 0
                })
        except:
            continue
    
    return pd.DataFrame(market_data)

def create_dynamic_market_table(df, filters=None):
    if filters:
        if 'category' in filters and filters['category'] and filters['category'] != 'All':
            df = df[df['Category'] == filters['category']]
        
        if 'sort_by' in filters and filters['sort_by']:
            ascending = filters.get('ascending', False)
            df = df.sort_values(filters['sort_by'], ascending=ascending)
    
    display_df = df.copy()
    display_df['Last'] = display_df['Last'].apply(format_currency)
    display_df['Change %'] = display_df['Change %'].apply(lambda x: add_arrow_indicator(format_percentage(x)))
    display_df['5D %'] = display_df['5D %'].apply(lambda x: add_arrow_indicator(format_percentage(x)))
    display_df['Volume'] = display_df['Volume'].apply(lambda x: f"{x:,.0f}")
    display_df['Vol/Avg'] = display_df['Vol/Avg'].apply(lambda x: f"{x:.2f}x")
    
    return display_df

# ============================================================================
# MAIN APP - COMPLETE WITH ALL MODULES
# ============================================================================

def main():
    st.markdown("<h1>üî• ATLAS TERMINAL v9.1 COMPLETE</h1>", unsafe_allow_html=True)
    st.markdown("<p style='text-align: center; color: #00d4ff; font-size: 18px;'>Portfolio Analytics + Valuation House üíé</p>", unsafe_allow_html=True)

    st.sidebar.markdown("## üéõÔ∏è NAVIGATION")
    page = st.sidebar.radio("Select Module", [
        "üî• Phoenix Parser",
        "üè† Portfolio Home",
        "üåç Market Watch",
        "üìà Risk Analysis",
        "üíé Performance Suite",
        "üî¨ Portfolio Deep Dive",
        "üìä Multi-Factor Analysis",
        "üíé Valuation House",
        "‚ÑπÔ∏è About"
    ])

    st.sidebar.markdown("---")
    st.sidebar.markdown("### üìÖ TIME RANGE")
    date_options = ["1D", "1W", "1M", "3M", "6M", "YTD", "1Y", "3Y", "5Y", "MAX"]
    selected_range = st.sidebar.selectbox("Period", date_options, index=6)
    
    st.sidebar.markdown("---")
    st.sidebar.markdown("### üéØ BENCHMARK")
    benchmark_options = ["SPY", "QQQ", "DIA", "IWM", "VTI", "ACWI"]
    selected_benchmark = st.sidebar.selectbox("Compare Against", benchmark_options, index=0)
    
    # Calculate date range
    if selected_range == "YTD":
        start_date = datetime(datetime.now().year, 1, 1)
        end_date = datetime.now()
    elif selected_range == "MAX":
        start_date = datetime(2000, 1, 1)
        end_date = datetime.now()
    else:
        days_map = {"1D": 1, "1W": 7, "1M": 30, "3M": 90, "6M": 180, "1Y": 365, "3Y": 1095, "5Y": 1825}
        days = days_map.get(selected_range, 365)
        end_date = datetime.now()
        start_date = end_date - timedelta(days=days)

    # ========================================================================
    # PHOENIX PARSER
    # ========================================================================
    if page == "üî• Phoenix Parser":
        st.markdown("## üî• PHOENIX MODE")

        col1, col2 = st.columns(2)

        with col1:
            st.markdown("### üìä Trade History")
            trade_file = st.file_uploader("Upload Trade History", type=['xls', 'xlsx'], key="trade")

            if trade_file:
                with st.spinner("Parsing..."):
                    trade_df = parse_trade_history_file(trade_file)

                    if trade_df is not None:
                        save_trade_history(trade_df)
                        st.success(f"‚úÖ Parsed {len(trade_df)} trades!")
                        st.dataframe(trade_df.head(10), use_container_width=True)

                        portfolio_df = calculate_portfolio_from_trades(trade_df)
                        if len(portfolio_df) > 0:
                            save_portfolio_data(portfolio_df.to_dict('records'))
                            st.success(f"üéâ Portfolio rebuilt! {len(portfolio_df)} positions")
                            st.dataframe(portfolio_df, use_container_width=True)

        with col2:
            st.markdown("### üí∞ Account History")
            account_file = st.file_uploader("Upload Account History", type=['xls', 'xlsx'], key="account")

            if account_file:
                with st.spinner("Parsing..."):
                    account_df = parse_account_history_file(account_file)

                    if account_df is not None:
                        save_account_history(account_df)
                        st.success(f"‚úÖ Parsed {len(account_df)} records!")
                        st.dataframe(account_df.head(10), use_container_width=True)

    # ========================================================================
    # PORTFOLIO HOME
    # ========================================================================
    elif page == "üè† Portfolio Home":
        st.markdown("## üè† PORTFOLIO HOME")

        portfolio_data = load_portfolio_data()

        if not portfolio_data:
            st.warning("‚ö†Ô∏è No portfolio data. Please upload via Phoenix Parser.")
            return

        df = pd.DataFrame(portfolio_data)

        with st.spinner("Loading portfolio data..."):
            enhanced_df = create_enhanced_holdings_table(df)

        total_value = enhanced_df['Total Value'].sum()
        total_cost = enhanced_df['Total Cost'].sum()
        total_gl = total_value - total_cost
        total_gl_pct = (total_gl / total_cost) * 100 if total_cost > 0 else 0
        daily_pl = enhanced_df['Daily P&L üéØ Sensitivity Analysis']
        xaxis_title="Discount Rate",
        yaxis_title="Terminal Growth Rate",
        height=400,
        paper_bgcolor=COLORS['background'],
        plot_bgcolor=COLORS['card_background'],
        font=dict(color=COLORS['text_primary'])
    )
    
    return fig

# ============================================================================
# PHOENIX PARSER
# ============================================================================

def parse_trade_history_file(uploaded_file):
    try:
        df = pd.read_html(uploaded_file)[0]
        required_cols = ['Date', 'Symbol', 'Trade Type', 'Quantity', 'Price']
        if not all(col in df.columns for col in required_cols):
            return None
        df['Price'] = df['Price'].astype(str).str.replace('$', '').str.replace(',', '').astype(float)
        df['Date'] = pd.to_datetime(df['Date'])
        df = df.sort_values('Date')
        return df
    except:
        return None

def parse_account_history_file(uploaded_file):
    try:
        df = pd.read_html(uploaded_file)[0]
        df['Date'] = pd.to_datetime(df['Date'])
        df = df.sort_values('Date')
        return df
    except:
        return None

def calculate_portfolio_from_trades(trade_df):
    holdings = {}
    for _, row in trade_df.iterrows():
        symbol = row['Symbol']
        trade_type = row['Trade Type']
        quantity = row['Quantity']
        price = row['Price']

        if is_option_ticker(symbol):
            continue

        if symbol not in holdings:
            holdings[symbol] = {'total_shares': 0, 'total_cost': 0, 'trades': []}

        is_buy = 'Buy' in trade_type

        if is_buy:
            holdings[symbol]['total_shares'] += quantity
            holdings[symbol]['total_cost'] += (quantity * price)
            holdings[symbol]['trades'].append({'type': 'BUY', 'quantity': quantity, 'price': price})
        else:
            remaining_to_sell = quantity
            for trade in holdings[symbol]['trades']:
                if trade['type'] == 'BUY' and remaining_to_sell > 0:
                    if trade['quantity'] <= remaining_to_sell:
                        holdings[symbol]['total_cost'] -= (trade['quantity'] * trade['price'])
                        holdings[symbol]['total_shares'] -= trade['quantity']
                        remaining_to_sell -= trade['quantity']
                        trade['quantity'] = 0
                    else:
                        holdings[symbol]['total_cost'] -= (remaining_to_sell * trade['price'])
                        holdings[symbol]['total_shares'] -= remaining_to_sell
                        trade['quantity'] -= remaining_to_sell
                        remaining_to_sell = 0

    portfolio_data = []
    for symbol, data in holdings.items():
        if data['total_shares'] > 0:
            avg_cost = data['total_cost'] / data['total_shares']
            portfolio_data.append({
                'Ticker': symbol,
                'Shares': data['total_shares'],
                'Avg Cost': avg_cost
            })

    if not portfolio_data:
        return pd.DataFrame(columns=['Ticker', 'Shares', 'Avg Cost'])
    return pd.DataFrame(portfolio_data).sort_values('Ticker')

# ============================================================================
# ENHANCED HOLDINGS TABLE
# ============================================================================

def create_enhanced_holdings_table(df):
    enhanced_df = df.copy()

    for idx, row in enhanced_df.iterrows():
        ticker = row['Ticker']
        market_data = fetch_market_data(ticker)

        if market_data:
            enhanced_df.at[idx, 'Asset Name'] = market_data['company_name']
            enhanced_df.at[idx, 'Current Price'] = market_data['price']
            enhanced_df.at[idx, 'Daily Change'] = market_data['daily_change']
            enhanced_df.at[idx, 'Daily Change %'] = market_data['daily_change_pct']
            enhanced_df.at[idx, 'Beta'] = market_data.get('beta', 'N/A')
            base_sector = market_data.get('sector', 'Unknown')
            enhanced_df.at[idx, 'Sector'] = classify_ticker_sector(ticker, base_sector)
        else:
            enhanced_df.at[idx, 'Asset Name'] = ticker
            enhanced_df.at[idx, 'Sector'] = 'Other'

    enhanced_df['Sector'] = enhanced_df['Sector'].fillna('Other')
    enhanced_df['Shares'] = enhanced_df['Shares'].round(0).astype(int)

    enhanced_df['Total Cost'] = enhanced_df['Shares'] * enhanced_df['Avg Cost']
    enhanced_df['Total Value'] = enhanced_df['Shares'] * enhanced_df['Current Price']
    enhanced_df['Total Gain/Loss' ] = enhanced_df['Total Value'] - enhanced_df['Total Cost']
    enhanced_df['Total Gain/Loss %'] = ((enhanced_df['Current Price'] - enhanced_df['Avg Cost']) / enhanced_df['Avg Cost']) * 100
    enhanced_df['Daily P&L' ] = enhanced_df['Shares'] * enhanced_df['Daily Change']

    total_value = enhanced_df['Total Value'].sum()
    enhanced_df['Weight %'] = (enhanced_df['Total Value'] / total_value * 100) if total_value > 0 else 0

    return enhanced_df

def style_holdings_dataframe(df):
    display_df = df[[
        'Ticker', 'Asset Name', 'Shares', 'Avg Cost', 'Current Price',
        'Daily Change %', 'Weight %', 'Daily P&L' 
        'Total Gain/Loss' , 'Total Gain/Loss %', 'Beta'
    ]].copy()

    pct_cols = ['Daily Change %', 'Weight %', 'Total Gain/Loss %']
    for col in pct_cols:
        display_df[col] = display_df[col].apply(lambda x: format_percentage(x))

    currency_cols = ['Avg Cost', 'Current Price', 'Daily P&L' , 'Total Gain/Loss' ]
    for col in currency_cols:
        display_df[col] = display_df[col].apply(format_currency)

    display_df['Daily Change %'] = display_df['Daily Change %'].apply(add_arrow_indicator)
    display_df['Total Gain/Loss %'] = display_df['Total Gain/Loss %'].apply(add_arrow_indicator)

    return display_df

# ============================================================================
# RISK METRICS (v8.8 COMPLETE)
# ============================================================================

def calculate_sharpe_ratio(returns, risk_free_rate=RISK_FREE_RATE):
    if not is_valid_series(returns) or len(returns) < 2:
        return None
    total_return = (1 + returns).prod() - 1
    n_years = len(returns) / 252
    annualized_return = (1 + total_return) ** (1/n_years) - 1 if n_years > 0 else 0
    annualized_vol = returns.std() * np.sqrt(252)
    sharpe = (annualized_return - risk_free_rate) / annualized_vol if annualized_vol > 0 else 0
    return sharpe

def calculate_sortino_ratio(returns, risk_free_rate=RISK_FREE_RATE):
    if not is_valid_series(returns) or len(returns) < 2:
        return None
    total_return = (1 + returns).prod() - 1
    n_years = len(returns) / 252
    annualized_return = (1 + total_return) ** (1/n_years) - 1 if n_years > 0 else 0
    downside_returns = returns[returns < 0]
    if len(downside_returns) < 2:
        return None
    downside_std = downside_returns.std() * np.sqrt(252)
    sortino = (annualized_return - risk_free_rate) / downside_std if downside_std > 0 else 0
    return sortino

def calculate_calmar_ratio(returns, risk_free_rate=RISK_FREE_RATE):
    if not is_valid_series(returns) or len(returns) < 2:
        return None
    total_return = (1 + returns).prod() - 1
    n_years = len(returns) / 252
    annualized_return = (1 + total_return) ** (1/n_years) - 1 if n_years > 0 else 0
    max_dd = abs(calculate_max_drawdown(returns))
    if max_dd == 0:
        return 0
    return (annualized_return - risk_free_rate) / (max_dd / 100)

def calculate_information_ratio(portfolio_returns, benchmark_returns):
    if not is_valid_series(portfolio_returns) or not is_valid_series(benchmark_returns):
        return None
    if len(portfolio_returns) < 2 or len(benchmark_returns) < 2:
        return None
    common_dates = portfolio_returns.index.intersection(benchmark_returns.index)
    portfolio_returns = portfolio_returns.loc[common_dates]
    benchmark_returns = benchmark_returns.loc[common_dates]
    excess_returns = portfolio_returns - benchmark_returns
    if len(excess_returns) < 2:
        return None
    total_excess = (1 + excess_returns).prod() - 1
    n_years = len(excess_returns) / 252
    annualized_excess = (1 + total_excess) ** (1/n_years) - 1 if n_years > 0 else 0
    tracking_error = excess_returns.std() * np.sqrt(252)
    info_ratio = annualized_excess / tracking_error if tracking_error > 0 else 0
    return info_ratio

def calculate_var(returns, confidence=0.95):
    if not is_valid_series(returns) or len(returns) < 2:
        return None
    var = np.percentile(returns, (1 - confidence) * 100)
    return var * 100

def calculate_cvar(returns, confidence=0.95):
    if not is_valid_series(returns) or len(returns) < 2:
        return None
    var = np.percentile(returns, (1 - confidence) * 100)
    cvar = returns[returns <= var].mean()
    return cvar * 100

def calculate_max_drawdown(returns):
    if not is_valid_series(returns) or len(returns) < 2:
        return None
    cumulative = (1 + returns).cumprod()
    running_max = cumulative.expanding().max()
    drawdown = (cumulative - running_max) / running_max
    return drawdown.min() * 100

@st.cache_data(ttl=600)
def calculate_portfolio_returns(df, start_date, end_date):
    try:
        valid_positions = []
        for _, row in df.iterrows():
            if not is_option_ticker(row['Ticker']):
                valid_positions.append(row)
        
        if not valid_positions:
            return None
        
        valid_df = pd.DataFrame(valid_positions)
        all_data = {}
        
        for _, row in valid_df.iterrows():
            ticker = row['Ticker']
            data = fetch_historical_data(ticker, start_date, end_date)
            if data is not None and len(data) > 0:
                all_data[ticker] = data
        
        if not all_data:
            return None
        
        common_dates = None
        for ticker, data in all_data.items():
            dates = set(data.index)
            common_dates = dates if common_dates is None else common_dates.intersection(dates)
        
        common_dates = sorted(list(common_dates))
        if len(common_dates) < 2:
            return None
        
        portfolio_values = []
        for date in common_dates:
            daily_value = 0
            for _, row in valid_df.iterrows():
                ticker = row['Ticker']
                if ticker in all_data:
                    try:
                        price = all_data[ticker].loc[date, 'Close']
                        daily_value += price * row['Shares']
                    except KeyError:
                        continue
            portfolio_values.append(daily_value)
        
        portfolio_series = pd.Series(portfolio_values, index=common_dates)
        returns = portfolio_series.pct_change().dropna()
        return returns
    except:
        return None

@st.cache_data(ttl=600)
def calculate_benchmark_returns(benchmark_ticker, start_date, end_date):
    try:
        data = fetch_historical_data(benchmark_ticker, start_date, end_date)
        if data is None or data.empty:
            return None
        returns = data['Close'].pct_change().dropna()
        return returns
    except:
        return None

# ============================================================================
# WORLD-CLASS VISUALIZATIONS (v8.8 COMPLETE)
# ============================================================================

def create_rolling_metrics_chart(returns, window=60):
    """Rolling metrics visualization"""
    if not is_valid_series(returns) or len(returns) < window:
        return None
    
    rolling_vol = returns.rolling(window).std() * np.sqrt(252) * 100
    rolling_sharpe = (returns.rolling(window).mean() * 252 - RISK_FREE_RATE) / (returns.rolling(window).std() * np.sqrt(252))
    
    fig = make_subplots(
        rows=2, cols=1,
        subplot_titles=('Rolling Volatility (60-Day)', 'Rolling Sharpe Ratio (60-Day)'),
        vertical_spacing=0.15
    )
    
    fig.add_trace(
        go.Scatter(
            x=rolling_vol.index,
            y=rolling_vol.values,
            fill='tozeroy',
            fillcolor='rgba(255, 0, 68, 0.2)',
            line=dict(color=COLORS['danger'], width=2),
            name='Volatility'
        ),
        row=1, col=1
    )
    
    fig.add_trace(
        go.Scatter(
            x=rolling_sharpe.index,
            y=rolling_sharpe.values,
            fill='tozeroy',
            fillcolor='rgba(0, 212, 255, 0.2)',
            line=dict(color=COLORS['neon_blue'], width=2),
            name='Sharpe Ratio'
        ),
        row=2, col=1
    )
    
    fig.add_hline(y=0, line_dash="dash", line_color=COLORS['text_muted'], row=2, col=1)
    
    fig.update_layout(
        height=600,
        showlegend=False,
        title_text="üìä Rolling Risk Metrics",
        paper_bgcolor=COLORS['background'],
        plot_bgcolor=COLORS['card_background'],
        font=dict(color=COLORS['text_primary'])
    )
    
    return fig

def create_underwater_plot(returns):
    """Underwater drawdown plot"""
    if not is_valid_series(returns) or len(returns) < 2:
        return None
    
    cumulative = (1 + returns).cumprod()
    running_max = cumulative.expanding().max()
    drawdown = ((cumulative - running_max) / running_max) * 100
    
    fig = go.Figure()
    
    fig.add_trace(go.Scatter(
        x=drawdown.index,
        y=drawdown.values,
        fill='tozeroy',
        fillcolor='rgba(255, 0, 68, 0.3)',
        line=dict(color=COLORS['danger'], width=2),
        name='Drawdown'
    ))
    
    fig.add_hline(y=0, line_dash="solid", line_color=COLORS['text_primary'], line_width=1)
    
    max_dd_idx = drawdown.idxmin()
    max_dd_val = drawdown.min()
    
    fig.add_annotation(
        x=max_dd_idx,
        y=max_dd_val,
        text=f"Max DD: {max_dd_val:.2f}%",
        showarrow=True,
        arrowhead=2,
        arrowcolor=COLORS['danger'],
        ax=0,
        ay=-40,
        bgcolor=COLORS['card_background'],
        bordercolor=COLORS['danger'],
        borderwidth=2
    )
    
    fig.update_layout(
        title="üåä Underwater Plot",
        xaxis_title="Date",
        yaxis_title="Drawdown (%)",
        height=500,
        paper_bgcolor=COLORS['background'],
        plot_bgcolor=COLORS['card_background'],
        font=dict(color=COLORS['text_primary'])
    )
    
    return fig

def create_var_waterfall(returns):
    """VaR/CVaR waterfall chart"""
    if not is_valid_series(returns) or len(returns) < 2:
        return None
    
    var_90 = calculate_var(returns, 0.90)
    var_95 = calculate_var(returns, 0.95)
    var_99 = calculate_var(returns, 0.99)
    cvar_95 = calculate_cvar(returns, 0.95)
    
    categories = ['VaR 90%', 'VaR 95%', 'VaR 99%', 'CVaR 95%']
    values = [var_90, var_95, var_99, cvar_95]
    
    colors_list = [COLORS['warning'], COLORS['orange'], COLORS['danger'], COLORS['danger']]
    
    fig = go.Figure()
    
    fig.add_trace(go.Bar(
        x=categories,
        y=values,
        marker=dict(
            color=colors_list,
            line=dict(color=COLORS['border'], width=2)
        ),
        text=[f"{v:.2f}%" for v in values],
        textposition='outside'
    ))
    
    fig.update_layout(
        title="‚ö†Ô∏è Value at Risk Waterfall",
        xaxis_title="Risk Measure",
        yaxis_title="Expected Loss (%)",
        height=500,
        paper_bgcolor=COLORS['background'],
        plot_bgcolor=COLORS['card_background'],
        font=dict(color=COLORS['text_primary'])
    )
    
    return fig

def create_risk_contribution_sunburst(df):
    """Risk contribution sunburst"""
    risk_data = []
    
    for _, row in df.iterrows():
        ticker = row['Ticker']
        weight = row['Weight %']
        sector = row['Sector']
        
        hist_data = fetch_historical_data(ticker, datetime.now() - timedelta(days=365), datetime.now())
        if hist_data is not None and len(hist_data) > 30:
            returns = hist_data['Close'].pct_change().dropna()
            vol = returns.std() * np.sqrt(252) * 100
            risk_contribution = weight * vol
            
            risk_data.append({
                'Ticker': ticker,
                'Sector': sector,
                'Weight': weight,
                'Volatility': vol,
                'Risk Contribution': risk_contribution
            })
    
    if not risk_data:
        return None
    
    risk_df = pd.DataFrame(risk_data)
    
    fig = px.sunburst(
        risk_df,
        path=['Sector', 'Ticker'],
        values='Risk Contribution',
        color='Volatility',
        color_continuous_scale='RdYlGn_r',
        title="‚òÄÔ∏è Risk Contribution Sunburst"
    )
    
    fig.update_layout(
        height=600,
        paper_bgcolor=COLORS['background'],
        font=dict(color=COLORS['text_primary'])
    )
    
    return fig

def create_risk_reward_plot(df):
    """Risk-reward scatter plot"""
    risk_reward_data = []
    
    for _, row in df.iterrows():
        ticker = row['Ticker']
        hist_data = fetch_historical_data(ticker, datetime.now() - timedelta(days=365), datetime.now())
        
        if hist_data is not None and len(hist_data) > 30:
            returns = hist_data['Close'].pct_change().dropna()
            annual_return = ((1 + returns.mean()) ** 252 - 1) * 100
            annual_vol = returns.std() * np.sqrt(252) * 100
            
            risk_reward_data.append({
                'Ticker': ticker,
                'Asset Name': row['Asset Name'],
                'Return': annual_return,
                'Risk': annual_vol,
                'Weight': row['Weight %'],
                'Sector': row['Sector']
            })
    
    if not risk_reward_data:
        return None
    
    rr_df = pd.DataFrame(risk_reward_data)
    
    fig = px.scatter(
        rr_df,
        x='Risk',
        y='Return',
        size='Weight',
        color='Sector',
        text='Ticker',
        hover_data=['Asset Name'],
        color_discrete_sequence=px.colors.qualitative.Set3
    )
    
    fig.update_traces(
        textposition='top center',
        marker=dict(line=dict(width=2, color=COLORS['border']))
    )
    
    fig.update_layout(
        title="üìà Risk-Reward Analysis",
        xaxis_title="Risk (Annual Volatility %)",
        yaxis_title="Expected Return (Annual %)",
        height=500,
        paper_bgcolor=COLORS['background'],
        plot_bgcolor=COLORS['card_background'],
        font=dict(color=COLORS['text_primary'])
    )
    
    return fig

def create_efficient_frontier(df):
    """FIXED BROADCASTING ERROR - Efficient Frontier"""
    returns_data = {}
    expected_returns = []
    volatilities = []
    tickers = []
    
    for _, row in df.iterrows():
        ticker = row['Ticker']
        hist_data = fetch_historical_data(ticker, datetime.now() - timedelta(days=365), datetime.now())
        
        if hist_data is not None and len(hist_data) > 30:
            returns = hist_data['Close'].pct_change().dropna()
            annual_return = ((1 + returns.mean()) ** 252 - 1)
            annual_vol = returns.std() * np.sqrt(252)
            
            expected_returns.append(annual_return)
            volatilities.append(annual_vol)
            tickers.append(ticker)
            returns_data[ticker] = returns
    
    if len(expected_returns) < 2:
        return None
    
    returns_df = pd.DataFrame(returns_data)
    cov_matrix = returns_df.cov() * 252
    
    num_portfolios = 5000
    results = np.zeros((3, num_portfolios))
    
    np.random.seed(42)
    
    for i in range(num_portfolios):
        weights = np.random.random(len(tickers))
        weights /= np.sum(weights)
        
        portfolio_return = np.sum(weights * np.array(expected_returns))
        portfolio_vol = np.sqrt(np.dot(weights.T, np.dot(cov_matrix, weights)))
        sharpe = (portfolio_return - RISK_FREE_RATE) / portfolio_vol if portfolio_vol > 0 else 0
        
        results[0, i] = portfolio_return * 100
        results[1, i] = portfolio_vol * 100
        results[2, i] = sharpe
    
    fig = go.Figure()
    
    fig.add_trace(go.Scatter(
        x=results[1],
        y=results[0],
        mode='markers',
        marker=dict(
            size=5,
            color=results[2],
            colorscale='Viridis',
            showscale=True,
            colorbar=dict(title="Sharpe Ratio")
        ),
        name='Efficient Frontier'
    ))
    
    # FIXED: Properly align weights and returns
    current_weights = df[df['Ticker'].isin(tickers)]['Weight %'].values / 100
    aligned_returns = np.array(expected_returns[:len(current_weights)])
    aligned_cov = cov_matrix.iloc[:len(current_weights), :len(current_weights)]
    
    current_return = np.sum(current_weights * aligned_returns) * 100
    current_vol = np.sqrt(np.dot(current_weights.T, np.dot(aligned_cov, current_weights))) * 100
    
    fig.add_trace(go.Scatter(
        x=[current_vol],
        y=[current_return],
        mode='markers',
        marker=dict(size=20, color=COLORS['danger'], symbol='star'),
        name='Current Portfolio'
    ))
    
    fig.update_layout(
        title="üìä Efficient Frontier",
        xaxis_title="Risk (Volatility %)",
        yaxis_title="Return %",
        height=600,
        paper_bgcolor=COLORS['background'],
        plot_bgcolor=COLORS['card_background'],
        font=dict(color=COLORS['text_primary'])
    )
    
    return fig

def create_risk_parity_analysis(df):
    """Risk parity analysis"""
    risk_contributions = []
    
    for _, row in df.iterrows():
        ticker = row['Ticker']
        weight = row['Weight %'] / 100
        
        hist_data = fetch_historical_data(ticker, datetime.now() - timedelta(days=365), datetime.now())
        if hist_data is not None and len(hist_data) > 30:
            returns = hist_data['Close'].pct_change().dropna()
            vol = returns.std() * np.sqrt(252)
            risk_contribution = weight * vol
            
            risk_contributions.append({
                'Ticker': ticker,
                'Weight %': row['Weight %'],
                'Volatility': vol * 100,
                'Risk Contribution': risk_contribution * 100
            })
    
    if not risk_contributions:
        return None
    
    rc_df = pd.DataFrame(risk_contributions)
    total_risk = rc_df['Risk Contribution'].sum()
    rc_df['Risk %'] = (rc_df['Risk Contribution'] / total_risk) * 100
    
    fig = go.Figure()
    
    fig.add_trace(go.Bar(
        name='Weight %',
        x=rc_df['Ticker'],
        y=rc_df['Weight %'],
        marker_color=COLORS['electric_blue']
    ))
    
    fig.add_trace(go.Bar(
        name='Risk Contribution %',
        x=rc_df['Ticker'],
        y=rc_df['Risk %'],
        marker_color=COLORS['danger']
    ))
    
    fig.update_layout(
        title="‚öñÔ∏è Risk Parity Analysis",
        xaxis_title="Asset",
        yaxis_title="Percentage",
        barmode='group',
        height=500,
        paper_bgcolor=COLORS['background'],
        plot_bgcolor=COLORS['card_background'],
        font=dict(color=COLORS['text_primary'])
    )
    
    return fig

def create_correlation_network(df, start_date, end_date):
    """Correlation network graph"""
    returns_data = {}
    
    for _, row in df.iterrows():
        ticker = row['Ticker']
        hist_data = fetch_historical_data(ticker, start_date, end_date)
        if hist_data is not None and len(hist_data) > 30:
            returns_data[ticker] = hist_data['Close'].pct_change().dropna()
    
    if len(returns_data) < 2:
        return None
    
    returns_df = pd.DataFrame(returns_data)
    corr_matrix = returns_df.corr()
    
    fig = go.Figure()
    
    G = nx.Graph()
    for ticker in corr_matrix.columns:
        G.add_node(ticker)
    
    threshold = 0.5
    for i, ticker1 in enumerate(corr_matrix.columns):
        for j, ticker2 in enumerate(corr_matrix.columns):
            if i < j:
                corr = corr_matrix.iloc[i, j]
                if abs(corr) > threshold:
                    G.add_edge(ticker1, ticker2, weight=abs(corr))
    
    pos = nx.spring_layout(G)
    
    for edge in G.edges():
        x0, y0 = pos[edge[0]]
        x1, y1 = pos[edge[1]]
        weight = G[edge[0]][edge[1]]['weight']
        
        fig.add_trace(go.Scatter(
            x=[x0, x1],
            y=[y0, y1],
            mode='lines',
            line=dict(width=weight*5, color=COLORS['electric_blue']),
            opacity=0.5,
            showlegend=False
        ))
    
    node_x = []
    node_y = []
    node_text = []
    
    for node in G.nodes():
        x, y = pos[node]
        node_x.append(x)
        node_y.append(y)
        node_text.append(node)
    
    fig.add_trace(go.Scatter(
        x=node_x,
        y=node_y,
        mode='markers+text',
        text=node_text,
        textposition='top center',
        marker=dict(
            size=20,
            color=COLORS['neon_blue'],
            line=dict(width=2, color=COLORS['border'])
        ),
        showlegend=False
    ))
    
    fig.update_layout(
        title="üîó Correlation Network",
        showlegend=False,
        height=600,
        paper_bgcolor=COLORS['background'],
        plot_bgcolor=COLORS['card_background'],
        font=dict(color=COLORS['text_primary']),
        xaxis=dict(showgrid=False, zeroline=False, showticklabels=False),
        yaxis=dict(showgrid=False, zeroline=False, showticklabels=False)
    )
    
    return fig

def run_monte_carlo_simulation(returns, initial_value=100000, days=252, simulations=1000):
    """Monte Carlo simulation"""
    if not is_valid_series(returns) or len(returns) < 30:
        return None
    
    daily_return = returns.mean()
    daily_vol = returns.std()
    
    simulation_results = []
    
    for _ in range(simulations):
        prices = [initial_value]
        for _ in range(days):
            price = prices[-1] * (1 + np.random.normal(daily_return, daily_vol))
            prices.append(price)
        simulation_results.append(prices)
    
    return np.array(simulation_results)

def create_monte_carlo_chart(simulation_results, initial_value=100000):
    """Monte Carlo visualization"""
    if simulation_results is None:
        return None, None
    
    fig = go.Figure()
    
    for i in range(min(100, len(simulation_results))):
        fig.add_trace(go.Scatter(
            y=simulation_results[i],
            mode='lines',
            line=dict(width=0.5, color=COLORS['electric_blue']),
            opacity=0.1,
            showlegend=False
        ))
    
    percentiles = [5, 25, 50, 75, 95]
    colors_pct = [COLORS['danger'], COLORS['warning'], COLORS['info'], 
                  COLORS['teal'], COLORS['success']]
    
    for p, color in zip(percentiles, colors_pct):
        values = np.percentile(simulation_results, p, axis=0)
        fig.add_trace(go.Scatter(
            y=values,
            mode='lines',
            line=dict(width=3, color=color),
            name=f'{p}th Percentile'
        ))
    
    fig.update_layout(
        title="üé≤ Monte Carlo Simulation",
        xaxis_title="Trading Days",
        yaxis_title="Portfolio Value ($)",
        height=500,
        paper_bgcolor=COLORS['background'],
        plot_bgcolor=COLORS['card_background'],
        font=dict(color=COLORS['text_primary'])
    )
    
    final_values = simulation_results[:, -1]
    stats = {
        'mean': np.mean(final_values),
        'median': np.median(final_values),
        'percentile_5': np.percentile(final_values, 5),
        'percentile_95': np.percentile(final_values, 95),
        'prob_profit': (final_values > initial_value).mean() * 100,
        'prob_loss_10': (final_values < initial_value * 0.9).mean() * 100,
        'prob_gain_20': (final_values > initial_value * 1.2).mean() * 100
    }
    
    return fig, stats

# ============================================================================
# PORTFOLIO DEEP DIVE VISUALIZATIONS (v8.8)
# ============================================================================

def create_portfolio_heatmap(df):
    """Portfolio treemap"""
    df_viz = df[['Ticker', 'Asset Name', 'Weight %', 'Total Gain/Loss %', 'Sector']].copy()
    df_viz['Sector'] = df_viz['Sector'].fillna('Other')
    df_viz = df_viz.dropna()
    
    if df_viz.empty:
        return None
    
    fig = px.treemap(
        df_viz,
        path=[px.Constant("Portfolio"), 'Sector', 'Ticker'],
        values='Weight %',
        color='Total Gain/Loss %',
        color_continuous_scale='RdYlGn',
        color_continuous_midpoint=0,
        hover_data={'Asset Name': True, 'Total Gain/Loss %': ':.2f'}
    )
    
    fig.update_layout(
        title="].sum()

        col1, col2, col3, col4, col5 = st.columns(5)
        col1.metric("Total Value", format_currency(total_value))
        col2.metric("Total Cost", format_currency(total_cost))
        col3.metric("Total G/L", format_currency(total_gl), format_percentage(total_gl_pct))
        col4.metric("Daily P&L", format_currency(daily_pl))
        col5.metric("Positions", len(enhanced_df))

        st.markdown("---")
        st.markdown("### üìã Holdings")
        display_df = style_holdings_dataframe(enhanced_df)
        st.dataframe(display_df, use_container_width=True, hide_index=True, height=500)
        
        st.info("üí° **Tip:** Use Valuation House to analyze intrinsic value of any stock!")

        st.markdown("---")
        
        col1, col2 = st.columns(2)
        
        with col1:
            risk_reward = create_risk_reward_plot(enhanced_df)
            if risk_reward:
                st.plotly_chart(risk_reward, use_container_width=True)
        
        with col2:
            heatmap = create_portfolio_heatmap(enhanced_df)
            if heatmap:
                st.plotly_chart(heatmap, use_container_width=True)

    # ========================================================================
    # MARKET WATCH
    # ========================================================================
    elif page == "üåç Market Watch":
        st.markdown("## üåç MARKET WATCH")
        
        st.markdown("### üîç Filters")
        col1, col2, col3 = st.columns(3)
        
        with col1:
            filter_category = st.selectbox("Category", ["All", "US", "Europe", "Asia"])
        with col2:
            sort_by = st.selectbox("Sort By", ["Change %", "5D %", "Volume"])
        with col3:
            st.write("")  # Spacer
        
        tab1, tab2, tab3 = st.tabs(["üìà Indices", "üè¶ ETFs", "üí∞ Commodities"])
        
        with tab1:
            with st.spinner("Loading indices..."):
                indices_df = fetch_market_watch_data(GLOBAL_INDICES)
                if not indices_df.empty:
                    if filter_category != "All":
                        indices_df = indices_df[indices_df['Category'] == filter_category]
                    
                    display_df = create_dynamic_market_table(indices_df, {'sort_by': sort_by, 'ascending': False})
                    st.dataframe(display_df, use_container_width=True, hide_index=True, height=500)
        
        with tab2:
            with st.spinner("Loading ETFs..."):
                etf_df = fetch_market_watch_data(POPULAR_ETFS)
                if not etf_df.empty:
                    display_df = create_dynamic_market_table(etf_df, {'sort_by': sort_by, 'ascending': False})
                    st.dataframe(display_df, use_container_width=True, hide_index=True, height=500)
        
        with tab3:
            with st.spinner("Loading commodities..."):
                comm_df = fetch_market_watch_data(COMMODITIES)
                if not comm_df.empty:
                    display_df = create_dynamic_market_table(comm_df, {'sort_by': sort_by, 'ascending': False})
                    st.dataframe(display_df, use_container_width=True, hide_index=True, height=500)

    # ========================================================================
    # RISK ANALYSIS - WORLD CLASS (v8.8 COMPLETE)
    # ========================================================================
    elif page == "üìà Risk Analysis":
        st.markdown("## üìà RISK ANALYSIS - WORLD CLASS")
        
        portfolio_data = load_portfolio_data()
        
        if not portfolio_data:
            st.warning("‚ö†Ô∏è No portfolio data. Please upload via Phoenix Parser.")
            return
        
        df = pd.DataFrame(portfolio_data)
        enhanced_df = create_enhanced_holdings_table(df)
        
        with st.spinner("Calculating risk metrics..."):
            portfolio_returns = calculate_portfolio_returns(df, start_date, end_date)
            benchmark_returns = calculate_benchmark_returns(selected_benchmark, start_date, end_date)
            
            if not is_valid_series(portfolio_returns):
                st.warning("‚ö†Ô∏è Insufficient data for risk analysis")
                return
            
            sharpe = calculate_sharpe_ratio(portfolio_returns)
            sortino = calculate_sortino_ratio(portfolio_returns)
            calmar = calculate_calmar_ratio(portfolio_returns)
            var_95 = calculate_var(portfolio_returns, 0.95)
            max_dd = calculate_max_drawdown(portfolio_returns)
        
        col1, col2, col3, col4, col5 = st.columns(5)
        col1.metric("Sharpe", f"{sharpe:.2f}" if sharpe else "N/A")
        col2.metric("Sortino", f"{sortino:.2f}" if sortino else "N/A")
        col3.metric("Calmar", f"{calmar:.2f}" if calmar else "N/A")
        col4.metric("VaR 95%", format_percentage(var_95) if var_95 else "N/A")
        col5.metric("Max DD", format_percentage(max_dd) if max_dd else "N/A")
        
        st.markdown("---")
        
        tab1, tab2, tab3, tab4 = st.tabs([
            "üìä Core Risk", "üé≤ Monte Carlo", "üî¨ Advanced Analytics", "‚ö° Correlation"
        ])
        
        with tab1:
            col1, col2 = st.columns(2)
            
            with col1:
                var_chart = create_var_waterfall(portfolio_returns)
                if var_chart:
                    st.plotly_chart(var_chart, use_container_width=True)
                
                risk_parity = create_risk_parity_analysis(enhanced_df)
                if risk_parity:
                    st.plotly_chart(risk_parity, use_container_width=True)
            
            with col2:
                efficient = create_efficient_frontier(enhanced_df)
                if efficient:
                    st.plotly_chart(efficient, use_container_width=True)
                else:
                    st.warning("‚ö†Ô∏è Insufficient data for efficient frontier")
        
        with tab2:
            st.markdown("### üé≤ Monte Carlo Simulation")
            
            col1, col2 = st.columns([1, 3])
            with col1:
                initial_val = st.number_input("Initial Value ($)", min_value=1000, max_value=10000000, value=100000, step=1000)
                sim_days = st.slider("Days to Simulate", 30, 1260, 252)
                num_sims = st.slider("Number of Simulations", 100, 5000, 1000, step=100)
            
            if st.button("üöÄ Run Simulation"):
                with st.spinner("Running Monte Carlo simulation..."):
                    simulations = run_monte_carlo_simulation(portfolio_returns, initial_val, sim_days, num_sims)
                    
                    if simulations is not None:
                        monte_carlo_chart, mc_stats = create_monte_carlo_chart(simulations, initial_val)
                        
                        if monte_carlo_chart:
                            st.plotly_chart(monte_carlo_chart, use_container_width=True)
                        
                        if mc_stats:
                            st.markdown("#### üìä Simulation Results")
                            
                            col1, col2, col3, col4 = st.columns(4)
                            col1.metric("Expected Value", format_currency(mc_stats['mean']))
                            col2.metric("Median Value", format_currency(mc_stats['median']))
                            col3.metric("95th Percentile", format_currency(mc_stats['percentile_95']))
                            col4.metric("5th Percentile", format_currency(mc_stats['percentile_5']))
                            
                            st.markdown("---")
                            
                            col1, col2, col3 = st.columns(3)
                            col1.metric("Prob of Profit", f"{mc_stats['prob_profit']:.1f}%")
                            col2.metric("Prob of 20%+ Gain", f"{mc_stats['prob_gain_20']:.1f}%")
                            col3.metric("Prob of 10%+ Loss", f"{mc_stats['prob_loss_10']:.1f}%")
        
        with tab3:
            col1, col2 = st.columns(2)
            
            with col1:
                rolling = create_rolling_metrics_chart(portfolio_returns)
                if rolling:
                    st.plotly_chart(rolling, use_container_width=True)
            
            with col2:
                underwater = create_underwater_plot(portfolio_returns)
                if underwater:
                    st.plotly_chart(underwater, use_container_width=True)
            
            sunburst = create_risk_contribution_sunburst(enhanced_df)
            if sunburst:
                st.plotly_chart(sunburst, use_container_width=True)
        
        with tab4:
            corr_network = create_correlation_network(enhanced_df, start_date, end_date)
            if corr_network:
                st.plotly_chart(corr_network, use_container_width=True)
            else:
                st.warning("‚ö†Ô∏è Insufficient data for correlation analysis")

    # ========================================================================
    # PERFORMANCE SUITE
    # ========================================================================
    elif page == "üíé Performance Suite":
        st.markdown("## üíé PERFORMANCE SUITE")
        
        portfolio_data = load_portfolio_data()
        
        if not portfolio_data:
            st.warning("‚ö†Ô∏è No portfolio data. Please upload via Phoenix Parser.")
            return
        
        df = pd.DataFrame(portfolio_data)
        enhanced_df = create_enhanced_holdings_table(df)
        
        with st.spinner("Calculating performance..."):
            portfolio_returns = calculate_portfolio_returns(df, start_date, end_date)
            benchmark_returns = calculate_benchmark_returns(selected_benchmark, start_date, end_date)
            
            metrics = None
            if is_valid_series(portfolio_returns):
                metrics = calculate_performance_metrics(enhanced_df, portfolio_returns, benchmark_returns)
        
        tab1, tab2, tab3 = st.tabs(["üìà Interactive Chart", "üìä Analytics", "üìã Metrics"])
        
        with tab1:
            st.markdown("### üìà Performance Comparison")
            
            available_tickers = enhanced_df['Ticker'].tolist()
            
            col1, col2 = st.columns([3, 1])
            with col1:
                selected_tickers = st.multiselect(
                    "Select Tickers to Compare",
                    options=available_tickers + ["SPY", "QQQ", "VTI"],
                    default=available_tickers[:min(5, len(available_tickers))]
                )
            
            with col2:
                custom_ticker = st.text_input("Add Custom Ticker", placeholder="TSLA")
                if custom_ticker:
                    selected_tickers.append(custom_ticker.upper())
            
            if selected_tickers:
                perf_chart = create_interactive_performance_chart(selected_tickers, start_date, end_date)
                if perf_chart:
                    st.plotly_chart(perf_chart, use_container_width=True)
                else:
                    st.warning("‚ö†Ô∏è Unable to fetch performance data")
        
        with tab2:
            if metrics:
                dashboard = create_performance_dashboard(metrics)
                st.plotly_chart(dashboard, use_container_width=True)
            else:
                st.warning("‚ö†Ô∏è Unable to calculate performance metrics")
        
        with tab3:
            if metrics:
                st.markdown("### üìã Detailed Metrics")
                
                metrics_df = pd.DataFrame([
                    ['Total Return', format_percentage(metrics['Total Return'])],
                    ['Annualized Return', format_percentage(metrics['Annualized Return'])],
                    ['Volatility', format_percentage(metrics['Annualized Volatility'])],
                    ['Sharpe Ratio', f"{metrics['Sharpe Ratio']:.3f}"],
                    ['Sortino Ratio', f"{metrics['Sortino Ratio']:.3f}"],
                    ['Calmar Ratio', f"{metrics['Calmar Ratio']:.3f}"],
                    ['Information Ratio', f"{metrics['Information Ratio']:.3f}" if metrics['Information Ratio'] else "N/A"],
                    ['VaR (95%)', format_percentage(metrics['VaR (95%)'])],
                    ['CVaR (95%)', format_percentage(metrics['CVaR (95%)'])],
                    ['Max Drawdown', format_percentage(metrics['Max Drawdown'])],
                    ['Win Rate', format_percentage(metrics['Win Rate'])],
                    ['Best Day', format_percentage(metrics['Best Day'])],
                    ['Worst Day', format_percentage(metrics['Worst Day'])]
                ], columns=['Metric', 'Value'])
                
                st.dataframe(metrics_df, use_container_width=True, hide_index=True, height=600)

    # ========================================================================
    # PORTFOLIO DEEP DIVE (v8.8)
    # ========================================================================
    elif page == "üî¨ Portfolio Deep Dive":
        st.markdown("## üî¨ PORTFOLIO DEEP DIVE")
        
        portfolio_data = load_portfolio_data()
        
        if not portfolio_data:
            st.warning("‚ö†Ô∏è No portfolio data. Please upload via Phoenix Parser.")
            return
        
        df = pd.DataFrame(portfolio_data)
        enhanced_df = create_enhanced_holdings_table(df)
        
        tab1, tab2, tab3 = st.tabs([
            "üéØ Attribution", "üîÑ Sector Rotation", "üìä Concentration"
        ])
        
        with tab1:
            st.markdown("### üéØ Attribution Analysis")
            
            col1, col2 = st.columns(2)
            
            with col1:
                heatmap = create_portfolio_heatmap(enhanced_df)
                if heatmap:
                    st.plotly_chart(heatmap, use_container_width=True)
            
            with col2:
                waterfall = create_holdings_attribution_waterfall(enhanced_df)
                if waterfall:
                    st.plotly_chart(waterfall, use_container_width=True)
        
        with tab2:
            st.markdown("### üîÑ Sector Rotation Analysis")
            
            rotation = create_sector_rotation_heatmap(enhanced_df, start_date, end_date)
            if rotation:
                st.plotly_chart(rotation, use_container_width=True)
            else:
                st.warning("‚ö†Ô∏è Insufficient data for sector rotation analysis")
        
        with tab3:
            st.markdown("### üìä Concentration Analysis")
            
            col1, col2 = st.columns([1, 2])
            
            with col1:
                gauge = create_concentration_gauge(enhanced_df)
                if gauge:
                    st.plotly_chart(gauge, use_container_width=True)
            
            with col2:
                st.markdown("#### Top 10 Holdings")
                top10 = enhanced_df.nlargest(10, 'Weight %')[['Ticker', 'Asset Name', 'Weight %', 'Total Gain/Loss %']]
                top10_display = top10.copy()
                top10_display['Weight %'] = top10_display['Weight %'].apply(format_percentage)
                top10_display['Total Gain/Loss %'] = top10_display['Total Gain/Loss %'].apply(format_percentage)
                st.dataframe(top10_display, use_container_width=True, hide_index=True)

    # ========================================================================
    # MULTI-FACTOR ANALYSIS (v8.8)
    # ========================================================================
    elif page == "üìä Multi-Factor Analysis":
        st.markdown("## üìä MULTI-FACTOR ANALYSIS")
        
        portfolio_data = load_portfolio_data()
        
        if not portfolio_data:
            st.warning("‚ö†Ô∏è No portfolio data. Please upload via Phoenix Parser.")
            return
        
        df = pd.DataFrame(portfolio_data)
        enhanced_df = create_enhanced_holdings_table(df)
        
        with st.spinner("Running factor analysis..."):
            factor_data = calculate_factor_exposures(enhanced_df, start_date, end_date)
        
        if factor_data:
            st.markdown(f"**Model R¬≤ = {factor_data['r_squared']:.3f}**")
            st.progress(factor_data['r_squared'])
            
            result = create_factor_attribution_table(factor_data, enhanced_df)
            
            tab1, tab2, tab3 = st.tabs([
                "üìà Factor Momentum", "üéØ Exposure Radar", "üìä Attribution"
            ])
            
            with tab1:
                st.markdown("### üìà Factor Momentum Over Time")
                momentum = create_factor_momentum_chart(factor_data)
                if momentum:
                    st.plotly_chart(momentum, use_container_width=True)
            
            with tab2:
                st.markdown("### üéØ Portfolio Factor Exposure")
                radar = create_factor_exposure_radar(factor_data)
                if radar:
                    st.plotly_chart(radar, use_container_width=True)
            
            with tab3:
                st.markdown("### üìä Factor Attribution Breakdown")
                
                if result is not None:
                    attr_df, factor_summary, sector_summary = result
                    
                    if factor_summary is not None:
                        st.markdown("#### Factor Summary")
                        factor_display = factor_summary.copy()
                        factor_display['Total Contribution'] = factor_display['Total Contribution'].apply(
                            lambda x: f"{x:.4f}")
                        st.dataframe(factor_display, use_container_width=True, hide_index=True)
                    
                    if attr_df is not None:
                        st.markdown("#### Holdings Attribution")
                        holdings_attr = attr_df.pivot_table(
                            index='Ticker',
                            columns='Factor',
                            values='Contribution',
                            aggfunc='sum'
                        ).round(4)
                        
                        st.dataframe(holdings_attr, use_container_width=True)
                        
                        st.info("""
                        **Interpretation:**
                        - **Positive values**: Holding increases portfolio exposure to that factor
                        - **Negative values**: Holding decreases portfolio exposure to that factor
                        - Larger absolute values indicate stronger factor influence
                        """)
        else:
            st.error("‚ö†Ô∏è Unable to calculate factor exposures. Need more historical data.")

    # ========================================================================
    # VALUATION HOUSE MODULE (v9.1)
    # ========================================================================
    elif page == "üíé Valuation House":
        st.markdown("## üíé VALUATION HOUSE")
        st.markdown("### Intrinsic Value Analysis with DCF")
        
        st.info("üéØ **Quick Start:** Enter a ticker, select valuation method (FCFF/FCFE), adjust assumptions, and see real-time intrinsic value calculations.")
        
        # Company Search Section
        st.markdown("---")
        st.markdown("#### üîç Company Search")
        
        col1, col2 = st.columns([3, 1])
        
        with col1:
            ticker_input = st.text_input(
                "Enter Ticker Symbol",
                placeholder="e.g., AAPL, MSFT, GOOGL",
                help="Enter any publicly traded company ticker"
            ).upper()
        
        with col2:
            search_button = st.button("üöÄ Load Company", type="primary", use_container_width=True)
        
        if search_button and ticker_input:
            with st.spinner(f"üìä Fetching data for {ticker_input}..."):
                company_data = fetch_company_financials(ticker_input)
                
                if company_data['success']:
                    st.session_state['valuation_company'] = company_data
                    st.success(f"‚úÖ Loaded {company_data['company']['name']}")
                else:
                    st.error(f"‚ùå Could not fetch data for {ticker_input}: {company_data.get('error', 'Unknown error')}")
        
        # Display valuation if company is loaded
        if 'valuation_company' in st.session_state:
            company = st.session_state['valuation_company']['company']
            financials = st.session_state['valuation_company']['financials']
            
            st.markdown("---")
            
            # Company Overview
            st.markdown(f"### üìä {company['name']} ({company['ticker']})")
            
            col1, col2, col3, col4, col5 = st.columns(5)
            col1.metric("Current Price", format_currency(company['current_price']))
            col2.metric("Market Cap", format_large_number(company['market_cap']))
            col3.metric("Sector", company['sector'])
            col4.metric("Beta", f"{company['beta']:.2f}")
            col5.metric("Forward P/E", f"{company.get('forward_pe', 'N/A'):.1f}" if company.get('forward_pe') else "N/A")
            
            st.markdown("---")
            
            # DCF Method Selection
            st.markdown("#### üéØ Valuation Method")
            
            col1, col2 = st.columns([1, 3])
            
            with col1:
                dcf_method = st.radio(
                    "Select DCF Method",
                    options=['FCFF', 'FCFE'],
                    help="FCFF: Free Cash Flow to Firm | FCFE: Free Cash Flow to Equity"
                )
            
            with col2:
                st.markdown(f"""
                **{'Free Cash Flow to Firm (FCFF)' if dcf_method == 'FCFF' else 'Free Cash Flow to Equity (FCFE)'}**
                
                {'Cash flows available to all investors (debt + equity holders). Discounted at WACC.' if dcf_method == 'FCFF' else 'Cash flows available to equity holders only. Discounted at cost of equity.'}
                """)
            
            st.markdown("---")
            
            # Assumptions Panel
            st.markdown("#### üéõÔ∏è Valuation Assumptions")
            
            tab1, tab2, tab3 = st.tabs(["üìà Growth & Operations", "üí∞ Cost of Capital", "üéØ Terminal Value"])
            
            with tab1:
                st.markdown("##### Growth & Operating Assumptions")
                
                col1, col2 = st.columns(2)
                
                with col1:
                    revenue_growth = st.slider(
                        "Revenue Growth Rate (%)",
                        min_value=-10.0,
                        max_value=30.0,
                        value=5.0,
                        step=0.5,
                        help="Expected annual revenue growth rate"
                    ) / 100
                    
                    ebit_margin = st.slider(
                        "EBIT Margin (%)",
                        min_value=0.0,
                        max_value=50.0,
                        value=20.0,
                        step=1.0,
                        help="Operating profit margin"
                    ) / 100
                    
                    forecast_years = st.slider(
                        "Forecast Horizon (Years)",
                        min_value=3,
                        max_value=15,
                        value=5,
                        step=1,
                        help="Number of years to project"
                    )
                
                with col2:
                    capex_pct = st.slider(
                        "CapEx (% of Revenue)",
                        min_value=0.0,
                        max_value=20.0,
                        value=5.0,
                        step=0.5,
                        help="Capital expenditure as % of revenue"
                    ) / 100
                    
                    depreciation_pct = st.slider(
                        "Depreciation (% of Revenue)",
                        min_value=0.0,
                        max_value=15.0,
                        value=3.0,
                        step=0.5,
                        help="Depreciation as % of revenue"
                    ) / 100
                    
                    wc_change = st.number_input(
                        "Working Capital Change ($M)",
                        min_value=-1000.0,
                        max_value=1000.0,
                        value=0.0,
                        step=10.0,
                        help="Annual change in working capital"
                    ) * 1e6
            
            with tab2:
                st.markdown("##### Cost of Capital Assumptions")
                
                col1, col2 = st.columns(2)
                
                with col1:
                    risk_free = st.slider(
                        "Risk-Free Rate (%)",
                        min_value=0.0,
                        max_value=10.0,
                        value=4.5,
                        step=0.1,
                        help="10-year Treasury yield"
                    ) / 100
                    
                    market_risk_premium = st.slider(
                        "Market Risk Premium (%)",
                        min_value=3.0,
                        max_value=10.0,
                        value=6.0,
                        step=0.5,
                        help="Expected market return above risk-free rate"
                    ) / 100
                    
                    beta = st.number_input(
                        "Beta",
                        min_value=0.0,
                        max_value=3.0,
                        value=float(company['beta']) if company['beta'] else 1.0,
                        step=0.1,
                        help="Stock's systematic risk"
                    )
                
                with col2:
                    if dcf_method == 'FCFF':
                        cost_debt = st.slider(
                            "Cost of Debt (%)",
                            min_value=0.0,
                            max_value=15.0,
                            value=5.0,
                            step=0.5,
                            help="Interest rate on debt"
                        ) / 100
                    
                    tax_rate = st.slider(
                        "Tax Rate (%)",
                        min_value=0.0,
                        max_value=40.0,
                        value=float(financials.get('tax_rate', 0.21) * 100),
                        step=1.0,
                        help="Corporate tax rate"
                    ) / 100
                    
                    if dcf_method == 'FCFE':
                        net_borrowing = st.number_input(
                            "Net Borrowing ($M)",
                            min_value=-1000.0,
                            max_value=1000.0,
                            value=0.0,
                            step=10.0,
                            help="Annual net debt increase/(decrease)"
                        ) * 1e6
            
            with tab3:
                st.markdown("##### Terminal Value Assumptions")
                
                col1, col2 = st.columns(2)
                
                with col1:
                    terminal_growth = st.slider(
                        "Perpetual Growth Rate (%)",
                        min_value=0.0,
                        max_value=5.0,
                        value=2.5,
                        step=0.1,
                        help="Long-term growth rate for terminal value"
                    ) / 100
                
                with col2:
                    st.info(f"""
                    **Terminal Value Method:** Gordon Growth Model
                    
                    TV = FCF‚Çô‚Çä‚ÇÅ / (r - g)
                    
                    Where:
                    - FCF‚Çô‚Çä‚ÇÅ = Final year FCF √ó (1 + g)
                    - r = Discount rate
                    - g = Perpetual growth rate
                    """)
            
            st.markdown("---")
            
            # Calculate DCF
            if st.button("üöÄ Calculate Intrinsic Value", type="primary", use_container_width=True):
                with st.spinner("üî¨ Running DCF Analysis..."):
                    
                    # Calculate cost of equity
                    cost_equity = calculate_cost_of_equity(risk_free, beta, market_risk_premium)
                    
                    # Calculate discount rate
                    if dcf_method == 'FCFF':
                        total_debt = financials.get('total_debt', 0)
                        total_equity = company['market_cap']
                        discount_rate = calculate_wacc(cost_equity, cost_debt, tax_rate, total_debt, total_equity)
                    else:
                        discount_rate = cost_equity
                    
                    # Get base financials
                    base_revenue = financials.get('revenue', 0)
                    base_ebit = financials.get('ebit', 0)
                    base_net_income = financials.get('net_income', 0)
                    
                    # Calculate per-year amounts
                    depreciation = base_revenue * depreciation_pct
                    capex = base_revenue * capex_pct
                    
                    # Project cash flows
                    if dcf_method == 'FCFF':
                        projections = project_fcff(
                            base_ebit, revenue_growth, ebit_margin, tax_rate,
                            depreciation, capex, wc_change, forecast_years
                        )
                        final_fcf = projections[-1]['fcff']
                    else:
                        projections = project_fcfe(
                            base_net_income, revenue_growth, tax_rate,
                            depreciation, capex, wc_change, net_borrowing, forecast_years
                        )
                        final_fcf = projections[-1]['fcfe']
                    
                    # Calculate terminal value
                    terminal_value = calculate_terminal_value(final_fcf, discount_rate, terminal_growth)
                    
                    # Calculate DCF value
                    net_debt = financials.get('total_debt', 0) - financials.get('cash', 0)
                    shares = company['shares_outstanding']
                    
                    dcf_results = calculate_dcf_value(
                        projections, discount_rate, terminal_value, shares,
                        net_debt if dcf_method == 'FCFF' else 0, dcf_method
                    )
                    
                    dcf_results['net_debt'] = net_debt
                    
                    # Store results
                    st.session_state['dcf_results'] = dcf_results
                    st.session_state['dcf_projections'] = projections
                    st.session_state['dcf_method'] = dcf_method
                    st.session_state['discount_rate'] = discount_rate
                    st.session_state['terminal_growth'] = terminal_growth
                    
                    st.success("‚úÖ Valuation Complete!")
            
            # Display Results
            if 'dcf_results' in st.session_state:
                results = st.session_state['dcf_results']
                projections = st.session_state['dcf_projections']
                method = st.session_state['dcf_method']
                
                st.markdown("---")
                st.markdown("### üìä Valuation Results")
                
                # Key metrics
                intrinsic_value = results['intrinsic_value_per_share']
                current_price = company['current_price']
                upside_downside = ((intrinsic_value - current_price) / current_price) * 100
                
                col1, col2, col3, col4 = st.columns(4)
                
                col1.metric(
                    "Intrinsic Value",
                    format_currency(intrinsic_value),
                    delta=format_percentage(upside_downside) if abs(upside_downside) < 1000 else "¬±‚àû"
                )
                
                col2.metric(
                    "Current Price",
                    format_currency(current_price)
                )
                
                col3.metric(
                    "Upside/Downside",
                    format_percentage(upside_downside) if abs(upside_downside) < 1000 else "¬±‚àû",
                    delta="Undervalued" if upside_downside > 0 else "Overvalued"
                )
                
                col4.metric(
                    "Discount Rate",
                    format_percentage(st.session_state['discount_rate'] * 100)
                )
                
                # Valuation interpretation
                st.markdown("---")
                
                if upside_downside > 20:
                    st.success(f"""
                    ‚úÖ **Significantly Undervalued**
                    
                    The intrinsic value of ${intrinsic_value:.2f} suggests the stock is trading at a {abs(upside_downside):.1f}% discount to fair value.
                    This represents a potential buying opportunity based on DCF analysis.
                    """)
                elif upside_downside > 0:
                    st.info(f"""
                    üìä **Slightly Undervalued**
                    
                    The intrinsic value of ${intrinsic_value:.2f} suggests modest upside potential of {upside_downside:.1f}%.
                    Stock appears fairly valued with some room for appreciation.
                    """)
                elif upside_downside > -20:
                    st.warning(f"""
                    ‚ö†Ô∏è **Slightly Overvalued**
                    
                    The intrinsic value of ${intrinsic_value:.2f} suggests the stock is trading {abs(upside_downside):.1f}% above fair value.
                    Consider waiting for better entry points.
                    """)
                else:
                    st.error(f"""
                    ‚ùå **Significantly Overvalued**
                    
                    The intrinsic value of ${intrinsic_value:.2f} suggests the stock is trading at a {abs(upside_downside):.1f}% premium to fair value.
                    High risk of downside based on current DCF assumptions.
                    """)
                
                st.markdown("---")
                
                # Visualizations
                col1, col2 = st.columns(2)
                
                with col1:
                    waterfall = create_dcf_waterfall(results, method)
                    st.plotly_chart(waterfall, use_container_width=True)
                
                with col2:
                    cf_chart = create_cash_flow_chart(projections, method)
                    st.plotly_chart(cf_chart, use_container_width=True)
                
                # Sensitivity Analysis
                st.markdown("---")
                st.markdown("#### üéØ Sensitivity Analysis")
                
                sensitivity = create_sensitivity_table(
                    intrinsic_value,
                    st.session_state['discount_rate'],
                    st.session_state['terminal_growth']
                )
                st.plotly_chart(sensitivity, use_container_width=True)
                
                # Detailed Projections Table
                st.markdown("---")
                st.markdown("#### üìã Detailed Cash Flow Projections")
                
                proj_df = pd.DataFrame(projections)
                
                # Format for display
                if method == 'FCFF':
                    display_cols = ['year', 'ebit', 'nopat', 'depreciation', 'capex', 'change_wc', 'fcff']
                    col_names = ['Year', 'EBIT', 'NOPAT', 'D&A', 'CapEx', 'ŒîWC', 'FCFF']
                else:
                    display_cols = ['year', 'net_income', 'depreciation', 'capex', 'change_wc', 'net_borrowing', 'fcfe']
                    col_names = ['Year', 'Net Income', 'D&A', 'CapEx', 'ŒîWC', 'Borrowing', 'FCFE']
                
                proj_display = proj_df[display_cols].copy()
                proj_display.columns = col_names
                
                # Format numbers
                for col in proj_display.columns:
                    if col != 'Year':
                        proj_display[col] = proj_display[col].apply(format_large_number)
                
                st.dataframe(proj_display, use_container_width=True, hide_index=True)
                
                # Export Options
                st.markdown("---")
                col1, col2, col3 = st.columns(3)
                
                with col1:
                    if st.button("üì• Export to Excel", use_container_width=True):
                        st.info("Excel export feature coming soon!")
                
                with col2:
                    if st.button("üìÑ Generate PDF Report", use_container_width=True):
                        st.info("PDF export feature coming soon!")
                
                with col3:
                    if st.button("üîÑ Reset Valuation", use_container_width=True):
                        if 'dcf_results' in st.session_state:
                            del st.session_state['dcf_results']
                        if 'dcf_projections' in st.session_state:
                            del st.session_state['dcf_projections']
                        st.rerun()
        
        else:
            # No company loaded - show instructions
            st.markdown("---")
            st.markdown("""
            ### üìö How to Use Valuation House
            
            **Step 1: Search for a Company**
            - Enter any publicly traded ticker symbol (e.g., AAPL, MSFT, TSLA)
            - Click "Load Company" to fetch financial data
            
            **Step 2: Choose Valuation Method**
            - **FCFF (Free Cash Flow to Firm):** Values entire enterprise, then subtracts debt
            - **FCFE (Free Cash Flow to Equity):** Direct equity valuation
            
            **Step 3: Adjust Assumptions**
            - Growth rates, margins, capital expenditure
            - Cost of capital (WACC or cost of equity)
            - Terminal value assumptions
            
            **Step 4: Calculate & Analyze**
            - Click "Calculate Intrinsic Value"
            - Review valuation vs. current price
            - Analyze sensitivity to key assumptions
            
            ---
            
            ### üí° Pro Tips
            
            - **Compare Methods:** Run both FCFF and FCFE to cross-check results
            - **Sensitivity Analysis:** Test multiple scenarios (bull/base/bear)
            - **Quality Check:** Ensure financial data is reasonable and complete
            - **Context Matters:** Consider industry dynamics, competitive position, and macro factors
            
            ---
            
            *Ready to start? Enter a ticker symbol above!* üöÄ
            """)

    # ========================================================================
    # ABOUT
    # ========================================================================
    elif page == "‚ÑπÔ∏è About":
        st.markdown("### ‚ÑπÔ∏è ATLAS Terminal v9.1 COMPLETE")
        st.success("""
        **ATLAS v9.1 COMPLETE - FULL COMBINED EDITION** üî•üíé

        **ALL FEATURES INCLUDED:**
        
        ‚úÖ **Phoenix Parser** - Upload trade/account history to rebuild portfolio
        ‚úÖ **Portfolio Home** - Enhanced holdings table with real-time data
        ‚úÖ **Market Watch** - Global indices, ETFs, and commodities tracking
        ‚úÖ **Risk Analysis** - 8+ world-class visualizations including:
           - Rolling metrics (volatility, Sharpe ratio)
           - Underwater plot (drawdown analysis)
           - VaR/CVaR waterfall
           - Risk contribution sunburst
           - Efficient frontier
           - Risk parity analysis
           - Correlation network
           - Monte Carlo simulation
        
        ‚úÖ **Performance Suite** - Interactive performance comparison and analytics
           - Multi-ticker performance charts
           - Performance dashboard (4 charts)
           - Comprehensive metrics table
        
        ‚úÖ **Portfolio Deep Dive** - Attribution and sector analysis
           - Portfolio heatmap (treemap)
           - Sector rotation heatmap
           - Holdings attribution waterfall
           - Concentration gauge
        
        ‚úÖ **Multi-Factor Analysis** - Factor exposure and attribution
           - Factor momentum charts
           - Factor exposure radar
           - Holdings factor attribution
           - Regression-based factor analysis
        
        ‚úÖ **Valuation House** - DCF valuation engine (NEW in v9.1)
           - FCFF (Free Cash Flow to Firm) valuation
           - FCFE (Free Cash Flow to Equity) valuation
           - Real-time adjustable assumptions
           - Cost of capital calculations (WACC, CAPM)
           - Terminal value using Gordon Growth Model
           - Sensitivity analysis
           - Professional valuation charts
           - Detailed cash flow projections
        
        **TECHNICAL FEATURES:**
        - 150+ total features
        - 100+ visualizations
        - Real-time market data via Yahoo Finance
        - Advanced risk metrics (Sharpe, Sortino, Calmar, VaR, CVaR)
        - Portfolio optimization (efficient frontier)
        - Factor regression models
        - Monte Carlo simulation
        - Correlation analysis
        
        **Total: 150+ Features in One Platform!**
        
        ---
        
        **Quick Start Guide:**
        
        1. **Phoenix Parser**: Upload your brokerage files to build portfolio
        2. **Portfolio Home**: View holdings with live prices and metrics
        3. **Risk Analysis**: Explore 8+ advanced risk visualizations
        4. **Performance Suite**: Track returns vs benchmarks
        5. **Portfolio Deep Dive**: Analyze attribution and concentration
        6. **Multi-Factor Analysis**: Understand factor exposures
        7. **Valuation House**: Analyze any stock's intrinsic value using DCF
        8. **Market Watch**: Monitor global markets in real-time
        
        ---
        
        **Built with:**
        - Streamlit (UI framework)
        - yfinance (market data)
        - Plotly (interactive charts)
        - Pandas & NumPy (data processing)
        - scikit-learn (factor analysis)
        - NetworkX (correlation networks)
        - SciPy (statistical analysis)
        """)
        
        st.markdown("---")
        st.markdown("### üéØ Version History")
        st.info("""
        **v9.1 COMPLETE** (Current)
        - ‚úÖ All v8.8 features preserved
        - ‚úÖ Valuation House module added
        - ‚úÖ FCFF/FCFE DCF calculations
        - ‚úÖ Real-time assumption adjustments
        - ‚úÖ Professional valuation visualizations
        
        **v8.8**
        - ‚úÖ Enhanced Risk Analysis (8+ charts)
        - ‚úÖ Enhanced Portfolio Deep Dive
        - ‚úÖ Enhanced Multi-Factor Analysis
        - ‚úÖ Fixed efficient frontier broadcasting error
        
        **Earlier versions**
        - v8.7.1: Core analytics
        - v8.0: Phoenix Parser
        - v7.0: Initial release
        """)
        
        st.markdown("---")
        st.markdown("### üöÄ Coming Soon")
        st.info("""
        **Phase 2 Enhancements:**
        - Alternative valuation methods (DDM, Multiples, Sum-of-Parts)
        - Peer comparison and relative valuation
        - Scenario builder with Monte Carlo for valuations
        - ML-powered projection guidance
        - Historical backtest framework
        - Options analytics module
        - Real-time alerts and notifications
        - Excel/PDF export functionality
        - Custom dashboard builder
        - API integration for automated portfolio updates
        """)

if __name__ == "__main__":
    main()
'''

# Write app
with open("atlas_app.py", "w", encoding="utf-8") as f:
    f.write(app_code)

print("‚úÖ ATLAS v9.1 COMPLETE - FULL COMBINED EDITION created!")

# ============================================================================
# RUN APP
# ============================================================================
print("\n" + "="*80)
print("üöÄ LAUNCHING ATLAS TERMINAL v9.1 COMPLETE - FULL COMBINED EDITION")
print("="*80)
print("‚ú® COMPLETE FEATURE SET:")
print("  ‚úÖ Phoenix Parser (v8.8)")
print("  ‚úÖ Portfolio Home (v8.8)")
print("  ‚úÖ Market Watch (v8.8)")
print("  ‚úÖ Risk Analysis (v8.8) - 8+ WORLD-CLASS CHARTS")
print("  ‚úÖ Performance Suite (v8.8) - COMPLETE")
print("  ‚úÖ Portfolio Deep Dive (v8.8) - COMPLETE")
print("  ‚úÖ Multi-Factor Analysis (v8.8) - COMPLETE")
print("  ‚úÖ Valuation House (v9.1) - DCF ENGINE")
print("\nüéâ ALL FEATURES FROM BOTH CODEBASES COMBINED!")
print("üíé 150+ Features | 100+ Visualizations")
print("="*80)

import threading

def run_streamlit():
    os.system("streamlit run atlas_app.py --server.port 8501 --server.headless true")

streamlit_thread = threading.Thread(target=run_streamlit, daemon=True)
streamlit_thread.start()

time.sleep(8)

public_url = ngrok.connect(8501)

print(f"\n‚úÖ ATLAS TERMINAL v9.1 COMPLETE is LIVE!")
print(f"üåê Access URL: {public_url}")
print(f"\nüéâ UNIFIED PLATFORM - EVERYTHING INCLUDED:")
print(f"   üî• Portfolio Analytics (from v8.8)")
print(f"   üìä 8+ Risk Visualizations")
print(f"   üî¨ Portfolio Deep Dive")
print(f"   üìà Multi-Factor Analysis")
print(f"   üíé Valuation House (from v9.1)")
print(f"   üåç Market Watch")
print(f"   ‚ö° Monte Carlo Simulation")
print(f"   üéØ Efficient Frontier")
print(f"   üîó Correlation Networks")
print("="*80)
print("üíé THE COMPLETE ULTIMATE INVESTMENT ANALYSIS PLATFORM!")
print("üî• Everything from v8.8 + Valuation House = 150+ Features!")
print("="*80)

try:
    while True:
        time.sleep(1)
except KeyboardInterrupt:
    print("\n\nüëã Shutting down...")
    ngrok.disconnect(public_url)

# üéØ Sensitivity Analysis
fig.update_layout(
    title="üéØ Sensitivity Analysis",
    xaxis_title="Discount Rate",
    yaxis_title="Terminal Growth Rate",
    height=400,
    paper_bgcolor=COLORS['background'],
    plot_bgcolor=COLORS['card_background'],
    font=dict(color=COLORS['text_primary'])
)

return fig


# ============================================================================
# PHOENIX PARSER
# ============================================================================

def parse_trade_history_file(uploaded_file):
    try:
        df = pd.read_html(uploaded_file)[0]
        required_cols = ['Date', 'Symbol', 'Trade Type', 'Quantity', 'Price']
        if not all(col in df.columns for col in required_cols):
            return None
        df['Price'] = df['Price'].astype(str).str.replace('$', '').str.replace(',', '').astype(float)
        df['Date'] = pd.to_datetime(df['Date'])
        df = df.sort_values('Date')
        return df
    except:
        return None

def parse_account_history_file(uploaded_file):
    try:
        df = pd.read_html(uploaded_file)[0]
        df['Date'] = pd.to_datetime(df['Date'])
        df = df.sort_values('Date')
        return df
    except:
        return None

def calculate_portfolio_from_trades(trade_df):
    holdings = {}
    for _, row in trade_df.iterrows():
        symbol = row['Symbol']
        trade_type = row['Trade Type']
        quantity = row['Quantity']
        price = row['Price']

        if is_option_ticker(symbol):
            continue

        if symbol not in holdings:
            holdings[symbol] = {'total_shares': 0, 'total_cost': 0, 'trades': []}

        is_buy = 'Buy' in trade_type

        if is_buy:
            holdings[symbol]['total_shares'] += quantity
            holdings[symbol]['total_cost'] += (quantity * price)
            holdings[symbol]['trades'].append({'type': 'BUY', 'quantity': quantity, 'price': price})
        else:
            remaining_to_sell = quantity
            for trade in holdings[symbol]['trades']:
                if trade['type'] == 'BUY' and remaining_to_sell > 0:
                    if trade['quantity'] <= remaining_to_sell:
                        holdings[symbol]['total_cost'] -= (trade['quantity'] * trade['price'])
                        holdings[symbol]['total_shares'] -= trade['quantity']
                        remaining_to_sell -= trade['quantity']
                        trade['quantity'] = 0
                    else:
                        holdings[symbol]['total_cost'] -= (remaining_to_sell * trade['price'])
                        holdings[symbol]['total_shares'] -= remaining_to_sell
                        trade['quantity'] -= remaining_to_sell
                        remaining_to_sell = 0

    portfolio_data = []
    for symbol, data in holdings.items():
        if data['total_shares'] > 0:
            avg_cost = data['total_cost'] / data['total_shares']
            portfolio_data.append({
                'Ticker': symbol,
                'Shares': data['total_shares'],
                'Avg Cost': avg_cost
            })

    if not portfolio_data:
        return pd.DataFrame(columns=['Ticker', 'Shares', 'Avg Cost'])
    return pd.DataFrame(portfolio_data).sort_values('Ticker')

# ============================================================================
# ENHANCED HOLDINGS TABLE
# ============================================================================

def create_enhanced_holdings_table(df):
    enhanced_df = df.copy()

    for idx, row in enhanced_df.iterrows():
        ticker = row['Ticker']
        market_data = fetch_market_data(ticker)

        if market_data:
            enhanced_df.at[idx, 'Asset Name'] = market_data['company_name']
            enhanced_df.at[idx, 'Current Price'] = market_data['price']
            enhanced_df.at[idx, 'Daily Change'] = market_data['daily_change']
            enhanced_df.at[idx, 'Daily Change %'] = market_data['daily_change_pct']
            enhanced_df.at[idx, 'Beta'] = market_data.get('beta', 'N/A')
            base_sector = market_data.get('sector', 'Unknown')
            enhanced_df.at[idx, 'Sector'] = classify_ticker_sector(ticker, base_sector)
        else:
            enhanced_df.at[idx, 'Asset Name'] = ticker
            enhanced_df.at[idx, 'Sector'] = 'Other'

    enhanced_df['Sector'] = enhanced_df['Sector'].fillna('Other')
    enhanced_df['Shares'] = enhanced_df['Shares'].round(0).astype(int)

    enhanced_df['Total Cost'] = enhanced_df['Shares'] * enhanced_df['Avg Cost']
    enhanced_df['Total Value'] = enhanced_df['Shares'] * enhanced_df['Current Price']
    enhanced_df['Total Gain/Loss' ] = enhanced_df['Total Value'] - enhanced_df['Total Cost']
    enhanced_df['Total Gain/Loss %'] = ((enhanced_df['Current Price'] - enhanced_df['Avg Cost']) / enhanced_df['Avg Cost']) * 100
    enhanced_df['Daily P&L' ] = enhanced_df['Shares'] * enhanced_df['Daily Change']

    total_value = enhanced_df['Total Value'].sum()
    enhanced_df['Weight %'] = (enhanced_df['Total Value'] / total_value * 100) if total_value > 0 else 0

    return enhanced_df

def style_holdings_dataframe(df):
    display_df = df[[
        'Ticker', 'Asset Name', 'Shares', 'Avg Cost', 'Current Price',
        'Daily Change %', 'Weight %', 'Daily P&L' ,
        'Total Gain/Loss' , 'Total Gain/Loss %', 'Beta'
    ]].copy()

    pct_cols = ['Daily Change %', 'Weight %', 'Total Gain/Loss %']
    for col in pct_cols:
        display_df[col] = display_df[col].apply(lambda x: format_percentage(x))

    currency_cols = ['Avg Cost', 'Current Price', 'Daily P&L' , 'Total Gain/Loss' ]
    for col in currency_cols:
        display_df[col] = display_df[col].apply(format_currency)

    display_df['Daily Change %'] = display_df['Daily Change %'].apply(add_arrow_indicator)
    display_df['Total Gain/Loss %'] = display_df['Total Gain/Loss %'].apply(add_arrow_indicator)

    return display_df

# ============================================================================
# RISK METRICS (v8.8 COMPLETE)
# ============================================================================

def calculate_sharpe_ratio(returns, risk_free_rate=RISK_FREE_RATE):
    if not is_valid_series(returns) or len(returns) < 2:
        return None
    total_return = (1 + returns).prod() - 1
    n_years = len(returns) / 252
    annualized_return = (1 + total_return) ** (1/n_years) - 1 if n_years > 0 else 0
    annualized_vol = returns.std() * np.sqrt(252)
    sharpe = (annualized_return - risk_free_rate) / annualized_vol if annualized_vol > 0 else 0
    return sharpe

def calculate_sortino_ratio(returns, risk_free_rate=RISK_FREE_RATE):
    if not is_valid_series(returns) or len(returns) < 2:
        return None
    total_return = (1 + returns).prod() - 1
    n_years = len(returns) / 252
    annualized_return = (1 + total_return) ** (1/n_years) - 1 if n_years > 0 else 0
    downside_returns = returns[returns < 0]
    if len(downside_returns) < 2:
        return None
    downside_std = downside_returns.std() * np.sqrt(252)
    sortino = (annualized_return - risk_free_rate) / downside_std if downside_std > 0 else 0
    return sortino

def calculate_calmar_ratio(returns, risk_free_rate=RISK_FREE_RATE):
    if not is_valid_series(returns) or len(returns) < 2:
        return None
    total_return = (1 + returns).prod() - 1
    n_years = len(returns) / 252
    annualized_return = (1 + total_return) ** (1/n_years) - 1 if n_years > 0 else 0
    max_dd = abs(calculate_max_drawdown(returns))
    if max_dd == 0:
        return 0
    return (annualized_return - risk_free_rate) / (max_dd / 100)

def calculate_information_ratio(portfolio_returns, benchmark_returns):
    if not is_valid_series(portfolio_returns) or not is_valid_series(benchmark_returns):
        return None
    if len(portfolio_returns) < 2 or len(benchmark_returns) < 2:
        return None
    common_dates = portfolio_returns.index.intersection(benchmark_returns.index)
    portfolio_returns = portfolio_returns.loc[common_dates]
    benchmark_returns = benchmark_returns.loc[common_dates]
    excess_returns = portfolio_returns - benchmark_returns
    if len(excess_returns) < 2:
        return None
    total_excess = (1 + excess_returns).prod() - 1
    n_years = len(excess_returns) / 252
    annualized_excess = (1 + total_excess) ** (1/n_years) - 1 if n_years > 0 else 0
    tracking_error = excess_returns.std() * np.sqrt(252)
    info_ratio = annualized_excess / tracking_error if tracking_error > 0 else 0
    return info_ratio

def calculate_var(returns, confidence=0.95):
    if not is_valid_series(returns) or len(returns) < 2:
        return None
    var = np.percentile(returns, (1 - confidence) * 100)
    return var * 100

def calculate_cvar(returns, confidence=0.95):
    if not is_valid_series(returns) or len(returns) < 2:
        return None
    var = np.percentile(returns, (1 - confidence) * 100)
    cvar = returns[returns <= var].mean()
    return cvar * 100

def calculate_max_drawdown(returns):
    if not is_valid_series(returns) or len(returns) < 2:
        return None
    cumulative = (1 + returns).cumprod()
    running_max = cumulative.expanding().max()
    drawdown = (cumulative - running_max) / running_max
    return drawdown.min() * 100

@st.cache_data(ttl=600)
def calculate_portfolio_returns(df, start_date, end_date):
    try:
        valid_positions = []
        for _, row in df.iterrows():
            if not is_option_ticker(row['Ticker']):
                valid_positions.append(row)
        
        if not valid_positions:
            return None
        
        valid_df = pd.DataFrame(valid_positions)
        all_data = {}
        
        for _, row in valid_df.iterrows():
            ticker = row['Ticker']
            data = fetch_historical_data(ticker, start_date, end_date)
            if data is not None and len(data) > 0:
                all_data[ticker] = data
        
        if not all_data:
            return None
        
        common_dates = None
        for ticker, data in all_data.items():
            dates = set(data.index)
            common_dates = dates if common_dates is None else common_dates.intersection(dates)
        
        common_dates = sorted(list(common_dates))
        if len(common_dates) < 2:
            return None
        
        portfolio_values = []
        for date in common_dates:
            daily_value = 0
            for _, row in valid_df.iterrows():
                ticker = row['Ticker']
                if ticker in all_data:
                    try:
                        price = all_data[ticker].loc[date, 'Close']
                        daily_value += price * row['Shares']
                    except KeyError:
                        continue
            portfolio_values.append(daily_value)
        
        portfolio_series = pd.Series(portfolio_values, index=common_dates)
        returns = portfolio_series.pct_change().dropna()
        return returns
    except:
        return None

@st.cache_data(ttl=600)
def calculate_benchmark_returns(benchmark_ticker, start_date, end_date):
    try:
        data = fetch_historical_data(benchmark_ticker, start_date, end_date)
        if data is None or data.empty:
            return None
        returns = data['Close'].pct_change().dropna()
        return returns
    except:
        return None

# ============================================================================
# WORLD-CLASS VISUALIZATIONS (v8.8 COMPLETE)
# ============================================================================

def create_rolling_metrics_chart(returns, window=60):
    """Rolling metrics visualization"""
    if not is_valid_series(returns) or len(returns) < window:
        return None
    
    rolling_vol = returns.rolling(window).std() * np.sqrt(252) * 100
    rolling_sharpe = (returns.rolling(window).mean() * 252 - RISK_FREE_RATE) / (returns.rolling(window).std() * np.sqrt(252))
    
    fig = make_subplots(
        rows=2, cols=1,
        subplot_titles=('Rolling Volatility (60-Day)', 'Rolling Sharpe Ratio (60-Day)'),
        vertical_spacing=0.15
    )
    
    fig.add_trace(
        go.Scatter(
            x=rolling_vol.index,
            y=rolling_vol.values,
            fill='tozeroy',
            fillcolor='rgba(255, 0, 68, 0.2)',
            line=dict(color=COLORS['danger'], width=2),
            name='Volatility'
        ),
        row=1, col=1
    )
    
    fig.add_trace(
        go.Scatter(
            x=rolling_sharpe.index,
            y=rolling_sharpe.values,
            fill='tozeroy',
            fillcolor='rgba(0, 212, 255, 0.2)',
            line=dict(color=COLORS['neon_blue'], width=2),
            name='Sharpe Ratio'
        ),
        row=2, col=1
    )
    
    fig.add_hline(y=0, line_dash="dash", line_color=COLORS['text_muted'], row=2, col=1)
    
    fig.update_layout(
        height=600,
        showlegend=False,
        title_text="üìä Rolling Risk Metrics",
        paper_bgcolor=COLORS['background'],
        plot_bgcolor=COLORS['card_background'],
        font=dict(color=COLORS['text_primary'])
    )
    
    return fig

def create_underwater_plot(returns):
    """Underwater drawdown plot"""
    if not is_valid_series(returns) or len(returns) < 2:
        return None
    
    cumulative = (1 + returns).cumprod()
    running_max = cumulative.expanding().max()
    drawdown = ((cumulative - running_max) / running_max) * 100
    
    fig = go.Figure()
    
    fig.add_trace(go.Scatter(
        x=drawdown.index,
        y=drawdown.values,
        fill='tozeroy',
        fillcolor='rgba(255, 0, 68, 0.3)',
        line=dict(color=COLORS['danger'], width=2),
        name='Drawdown'
    ))
    
    fig.add_hline(y=0, line_dash="solid", line_color=COLORS['text_primary'], line_width=1)
    
    max_dd_idx = drawdown.idxmin()
    max_dd_val = drawdown.min()
    
    fig.add_annotation(
        x=max_dd_idx,
        y=max_dd_val,
        text=f"Max DD: {max_dd_val:.2f}%",
        showarrow=True,
        arrowhead=2,
        arrowcolor=COLORS['danger'],
        ax=0,
        ay=-40,
        bgcolor=COLORS['card_background'],
        bordercolor=COLORS['danger'],
        borderwidth=2
    )
    
    fig.update_layout(
        title="üåä Underwater Plot",
        xaxis_title="Date",
        yaxis_title="Drawdown (%)",
        height=500,
        paper_bgcolor=COLORS['background'],
        plot_bgcolor=COLORS['card_background'],
        font=dict(color=COLORS['text_primary'])
    )
    
    return fig

def create_var_waterfall(returns):
    """VaR/CVaR waterfall chart"""
    if not is_valid_series(returns) or len(returns) < 2:
        return None
    
    var_90 = calculate_var(returns, 0.90)
    var_95 = calculate_var(returns, 0.95)
    var_99 = calculate_var(returns, 0.99)
    cvar_95 = calculate_cvar(returns, 0.95)
    
    categories = ['VaR 90%', 'VaR 95%', 'VaR 99%', 'CVaR 95%']
    values = [var_90, var_95, var_99, cvar_95]
    
    colors_list = [COLORS['warning'], COLORS['orange'], COLORS['danger'], COLORS['danger']]
    
    fig = go.Figure()
    
    fig.add_trace(go.Bar(
        x=categories,
        y=values,
        marker=dict(
            color=colors_list,
            line=dict(color=COLORS['border'], width=2)
        ),
        text=[f"{v:.2f}%" for v in values],
        textposition='outside'
    ))
    
    fig.update_layout(
        title="‚ö†Ô∏è Value at Risk Waterfall",
        xaxis_title="Risk Measure",
        yaxis_title="Expected Loss (%)",
        height=500,
        paper_bgcolor=COLORS['background'],
        plot_bgcolor=COLORS['card_background'],
        font=dict(color=COLORS['text_primary'])
    )
    
    return fig

def create_risk_contribution_sunburst(df):
    """Risk contribution sunburst"""
    risk_data = []
    
    for _, row in df.iterrows():
        ticker = row['Ticker']
        weight = row['Weight %']
        sector = row['Sector']
        
        hist_data = fetch_historical_data(ticker, datetime.now() - timedelta(days=365), datetime.now())
        if hist_data is not None and len(hist_data) > 30:
            returns = hist_data['Close'].pct_change().dropna()
            vol = returns.std() * np.sqrt(252) * 100
            risk_contribution = weight * vol
            
            risk_data.append({
                'Ticker': ticker,
                'Sector': sector,
                'Weight': weight,
                'Volatility': vol,
                'Risk Contribution': risk_contribution
            })
    
    if not risk_data:
        return None
    
    risk_df = pd.DataFrame(risk_data)
    
    fig = px.sunburst(
        risk_df,
        path=['Sector', 'Ticker'],
        values='Risk Contribution',
        color='Volatility',
        color_continuous_scale='RdYlGn_r',
        title="‚òÄÔ∏è Risk Contribution Sunburst"
    )
    
    fig.update_layout(
        height=600,
        paper_bgcolor=COLORS['background'],
        font=dict(color=COLORS['text_primary'])
    )
    
    return fig

def create_risk_reward_plot(df):
    """Risk-reward scatter plot"""
    risk_reward_data = []
    
    for _, row in df.iterrows():
        ticker = row['Ticker']
        hist_data = fetch_historical_data(ticker, datetime.now() - timedelta(days=365), datetime.now())
        
        if hist_data is not None and len(hist_data) > 30:
            returns = hist_data['Close'].pct_change().dropna()
            annual_return = ((1 + returns.mean()) ** 252 - 1) * 100
            annual_vol = returns.std() * np.sqrt(252) * 100
            
            risk_reward_data.append({
                'Ticker': ticker,
                'Asset Name': row['Asset Name'],
                'Return': annual_return,
                'Risk': annual_vol,
                'Weight': row['Weight %'],
                'Sector': row['Sector']
            })
    
    if not risk_reward_data:
        return None
    
    rr_df = pd.DataFrame(risk_reward_data)
    
    fig = px.scatter(
        rr_df,
        x='Risk',
        y='Return',
        size='Weight',
        color='Sector',
        text='Ticker',
        hover_data=['Asset Name'],
        color_discrete_sequence=px.colors.qualitative.Set3
    )
    
    fig.update_traces(
        textposition='top center',
        marker=dict(line=dict(width=2, color=COLORS['border']))
    )
    
    fig.update_layout(
        title="üìà Risk-Reward Analysis",
        xaxis_title="Risk (Annual Volatility %)",
        yaxis_title="Expected Return (Annual %)",
        height=500,
        paper_bgcolor=COLORS['background'],
        plot_bgcolor=COLORS['card_background'],
        font=dict(color=COLORS['text_primary'])
    )
    
    return fig

def create_efficient_frontier(df):
    """FIXED BROADCASTING ERROR - Efficient Frontier"""
    returns_data = {}
    expected_returns = []
    volatilities = []
    tickers = []
    
    for _, row in df.iterrows():
        ticker = row['Ticker']
        hist_data = fetch_historical_data(ticker, datetime.now() - timedelta(days=365), datetime.now())
        
        if hist_data is not None and len(hist_data) > 30:
            returns = hist_data['Close'].pct_change().dropna()
            annual_return = ((1 + returns.mean()) ** 252 - 1)
            annual_vol = returns.std() * np.sqrt(252)
            
            expected_returns.append(annual_return)
            volatilities.append(annual_vol)
            tickers.append(ticker)
            returns_data[ticker] = returns
    
    if len(expected_returns) < 2:
        return None
    
    returns_df = pd.DataFrame(returns_data)
    cov_matrix = returns_df.cov() * 252
    
    num_portfolios = 5000
    results = np.zeros((3, num_portfolios))
    
    np.random.seed(42)
    
    for i in range(num_portfolios):
        weights = np.random.random(len(tickers))
        weights /= np.sum(weights)
        
        portfolio_return = np.sum(weights * np.array(expected_returns))
        portfolio_vol = np.sqrt(np.dot(weights.T, np.dot(cov_matrix, weights)))
        sharpe = (portfolio_return - RISK_FREE_RATE) / portfolio_vol if portfolio_vol > 0 else 0
        
        results[0, i] = portfolio_return * 100
        results[1, i] = portfolio_vol * 100
        results[2, i] = sharpe
    
    fig = go.Figure()
    
    fig.add_trace(go.Scatter(
        x=results[1],
        y=results[0],
        mode='markers',
        marker=dict(
            size=5,
            color=results[2],
            colorscale='Viridis',
            showscale=True,
            colorbar=dict(title="Sharpe Ratio")
        ),
        name='Efficient Frontier'
    ))
    
    # FIXED: Properly align weights and returns
    current_weights = df[df['Ticker'].isin(tickers)]['Weight %'].values / 100
    aligned_returns = np.array(expected_returns[:len(current_weights)])
    aligned_cov = cov_matrix.iloc[:len(current_weights), :len(current_weights)]
    
    current_return = np.sum(current_weights * aligned_returns) * 100
    current_vol = np.sqrt(np.dot(current_weights.T, np.dot(aligned_cov, current_weights))) * 100
    
    fig.add_trace(go.Scatter(
        x=[current_vol],
        y=[current_return],
        mode='markers',
        marker=dict(size=20, color=COLORS['danger'], symbol='star'),
        name='Current Portfolio'
    ))
    
    fig.update_layout(
        title="üìä Efficient Frontier",
        xaxis_title="Risk (Volatility %)",
        yaxis_title="Return %",
        height=600,
        paper_bgcolor=COLORS['background'],
        plot_bgcolor=COLORS['card_background'],
        font=dict(color=COLORS['text_primary'])
    )
    
    return fig

def create_risk_parity_analysis(df):
    """Risk parity analysis"""
    risk_contributions = []
    
    for _, row in df.iterrows():
        ticker = row['Ticker']
        weight = row['Weight %'] / 100
        
        hist_data = fetch_historical_data(ticker, datetime.now() - timedelta(days=365), datetime.now())
        if hist_data is not None and len(hist_data) > 30:
            returns = hist_data['Close'].pct_change().dropna()
            vol = returns.std() * np.sqrt(252)
            risk_contribution = weight * vol
            
            risk_contributions.append({
                'Ticker': ticker,
                'Weight %': row['Weight %'],
                'Volatility': vol * 100,
                'Risk Contribution': risk_contribution * 100
            })
    
    if not risk_contributions:
        return None
    
    rc_df = pd.DataFrame(risk_contributions)
    total_risk = rc_df['Risk Contribution'].sum()
    rc_df['Risk %'] = (rc_df['Risk Contribution'] / total_risk) * 100
    
    fig = go.Figure()
    
    fig.add_trace(go.Bar(
        name='Weight %',
        x=rc_df['Ticker'],
        y=rc_df['Weight %'],
        marker_color=COLORS['electric_blue']
    ))
    
    fig.add_trace(go.Bar(
        name='Risk Contribution %',
        x=rc_df['Ticker'],
        y=rc_df['Risk %'],
        marker_color=COLORS['danger']
    ))
    
    fig.update_layout(
        title="‚öñÔ∏è Risk Parity Analysis",
        xaxis_title="Asset",
        yaxis_title="Percentage",
        barmode='group',
        height=500,
        paper_bgcolor=COLORS['background'],
        plot_bgcolor=COLORS['card_background'],
        font=dict(color=COLORS['text_primary'])
    )
    
    return fig

def create_correlation_network(df, start_date, end_date):
    """Correlation network graph"""
    returns_data = {}
    
    for _, row in df.iterrows():
        ticker = row['Ticker']
        hist_data = fetch_historical_data(ticker, start_date, end_date)
        if hist_data is not None and len(hist_data) > 30:
            returns_data[ticker] = hist_data['Close'].pct_change().dropna()
    
    if len(returns_data) < 2:
        return None
    
    returns_df = pd.DataFrame(returns_data)
    corr_matrix = returns_df.corr()
    
    fig = go.Figure()
    
    G = nx.Graph()
    for ticker in corr_matrix.columns:
        G.add_node(ticker)
    
    threshold = 0.5
    for i, ticker1 in enumerate(corr_matrix.columns):
        for j, ticker2 in enumerate(corr_matrix.columns):
            if i < j:
                corr = corr_matrix.iloc[i, j]
                if abs(corr) > threshold:
                    G.add_edge(ticker1, ticker2, weight=abs(corr))
    
    pos = nx.spring_layout(G)
    
    for edge in G.edges():
        x0, y0 = pos[edge[0]]
        x1, y1 = pos[edge[1]]
        weight = G[edge[0]][edge[1]]['weight']
        
        fig.add_trace(go.Scatter(
            x=[x0, x1],
            y=[y0, y1],
            mode='lines',
            line=dict(width=weight*5, color=COLORS['electric_blue']),
            opacity=0.5,
            showlegend=False
        ))
    
    node_x = []
    node_y = []
    node_text = []
    
    for node in G.nodes():
        x, y = pos[node]
        node_x.append(x)
        node_y.append(y)
        node_text.append(node)
    
    fig.add_trace(go.Scatter(
        x=node_x,
        y=node_y,
        mode='markers+text',
        text=node_text,
        textposition='top center',
        marker=dict(
            size=20,
            color=COLORS['neon_blue'],
            line=dict(width=2, color=COLORS['border'])
        ),
        showlegend=False
    ))
    
    fig.update_layout(
        title="üîó Correlation Network",
        showlegend=False,
        height=600,
        paper_bgcolor=COLORS['background'],
        plot_bgcolor=COLORS['card_background'],
        font=dict(color=COLORS['text_primary']),
        xaxis=dict(showgrid=False, zeroline=False, showticklabels=False),
        yaxis=dict(showgrid=False, zeroline=False, showticklabels=False)
    )
    
    return fig

def run_monte_carlo_simulation(returns, initial_value=100000, days=252, simulations=1000):
    """Monte Carlo simulation"""
    if not is_valid_series(returns) or len(returns) < 30:
        return None
    
    daily_return = returns.mean()
    daily_vol = returns.std()
    
    simulation_results = []
    
    for _ in range(simulations):
        prices = [initial_value]
        for _ in range(days):
            price = prices[-1] * (1 + np.random.normal(daily_return, daily_vol))
            prices.append(price)
        simulation_results.append(prices)
    
    return np.array(simulation_results)

def create_monte_carlo_chart(simulation_results, initial_value=100000):
    """Monte Carlo visualization"""
    if simulation_results is None:
        return None, None
    
    fig = go.Figure()
    
    for i in range(min(100, len(simulation_results))):
        fig.add_trace(go.Scatter(
            y=simulation_results[i],
            mode='lines',
            line=dict(width=0.5, color=COLORS['electric_blue']),
            opacity=0.1,
            showlegend=False
        ))
    
    percentiles = [5, 25, 50, 75, 95]
    colors_pct = [COLORS['danger'], COLORS['warning'], COLORS['info'], 
                  COLORS['teal'], COLORS['success']]
    
    for p, color in zip(percentiles, colors_pct):
        values = np.percentile(simulation_results, p, axis=0)
        fig.add_trace(go.Scatter(
            y=values,
            mode='lines',
            line=dict(width=3, color=color),
            name=f'{p}th Percentile'
        ))
    
    fig.update_layout(
    title="üé≤ Monte Carlo Simulation",
    xaxis_title="Trading Days",
    yaxis_title="Portfolio Value ($)",
    height=500,
    paper_bgcolor=COLORS['background'],
    plot_bgcolor=COLORS['card_background'],
    font=dict(color=COLORS['text_primary'])
)



    
    
    final_values = simulation_results[:, -1]
    stats = {
        'mean': np.mean(final_values),
        'median': np.median(final_values),
        'percentile_5': np.percentile(final_values, 5),
        'percentile_95': np.percentile(final_values, 95),
        'prob_profit': (final_values > initial_value).mean() * 100,
        'prob_loss_10': (final_values < initial_value * 0.9).mean() * 100,
        'prob_gain_20': (final_values > initial_value * 1.2).mean() * 100
    }
    
    return fig, stats

# ============================================================================
# PORTFOLIO DEEP DIVE VISUALIZATIONS (v8.8)
# ============================================================================

def create_portfolio_heatmap(df):
    """Portfolio treemap"""
    df_viz = df[['Ticker', 'Asset Name', 'Weight %', 'Total Gain/Loss %', 'Sector']].copy()
    df_viz['Sector'] = df_viz['Sector'].fillna('Other')
    df_viz = df_viz.dropna()
    
    if df_viz.empty:
        return None
    
    fig = px.treemap(
        df_viz,
        path=[px.Constant("Portfolio"), 'Sector', 'Ticker'],
        values='Weight %',
        color='Total Gain/Loss %',
        color_continuous_scale='RdYlGn',
        color_continuous_midpoint=0,
        hover_data={'Asset Name': True, 'Total Gain/Loss %': ':.2f'}
    )
    
    fig.update_layout(
    title="üìà Portfolio Treemap",
    height=600,
    paper_bgcolor=COLORS['background'],
    plot_bgcolor=COLORS['card_background'],
    font=dict(color=COLORS['text_primary'])
)
