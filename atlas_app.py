#!/usr/bin/env python3
"""
ATLAS TERMINAL v10.0 INSTITUTIONAL EDITION
Complete Portfolio Analytics + Valuation House - Bloomberg Terminal Quality

üöÄ NEW IN v10.0 (Latest Release - November 16, 2025):
‚úÖ INSTITUTIONAL PERFORMANCE SUITE: 4-tab professional analysis system
   ‚Ä¢ Portfolio Performance: Enhanced metrics with rolling Sharpe, returns distribution
   ‚Ä¢ Individual Securities: Deep-dive analysis for each holding with technical indicators
   ‚Ä¢ Risk Decomposition: Position-level risk contribution analysis
   ‚Ä¢ Attribution & Benchmarking: Alpha generation and tracking error metrics
‚úÖ Professional Sector Allocation Charts: Clean, modern donut and bar visualizations
‚úÖ Portfolio Correlation Heatmap: Understand diversification with correlation matrix
‚úÖ Individual Security Analysis: Candlestick charts, Bollinger Bands, MA50/MA200
‚úÖ Risk Contribution Analysis: Marginal contribution to risk (MCR) for each position
‚úÖ Beta & Correlation Metrics: Market relationship analysis vs SPY
‚úÖ Enhanced Diversification Scoring: Automated correlation insights

üéØ v9.8 FEATURES (November 2025):
‚úÖ Brinson Attribution Analysis: Measure allocation vs selection skill
‚úÖ Portfolio Management Skill Scores: 0-10 ratings for sector timing and stock picking
‚úÖ Benchmark Sector Returns: Real-time sector ETF performance tracking
‚úÖ Table Dropdown Fix: Nuclear CSS override eliminates all UI glitches
‚úÖ Enhanced Data Tables: Clean, professional rendering across all pages

PREVIOUS ENHANCEMENTS (v9.3-v9.7):
‚úÖ Advanced Risk Metrics: VaR, CVaR, and Maximum Drawdown analysis
‚úÖ Home Page: Top Contributors/Detractors + Enhanced Dashboard
‚úÖ Market Watch: COMPLETE REVAMP (Crypto, Bonds, Spreads, Expanded Universe)
‚úÖ Chart Theming: ALL charts blend seamlessly with dark background
‚úÖ Portfolio Deep Dive: Enhanced visuals + Fixed Nov 2024 columns
‚úÖ Valuation House: Analyst-grade fixes (scaling D&A/CapEx, Smart Assumptions, Editable Projections)

RELEASE DATE: November 16, 2025
PRODUCTION STATUS: VERIFIED AND TESTED
VERSION: 10.0
"""

import pickle
import warnings
import re
import time
import io
import json
import random
import base64
from datetime import datetime, timedelta, date
from pathlib import Path
from collections import Counter, defaultdict
import numpy as np
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import streamlit as st

# ============================================================================
# PHASE 2A: NAVIGATION SYSTEM (New modular architecture)
# ============================================================================
from navigation import PAGE_REGISTRY, get_page_by_key, route_to_page

# Auto-install streamlit_option_menu if missing
try:
    from streamlit_option_menu import option_menu
except ImportError:
    import subprocess
    import sys
    print("üì¶ Installing streamlit-option-menu...")
    subprocess.check_call([sys.executable, "-m", "pip", "install", "-q", "streamlit-option-menu>=0.3.6"])
    from streamlit_option_menu import option_menu
    print("‚úÖ streamlit-option-menu installed successfully!")

import yfinance as yf
from scipy import stats
from scipy.optimize import minimize
import networkx as nx
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA
from sklearn.linear_model import LinearRegression

# ATLAS v10.0 Advanced Modules
try:
    from valuation.atlas_dcf_engine import DCFValuation
    from risk_analytics.atlas_monte_carlo import MonteCarloSimulation
    from risk_analytics.atlas_risk_metrics import RiskAnalytics
    from portfolio_tools.atlas_phoenix_mode import PhoenixMode
    from analytics.atlas_performance_attribution import PerformanceAttribution
    from ui.atlas_enhanced_components import (
        create_allocation_chart,
        create_performance_chart,
        create_drawdown_chart,
        create_risk_return_scatter
    )
    V10_MODULES_AVAILABLE = True
except ImportError as e:
    V10_MODULES_AVAILABLE = False
    print(f"‚ö†Ô∏è v10.0 modules not available: {e}")

# ATLAS v11.0 SQL & R Integration
try:
    from data import get_db
    SQL_AVAILABLE = True
    print("‚úÖ SQL data layer loaded")
except ImportError as e:
    SQL_AVAILABLE = False
    print(f"‚ö†Ô∏è SQL layer not available: {e}")

# ATLAS v11.0 DCF Trap Detection System
try:
    from analytics.dcf_trap_detector import DCFTrapDetector, analyze_dcf_traps
    DCF_TRAP_DETECTION_AVAILABLE = True
    print("‚úÖ DCF Trap Detection System loaded")
except ImportError as e:
    DCF_TRAP_DETECTION_AVAILABLE = False
    print(f"‚ö†Ô∏è DCF Trap Detection not available: {e}")

# ATLAS v11.0 Model Inputs Dashboard
try:
    from analytics.model_inputs_ui import display_model_inputs_dashboard
    MODEL_INPUTS_DASHBOARD_AVAILABLE = True
    print("‚úÖ Model Inputs Dashboard loaded")
except ImportError as e:
    MODEL_INPUTS_DASHBOARD_AVAILABLE = False
    print(f"‚ö†Ô∏è Model Inputs Dashboard not available: {e}")

# ATLAS v11.0 SBC Integration
try:
    from analytics.sbc_forecaster import (
        SBCForecaster,
        SBCForecastConfig,
        SBCForecastMethod,
        integrate_sbc_with_fcff,
        create_sbc_comparison_analysis
    )
    from analytics.sbc_ui import display_sbc_valuation_impact
    SBC_AVAILABLE = True
    print("‚úÖ SBC Integration loaded")
except ImportError as e:
    SBC_AVAILABLE = False
    print(f"‚ö†Ô∏è SBC Integration not available: {e}")

# ATLAS v11.0 Multi-Stage DCF
try:
    from analytics.multistage_ui import (
        display_model_selection,
        visualize_stage_transitions,
        display_multistage_results
    )
    from analytics.multistage_dcf import (
        MultiStageProjectionEngine,
        calculate_multistage_dcf
    )
    MULTISTAGE_DCF_AVAILABLE = True
    print("‚úÖ Multi-Stage DCF loaded")
except ImportError as e:
    MULTISTAGE_DCF_AVAILABLE = False
    print(f"‚ö†Ô∏è Multi-Stage DCF not available: {e}")

try:
    from r_analytics import get_r
    R_AVAILABLE = True
    print("‚úÖ R analytics layer loaded")
except ImportError as e:
    R_AVAILABLE = False
    print(f"‚ö†Ô∏è R analytics not available: {e}")

# ATLAS REFACTORING - Phase 1 Infrastructure (Week 1)
try:
    from atlas_terminal.core.cache_manager import cached, cache_manager
    from atlas_terminal.core.error_handler import safe_execute, ErrorHandler
    from atlas_terminal.data.fetchers.market_data import market_data
    REFACTORED_MODULES_AVAILABLE = True
    print("‚úÖ ATLAS Refactored Infrastructure loaded (Cache + Error + Data)")
except ImportError as e:
    REFACTORED_MODULES_AVAILABLE = False
    print(f"‚ö†Ô∏è Refactored modules not available: {e}")

warnings.filterwarnings("ignore")

# ============================================================================
# HELPER FUNCTIONS FOR VALIDATION
# ============================================================================
def is_valid_series(series):
    """Safely check if a pandas Series has valid data"""
    return series is not None and isinstance(series, pd.Series) and not series.empty

def is_valid_dataframe(df):
    """Safely check if a pandas DataFrame has valid data"""
    return df is not None and isinstance(df, pd.DataFrame) and not df.empty


def get_current_portfolio_metrics():
    """
    Extract current portfolio metrics from uploaded performance history.
    Returns dict with equity, gross_exposure, leverage, cash, etc.

    Data source: Performance history file Column F (Account Value)
    - Row 2 (most recent) = Current equity exposure

    Returns:
        dict with keys: equity, cash, stock_value, short_value, gross_exposure,
                       leverage, date, ytd_return, avg_leverage
        None if performance history not loaded
    """
    try:
        # Check if leverage tracker exists in session state
        if 'leverage_tracker' in st.session_state and st.session_state.leverage_tracker is not None:
            tracker = st.session_state.leverage_tracker
            stats = tracker.get_current_stats()

            if stats:
                return {
                    'equity': stats.get('current_equity', 0),
                    'gross_exposure': stats.get('current_gross_exposure', 0),
                    'leverage': stats.get('current_leverage', 1.0),
                    'ytd_return': stats.get('ytd_equity_return', 0),
                    'avg_leverage': stats.get('avg_leverage', 1.0),
                    'max_leverage': stats.get('max_leverage', 1.0),
                    'min_leverage': stats.get('min_leverage', 1.0),
                    'source': 'leverage_tracker'
                }

        # Fallback: Check if equity_capital was stored directly
        if 'equity_capital' in st.session_state and st.session_state.equity_capital:
            return {
                'equity': st.session_state.equity_capital,
                'gross_exposure': st.session_state.get('gross_exposure', st.session_state.equity_capital),
                'leverage': st.session_state.get('leverage', 1.0),
                'ytd_return': 0,
                'avg_leverage': 1.0,
                'source': 'session_state'
            }

        return None

    except Exception as e:
        print(f"Error getting portfolio metrics: {e}")
        return None


def format_currency(value, decimals=2):
    """Format value as currency string"""
    if value is None:
        return "$0.00"
    return f"${value:,.{decimals}f}"


def format_percentage(value, decimals=2):
    """Format value as percentage string"""
    if value is None:
        return "0.00%"
    return f"{value:.{decimals}f}%"


def make_scrollable_table(df, height=600, hide_index=True, use_container_width=True, column_config=None):
    """
    Make any dataframe horizontally scrollable with professional styling.

    Args:
        df: DataFrame to display
        height: Table height in pixels (default 600)
        hide_index: Whether to hide the index column (default True)
        use_container_width: Whether to use full container width (default True)
        column_config: Optional column configuration dict

    Returns:
        Streamlit dataframe component with horizontal scrolling enabled
    """
    # Inject CSS for horizontal scrolling
    st.markdown(
        """
        <style>
        /* Enable horizontal scrolling for all dataframes */
        div[data-testid="stDataFrame"] > div {
            overflow-x: auto !important;
            max-width: 100% !important;
        }

        /* Ensure table doesn't collapse */
        div[data-testid="stDataFrame"] table {
            min-width: 100% !important;
        }

        /* Better scrollbar styling */
        div[data-testid="stDataFrame"] > div::-webkit-scrollbar {
            height: 8px;
        }

        div[data-testid="stDataFrame"] > div::-webkit-scrollbar-track {
            background: #0a1929;
        }

        div[data-testid="stDataFrame"] > div::-webkit-scrollbar-thumb {
            background: #00d4ff;
            border-radius: 4px;
        }

        div[data-testid="stDataFrame"] > div::-webkit-scrollbar-thumb:hover {
            background: #00ffcc;
        }
        </style>
        """,
        unsafe_allow_html=True
    )

    # Display the dataframe
    return st.dataframe(
        df,
        use_container_width=use_container_width,
        hide_index=hide_index,
        height=height,
        column_config=column_config
    )

@st.cache_data(ttl=300)
def search_yahoo_finance(query):
    """
    Search Yahoo Finance for any ticker/company with live data lookup.

    Args:
        query: Search query (ticker symbol or company name)

    Returns:
        List of matching securities with metadata, or None if not found
    """
    if not query or len(query) < 1:
        return None

    try:
        # ATLAS Refactoring - Use cached market data fetcher
        # Try direct ticker lookup first
        if REFACTORED_MODULES_AVAILABLE:
            info = market_data.get_company_info(query.upper())
        else:
            # Fallback to old method
            ticker = yf.Ticker(query.upper())
            info = ticker.info

        if info and info.get('symbol'):
            return [{
                'symbol': info.get('symbol', query.upper()),
                'name': info.get('longName', info.get('shortName', query)),
                'type': info.get('quoteType', 'Unknown'),
                'exchange': info.get('exchange', 'N/A'),
                'currency': info.get('currency', 'USD'),
                'market_cap': info.get('marketCap', 0),
                'sector': info.get('sector', 'N/A'),
                'industry': info.get('industry', 'N/A')
            }]
        else:
            return None
    except Exception as e:
        return None

def init_watchlist():
    """Initialize personal watchlist in session state"""
    if 'personal_watchlist' not in st.session_state:
        st.session_state['personal_watchlist'] = []
        # Try loading from file
        try:
            import json
            from pathlib import Path
            watchlist_file = Path('.atlas_watchlist.json')
            if watchlist_file.exists():
                with open(watchlist_file, 'r') as f:
                    st.session_state['personal_watchlist'] = json.load(f)
        except:
            pass

def add_to_watchlist(ticker, name, asset_type='Stock'):
    """
    Add a ticker to personal watchlist.

    Args:
        ticker: Ticker symbol
        name: Asset name
        asset_type: Type of asset (Stock, ETF, Crypto, etc.)

    Returns:
        True if added, False if already exists
    """
    init_watchlist()

    # Check if already in watchlist
    if any(item['ticker'] == ticker for item in st.session_state['personal_watchlist']):
        return False

    # Add to watchlist
    st.session_state['personal_watchlist'].append({
        'ticker': ticker,
        'name': name,
        'type': asset_type,
        'added_date': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
    })

    # Save to file
    save_watchlist()
    return True

def remove_from_watchlist(ticker):
    """Remove a ticker from personal watchlist"""
    init_watchlist()
    st.session_state['personal_watchlist'] = [
        item for item in st.session_state['personal_watchlist']
        if item['ticker'] != ticker
    ]
    save_watchlist()

def save_watchlist():
    """Save watchlist to file"""
    try:
        import json
        with open('.atlas_watchlist.json', 'w') as f:
            json.dump(st.session_state['personal_watchlist'], f, indent=2)
    except:
        pass

def get_watchlist():
    """Get current watchlist"""
    init_watchlist()
    return st.session_state['personal_watchlist']

@st.cache_data(ttl=1800)
def fetch_us_treasury_yields_fred():
    """
    Fetch US Treasury yields from FRED API (Federal Reserve Economic Data).

    Returns:
        tuple: (maturities, yields, data_source) where data_source indicates FRED, Yahoo, or Fallback
    """
    # FRED series IDs for various Treasury maturities
    fred_series = {
        "DGS1MO": 1/12,      # 1-month
        "DGS3MO": 0.25,      # 3-month
        "DGS6MO": 0.5,       # 6-month
        "DGS1": 1,           # 1-year
        "DGS2": 2,           # 2-year
        "DGS3": 3,           # 3-year
        "DGS5": 5,           # 5-year
        "DGS7": 7,           # 7-year
        "DGS10": 10,         # 10-year
        "DGS20": 20,         # 20-year
        "DGS30": 30          # 30-year
    }

    # Try FRED API first
    try:
        import requests

        # Check if FRED API key is available (from secrets or environment)
        try:
            FRED_API_KEY = st.secrets.get("FRED_API_KEY", None)
        except:
            FRED_API_KEY = None

        if FRED_API_KEY and FRED_API_KEY != "YOUR_API_KEY_HERE":
            maturities = []
            yields = []

            for series_id, maturity in fred_series.items():
                try:
                    url = f"https://api.stlouisfed.org/fred/series/observations"
                    params = {
                        "series_id": series_id,
                        "api_key": FRED_API_KEY,
                        "file_type": "json",
                        "sort_order": "desc",
                        "limit": 1
                    }

                    response = requests.get(url, params=params, timeout=5)

                    if response.status_code == 200:
                        data = response.json()
                        if data.get('observations'):
                            latest = data['observations'][0]
                            yield_value = float(latest['value'])
                            maturities.append(maturity)
                            yields.append(yield_value)
                except:
                    continue

            # If we got good FRED data, return it
            if len(yields) >= 5:
                # Sort by maturity
                sorted_data = sorted(zip(maturities, yields))
                maturities, yields = zip(*sorted_data)
                return list(maturities), list(yields), "FRED API"
    except:
        pass

    # Fallback to Yahoo Finance
    treasuries = {
        "^IRX": 0.25,   # 3-month
        "^FVX": 5,      # 5-year
        "^TNX": 10,     # 10-year
        "^TYX": 30      # 30-year
    }

    maturities = []
    yields = []

    for ticker, maturity in treasuries.items():
        try:
            stock = yf.Ticker(ticker)
            hist = stock.history(period="1d")
            if not hist.empty:
                current_yield = hist['Close'].iloc[-1]
                maturities.append(maturity)
                yields.append(current_yield)
        except:
            continue

    # If Yahoo data worked, return it
    if len(yields) >= 3:
        sorted_data = sorted(zip(maturities, yields))
        maturities, yields = zip(*sorted_data)
        return list(maturities), list(yields), "Yahoo Finance"

    # Final fallback to sample data
    maturities = [0.25, 0.5, 1, 2, 3, 5, 7, 10, 20, 30]
    yields = [4.5, 4.4, 4.3, 4.2, 4.1, 4.0, 4.05, 4.1, 4.3, 4.4]
    return maturities, yields, "Fallback Data"

# ============================================================================
# PAGE CONFIG
# ============================================================================
st.set_page_config(
    page_title="ATLAS Terminal v10.0 INSTITUTIONAL",
    page_icon="üöÄ",
    layout="wide",
    initial_sidebar_state="collapsed"
)
st.markdown(
    """
    <script>
        document.documentElement.setAttribute('data-theme', 'dark');
    </script>
    """,
    unsafe_allow_html=True
)

# ============================================================================
# PROFESSIONAL THEME SYSTEM - ENHANCED FOR SEAMLESS CHARTS
# ============================================================================

COLORS = {
    "background": "#000000",
    "card_background": "#0a1929",
    "card_background_alt": "#050f17",
    "neon_blue": "#00d4ff",
    "electric_blue": "#0080ff",
    "teal": "#00ffcc",
    "cyan": "#00ffff",
    "success": "#00ff88",
    "warning": "#ffaa00",
    "danger": "#ff0044",
    "info": "#00d4ff",
    "purple": "#b794f6",
    "pink": "#ff00ff",
    "orange": "#ff6b00",
    "chart_primary": "#00d4ff",
    "chart_secondary": "#0080ff",
    "chart_accent": "#00ffcc",
    "chart_grid": "#1a3a52",
    "text_primary": "#ffffff",
    "text_secondary": "#b0c4de",
    "text_muted": "#6c8ca8",
    "border": "#00d4ff",
    "shadow": "rgba(0, 212, 255, 0.3)",
    "shadow_strong": "rgba(0, 212, 255, 0.6)",
    "gain_bg": "rgba(0, 255, 136, 0.15)",
    "gain_text": "#00ff88",
    "loss_bg": "rgba(255, 0, 68, 0.15)",
    "loss_text": "#ff0044",
}

# ===== P1-4: STANDARD CHART HEIGHTS =====
# Standardized height constants for consistent UI/UX across application
CHART_HEIGHT_COMPACT = 400      # Small widgets, mini-charts, compact visualizations
CHART_HEIGHT_STANDARD = 500     # Most dashboard charts (default for new charts)
CHART_HEIGHT_LARGE = 600        # Primary analysis charts, yield curves, heatmaps
CHART_HEIGHT_DEEP_DIVE = 700    # Detailed analysis pages, Monte Carlo simulations

# ============================================================================
# CHART THEME CONFIGURATION - SEAMLESS DARK MODE
# ============================================================================
CHART_THEME = {
    'paper_bgcolor': 'rgba(0, 0, 0, 0)',  # Transparent background
    'plot_bgcolor': 'rgba(10, 25, 41, 0.3)',  # Semi-transparent plot area
    'font': {'color': COLORS['text_primary'], 'family': 'Inter, sans-serif'},
    'xaxis': {
        'gridcolor': COLORS['chart_grid'],
        'linecolor': COLORS['chart_grid'],
        'zerolinecolor': COLORS['chart_grid']
    },
    'yaxis': {
        'gridcolor': COLORS['chart_grid'],
        'linecolor': COLORS['chart_grid'],
        'zerolinecolor': COLORS['chart_grid']
    }
}

def apply_chart_theme(fig):
    """Apply seamless dark theme to any Plotly figure"""
    fig.update_layout(
        paper_bgcolor='rgba(0, 0, 0, 0)',
        plot_bgcolor='rgba(10, 25, 41, 0.3)',
        font=dict(color=COLORS['text_primary'], family='Inter, sans-serif'),
        xaxis=dict(
            gridcolor=COLORS['chart_grid'],
            linecolor=COLORS['chart_grid'],
            zerolinecolor=COLORS['chart_grid']
        ),
        yaxis=dict(
            gridcolor=COLORS['chart_grid'],
            linecolor=COLORS['chart_grid'],
            zerolinecolor=COLORS['chart_grid']
        )
    )
    return fig

COLORSCALES = {
    "viridis": px.colors.sequential.Viridis,
    "plasma": px.colors.sequential.Plasma,
    "turbo": px.colors.sequential.Turbo,
    "rdylgn": px.colors.diverging.RdYlGn,
    "spectral": px.colors.diverging.Spectral,
}

# ============================================================================
# MODERN UI/UX - GLASSMORPHISM & BEAUTIFUL DESIGN
# ============================================================================
st.markdown("""
<style>
    @import url('https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700;800;900&family=JetBrains+Mono:wght@400;600;700&display=swap');

    /* ============================================
       CORE FOUNDATIONS - Beautiful Basics
       ============================================ */

    * {
        font-family: 'Inter', -apple-system, BlinkMacSystemFont, 'Segoe UI', sans-serif !important;
        -webkit-font-smoothing: antialiased;
        -moz-osx-font-smoothing: grayscale;
    }

    code, pre, .monospace {
        font-family: 'JetBrains Mono', monospace !important;
    }

    /* Dark Background with Subtle Gradient */
    .main {
        background: linear-gradient(135deg, #000000 0%, #0a0e1a 50%, #000000 100%);
        background-attachment: fixed;
    }

    /* Add subtle noise texture for depth */
    .main::before {
        content: '';
        position: fixed;
        top: 0;
        left: 0;
        width: 100%;
        height: 100%;
        opacity: 0.03;
        background-image: url("data:image/svg+xml,%3Csvg viewBox='0 0 400 400' xmlns='http://www.w3.org/2000/svg'%3E%3Cfilter id='noiseFilter'%3E%3CfeTurbulence type='fractalNoise' baseFrequency='0.9' numOctaves='4' stitchTiles='stitch'/%3E%3C/filter%3E%3Crect width='100%25' height='100%25' filter='url(%23noiseFilter)'/%3E%3C/svg%3E");
        pointer-events: none;
        z-index: 1;
    }

    .block-container {
        position: relative !important;
        z-index: 100 !important;
        padding-top: 3rem !important;
        padding-bottom: 3rem !important;
        max-width: 1400px !important;
    }

    /* Prevent text overflow and wrapping issues */
    .block-container * {
        max-width: 100%;
        overflow-wrap: break-word;
        word-wrap: break-word;
    }

    /* Fix for inline-flex containers that could overflow */
    div[style*="display: inline-flex"],
    div[style*="display:inline-flex"] {
        flex-wrap: wrap !important;
        overflow: hidden !important;
    }

    /* ============================================
       GLASSMORPHISM CARDS - Modern Aesthetic
       ============================================ */

    /* FIXED: Removed over-broad stMarkdownContainer selector to prevent text overlap */
    div[data-testid="stMetric"],
    .stExpander {
        background: rgba(10, 25, 41, 0.4) !important;
        backdrop-filter: blur(20px) saturate(180%) !important;
        -webkit-backdrop-filter: blur(20px) saturate(180%) !important;
        border: 1px solid rgba(0, 212, 255, 0.15) !important;
        border-radius: 16px !important;
        padding: 24px !important;
        box-shadow:
            0 8px 32px 0 rgba(0, 0, 0, 0.37),
            inset 0 1px 0 0 rgba(255, 255, 255, 0.05) !important;
        transition: all 0.4s cubic-bezier(0.4, 0, 0.2, 1) !important;
    }

    div[data-testid="stMetric"]:hover,
    .stExpander:hover {
        transform: translateY(-4px) !important;
        border-color: rgba(0, 212, 255, 0.4) !important;
        box-shadow:
            0 12px 48px 0 rgba(0, 212, 255, 0.2),
            0 0 0 1px rgba(0, 212, 255, 0.1),
            inset 0 1px 0 0 rgba(255, 255, 255, 0.1) !important;
    }

    /* ============================================
       TYPOGRAPHY - Crisp & Modern
       ============================================ */

    h1 {
        font-weight: 900 !important;
        font-size: 3.5em !important;
        letter-spacing: -0.02em !important;
        line-height: 1.1 !important;
        margin-bottom: 0.5em !important;
        /* Fallback color for browsers that don't support background-clip */
        color: #00d4ff !important;
        background: linear-gradient(135deg, #00d4ff 0%, #00ff88 50%, #00d4ff 100%);
        background-size: 200% auto;
        background-clip: text;
        -webkit-background-clip: text;
        -webkit-text-fill-color: transparent;
        animation: shimmer 3s linear infinite;
        /* Prevent duplicate rendering */
        text-shadow: none !important;
    }

    @keyframes shimmer {
        0% { background-position: 0% center; }
        100% { background-position: 200% center; }
    }

    h2 {
        font-weight: 700 !important;
        font-size: 2em !important;
        color: #ffffff !important;
        letter-spacing: -0.01em !important;
        margin-top: 1.5em !important;
        margin-bottom: 0.75em !important;
        position: relative;
        padding-left: 20px;
    }

    h2::before {
        content: '';
        position: absolute;
        left: 0;
        top: 50%;
        transform: translateY(-50%);
        width: 4px;
        height: 70%;
        background: linear-gradient(180deg, #00d4ff, #00ff88);
        border-radius: 2px;
    }

    h3 {
        font-weight: 600 !important;
        font-size: 1.4em !important;
        color: #00d4ff !important;
        letter-spacing: -0.01em !important;
        margin-top: 1.2em !important;
        margin-bottom: 0.6em !important;
    }

    p {
        font-size: 1.05em !important;
        line-height: 1.7 !important;
        color: #b0c4de !important;
        font-weight: 400 !important;
    }

    /* ============================================
       METRICS - Beautiful Number Display
       ============================================ */

    div[data-testid="stMetric"] {
        background: linear-gradient(135deg, rgba(10, 25, 41, 0.6) 0%, rgba(5, 15, 23, 0.8) 100%) !important;
        position: relative;
        overflow: hidden;
    }

    /* Animated gradient background on hover */
    div[data-testid="stMetric"]::before {
        content: '';
        position: absolute;
        top: -50%;
        left: -50%;
        width: 200%;
        height: 200%;
        background: radial-gradient(circle, rgba(0, 212, 255, 0.1) 0%, transparent 70%);
        opacity: 0;
        transition: opacity 0.4s ease;
    }

    div[data-testid="stMetric"]:hover::before {
        opacity: 1;
    }

    div[data-testid="stMetric"] label {
        font-size: 0.85em !important;
        font-weight: 600 !important;
        text-transform: uppercase !important;
        letter-spacing: 0.1em !important;
        color: #6c8ca8 !important;
        margin-bottom: 8px !important;
    }

    div[data-testid="stMetric"] [data-testid="stMetricValue"] {
        font-size: 1.8em !important;
        font-weight: 800 !important;
        background: linear-gradient(135deg, #ffffff 0%, #00d4ff 100%);
        background-clip: text;
        -webkit-background-clip: text;
        -webkit-text-fill-color: transparent;
        letter-spacing: -0.02em !important;
    }

    div[data-testid="stMetric"] [data-testid="stMetricDelta"] {
        font-size: 1em !important;
        font-weight: 600 !important;
        margin-top: 4px !important;
    }

    /* ============================================
       TABLES - Sleek Data Display
       ============================================ */

    div[data-testid="stDataFrame"] {
        background: rgba(10, 25, 41, 0.3) !important;
        border: 1px solid rgba(0, 212, 255, 0.15) !important;
        border-radius: 12px !important;
        overflow: visible !important;
        box-shadow: 0 4px 24px rgba(0, 0, 0, 0.3) !important;
    }

    /* Fix for column header popovers - prevent text overlap */
    div[data-testid="stDataFrame"] div[data-baseweb="popover"] {
        z-index: 9999 !important;
        display: block !important;
        position: fixed !important;
    }

    /* Ensure popover content doesn't overflow */
    div[data-testid="stDataFrame"] div[role="tooltip"],
    div[data-testid="stDataFrame"] div[data-baseweb="popover"] > div {
        max-width: 300px !important;
        word-wrap: break-word !important;
        white-space: normal !important;
        overflow: visible !important;
        background: rgba(10, 25, 41, 0.95) !important;
        border: 1px solid rgba(0, 212, 255, 0.3) !important;
        border-radius: 8px !important;
        padding: 12px !important;
        box-shadow: 0 4px 16px rgba(0, 0, 0, 0.4) !important;
        backdrop-filter: blur(20px) !important;
    }

    /* Table Headers - Gradient Effect */
    div[data-testid="stDataFrame"] thead th {
        background: linear-gradient(135deg, #00d4ff 0%, #0080ff 100%) !important;
        color: #000000 !important;
        font-weight: 700 !important;
        font-size: 13px !important;
        text-transform: uppercase !important;
        letter-spacing: 0.05em !important;
        padding: 16px 12px !important;
        border: none !important;
        position: sticky !important;
        top: 0 !important;
        z-index: 10 !important;
        overflow: visible !important;
    }

    /* Table Rows - Smooth Hover */
    div[data-testid="stDataFrame"] tbody tr {
        transition: all 0.2s ease !important;
        border-bottom: 1px solid rgba(26, 58, 82, 0.5) !important;
    }

    div[data-testid="stDataFrame"] tbody tr:hover {
        background: linear-gradient(90deg,
            rgba(0, 212, 255, 0.08) 0%,
            rgba(0, 212, 255, 0.15) 50%,
            rgba(0, 212, 255, 0.08) 100%) !important;
        transform: translateX(4px) scale(1.002) !important;
        border-left: 3px solid #00d4ff !important;
        box-shadow: 0 2px 12px rgba(0, 212, 255, 0.2) !important;
    }

    div[data-testid="stDataFrame"] tbody td {
        padding: 14px 12px !important;
        font-size: 14px !important;
        color: #e0e7ee !important;
        font-weight: 500 !important;
    }

    /* ============================================
       NUCLEAR OPTION - COMPLETELY REMOVE TABLE DROPDOWNS
       ============================================ */

    /* Hide ALL table controls that cause issues */
    div[data-testid="stDataFrame"] button,
    div[data-testid="stDataFrame"] [role="button"],
    div[data-testid="stDataFrame"] [data-baseweb="popover"],
    div[data-testid="stDataFrame"] [data-baseweb="menu"],
    div[data-testid="stDataFrame"] [role="menu"],
    div[data-testid="stDataFrame"] [role="listbox"] {
        display: none !important;
        visibility: hidden !important;
        opacity: 0 !important;
        pointer-events: none !important;
        position: absolute !important;
        left: -9999px !important;
    }

    /* Remove column resize handles */
    div[data-testid="stDataFrameResizeHandle"] {
        display: none !important;
    }

    /* ============================================
       BUTTONS - Modern Interactive Elements
       ============================================ */

    .stButton > button {
        background: linear-gradient(135deg, #00d4ff 0%, #0080ff 100%) !important;
        color: #000000 !important;
        border: none !important;
        border-radius: 12px !important;
        padding: 14px 32px !important;
        font-weight: 700 !important;
        font-size: 15px !important;
        letter-spacing: 0.05em !important;
        text-transform: uppercase !important;
        box-shadow: 0 4px 16px rgba(0, 212, 255, 0.3) !important;
        transition: all 0.3s cubic-bezier(0.4, 0, 0.2, 1) !important;
        position: relative !important;
        overflow: hidden !important;
    }

    .stButton > button::before {
        content: '';
        position: absolute;
        top: 50%;
        left: 50%;
        width: 0;
        height: 0;
        border-radius: 50%;
        background: rgba(255, 255, 255, 0.3);
        transform: translate(-50%, -50%);
        transition: width 0.6s, height 0.6s;
    }

    .stButton > button:hover::before {
        width: 300px;
        height: 300px;
    }

    .stButton > button:hover {
        transform: translateY(-2px) !important;
        box-shadow: 0 8px 24px rgba(0, 212, 255, 0.5) !important;
    }

    .stButton > button:active {
        transform: translateY(0) !important;
    }

    /* ============================================
       INPUTS - Clean Form Elements
       ============================================ */

    input[type="text"],
    input[type="number"],
    textarea,
    .stTextInput > div > div > input,
    .stNumberInput > div > div > input {
        background: rgba(10, 25, 41, 0.5) !important;
        border: 2px solid rgba(0, 212, 255, 0.2) !important;
        border-radius: 10px !important;
        color: #ffffff !important;
        padding: 12px 16px !important;
        font-size: 15px !important;
        font-weight: 500 !important;
        transition: all 0.3s ease !important;
    }

    input:focus,
    textarea:focus {
        border-color: #00d4ff !important;
        box-shadow: 0 0 0 3px rgba(0, 212, 255, 0.1) !important;
        outline: none !important;
        background: rgba(10, 25, 41, 0.7) !important;
    }

    /* ============================================
       TABS - Sleek Navigation
       ============================================ */

    .stTabs [data-baseweb="tab-list"] {
        gap: 8px !important;
        background: rgba(10, 25, 41, 0.3) !important;
        padding: 8px !important;
        border-radius: 12px !important;
        border: 1px solid rgba(0, 212, 255, 0.1) !important;
    }

    .stTabs [data-baseweb="tab"] {
        background: transparent !important;
        border: none !important;
        border-radius: 8px !important;
        padding: 12px 24px !important;
        font-weight: 600 !important;
        font-size: 14px !important;
        color: #6c8ca8 !important;
        transition: all 0.3s ease !important;
    }

    .stTabs [data-baseweb="tab"]:hover {
        background: rgba(0, 212, 255, 0.1) !important;
        color: #00d4ff !important;
    }

    .stTabs [aria-selected="true"] {
        background: linear-gradient(135deg, rgba(0, 212, 255, 0.2) 0%, rgba(0, 128, 255, 0.2) 100%) !important;
        color: #00d4ff !important;
        border: 1px solid rgba(0, 212, 255, 0.3) !important;
        box-shadow: 0 4px 12px rgba(0, 212, 255, 0.15) !important;
    }

    /* ============================================
       HIDE SIDEBAR - Using Horizontal Navigation
       ============================================ */

    section[data-testid="stSidebar"] {
        display: none !important;
    }

    /* Hide sidebar collapse button */
    button[kind="header"] {
        display: none !important;
    }

    [data-testid="collapsedControl"] {
        display: none !important;
    }

    /* ============================================
       HORIZONTAL NAVIGATION - RESPONSIVE DESIGN
       ============================================ */

    /* Ensure full-width content area */
    .main .block-container {
        max-width: 100%;
        padding-left: 2rem;
        padding-right: 2rem;
    }

    /* Professional header styling */
    h1 {
        font-weight: 600;
        margin-top: 0.5rem !important;
        margin-bottom: 1rem !important;
        background: linear-gradient(135deg, #00d4ff 0%, #0080ff 100%);
        -webkit-background-clip: text;
        -webkit-text-fill-color: transparent;
        background-clip: text;
    }

    /* Make horizontal menu scrollable on smaller screens */
    nav[role="navigation"] {
        overflow-x: auto;
        white-space: nowrap;
    }

    /* Smooth scrolling for menu */
    nav[role="navigation"]::-webkit-scrollbar {
        height: 6px;
    }

    nav[role="navigation"]::-webkit-scrollbar-thumb {
        background-color: rgba(0, 212, 255, 0.3);
        border-radius: 3px;
    }

    nav[role="navigation"]::-webkit-scrollbar-track {
        background-color: rgba(10, 25, 41, 0.2);
    }

    /* Professional card styling for metrics */
    [data-testid="metric-container"] {
        background-color: rgba(10, 25, 41, 0.3);
        border: 1px solid rgba(0, 212, 255, 0.2);
        padding: 15px;
        border-radius: 10px;
    }

    /* ============================================
       EXPANDERS - Collapsible Sections
       ============================================ */

    .streamlit-expanderHeader {
        background: rgba(10, 25, 41, 0.5) !important;
        border: 1px solid rgba(0, 212, 255, 0.2) !important;
        border-radius: 10px !important;
        padding: 16px !important;
        font-weight: 600 !important;
        font-size: 15px !important;
        color: #00d4ff !important;
        transition: all 0.3s ease !important;
    }

    .streamlit-expanderHeader:hover {
        background: rgba(0, 212, 255, 0.1) !important;
        border-color: rgba(0, 212, 255, 0.4) !important;
    }

    /* ============================================
       FIX: EXPANDER ICON/TEXT OVERLAP (PR #7596)
       Prevent icon shrinking with long labels
       ============================================ */

    /* Target expander summary (header) */
    [data-testid="stExpander"] details summary {
        display: flex !important;
        align-items: center !important;
        gap: 8px !important;
        min-height: 48px !important;
    }

    /* CRITICAL FIX: Prevent icon from shrinking */
    [data-testid="stExpander"] details summary svg,
    [data-testid="stExpander"] details summary .streamlit-expanderHeader svg,
    .streamlit-expanderHeader svg {
        flex-shrink: 0 !important;
        min-width: 20px !important;
        min-height: 20px !important;
        margin-right: 8px !important;
    }

    /* Handle long text in expander labels */
    [data-testid="stExpander"] details summary > div,
    [data-testid="stExpander"] details summary .streamlit-expanderHeader {
        flex: 1 !important;
        overflow: hidden !important;
        text-overflow: ellipsis !important;
        white-space: nowrap !important;
    }

    /* On hover, show full text */
    [data-testid="stExpander"] details summary:hover > div {
        overflow: visible !important;
        white-space: normal !important;
        position: relative !important;
        z-index: 1000 !important;
    }

    /* Ensure adequate container width */
    [data-testid="stExpander"] {
        width: 100% !important;
    }

    /* ============================================
       PROGRESS BARS - Animated Loading
       ============================================ */

    .stProgress > div > div > div {
        background: linear-gradient(90deg, #00d4ff, #00ff88, #00d4ff) !important;
        background-size: 200% auto !important;
        animation: shimmer 2s linear infinite !important;
        border-radius: 10px !important;
        height: 8px !important;
    }

    /* ============================================
       ALERTS & NOTIFICATIONS
       ============================================ */

    .stAlert {
        background: rgba(10, 25, 41, 0.6) !important;
        border-left: 4px solid #00d4ff !important;
        border-radius: 10px !important;
        padding: 16px 20px !important;
        backdrop-filter: blur(10px) !important;
    }

    .stSuccess {
        border-left-color: #00ff88 !important;
    }

    .stError {
        border-left-color: #ff0044 !important;
    }

    .stWarning {
        border-left-color: #ffaa00 !important;
    }

    /* ============================================
       SELECTBOX & MULTISELECT - Working Dropdowns
       ============================================ */

    div[data-baseweb="select"] > div {
        background: rgba(10, 25, 41, 0.5) !important;
        border: 2px solid rgba(0, 212, 255, 0.2) !important;
        border-radius: 10px !important;
        min-height: 48px !important;
    }

    div[data-baseweb="select"]:hover > div {
        border-color: rgba(0, 212, 255, 0.4) !important;
    }

    /* ============================================
       SURGICAL FIX: OVERLAPPING TEXT - v10.0.6
       Completely removes Material Icons ligature text
       ============================================ */

    /* ============================================
       NUCLEAR OPTION: Hide ALL expander icons and use custom arrows
       Fixes "keyboard_arrow_right" text showing instead of icon
       ============================================ */

    /* Hide the entire icon container in expanders */
    [data-testid="stExpander"] summary svg,
    [data-testid="stExpander"] summary [data-baseweb="icon"],
    [data-testid="stExpander"] summary span[role="img"],
    .streamlit-expanderHeader svg,
    .streamlit-expanderHeader [data-baseweb="icon"],
    .streamlit-expanderHeader span[role="img"] {
        display: none !important;
        visibility: hidden !important;
    }

    /* Add custom arrow using CSS */
    [data-testid="stExpander"] summary {
        position: relative !important;
        padding-left: 30px !important;
    }

    [data-testid="stExpander"] summary::before {
        content: '‚ñ∂' !important;
        position: absolute !important;
        left: 8px !important;
        top: 50% !important;
        transform: translateY(-50%) !important;
        font-size: 14px !important;
        color: rgba(0, 212, 255, 0.8) !important;
        transition: transform 0.2s ease !important;
        font-family: Arial, sans-serif !important;
    }

    [data-testid="stExpander"][open] summary::before {
        transform: translateY(-50%) rotate(90deg) !important;
    }

    /* Also hide any stray Material Icons text nodes */
    [data-testid="stExpander"] summary *:not(div):not(p) {
        font-size: 0 !important;
    }

    /* Make sure the label text is still visible */
    [data-testid="stExpander"] summary > div {
        font-size: 15px !important;
    }

    /* Select/Dropdown icons - hide keyboard_arrow_down text */
    div[data-baseweb="select"] svg,
    div[data-baseweb="select"] [data-baseweb="icon"],
    div[data-baseweb="select"] [role="presentation"] {
        display: none !important;
        visibility: hidden !important;
    }

    /* DataFrame menu icons - hide arrow_upward/downward text */
    div[data-testid="stDataFrame"] [role="menuitem"] span[aria-hidden="true"],
    div[data-testid="stDataFrame"] [role="menuitem"] [data-baseweb="icon"],
    div[data-testid="stDataFrame"] [role="menuitem"] svg {
        display: none !important;
        position: absolute !important;
        left: -9999px !important;
        width: 0 !important;
        height: 0 !important;
        overflow: hidden !important;
        visibility: hidden !important;
    }

    /* Dropdown label text - ensure visible */
    div[data-baseweb="select"] [role="option"],
    div[data-baseweb="select"] > div > div:first-child > div {
        font-size: 14px !important;
        font-family: 'Inter', sans-serif !important;
        color: #ffffff !important;
        -webkit-text-fill-color: #ffffff !important;
        display: block !important;
        visibility: visible !important;
    }

    /* Add custom dropdown arrow */
    div[data-baseweb="select"] > div {
        padding-right: 40px !important;
        position: relative !important;
    }

    div[data-baseweb="select"]::after {
        content: '‚ñæ' !important;
        font-family: system-ui, sans-serif !important;
        font-size: 16px !important;
        color: #00d4ff !important;
        -webkit-text-fill-color: #00d4ff !important;
        position: absolute !important;
        right: 14px !important;
        top: 50% !important;
        transform: translateY(-50%) !important;
        pointer-events: none !important;
        z-index: 10 !important;
        display: block !important;
        visibility: visible !important;
    }

    /* ============================================
       SURGICAL FIX: MULTISELECT RED SQUARES - v10.0.5
       Restore text visibility to tag labels
       ============================================ */

    /* Tag container styling */
    div[data-baseweb="tag"] {
        background: rgba(0, 212, 255, 0.25) !important;
        border: 1px solid rgba(0, 212, 255, 0.5) !important;
        border-radius: 6px !important;
        padding: 4px 10px !important;
        margin: 2px !important;
        display: inline-flex !important;
        align-items: center !important;
    }

    /* Tag text - MUST be visible (fixes red squares) */
    div[data-baseweb="tag"] span,
    div[data-baseweb="tag"] > span:first-child {
        font-size: 13px !important;
        color: #ffffff !important;
        -webkit-text-fill-color: #ffffff !important;
        font-family: 'Inter', sans-serif !important;
        display: inline !important;
        visibility: visible !important;
        opacity: 1 !important;
    }

    /* Tag close/remove button */
    div[data-baseweb="tag"] svg,
    div[data-baseweb="tag"] [role="button"] {
        display: inline-flex !important;
        visibility: visible !important;
        width: 14px !important;
        height: 14px !important;
        color: #ffffff !important;
        opacity: 0.7 !important;
        cursor: pointer !important;
        margin-left: 6px !important;
    }

    div[data-baseweb="tag"] [role="button"]:hover {
        opacity: 1 !important;
    }

    /* Multiselect dropdown options */
    div[data-baseweb="select"] div[role="option"] {
        font-size: 14px !important;
        color: #ffffff !important;
        -webkit-text-fill-color: #ffffff !important;
        display: flex !important;
        visibility: visible !important;
    }

    /* ============================================
       SCROLLBAR - Custom Styling
       ============================================ */

    ::-webkit-scrollbar {
        width: 10px !important;
        height: 10px !important;
    }

    ::-webkit-scrollbar-track {
        background: rgba(10, 25, 41, 0.3) !important;
        border-radius: 10px !important;
    }

    ::-webkit-scrollbar-thumb {
        background: linear-gradient(180deg, #00d4ff, #0080ff) !important;
        border-radius: 10px !important;
        border: 2px solid rgba(10, 25, 41, 0.3) !important;
    }

    ::-webkit-scrollbar-thumb:hover {
        background: linear-gradient(180deg, #00ff88, #00d4ff) !important;
    }

    /* ============================================
       PLOTLY CHARTS - Seamless Integration
       ============================================ */

    .js-plotly-plot {
        border-radius: 12px !important;
        overflow: hidden !important;
    }

    /* ============================================
       SPECIAL EFFECTS - Glows & Shadows
       ============================================ */

    .glow-text {
        text-shadow: 0 0 20px rgba(0, 212, 255, 0.5),
                     0 0 40px rgba(0, 212, 255, 0.3),
                     0 0 60px rgba(0, 212, 255, 0.2);
    }

    .glow-box {
        box-shadow: 0 0 20px rgba(0, 212, 255, 0.3),
                    0 0 40px rgba(0, 212, 255, 0.2),
                    inset 0 1px 0 rgba(255, 255, 255, 0.1);
    }

    /* ============================================
       RESPONSIVE DESIGN
       ============================================ */

    @media (max-width: 768px) {
        h1 { font-size: 2.5em !important; }
        h2 { font-size: 1.8em !important; }
        h3 { font-size: 1.3em !important; }

        div[data-testid="stMetric"] {
            padding: 16px !important;
        }
    }

    /* ============================================
       HIDE STREAMLIT BRANDING
       ============================================ */

    #MainMenu {visibility: hidden;}
    footer {visibility: hidden;}
    header {visibility: hidden;}

</style>

<!-- Note: Sidebar toggle removed - Using horizontal navigation bar for maximum screen space -->

""", unsafe_allow_html=True)

# ============================================================================
# CONSTANTS & CONFIG
# ============================================================================
CACHE_DIR = Path.home() / ".atlas_cache"
CACHE_DIR.mkdir(exist_ok=True)
PORTFOLIO_CACHE = CACHE_DIR / "portfolio.pkl"
TRADE_HISTORY_CACHE = CACHE_DIR / "trade_history.pkl"
ACCOUNT_HISTORY_CACHE = CACHE_DIR / "account_history.pkl"

RISK_FREE_RATE = 0.045
MARKET_RETURN = 0.10

# ============================================================================
# EXPANDED MARKET WATCH UNIVERSE - EXCELLENCE EDITION
# ============================================================================

# Global Market Indices - BLOOMBERG KILLER EDITION
# EXPANDED: 46 ‚Üí 200+ indices across all major global markets
GLOBAL_INDICES = {
    # ===== NORTH AMERICA (50+) =====
    # United States - Major
    "^GSPC": {"name": "S&P 500", "region": "US"},
    "^NDX": {"name": "Nasdaq 100", "region": "US"},
    "^DJI": {"name": "Dow Jones Industrial", "region": "US"},
    "^IXIC": {"name": "Nasdaq Composite", "region": "US"},
    "^NYA": {"name": "NYSE Composite", "region": "US"},
    "^RUT": {"name": "Russell 2000", "region": "US"},
    "^RUA": {"name": "Russell 3000", "region": "US"},
    "^RUI": {"name": "Russell 1000", "region": "US"},
    "^VIX": {"name": "CBOE Volatility Index", "region": "US"},
    "^VVIX": {"name": "CBOE VIX of VIX", "region": "US"},

    # US - Sector Indices
    "^SP500-15": {"name": "S&P 500 Materials", "region": "US"},
    "^SP500-20": {"name": "S&P 500 Industrials", "region": "US"},
    "^SP500-25": {"name": "S&P 500 Consumer Discretionary", "region": "US"},
    "^SP500-30": {"name": "S&P 500 Consumer Staples", "region": "US"},
    "^SP500-35": {"name": "S&P 500 Healthcare", "region": "US"},
    "^SP500-40": {"name": "S&P 500 Financials", "region": "US"},
    "^SP500-45": {"name": "S&P 500 Technology", "region": "US"},
    "^SP500-50": {"name": "S&P 500 Telecom", "region": "US"},
    "^SP500-55": {"name": "S&P 500 Utilities", "region": "US"},
    "^SP500-60": {"name": "S&P 500 Real Estate", "region": "US"},

    # US - Style Indices
    "^RLG": {"name": "Russell 1000 Growth", "region": "US"},
    "^RLV": {"name": "Russell 1000 Value", "region": "US"},
    "^RUO": {"name": "Russell 2000 Growth", "region": "US"},
    "^RUJ": {"name": "Russell 2000 Value", "region": "US"},
    "^SP400": {"name": "S&P MidCap 400", "region": "US"},
    "^SP600": {"name": "S&P SmallCap 600", "region": "US"},
    "^OEX": {"name": "S&P 100", "region": "US"},
    "^DJT": {"name": "Dow Jones Transportation", "region": "US"},
    "^DJU": {"name": "Dow Jones Utilities", "region": "US"},
    "^W5000": {"name": "Wilshire 5000", "region": "US"},

    # Canada
    "^GSPTSE": {"name": "S&P/TSX Composite", "region": "Canada"},
    "^TX60": {"name": "S&P/TSX 60", "region": "Canada"},

    # ===== EUROPE (80+) =====
    # Pan-European
    "^STOXX50E": {"name": "EURO STOXX 50", "region": "Europe"},
    "^STOXX": {"name": "STOXX Europe 600", "region": "Europe"},
    "^SX5E": {"name": "EURO STOXX 50 Price", "region": "Europe"},
    "^SXXP": {"name": "STOXX Europe 600 Price", "region": "Europe"},

    # United Kingdom
    "^FTSE": {"name": "FTSE 100", "region": "UK"},
    "^FTMC": {"name": "FTSE 250", "region": "UK"},
    "^FTSC": {"name": "FTSE 350", "region": "UK"},
    "^FTAS": {"name": "FTSE All-Share", "region": "UK"},
    "^FTLC": {"name": "FTSE SmallCap", "region": "UK"},
    "^FTAI": {"name": "FTSE AIM All-Share", "region": "UK"},

    # Germany
    "^GDAXI": {"name": "DAX", "region": "Germany"},
    "^MDAXI": {"name": "MDAX", "region": "Germany"},
    "^SDAXI": {"name": "SDAX", "region": "Germany"},
    "^TECDAX": {"name": "TecDAX", "region": "Germany"},

    # France
    "^FCHI": {"name": "CAC 40", "region": "France"},
    "^CAC": {"name": "CAC Mid 60", "region": "France"},
    "^SBF120": {"name": "SBF 120", "region": "France"},

    # Switzerland
    "^SSMI": {"name": "SMI", "region": "Switzerland"},
    "^SMIM": {"name": "Swiss Market Mid Cap", "region": "Switzerland"},

    # Netherlands
    "^AEX": {"name": "AEX Amsterdam", "region": "Netherlands"},
    "^AMX": {"name": "AMX Amsterdam Mid Cap", "region": "Netherlands"},

    # Spain
    "^IBEX": {"name": "IBEX 35", "region": "Spain"},

    # Italy
    "FTSEMIB.MI": {"name": "FTSE MIB", "region": "Italy"},

    # Belgium
    "^BFX": {"name": "BEL 20", "region": "Belgium"},

    # Nordic Countries
    "^OMX": {"name": "OMX Stockholm 30", "region": "Sweden"},
    "^OMXSPI": {"name": "OMX Stockholm All-Share", "region": "Sweden"},
    "^OMXC25": {"name": "OMX Copenhagen 25", "region": "Denmark"},
    "^OMXHPI": {"name": "OMX Helsinki All-Share", "region": "Finland"},
    "^OSEAX": {"name": "OSE All-Share", "region": "Norway"},

    # Eastern Europe
    "^ATX": {"name": "ATX Austria", "region": "Austria"},
    "^PX": {"name": "PX Prague", "region": "Czech Republic"},
    "^WIG20": {"name": "WIG20 Warsaw", "region": "Poland"},
    "^BUX": {"name": "BUX Budapest", "region": "Hungary"},
    "^RTSI": {"name": "RTS Russia", "region": "Russia"},

    # Portugal, Greece, Ireland
    "^PSI20": {"name": "PSI 20", "region": "Portugal"},
    "^ATG.AT": {"name": "Athens General", "region": "Greece"},
    "^ISEQ": {"name": "ISEQ All-Share", "region": "Ireland"},

    # ===== ASIA-PACIFIC (70+) =====
    # Japan
    "^N225": {"name": "Nikkei 225", "region": "Japan"},
    "^N300": {"name": "Nikkei 300", "region": "Japan"},
    "^TPX": {"name": "TOPIX", "region": "Japan"},
    "^NKY": {"name": "Nikkei Stock Average", "region": "Japan"},

    # China & Hong Kong
    "^HSI": {"name": "Hang Seng Index", "region": "Hong Kong"},
    "^HSCE": {"name": "Hang Seng China Enterprises", "region": "Hong Kong"},
    "^HSTECH": {"name": "Hang Seng TECH", "region": "Hong Kong"},
    "000001.SS": {"name": "Shanghai Composite", "region": "China"},
    "000300.SS": {"name": "CSI 300", "region": "China"},
    "000688.SS": {"name": "SSE STAR 50", "region": "China"},
    "399001.SZ": {"name": "Shenzhen Component", "region": "China"},
    "399006.SZ": {"name": "ChiNext", "region": "China"},

    # India
    "^BSESN": {"name": "S&P BSE Sensex", "region": "India"},
    "^NSEI": {"name": "Nifty 50", "region": "India"},
    "^NSEBANK": {"name": "Nifty Bank", "region": "India"},
    "^CNXIT": {"name": "Nifty IT", "region": "India"},

    # South Korea
    "^KS11": {"name": "KOSPI", "region": "South Korea"},
    "^KQ11": {"name": "KOSDAQ", "region": "South Korea"},

    # Taiwan
    "^TWII": {"name": "Taiwan Weighted", "region": "Taiwan"},

    # Singapore
    "^STI": {"name": "Straits Times Index", "region": "Singapore"},

    # Australia & New Zealand
    "^AXJO": {"name": "ASX 200", "region": "Australia"},
    "^AORD": {"name": "All Ordinaries", "region": "Australia"},
    "^AXSO": {"name": "ASX Small Ordinaries", "region": "Australia"},
    "^NZ50": {"name": "NZX 50", "region": "New Zealand"},

    # Southeast Asia
    "^JKSE": {"name": "Jakarta Composite", "region": "Indonesia"},
    "^KLSE": {"name": "FTSE Bursa Malaysia KLCI", "region": "Malaysia"},
    "^SET.BK": {"name": "SET Index", "region": "Thailand"},
    "^PSEI": {"name": "PSE Composite", "region": "Philippines"},
    "^VNI": {"name": "VN-Index", "region": "Vietnam"},

    # ===== MIDDLE EAST & AFRICA (30+) =====
    # Israel
    "^TA125.TA": {"name": "TA-125", "region": "Israel"},
    "^TA35.TA": {"name": "TA-35", "region": "Israel"},

    # Gulf States
    "^TASI.SR": {"name": "Tadawul All Share", "region": "Saudi Arabia"},
    "^DFMGI.DU": {"name": "DFM General Index", "region": "UAE"},
    "^ADI.AD": {"name": "ADX General", "region": "UAE"},
    "^QSI": {"name": "QE Index", "region": "Qatar"},
    "^KWSE": {"name": "Kuwait Stock Exchange", "region": "Kuwait"},

    # Africa
    "^JN0U.JO": {"name": "FTSE/JSE Top 40", "region": "South Africa"},
    "^J203.JO": {"name": "JSE All Share", "region": "South Africa"},
    "^CASE30": {"name": "EGX 30", "region": "Egypt"},
    "^MASI.CS": {"name": "MASI Morocco", "region": "Morocco"},
    "^NGSEINDX": {"name": "NSE All-Share", "region": "Nigeria"},

    # Turkey
    "XU100.IS": {"name": "BIST 100", "region": "Turkey"},

    # ===== LATIN AMERICA (20+) =====
    # Brazil
    "^BVSP": {"name": "Ibovespa", "region": "Brazil"},
    "^BVMF": {"name": "Brazil Broad Index", "region": "Brazil"},

    # Mexico
    "^MXX": {"name": "IPC Mexico", "region": "Mexico"},

    # Argentina
    "^MERV": {"name": "MERVAL", "region": "Argentina"},

    # Chile
    "^IPSA": {"name": "S&P/CLX IPSA", "region": "Chile"},

    # Colombia
    "^COLCAP": {"name": "COLCAP", "region": "Colombia"},

    # Peru
    "^SPBLPGPT": {"name": "S&P/BVL Peru General", "region": "Peru"}
}

# EXPANDED: Major Cryptocurrencies - BLOOMBERG KILLER EDITION
# 50 ‚Üí 150+ coins across all major categories
CRYPTOCURRENCIES = {
    # ===== LARGE CAP (>$10B) - Top 15 =====
    "BTC-USD": {"name": "Bitcoin", "category": "Layer 1", "market_cap": "Large"},
    "ETH-USD": {"name": "Ethereum", "category": "Layer 1", "market_cap": "Large"},
    "BNB-USD": {"name": "Binance Coin", "category": "Exchange", "market_cap": "Large"},
    "XRP-USD": {"name": "Ripple", "category": "Payments", "market_cap": "Large"},
    "SOL-USD": {"name": "Solana", "category": "Layer 1", "market_cap": "Large"},
    "ADA-USD": {"name": "Cardano", "category": "Layer 1", "market_cap": "Large"},
    "DOGE-USD": {"name": "Dogecoin", "category": "Meme", "market_cap": "Large"},
    "AVAX-USD": {"name": "Avalanche", "category": "Layer 1", "market_cap": "Large"},
    "DOT-USD": {"name": "Polkadot", "category": "Layer 0", "market_cap": "Large"},
    "MATIC-USD": {"name": "Polygon", "category": "Layer 2", "market_cap": "Large"},
    "TRX-USD": {"name": "Tron", "category": "Layer 1", "market_cap": "Large"},
    "LINK-USD": {"name": "Chainlink", "category": "Oracle", "market_cap": "Large"},
    "TON-USD": {"name": "Toncoin", "category": "Layer 1", "market_cap": "Large"},
    "SHIB-USD": {"name": "Shiba Inu", "category": "Meme", "market_cap": "Large"},

    # ===== MID CAP ($1B-$10B) - Top 50 =====
    # DeFi Protocols
    "UNI-USD": {"name": "Uniswap", "category": "DeFi", "market_cap": "Mid"},
    "AAVE-USD": {"name": "Aave", "category": "DeFi", "market_cap": "Mid"},
    "MKR-USD": {"name": "Maker", "category": "DeFi", "market_cap": "Mid"},
    "CRV-USD": {"name": "Curve DAO", "category": "DeFi", "market_cap": "Mid"},
    "COMP-USD": {"name": "Compound", "category": "DeFi", "market_cap": "Mid"},
    "SNX-USD": {"name": "Synthetix", "category": "DeFi", "market_cap": "Mid"},
    "LDO-USD": {"name": "Lido DAO", "category": "DeFi", "market_cap": "Mid"},
    "SUSHI-USD": {"name": "SushiSwap", "category": "DeFi", "market_cap": "Mid"},
    "BAL-USD": {"name": "Balancer", "category": "DeFi", "market_cap": "Mid"},
    "YFI-USD": {"name": "yearn.finance", "category": "DeFi", "market_cap": "Mid"},

    # Layer 1 Platforms
    "ATOM-USD": {"name": "Cosmos", "category": "Layer 0", "market_cap": "Mid"},
    "NEAR-USD": {"name": "NEAR Protocol", "category": "Layer 1", "market_cap": "Mid"},
    "ALGO-USD": {"name": "Algorand", "category": "Layer 1", "market_cap": "Mid"},
    "FTM-USD": {"name": "Fantom", "category": "Layer 1", "market_cap": "Mid"},
    "ICP-USD": {"name": "Internet Computer", "category": "Layer 1", "market_cap": "Mid"},
    "HBAR-USD": {"name": "Hedera", "category": "Layer 1", "market_cap": "Mid"},
    "APT-USD": {"name": "Aptos", "category": "Layer 1", "market_cap": "Mid"},
    "SUI-USD": {"name": "Sui", "category": "Layer 1", "market_cap": "Mid"},
    "VET-USD": {"name": "VeChain", "category": "Layer 1", "market_cap": "Mid"},
    "ETC-USD": {"name": "Ethereum Classic", "category": "Layer 1", "market_cap": "Mid"},
    "XTZ-USD": {"name": "Tezos", "category": "Layer 1", "market_cap": "Mid"},
    "EOS-USD": {"name": "EOS", "category": "Layer 1", "market_cap": "Mid"},
    "FLOW-USD": {"name": "Flow", "category": "Layer 1", "market_cap": "Mid"},
    "KLAY-USD": {"name": "Klaytn", "category": "Layer 1", "market_cap": "Mid"},

    # Layer 2 & Scaling
    "ARB-USD": {"name": "Arbitrum", "category": "Layer 2", "market_cap": "Mid"},
    "OP-USD": {"name": "Optimism", "category": "Layer 2", "market_cap": "Mid"},
    "IMX-USD": {"name": "Immutable X", "category": "Layer 2", "market_cap": "Mid"},
    "LRC-USD": {"name": "Loopring", "category": "Layer 2", "market_cap": "Mid"},

    # Infrastructure & Oracles
    "FIL-USD": {"name": "Filecoin", "category": "Storage", "market_cap": "Mid"},
    "GRT-USD": {"name": "The Graph", "category": "Indexing", "market_cap": "Mid"},
    "AR-USD": {"name": "Arweave", "category": "Storage", "market_cap": "Mid"},
    "RNDR-USD": {"name": "Render", "category": "Computing", "market_cap": "Mid"},

    # Gaming & Metaverse
    "SAND-USD": {"name": "The Sandbox", "category": "Gaming", "market_cap": "Mid"},
    "MANA-USD": {"name": "Decentraland", "category": "Metaverse", "market_cap": "Mid"},
    "AXS-USD": {"name": "Axie Infinity", "category": "Gaming", "market_cap": "Mid"},
    "APE-USD": {"name": "ApeCoin", "category": "Metaverse", "market_cap": "Mid"},
    "GALA-USD": {"name": "Gala", "category": "Gaming", "market_cap": "Mid"},
    "ENJ-USD": {"name": "Enjin Coin", "category": "Gaming", "market_cap": "Mid"},
    "THETA-USD": {"name": "Theta Network", "category": "Media", "market_cap": "Mid"},

    # Privacy Coins
    "XMR-USD": {"name": "Monero", "category": "Privacy", "market_cap": "Mid"},

    # Payment & Transfer
    "LTC-USD": {"name": "Litecoin", "category": "Payments", "market_cap": "Mid"},
    "BCH-USD": {"name": "Bitcoin Cash", "category": "Payments", "market_cap": "Mid"},
    "XLM-USD": {"name": "Stellar", "category": "Payments", "market_cap": "Mid"},
    "RUNE-USD": {"name": "THORChain", "category": "Cross-chain", "market_cap": "Mid"},

    # ===== SMALL CAP (<$1B) - Top 85 =====
    # AI & Machine Learning
    "FET-USD": {"name": "Fetch.ai", "category": "AI", "market_cap": "Small"},
    "AGIX-USD": {"name": "SingularityNET", "category": "AI", "market_cap": "Small"},
    "OCEAN-USD": {"name": "Ocean Protocol", "category": "AI", "market_cap": "Small"},

    # DeFi Emerging
    "1INCH-USD": {"name": "1inch", "category": "DeFi", "market_cap": "Small"},
    "CVX-USD": {"name": "Convex Finance", "category": "DeFi", "market_cap": "Small"},
    "FRAX-USD": {"name": "Frax", "category": "Stablecoin", "market_cap": "Small"},
    "FXS-USD": {"name": "Frax Share", "category": "DeFi", "market_cap": "Small"},
    "GMX-USD": {"name": "GMX", "category": "DeFi", "market_cap": "Small"},
    "DYDX-USD": {"name": "dYdX", "category": "DeFi", "market_cap": "Small"},

    # Layer 2 Emerging
    "METIS-USD": {"name": "Metis", "category": "Layer 2", "market_cap": "Small"},
    "BOBA-USD": {"name": "Boba Network", "category": "Layer 2", "market_cap": "Small"},

    # Gaming Emerging
    "ILV-USD": {"name": "Illuvium", "category": "Gaming", "market_cap": "Small"},
    "YGG-USD": {"name": "Yield Guild Games", "category": "Gaming", "market_cap": "Small"},
    "GODS-USD": {"name": "Gods Unchained", "category": "Gaming", "market_cap": "Small"},
    "MAGIC-USD": {"name": "Magic", "category": "Gaming", "market_cap": "Small"},

    # Meme Coins
    "PEPE-USD": {"name": "Pepe", "category": "Meme", "market_cap": "Small"},
    "FLOKI-USD": {"name": "Floki Inu", "category": "Meme", "market_cap": "Small"},
    "BONK-USD": {"name": "Bonk", "category": "Meme", "market_cap": "Small"},

    # Infrastructure Emerging
    "ANKR-USD": {"name": "Ankr", "category": "Infrastructure", "market_cap": "Small"},
    "STORJ-USD": {"name": "Storj", "category": "Storage", "market_cap": "Small"},
    "HNT-USD": {"name": "Helium", "category": "IoT", "market_cap": "Small"},

    # Web3 & Social
    "BAT-USD": {"name": "Basic Attention Token", "category": "Web3", "market_cap": "Small"},
    "ENS-USD": {"name": "Ethereum Name Service", "category": "Web3", "market_cap": "Small"},

    # Interoperability
    "ZIL-USD": {"name": "Zilliqa", "category": "Layer 1", "market_cap": "Small"},
    "KAVA-USD": {"name": "Kava", "category": "DeFi", "market_cap": "Small"},
    "ZRX-USD": {"name": "0x Protocol", "category": "DeFi", "market_cap": "Small"},
    "BNT-USD": {"name": "Bancor", "category": "DeFi", "market_cap": "Small"},

    # Exchange Tokens
    "CRO-USD": {"name": "Crypto.com Coin", "category": "Exchange", "market_cap": "Small"},
    "KCS-USD": {"name": "KuCoin Token", "category": "Exchange", "market_cap": "Small"},
    "GT-USD": {"name": "GateToken", "category": "Exchange", "market_cap": "Small"},

    # NFT & Digital Assets
    "BLUR-USD": {"name": "Blur", "category": "NFT", "market_cap": "Small"},
    "LOOKS-USD": {"name": "LooksRare", "category": "NFT", "market_cap": "Small"},

    # Emerging Layer 1s
    "CFX-USD": {"name": "Conflux", "category": "Layer 1", "market_cap": "Small"},
    "CELO-USD": {"name": "Celo", "category": "Layer 1", "market_cap": "Small"},
    "ONE-USD": {"name": "Harmony", "category": "Layer 1", "market_cap": "Small"},
    "ROSE-USD": {"name": "Oasis Network", "category": "Layer 1", "market_cap": "Small"},
    "MINA-USD": {"name": "Mina Protocol", "category": "Layer 1", "market_cap": "Small"},

    # DeFi Specialized
    "RSR-USD": {"name": "Reserve Rights", "category": "DeFi", "market_cap": "Small"},
    "ALCX-USD": {"name": "Alchemix", "category": "DeFi", "market_cap": "Small"},
    "BADGER-USD": {"name": "Badger DAO", "category": "DeFi", "market_cap": "Small"},

    # Derivatives & Synthetics
    "PERP-USD": {"name": "Perpetual Protocol", "category": "DeFi", "market_cap": "Small"},
    "INJ-USD": {"name": "Injective", "category": "DeFi", "market_cap": "Small"},

    # Cross-chain Bridges
    "SYN-USD": {"name": "Synapse", "category": "Bridge", "market_cap": "Small"},

    # ===== STABLECOINS (for reference) =====
    "USDT-USD": {"name": "Tether", "category": "Stablecoin", "market_cap": "Large"},
    "USDC-USD": {"name": "USD Coin", "category": "Stablecoin", "market_cap": "Large"},
    "DAI-USD": {"name": "Dai", "category": "Stablecoin", "market_cap": "Large"},
    "BUSD-USD": {"name": "Binance USD", "category": "Stablecoin", "market_cap": "Large"},
    "TUSD-USD": {"name": "TrueUSD", "category": "Stablecoin", "market_cap": "Mid"},
    "USDP-USD": {"name": "Pax Dollar", "category": "Stablecoin", "market_cap": "Mid"},
    "GUSD-USD": {"name": "Gemini Dollar", "category": "Stablecoin", "market_cap": "Small"}
}

# FX Pairs (NEW CATEGORY)
# CURRENCY PAIRS - BLOOMBERG KILLER EDITION
# 20 ‚Üí 50+ FX pairs across all major categories
FX_PAIRS = {
    # ===== MAJOR PAIRS (7) =====
    "EURUSD=X": {"name": "EUR/USD", "category": "Major", "region": "Global"},
    "GBPUSD=X": {"name": "GBP/USD", "category": "Major", "region": "Global"},
    "USDJPY=X": {"name": "USD/JPY", "category": "Major", "region": "Global"},
    "AUDUSD=X": {"name": "AUD/USD", "category": "Major", "region": "Global"},
    "USDCAD=X": {"name": "USD/CAD", "category": "Major", "region": "Global"},
    "USDCHF=X": {"name": "USD/CHF", "category": "Major", "region": "Global"},
    "NZDUSD=X": {"name": "NZD/USD", "category": "Major", "region": "Global"},

    # ===== EUR CROSS PAIRS (10) =====
    "EURGBP=X": {"name": "EUR/GBP", "category": "EUR Cross", "region": "Europe"},
    "EURJPY=X": {"name": "EUR/JPY", "category": "EUR Cross", "region": "Global"},
    "EURAUD=X": {"name": "EUR/AUD", "category": "EUR Cross", "region": "Global"},
    "EURNZD=X": {"name": "EUR/NZD", "category": "EUR Cross", "region": "Global"},
    "EURCAD=X": {"name": "EUR/CAD", "category": "EUR Cross", "region": "Global"},
    "EURCHF=X": {"name": "EUR/CHF", "category": "EUR Cross", "region": "Europe"},
    "EURSEK=X": {"name": "EUR/SEK", "category": "EUR Cross", "region": "Europe"},
    "EURNOK=X": {"name": "EUR/NOK", "category": "EUR Cross", "region": "Europe"},
    "EURDKK=X": {"name": "EUR/DKK", "category": "EUR Cross", "region": "Europe"},
    "EURPLN=X": {"name": "EUR/PLN", "category": "EUR Cross", "region": "Europe"},

    # ===== GBP CROSS PAIRS (5) =====
    "GBPJPY=X": {"name": "GBP/JPY", "category": "GBP Cross", "region": "Global"},
    "GBPAUD=X": {"name": "GBP/AUD", "category": "GBP Cross", "region": "Global"},
    "GBPCAD=X": {"name": "GBP/CAD", "category": "GBP Cross", "region": "Global"},
    "GBPCHF=X": {"name": "GBP/CHF", "category": "GBP Cross", "region": "Europe"},
    "GBPNZD=X": {"name": "GBP/NZD", "category": "GBP Cross", "region": "Global"},

    # ===== JPY CROSS PAIRS (5) =====
    "AUDJPY=X": {"name": "AUD/JPY", "category": "JPY Cross", "region": "Asia-Pacific"},
    "CADJPY=X": {"name": "CAD/JPY", "category": "JPY Cross", "region": "Global"},
    "CHFJPY=X": {"name": "CHF/JPY", "category": "JPY Cross", "region": "Global"},
    "NZDJPY=X": {"name": "NZD/JPY", "category": "JPY Cross", "region": "Asia-Pacific"},
    "SGDJPY=X": {"name": "SGD/JPY", "category": "JPY Cross", "region": "Asia"},

    # ===== OTHER CROSS PAIRS (5) =====
    "AUDCAD=X": {"name": "AUD/CAD", "category": "Commodity Cross", "region": "Global"},
    "AUDNZD=X": {"name": "AUD/NZD", "category": "Commodity Cross", "region": "Pacific"},
    "CADCHF=X": {"name": "CAD/CHF", "category": "Cross", "region": "Global"},
    "NZDCAD=X": {"name": "NZD/CAD", "category": "Commodity Cross", "region": "Global"},
    "AUDCHF=X": {"name": "AUD/CHF", "category": "Cross", "region": "Global"},

    # ===== EMERGING MARKET - ASIA (8) =====
    "USDCNY=X": {"name": "USD/CNY", "category": "EM - Asia", "region": "China"},
    "USDHKD=X": {"name": "USD/HKD", "category": "EM - Asia", "region": "Hong Kong"},
    "USDINR=X": {"name": "USD/INR", "category": "EM - Asia", "region": "India"},
    "USDKRW=X": {"name": "USD/KRW", "category": "EM - Asia", "region": "South Korea"},
    "USDSGD=X": {"name": "USD/SGD", "category": "EM - Asia", "region": "Singapore"},
    "USDTHB=X": {"name": "USD/THB", "category": "EM - Asia", "region": "Thailand"},
    "USDPHP=X": {"name": "USD/PHP", "category": "EM - Asia", "region": "Philippines"},
    "USDIDR=X": {"name": "USD/IDR", "category": "EM - Asia", "region": "Indonesia"},

    # ===== EMERGING MARKET - LATAM (4) =====
    "USDBRL=X": {"name": "USD/BRL", "category": "EM - LATAM", "region": "Brazil"},
    "USDMXN=X": {"name": "USD/MXN", "category": "EM - LATAM", "region": "Mexico"},
    "USDCLP=X": {"name": "USD/CLP", "category": "EM - LATAM", "region": "Chile"},
    "USDARS=X": {"name": "USD/ARS", "category": "EM - LATAM", "region": "Argentina"},

    # ===== EMERGING MARKET - EMEA (6) =====
    "USDTRY=X": {"name": "USD/TRY", "category": "EM - EMEA", "region": "Turkey"},
    "USDZAR=X": {"name": "USD/ZAR", "category": "EM - EMEA", "region": "South Africa"},
    "USDRUB=X": {"name": "USD/RUB", "category": "EM - EMEA", "region": "Russia"},
    "USDPLN=X": {"name": "USD/PLN", "category": "EM - EMEA", "region": "Poland"},
    "USDHUF=X": {"name": "USD/HUF", "category": "EM - EMEA", "region": "Hungary"},
    "USDCZK=X": {"name": "USD/CZK", "category": "EM - EMEA", "region": "Czech Republic"}
}

# EXPANDED: Bond Yields and Rates - COMPREHENSIVE GLOBAL COVERAGE
BOND_YIELDS = {
    # US Treasuries (Direct Yield Indices)
    "^TNX": {"name": "US 10Y Treasury", "category": "Government Bonds"},
    "^TYX": {"name": "US 30Y Treasury", "category": "Government Bonds"},
    "^FVX": {"name": "US 5Y Treasury", "category": "Government Bonds"},
    "^IRX": {"name": "US 13W Treasury", "category": "Government Bonds"},

    # UK Gilts (ETF proxies - Yahoo Finance doesn't have direct UK yield indices)
    "IGLT.L": {"name": "UK Gilt (Long-Term)", "category": "Government Bonds"},
    "IGLS.L": {"name": "UK Gilt (Short-Term)", "category": "Government Bonds"},

    # German Bunds (ETF proxies)
    "IBGM.DE": {"name": "Germany Govt Bonds", "category": "Government Bonds"},
    "DTLA.DE": {"name": "German Bund 10Y", "category": "Government Bonds"},

    # Japanese JGBs (ETF proxies)
    "1346.T": {"name": "Japan Govt Bonds (ETF)", "category": "Government Bonds"},

    # Other Major Economies (ETF proxies)
    "XGB.TO": {"name": "Canada Govt Bonds", "category": "Government Bonds"},
    "IGB.AX": {"name": "Australia Govt Bonds", "category": "Government Bonds"},
    "AGGH": {"name": "Global Aggregate Bonds", "category": "Government Bonds"},
}

# v9.7 EXPANDED: Credit Spreads (using ETF proxies)
CREDIT_SPREADS = {
    "LQD": {"name": "Investment Grade Credit", "category": "Credit"},
    "HYG": {"name": "High Yield Credit", "category": "Credit"},
    "JNK": {"name": "High Yield Junk Bonds", "category": "Credit"},
    "EMB": {"name": "Emerging Market Bonds", "category": "Credit"},
    "TIP": {"name": "TIPS (Inflation-Protected)", "category": "Government Bonds"},
    "MBB": {"name": "Mortgage-Backed Securities", "category": "Credit"},
    # v9.7 NEW: Additional spreads
    "VCSH": {"name": "Short-Term Corporate", "category": "Credit"},
    "VCIT": {"name": "Intermediate Corporate", "category": "Credit"},
    "VCLT": {"name": "Long-Term Corporate", "category": "Credit"},
    "BKLN": {"name": "Senior Loan (Floating Rate)", "category": "Credit"},
    "ANGL": {"name": "Fallen Angels", "category": "Credit"},
    "SHYG": {"name": "Short Duration High Yield", "category": "Credit"},
}

# EXPANDED: Commodities (50+ instruments)
# COMMODITIES - BLOOMBERG KILLER EDITION
# 29 ‚Üí 80+ commodities and futures contracts
COMMODITIES = {
    # ===== PRECIOUS METALS (10) =====
    "GC=F": {"name": "Gold Futures", "category": "Precious Metals", "exchange": "COMEX"},
    "SI=F": {"name": "Silver Futures", "category": "Precious Metals", "exchange": "COMEX"},
    "PL=F": {"name": "Platinum Futures", "category": "Precious Metals", "exchange": "NYMEX"},
    "PA=F": {"name": "Palladium Futures", "category": "Precious Metals", "exchange": "NYMEX"},
    "HG=F": {"name": "Copper Futures", "category": "Base Metals", "exchange": "COMEX"},
    "GC.MICRO": {"name": "Micro Gold", "category": "Precious Metals", "exchange": "COMEX"},
    "SI.MICRO": {"name": "Micro Silver", "category": "Precious Metals", "exchange": "COMEX"},

    # ===== ENERGY (20) =====
    # Crude Oil
    "CL=F": {"name": "Crude Oil WTI", "category": "Energy - Oil", "exchange": "NYMEX"},
    "BZ=F": {"name": "Brent Crude", "category": "Energy - Oil", "exchange": "ICE"},
    "MCL=F": {"name": "Micro WTI Crude", "category": "Energy - Oil", "exchange": "NYMEX"},

    # Natural Gas & Products
    "NG=F": {"name": "Natural Gas", "category": "Energy - Gas", "exchange": "NYMEX"},
    "RB=F": {"name": "RBOB Gasoline", "category": "Energy - Refined", "exchange": "NYMEX"},
    "HO=F": {"name": "Heating Oil", "category": "Energy - Refined", "exchange": "NYMEX"},
    "B0=F": {"name": "Ethanol", "category": "Energy - Biofuels", "exchange": "CBOT"},

    # Coal
    "MTF=F": {"name": "Coal (API 2)", "category": "Energy - Coal", "exchange": "ICE"},

    # ===== INDUSTRIAL/BASE METALS (15) =====
    "ALI=F": {"name": "Aluminum", "category": "Industrial Metals", "exchange": "LME"},
    "ZN=F": {"name": "Zinc", "category": "Industrial Metals", "exchange": "LME"},
    "NI=F": {"name": "Nickel", "category": "Industrial Metals", "exchange": "LME"},
    "PB=F": {"name": "Lead", "category": "Industrial Metals", "exchange": "LME"},
    "SN=F": {"name": "Tin", "category": "Industrial Metals", "exchange": "LME"},
    "STEEL=F": {"name": "Steel", "category": "Industrial Metals", "exchange": "LME"},
    "COBALT": {"name": "Cobalt", "category": "Industrial Metals", "exchange": "LME"},
    "LITHIUM": {"name": "Lithium", "category": "Battery Metals", "exchange": "LME"},

    # ===== AGRICULTURE - GRAINS (15) =====
    "ZC=F": {"name": "Corn", "category": "Agriculture - Grains", "exchange": "CBOT"},
    "ZW=F": {"name": "Wheat", "category": "Agriculture - Grains", "exchange": "CBOT"},
    "ZS=F": {"name": "Soybeans", "category": "Agriculture - Grains", "exchange": "CBOT"},
    "ZO=F": {"name": "Oats", "category": "Agriculture - Grains", "exchange": "CBOT"},
    "ZR=F": {"name": "Rough Rice", "category": "Agriculture - Grains", "exchange": "CBOT"},
    "ZM=F": {"name": "Soybean Meal", "category": "Agriculture - Grains", "exchange": "CBOT"},
    "ZL=F": {"name": "Soybean Oil", "category": "Agriculture - Grains", "exchange": "CBOT"},
    "KE=F": {"name": "KC HRW Wheat", "category": "Agriculture - Grains", "exchange": "KCBT"},
    "MWE=F": {"name": "MW Wheat", "category": "Agriculture - Grains", "exchange": "MGEX"},

    # ===== AGRICULTURE - SOFTS (15) =====
    "KC=F": {"name": "Coffee C", "category": "Agriculture - Softs", "exchange": "ICE"},
    "SB=F": {"name": "Sugar #11", "category": "Agriculture - Softs", "exchange": "ICE"},
    "CC=F": {"name": "Cocoa", "category": "Agriculture - Softs", "exchange": "ICE"},
    "CT=F": {"name": "Cotton #2", "category": "Agriculture - Softs", "exchange": "ICE"},
    "OJ=F": {"name": "Orange Juice", "category": "Agriculture - Softs", "exchange": "ICE"},
    "LBS=F": {"name": "Lumber", "category": "Agriculture - Softs", "exchange": "CME"},
    "RC=F": {"name": "Robusta Coffee", "category": "Agriculture - Softs", "exchange": "ICE"},

    # ===== LIVESTOCK (5) =====
    "LE=F": {"name": "Live Cattle", "category": "Livestock", "exchange": "CME"},
    "GF=F": {"name": "Feeder Cattle", "category": "Livestock", "exchange": "CME"},
    "HE=F": {"name": "Lean Hogs", "category": "Livestock", "exchange": "CME"},

    # ===== INDICES FUTURES (10) =====
    "ES=F": {"name": "E-mini S&P 500", "category": "Equity Index Futures", "exchange": "CME"},
    "NQ=F": {"name": "E-mini Nasdaq 100", "category": "Equity Index Futures", "exchange": "CME"},
    "YM=F": {"name": "E-mini Dow", "category": "Equity Index Futures", "exchange": "CBOT"},
    "RTY=F": {"name": "E-mini Russell 2000", "category": "Equity Index Futures", "exchange": "CME"},
    "VIX=F": {"name": "VIX Futures", "category": "Volatility Futures", "exchange": "CFE"},

    # ===== BOND/RATE FUTURES (8) =====
    "ZB=F": {"name": "30-Year T-Bond", "category": "Interest Rate Futures", "exchange": "CBOT"},
    "ZN=F": {"name": "10-Year T-Note", "category": "Interest Rate Futures", "exchange": "CBOT"},
    "ZF=F": {"name": "5-Year T-Note", "category": "Interest Rate Futures", "exchange": "CBOT"},
    "ZT=F": {"name": "2-Year T-Note", "category": "Interest Rate Futures", "exchange": "CBOT"},
    "GE=F": {"name": "Eurodollar", "category": "Interest Rate Futures", "exchange": "CME"}
}

# EXPANDED: Popular Stocks (45 diverse companies - FIXED)
POPULAR_STOCKS = {
    # Mega Cap Tech
    "AAPL": {"name": "Apple", "sector": "Technology", "category": "Mega Cap Tech"},
    "MSFT": {"name": "Microsoft", "sector": "Technology", "category": "Mega Cap Tech"},
    "GOOGL": {"name": "Alphabet", "sector": "Technology", "category": "Mega Cap Tech"},
    "AMZN": {"name": "Amazon", "sector": "Consumer Cyclical", "category": "Mega Cap Tech"},
    "NVDA": {"name": "NVIDIA", "sector": "Technology", "category": "Mega Cap Tech"},
    "META": {"name": "Meta", "sector": "Technology", "category": "Mega Cap Tech"},
    "TSLA": {"name": "Tesla", "sector": "Consumer Cyclical", "category": "Mega Cap Tech"},
    "NFLX": {"name": "Netflix", "sector": "Communication Services", "category": "Mega Cap Tech"},

    # Financials
    "JPM": {"name": "JPMorgan", "sector": "Financial Services", "category": "Financials"},
    "BAC": {"name": "Bank of America", "sector": "Financial Services", "category": "Financials"},
    "WFC": {"name": "Wells Fargo", "sector": "Financial Services", "category": "Financials"},
    "GS": {"name": "Goldman Sachs", "sector": "Financial Services", "category": "Financials"},
    "MS": {"name": "Morgan Stanley", "sector": "Financial Services", "category": "Financials"},
    "C": {"name": "Citigroup", "sector": "Financial Services", "category": "Financials"},
    "BLK": {"name": "BlackRock", "sector": "Financial Services", "category": "Financials"},
    "V": {"name": "Visa", "sector": "Financial Services", "category": "Financials"},
    "MA": {"name": "Mastercard", "sector": "Financial Services", "category": "Financials"},

    # Healthcare
    "JNJ": {"name": "Johnson & Johnson", "sector": "Healthcare", "category": "Healthcare"},
    "UNH": {"name": "UnitedHealth", "sector": "Healthcare", "category": "Healthcare"},
    "PFE": {"name": "Pfizer", "sector": "Healthcare", "category": "Healthcare"},
    "ABBV": {"name": "AbbVie", "sector": "Healthcare", "category": "Healthcare"},
    "TMO": {"name": "Thermo Fisher", "sector": "Healthcare", "category": "Healthcare"},
    "LLY": {"name": "Eli Lilly", "sector": "Healthcare", "category": "Healthcare"},

    # Consumer
    "WMT": {"name": "Walmart", "sector": "Consumer Defensive", "category": "Consumer"},
    "PG": {"name": "Procter & Gamble", "sector": "Consumer Defensive", "category": "Consumer"},
    "KO": {"name": "Coca-Cola", "sector": "Consumer Defensive", "category": "Consumer"},
    "PEP": {"name": "PepsiCo", "sector": "Consumer Defensive", "category": "Consumer"},
    "COST": {"name": "Costco", "sector": "Consumer Defensive", "category": "Consumer"},
    "NKE": {"name": "Nike", "sector": "Consumer Cyclical", "category": "Consumer"},
    "MCD": {"name": "McDonald's", "sector": "Consumer Cyclical", "category": "Consumer"},
    "SBUX": {"name": "Starbucks", "sector": "Consumer Cyclical", "category": "Consumer"},
    "DIS": {"name": "Disney", "sector": "Communication Services", "category": "Consumer"},

    # Energy
    "XOM": {"name": "Exxon Mobil", "sector": "Energy", "category": "Energy"},
    "CVX": {"name": "Chevron", "sector": "Energy", "category": "Energy"},
    "COP": {"name": "ConocoPhillips", "sector": "Energy", "category": "Energy"},
    "SLB": {"name": "Schlumberger", "sector": "Energy", "category": "Energy"},

    # Industrials
    "BA": {"name": "Boeing", "sector": "Industrials", "category": "Industrials"},
    "CAT": {"name": "Caterpillar", "sector": "Industrials", "category": "Industrials"},
    "GE": {"name": "General Electric", "sector": "Industrials", "category": "Industrials"},
    "UPS": {"name": "UPS", "sector": "Industrials", "category": "Industrials"},

    # Tech (Additional)
    "ORCL": {"name": "Oracle", "sector": "Technology", "category": "Tech"},
    "CRM": {"name": "Salesforce", "sector": "Technology", "category": "Tech"},
    "ADBE": {"name": "Adobe", "sector": "Technology", "category": "Tech"},
    "INTC": {"name": "Intel", "sector": "Technology", "category": "Tech"},
    "AMD": {"name": "AMD", "sector": "Technology", "category": "Tech"},
    "CSCO": {"name": "Cisco", "sector": "Technology", "category": "Tech"},

    # Semiconductors
    "TSM": {"name": "TSMC", "sector": "Technology", "category": "Semiconductors"},
    "ASML": {"name": "ASML", "sector": "Technology", "category": "Semiconductors"},
    "AVGO": {"name": "Broadcom", "sector": "Technology", "category": "Semiconductors"},
    "QCOM": {"name": "Qualcomm", "sector": "Technology", "category": "Semiconductors"},
    "TXN": {"name": "Texas Instruments", "sector": "Technology", "category": "Semiconductors"},
    "MU": {"name": "Micron", "sector": "Technology", "category": "Semiconductors"},
    "LRCX": {"name": "Lam Research", "sector": "Technology", "category": "Semiconductors"},
    "AMAT": {"name": "Applied Materials", "sector": "Technology", "category": "Semiconductors"},
    "KLAC": {"name": "KLA Corporation", "sector": "Technology", "category": "Semiconductors"},
    "MRVL": {"name": "Marvell", "sector": "Technology", "category": "Semiconductors"},

    # Software & Cloud
    "NOW": {"name": "ServiceNow", "sector": "Technology", "category": "Software"},
    "SNOW": {"name": "Snowflake", "sector": "Technology", "category": "Software"},
    "PANW": {"name": "Palo Alto Networks", "sector": "Technology", "category": "Software"},
    "CRWD": {"name": "CrowdStrike", "sector": "Technology", "category": "Software"},
    "DDOG": {"name": "Datadog", "sector": "Technology", "category": "Software"},
    "NET": {"name": "Cloudflare", "sector": "Technology", "category": "Software"},
    "ZS": {"name": "Zscaler", "sector": "Technology", "category": "Software"},
    "WDAY": {"name": "Workday", "sector": "Technology", "category": "Software"},
    "TEAM": {"name": "Atlassian", "sector": "Technology", "category": "Software"},
    "PLTR": {"name": "Palantir", "sector": "Technology", "category": "Software"},

    # E-Commerce & Payments
    "SHOP": {"name": "Shopify", "sector": "Technology", "category": "E-Commerce"},
    "PYPL": {"name": "PayPal", "sector": "Technology", "category": "Payments"},
    "SQ": {"name": "Block (Square)", "sector": "Technology", "category": "Payments"},
    "COIN": {"name": "Coinbase", "sector": "Technology", "category": "Crypto"},
    "MELI": {"name": "MercadoLibre", "sector": "Technology", "category": "E-Commerce"},
    "SE": {"name": "Sea Limited", "sector": "Technology", "category": "E-Commerce"},

    # Telecom & Media
    "T": {"name": "AT&T", "sector": "Communication Services", "category": "Telecom"},
    "VZ": {"name": "Verizon", "sector": "Communication Services", "category": "Telecom"},
    "TMUS": {"name": "T-Mobile", "sector": "Communication Services", "category": "Telecom"},
    "CMCSA": {"name": "Comcast", "sector": "Communication Services", "category": "Media"},
    "CHTR": {"name": "Charter", "sector": "Communication Services", "category": "Telecom"},

    # Biotech
    "GILD": {"name": "Gilead", "sector": "Healthcare", "category": "Biotech"},
    "AMGN": {"name": "Amgen", "sector": "Healthcare", "category": "Biotech"},
    "BIIB": {"name": "Biogen", "sector": "Healthcare", "category": "Biotech"},
    "REGN": {"name": "Regeneron", "sector": "Healthcare", "category": "Biotech"},
    "VRTX": {"name": "Vertex", "sector": "Healthcare", "category": "Biotech"},
    "MRNA": {"name": "Moderna", "sector": "Healthcare", "category": "Biotech"},
    "BNTX": {"name": "BioNTech", "sector": "Healthcare", "category": "Biotech"},

    # Medical Devices
    "MDT": {"name": "Medtronic", "sector": "Healthcare", "category": "Medical Devices"},
    "ABT": {"name": "Abbott Labs", "sector": "Healthcare", "category": "Medical Devices"},
    "SYK": {"name": "Stryker", "sector": "Healthcare", "category": "Medical Devices"},
    "BSX": {"name": "Boston Scientific", "sector": "Healthcare", "category": "Medical Devices"},
    "ISRG": {"name": "Intuitive Surgical", "sector": "Healthcare", "category": "Medical Devices"},

    # Insurance
    "BRK-B": {"name": "Berkshire Hathaway", "sector": "Financial Services", "category": "Insurance"},
    "PGR": {"name": "Progressive", "sector": "Financial Services", "category": "Insurance"},
    "TRV": {"name": "Travelers", "sector": "Financial Services", "category": "Insurance"},
    "AIG": {"name": "AIG", "sector": "Financial Services", "category": "Insurance"},
    "MET": {"name": "MetLife", "sector": "Financial Services", "category": "Insurance"},
    "PRU": {"name": "Prudential", "sector": "Financial Services", "category": "Insurance"},

    # Real Estate
    "AMT": {"name": "American Tower", "sector": "Real Estate", "category": "REITs"},
    "PLD": {"name": "Prologis", "sector": "Real Estate", "category": "REITs"},
    "CCI": {"name": "Crown Castle", "sector": "Real Estate", "category": "REITs"},
    "EQIX": {"name": "Equinix", "sector": "Real Estate", "category": "REITs"},
    "PSA": {"name": "Public Storage", "sector": "Real Estate", "category": "REITs"},
    "SPG": {"name": "Simon Property", "sector": "Real Estate", "category": "REITs"},

    # Retail
    "TGT": {"name": "Target", "sector": "Consumer Defensive", "category": "Retail"},
    "HD": {"name": "Home Depot", "sector": "Consumer Cyclical", "category": "Retail"},
    "LOW": {"name": "Lowe's", "sector": "Consumer Cyclical", "category": "Retail"},
    "TJX": {"name": "TJX Companies", "sector": "Consumer Cyclical", "category": "Retail"},
    "ROST": {"name": "Ross Stores", "sector": "Consumer Cyclical", "category": "Retail"},

    # Automotive
    "F": {"name": "Ford", "sector": "Consumer Cyclical", "category": "Automotive"},
    "GM": {"name": "General Motors", "sector": "Consumer Cyclical", "category": "Automotive"},
    "RIVN": {"name": "Rivian", "sector": "Consumer Cyclical", "category": "Automotive"},
    "LCID": {"name": "Lucid", "sector": "Consumer Cyclical", "category": "Automotive"},

    # Materials
    "LIN": {"name": "Linde", "sector": "Basic Materials", "category": "Chemicals"},
    "APD": {"name": "Air Products", "sector": "Basic Materials", "category": "Chemicals"},
    "SHW": {"name": "Sherwin-Williams", "sector": "Basic Materials", "category": "Chemicals"},
    "ECL": {"name": "Ecolab", "sector": "Basic Materials", "category": "Chemicals"},
    "DD": {"name": "DuPont", "sector": "Basic Materials", "category": "Chemicals"},
    "NEM": {"name": "Newmont", "sector": "Basic Materials", "category": "Mining"},
    "FCX": {"name": "Freeport-McMoRan", "sector": "Basic Materials", "category": "Mining"},

    # Aerospace & Defense
    "LMT": {"name": "Lockheed Martin", "sector": "Industrials", "category": "Aerospace"},
    "RTX": {"name": "Raytheon", "sector": "Industrials", "category": "Aerospace"},
    "NOC": {"name": "Northrop Grumman", "sector": "Industrials", "category": "Aerospace"},
    "GD": {"name": "General Dynamics", "sector": "Industrials", "category": "Aerospace"},
    "LHX": {"name": "L3Harris", "sector": "Industrials", "category": "Aerospace"},

    # Transportation
    "UNP": {"name": "Union Pacific", "sector": "Industrials", "category": "Transportation"},
    "CSX": {"name": "CSX", "sector": "Industrials", "category": "Transportation"},
    "NSC": {"name": "Norfolk Southern", "sector": "Industrials", "category": "Transportation"},
    "FDX": {"name": "FedEx", "sector": "Industrials", "category": "Transportation"},
    "DAL": {"name": "Delta Air Lines", "sector": "Industrials", "category": "Airlines"},
    "UAL": {"name": "United Airlines", "sector": "Industrials", "category": "Airlines"},
    "AAL": {"name": "American Airlines", "sector": "Industrials", "category": "Airlines"},

    # Utilities
    "NEE": {"name": "NextEra Energy", "sector": "Utilities", "category": "Utilities"},
    "DUK": {"name": "Duke Energy", "sector": "Utilities", "category": "Utilities"},
    "SO": {"name": "Southern Company", "sector": "Utilities", "category": "Utilities"},
    "D": {"name": "Dominion Energy", "sector": "Utilities", "category": "Utilities"},
    "AEP": {"name": "AEP", "sector": "Utilities", "category": "Utilities"},

    # Oil Services
    "HAL": {"name": "Halliburton", "sector": "Energy", "category": "Oil Services"},
    "BKR": {"name": "Baker Hughes", "sector": "Energy", "category": "Oil Services"},

    # Mid-Caps & Growth
    "ROKU": {"name": "Roku", "sector": "Technology", "category": "Media"},
    "ZM": {"name": "Zoom", "sector": "Technology", "category": "Software"},
    "UBER": {"name": "Uber", "sector": "Technology", "category": "Rideshare"},
    "LYFT": {"name": "Lyft", "sector": "Technology", "category": "Rideshare"},
    "ABNB": {"name": "Airbnb", "sector": "Consumer Cyclical", "category": "Travel"},
    "DASH": {"name": "DoorDash", "sector": "Consumer Cyclical", "category": "Delivery"},
    "RBLX": {"name": "Roblox", "sector": "Technology", "category": "Gaming"},
    "U": {"name": "Unity", "sector": "Technology", "category": "Gaming"},
    "TTWO": {"name": "Take-Two", "sector": "Technology", "category": "Gaming"},
    "EA": {"name": "EA", "sector": "Technology", "category": "Gaming"},

    # ===== ADDITIONAL US STOCKS (100+) =====

    # More Banks & Financials
    "USB": {"name": "US Bancorp", "sector": "Financial Services", "category": "Banking"},
    "PNC": {"name": "PNC Financial", "sector": "Financial Services", "category": "Banking"},
    "TFC": {"name": "Truist Financial", "sector": "Financial Services", "category": "Banking"},
    "SCHW": {"name": "Schwab", "sector": "Financial Services", "category": "Brokerage"},
    "BX": {"name": "Blackstone", "sector": "Financial Services", "category": "Private Equity"},
    "KKR": {"name": "KKR", "sector": "Financial Services", "category": "Private Equity"},
    "CME": {"name": "CME Group", "sector": "Financial Services", "category": "Exchanges"},
    "ICE": {"name": "ICE", "sector": "Financial Services", "category": "Exchanges"},
    "AXP": {"name": "American Express", "sector": "Financial Services", "category": "Payments"},

    # More Pharma & Biotech
    "MRK": {"name": "Merck", "sector": "Healthcare", "category": "Pharma"},
    "BMY": {"name": "Bristol Myers", "sector": "Healthcare", "category": "Pharma"},
    "CVS": {"name": "CVS Health", "sector": "Healthcare", "category": "Pharmacy"},
    "CI": {"name": "Cigna", "sector": "Healthcare", "category": "Managed Care"},
    "HUM": {"name": "Humana", "sector": "Healthcare", "category": "Managed Care"},
    "ILMN": {"name": "Illumina", "sector": "Healthcare", "category": "Biotech"},
    "DHR": {"name": "Danaher", "sector": "Healthcare", "category": "Life Sciences"},
    "EW": {"name": "Edwards Lifesciences", "sector": "Healthcare", "category": "Medical Devices"},
    "ZBH": {"name": "Zimmer Biomet", "sector": "Healthcare", "category": "Medical Devices"},
    "BDX": {"name": "Becton Dickinson", "sector": "Healthcare", "category": "Medical Devices"},

    # More Semiconductors
    "NXPI": {"name": "NXP Semiconductors", "sector": "Technology", "category": "Semiconductors"},
    "ADI": {"name": "Analog Devices", "sector": "Technology", "category": "Semiconductors"},
    "ON": {"name": "ON Semiconductor", "sector": "Technology", "category": "Semiconductors"},
    "MPWR": {"name": "Monolithic Power", "sector": "Technology", "category": "Semiconductors"},
    "SWKS": {"name": "Skyworks", "sector": "Technology", "category": "Semiconductors"},
    "QRVO": {"name": "Qorvo", "sector": "Technology", "category": "Semiconductors"},

    # More Software
    "DOCU": {"name": "DocuSign", "sector": "Technology", "category": "Software"},
    "TWLO": {"name": "Twilio", "sector": "Technology", "category": "Software"},
    "OKTA": {"name": "Okta", "sector": "Technology", "category": "Software"},
    "MDB": {"name": "MongoDB", "sector": "Technology", "category": "Software"},
    "FTNT": {"name": "Fortinet", "sector": "Technology", "category": "Cybersecurity"},
    "IBM": {"name": "IBM", "sector": "Technology", "category": "IT Services"},

    # More Consumer
    "PM": {"name": "Philip Morris", "sector": "Consumer Defensive", "category": "Tobacco"},
    "MO": {"name": "Altria", "sector": "Consumer Defensive", "category": "Tobacco"},
    "MDLZ": {"name": "Mondelez", "sector": "Consumer Defensive", "category": "Food"},
    "KHC": {"name": "Kraft Heinz", "sector": "Consumer Defensive", "category": "Food"},
    "GIS": {"name": "General Mills", "sector": "Consumer Defensive", "category": "Food"},
    "HSY": {"name": "Hershey", "sector": "Consumer Defensive", "category": "Food"},
    "CL": {"name": "Colgate-Palmolive", "sector": "Consumer Defensive", "category": "Personal Care"},
    "EL": {"name": "Estee Lauder", "sector": "Consumer Defensive", "category": "Personal Care"},
    "LULU": {"name": "Lululemon", "sector": "Consumer Cyclical", "category": "Apparel"},
    "DG": {"name": "Dollar General", "sector": "Consumer Defensive", "category": "Retail"},
    "DLTR": {"name": "Dollar Tree", "sector": "Consumer Defensive", "category": "Retail"},
    "YUM": {"name": "Yum Brands", "sector": "Consumer Cyclical", "category": "Restaurants"},
    "CMG": {"name": "Chipotle", "sector": "Consumer Cyclical", "category": "Restaurants"},
    "MAR": {"name": "Marriott", "sector": "Consumer Cyclical", "category": "Hotels"},
    "HLT": {"name": "Hilton", "sector": "Consumer Cyclical", "category": "Hotels"},
    "BKNG": {"name": "Booking Holdings", "sector": "Consumer Cyclical", "category": "Travel"},

    # More Energy
    "EOG": {"name": "EOG Resources", "sector": "Energy", "category": "Oil & Gas"},
    "PXD": {"name": "Pioneer Natural", "sector": "Energy", "category": "Oil & Gas"},
    "MPC": {"name": "Marathon Petroleum", "sector": "Energy", "category": "Refining"},
    "PSX": {"name": "Phillips 66", "sector": "Energy", "category": "Refining"},
    "VLO": {"name": "Valero", "sector": "Energy", "category": "Refining"},
    "OXY": {"name": "Occidental", "sector": "Energy", "category": "Oil & Gas"},
    "KMI": {"name": "Kinder Morgan", "sector": "Energy", "category": "Pipelines"},
    "WMB": {"name": "Williams Companies", "sector": "Energy", "category": "Pipelines"},

    # More Industrials
    "DE": {"name": "Deere & Company", "sector": "Industrials", "category": "Machinery"},
    "EMR": {"name": "Emerson Electric", "sector": "Industrials", "category": "Equipment"},
    "MMM": {"name": "3M", "sector": "Industrials", "category": "Conglomerate"},
    "HON": {"name": "Honeywell", "sector": "Industrials", "category": "Conglomerate"},
    "LUV": {"name": "Southwest Airlines", "sector": "Industrials", "category": "Airlines"},

    # More Materials
    "DOW": {"name": "Dow Inc", "sector": "Basic Materials", "category": "Chemicals"},
    "NUE": {"name": "Nucor", "sector": "Basic Materials", "category": "Steel"},
    "ALB": {"name": "Albemarle", "sector": "Basic Materials", "category": "Chemicals"},

    # More Real Estate
    "O": {"name": "Realty Income", "sector": "Real Estate", "category": "REITs"},
    "DLR": {"name": "Digital Realty", "sector": "Real Estate", "category": "REITs"},
    "WELL": {"name": "Welltower", "sector": "Real Estate", "category": "REITs"},
    "AVB": {"name": "AvalonBay", "sector": "Real Estate", "category": "REITs"},

    # More Utilities
    "EXC": {"name": "Exelon", "sector": "Utilities", "category": "Utilities"},
    "XEL": {"name": "Xcel Energy", "sector": "Utilities", "category": "Utilities"},
    "SRE": {"name": "Sempra Energy", "sector": "Utilities", "category": "Utilities"},
    "PCG": {"name": "PG&E", "sector": "Utilities", "category": "Utilities"},

    # More Insurance
    "AFL": {"name": "Aflac", "sector": "Financial Services", "category": "Insurance"},
    "ALL": {"name": "Allstate", "sector": "Financial Services", "category": "Insurance"},
    "PRU": {"name": "Prudential", "sector": "Financial Services", "category": "Insurance"},

    # ===== INTERNATIONAL - EUROPE (50+) =====

    # United Kingdom
    "HSBC": {"name": "HSBC Holdings", "sector": "Financial Services", "category": "International - UK"},
    "AZN": {"name": "AstraZeneca", "sector": "Healthcare", "category": "International - UK"},
    "GSK": {"name": "GSK", "sector": "Healthcare", "category": "International - UK"},
    "BP": {"name": "BP", "sector": "Energy", "category": "International - UK"},
    "SHEL": {"name": "Shell", "sector": "Energy", "category": "International - UK"},
    "RIO": {"name": "Rio Tinto", "sector": "Basic Materials", "category": "International - UK"},
    "BTI": {"name": "British American Tobacco", "sector": "Consumer Defensive", "category": "International - UK"},

    # France
    "TTE": {"name": "TotalEnergies", "sector": "Energy", "category": "International - France"},

    # Spain
    "SAN": {"name": "Banco Santander", "sector": "Financial Services", "category": "International - Spain"},

    # Italy
    "RACE": {"name": "Ferrari", "sector": "Consumer Cyclical", "category": "International - Italy"},

    # Denmark
    "NVO": {"name": "Novo Nordisk", "sector": "Healthcare", "category": "International - Denmark"},

    # Sweden/Finland
    "ERIC": {"name": "Ericsson", "sector": "Technology", "category": "International - Sweden"},
    "NOK": {"name": "Nokia", "sector": "Technology", "category": "International - Finland"},

    # ===== INTERNATIONAL - ASIA PACIFIC (70+) =====

    # Japan
    "NTDOY": {"name": "Nintendo", "sector": "Communication Services", "category": "International - Japan"},
    "HMC": {"name": "Honda Motor", "sector": "Consumer Cyclical", "category": "International - Japan"},
    "MUFG": {"name": "Mitsubishi UFJ", "sector": "Financial Services", "category": "International - Japan"},

    # China & Hong Kong
    "BABA": {"name": "Alibaba", "sector": "Technology", "category": "International - China"},
    "TCEHY": {"name": "Tencent", "sector": "Technology", "category": "International - China"},
    "PDD": {"name": "PDD Holdings", "sector": "Technology", "category": "International - China"},
    "JD": {"name": "JD.com", "sector": "Technology", "category": "International - China"},
    "BIDU": {"name": "Baidu", "sector": "Technology", "category": "International - China"},
    "LI": {"name": "Li Auto", "sector": "Consumer Cyclical", "category": "International - China"},
    "XPEV": {"name": "XPeng", "sector": "Consumer Cyclical", "category": "International - China"},
    "BYDDY": {"name": "BYD", "sector": "Consumer Cyclical", "category": "International - China"},
    "YUMC": {"name": "Yum China", "sector": "Consumer Cyclical", "category": "International - China"},

    # India
    "INFY": {"name": "Infosys", "sector": "Technology", "category": "International - India"},
    "WIT": {"name": "Wipro", "sector": "Technology", "category": "International - India"},
    "HDB": {"name": "HDFC Bank", "sector": "Financial Services", "category": "International - India"},
    "IBN": {"name": "ICICI Bank", "sector": "Financial Services", "category": "International - India"},

    # Australia
    "BHP": {"name": "BHP Group", "sector": "Basic Materials", "category": "International - Australia"},

    # ===== INTERNATIONAL - LATIN AMERICA (20+) =====

    # Brazil
    "PBR": {"name": "Petrobras", "sector": "Energy", "category": "International - Brazil"},
    "VALE": {"name": "Vale", "sector": "Basic Materials", "category": "International - Brazil"},
    "ITUB": {"name": "Itau Unibanco", "sector": "Financial Services", "category": "International - Brazil"},
    "BBD": {"name": "Banco Bradesco", "sector": "Financial Services", "category": "International - Brazil"},
    "ABEV": {"name": "Ambev", "sector": "Consumer Defensive", "category": "International - Brazil"},

    # Mexico
    "AMX": {"name": "America Movil", "sector": "Communication Services", "category": "International - Mexico"},

    # ===== ALREADY LISTED INTERNATIONAL =====
    "NIO": {"name": "NIO", "sector": "Consumer Cyclical", "category": "International - China"},
    "SAP": {"name": "SAP", "sector": "Technology", "category": "International - Germany"},
    "SNY": {"name": "Sanofi", "sector": "Healthcare", "category": "International - France"},
    "NVS": {"name": "Novartis", "sector": "Healthcare", "category": "International - Switzerland"},
    "UL": {"name": "Unilever", "sector": "Consumer Defensive", "category": "International - UK"},
    "DEO": {"name": "Diageo", "sector": "Consumer Defensive", "category": "International - UK"},
    "TM": {"name": "Toyota", "sector": "Consumer Cyclical", "category": "International - Japan"},
    "SONY": {"name": "Sony", "sector": "Technology", "category": "International - Japan"},
    "SPOT": {"name": "Spotify", "sector": "Communication Services", "category": "International - Sweden"}
}

# EXPANDED: Popular ETFs (150+ funds across all categories)
POPULAR_ETFS = {
    # Broad Market - Large Cap
    "SPY": {"name": "SPDR S&P 500", "category": "Broad Market", "avg_volume": 70000000},
    "VOO": {"name": "Vanguard S&P 500", "category": "Broad Market", "avg_volume": 5000000},
    "IVV": {"name": "iShares S&P 500", "category": "Broad Market", "avg_volume": 4000000},
    "QQQ": {"name": "Invesco QQQ", "category": "Broad Market", "avg_volume": 40000000},
    "VTI": {"name": "Total Stock Market", "category": "Broad Market", "avg_volume": 5000000},
    "ITOT": {"name": "iShares Total Market", "category": "Broad Market", "avg_volume": 1000000},
    "SCHB": {"name": "Schwab US Broad Market", "category": "Broad Market", "avg_volume": 1500000},

    # Mid & Small Cap
    "IWM": {"name": "Russell 2000", "category": "Small Cap", "avg_volume": 30000000},
    "IJH": {"name": "iShares Mid-Cap", "category": "Mid Cap", "avg_volume": 2000000},
    "MDY": {"name": "SPDR Mid-Cap 400", "category": "Mid Cap", "avg_volume": 1000000},
    "VB": {"name": "Vanguard Small-Cap", "category": "Small Cap", "avg_volume": 800000},
    "IJR": {"name": "iShares Small-Cap", "category": "Small Cap", "avg_volume": 3000000},

    # Sector - Technology
    "XLK": {"name": "Technology Select", "category": "Sector", "avg_volume": 15000000},
    "VGT": {"name": "Vanguard Technology", "category": "Sector", "avg_volume": 1500000},
    "FTEC": {"name": "Fidelity MSCI Tech", "category": "Sector", "avg_volume": 500000},
    "SOXX": {"name": "Semiconductor", "category": "Sector", "avg_volume": 5000000},
    "SMH": {"name": "VanEck Semiconductors", "category": "Sector", "avg_volume": 8000000},
    "IGV": {"name": "iShares Software", "category": "Sector", "avg_volume": 1000000},
    "CLOU": {"name": "Cloud Computing", "category": "Sector", "avg_volume": 500000},

    # Sector - Financial
    "XLF": {"name": "Financial Select", "category": "Sector", "avg_volume": 50000000},
    "VFH": {"name": "Vanguard Financials", "category": "Sector", "avg_volume": 2000000},
    "KRE": {"name": "Regional Banks", "category": "Sector", "avg_volume": 10000000},
    "KBE": {"name": "Bank ETF", "category": "Sector", "avg_volume": 2000000},

    # Sector - Healthcare
    "XLV": {"name": "Health Care Select", "category": "Sector", "avg_volume": 10000000},
    "VHT": {"name": "Vanguard Health Care", "category": "Sector", "avg_volume": 1000000},
    "IBB": {"name": "Biotech", "category": "Sector", "avg_volume": 3000000},
    "XBI": {"name": "SPDR Biotech", "category": "Sector", "avg_volume": 8000000},
    "IHI": {"name": "Medical Devices", "category": "Sector", "avg_volume": 500000},
    "XPH": {"name": "Pharmaceuticals", "category": "Sector", "avg_volume": 200000},

    # Sector - Energy
    "XLE": {"name": "Energy Select", "category": "Sector", "avg_volume": 20000000},
    "VDE": {"name": "Vanguard Energy", "category": "Sector", "avg_volume": 1000000},
    "XOP": {"name": "Oil & Gas Exploration", "category": "Sector", "avg_volume": 15000000},
    "USO": {"name": "US Oil Fund", "category": "Commodities", "avg_volume": 25000000},
    "OIH": {"name": "Oil Services", "category": "Sector", "avg_volume": 2000000},

    # Sector - Industrials
    "XLI": {"name": "Industrial Select", "category": "Sector", "avg_volume": 12000000},
    "VIS": {"name": "Vanguard Industrials", "category": "Sector", "avg_volume": 300000},
    "IYT": {"name": "Transportation", "category": "Sector", "avg_volume": 500000},
    "JETS": {"name": "Airlines", "category": "Sector", "avg_volume": 5000000},
    "ITA": {"name": "Aerospace & Defense", "category": "Sector", "avg_volume": 800000},

    # Sector - Consumer
    "XLY": {"name": "Consumer Discretionary", "category": "Sector", "avg_volume": 8000000},
    "XLP": {"name": "Consumer Staples", "category": "Sector", "avg_volume": 10000000},
    "VCR": {"name": "Vanguard Consumer Disc", "category": "Sector", "avg_volume": 300000},
    "VDC": {"name": "Vanguard Consumer Stpl", "category": "Sector", "avg_volume": 400000},
    "XRT": {"name": "Retail", "category": "Sector", "avg_volume": 8000000},

    # Sector - Materials & Utilities
    "XLB": {"name": "Materials Select", "category": "Sector", "avg_volume": 8000000},
    "XLU": {"name": "Utilities Select", "category": "Sector", "avg_volume": 12000000},
    "VAW": {"name": "Vanguard Materials", "category": "Sector", "avg_volume": 300000},
    "VPU": {"name": "Vanguard Utilities", "category": "Sector", "avg_volume": 400000},

    # Real Estate
    "XLRE": {"name": "Real Estate Select", "category": "Sector", "avg_volume": 5000000},
    "VNQ": {"name": "Vanguard Real Estate", "category": "Real Estate", "avg_volume": 5000000},
    "IYR": {"name": "iShares Real Estate", "category": "Real Estate", "avg_volume": 3000000},
    "REET": {"name": "iShares Global REIT", "category": "Real Estate", "avg_volume": 500000},

    # Communication Services
    "XLC": {"name": "Communication Services", "category": "Sector", "avg_volume": 8000000},
    "VOX": {"name": "Vanguard Comm Services", "category": "Sector", "avg_volume": 300000},

    # Thematic - Clean Energy
    "ICLN": {"name": "Clean Energy", "category": "Thematic", "avg_volume": 5000000},
    "TAN": {"name": "Solar Energy", "category": "Thematic", "avg_volume": 1500000},
    "QCLN": {"name": "Clean Energy", "category": "Thematic", "avg_volume": 2000000},
    "PBW": {"name": "Wilderhill Clean Energy", "category": "Thematic", "avg_volume": 800000},
    "FAN": {"name": "Wind Energy", "category": "Thematic", "avg_volume": 200000},

    # Thematic - Innovation & Tech
    "ARKK": {"name": "ARK Innovation", "category": "Thematic", "avg_volume": 8000000},
    "ARKQ": {"name": "ARK Autonomous Tech", "category": "Thematic", "avg_volume": 2000000},
    "ARKW": {"name": "ARK Next Gen Internet", "category": "Thematic", "avg_volume": 1500000},
    "ARKF": {"name": "ARK FinTech", "category": "Thematic", "avg_volume": 1000000},
    "ARKG": {"name": "ARK Genomic", "category": "Thematic", "avg_volume": 1200000},
    "ROBO": {"name": "Robotics & AI", "category": "Thematic", "avg_volume": 500000},
    "BOTZ": {"name": "Global Robotics", "category": "Thematic", "avg_volume": 1000000},
    "HACK": {"name": "Cybersecurity", "category": "Thematic", "avg_volume": 800000},
    "CIBR": {"name": "Cybersecurity & Tech", "category": "Thematic", "avg_volume": 1500000},
    "FINX": {"name": "FinTech", "category": "Thematic", "avg_volume": 300000},
    "BLOK": {"name": "Blockchain", "category": "Thematic", "avg_volume": 500000},

    # Thematic - Space, Gaming, Cannabis
    "UFO": {"name": "Space & Satellite", "category": "Thematic", "avg_volume": 100000},
    "ESPO": {"name": "Video Game Tech", "category": "Thematic", "avg_volume": 200000},
    "HERO": {"name": "Video Game & Esports", "category": "Thematic", "avg_volume": 150000},
    "MSOS": {"name": "US Cannabis", "category": "Thematic", "avg_volume": 5000000},
    "MJ": {"name": "Cannabis", "category": "Thematic", "avg_volume": 1000000},

    # International - Developed Markets
    "EFA": {"name": "EAFE", "category": "International", "avg_volume": 15000000},
    "VEA": {"name": "FTSE Developed Markets", "category": "International", "avg_volume": 8000000},
    "IEFA": {"name": "iShares Developed ex-US", "category": "International", "avg_volume": 5000000},
    "EWJ": {"name": "Japan", "category": "International", "avg_volume": 8000000},
    "EWG": {"name": "Germany", "category": "International", "avg_volume": 2000000},
    "EWU": {"name": "United Kingdom", "category": "International", "avg_volume": 5000000},
    "EWC": {"name": "Canada", "category": "International", "avg_volume": 2000000},
    "EWA": {"name": "Australia", "category": "International", "avg_volume": 3000000},
    "EWY": {"name": "South Korea", "category": "International", "avg_volume": 10000000},
    "EWT": {"name": "Taiwan", "category": "International", "avg_volume": 5000000},

    # International - Emerging Markets
    "EEM": {"name": "Emerging Markets", "category": "International", "avg_volume": 25000000},
    "VWO": {"name": "FTSE Emerging Markets", "category": "International", "avg_volume": 10000000},
    "IEMG": {"name": "iShares Emerging Markets", "category": "International", "avg_volume": 12000000},
    "FXI": {"name": "China Large-Cap", "category": "International", "avg_volume": 20000000},
    "MCHI": {"name": "iShares China", "category": "International", "avg_volume": 8000000},
    "KWEB": {"name": "China Internet", "category": "International", "avg_volume": 15000000},
    "EWZ": {"name": "Brazil", "category": "International", "avg_volume": 25000000},
    "RSX": {"name": "Russia", "category": "International", "avg_volume": 5000000},
    "EWW": {"name": "Mexico", "category": "International", "avg_volume": 3000000},
    "INDA": {"name": "India", "category": "International", "avg_volume": 5000000},
    "EWH": {"name": "Hong Kong", "category": "International", "avg_volume": 2000000},
    "EIDO": {"name": "Indonesia", "category": "International", "avg_volume": 500000},
    "EPHE": {"name": "Philippines", "category": "International", "avg_volume": 200000},
    "THD": {"name": "Thailand", "category": "International", "avg_volume": 300000},

    # Fixed Income - Government
    "TLT": {"name": "20+ Year Treasury", "category": "Bonds", "avg_volume": 15000000},
    "IEF": {"name": "7-10 Year Treasury", "category": "Bonds", "avg_volume": 8000000},
    "SHY": {"name": "1-3 Year Treasury", "category": "Bonds", "avg_volume": 15000000},
    "AGG": {"name": "Aggregate Bond", "category": "Bonds", "avg_volume": 10000000},
    "BND": {"name": "Vanguard Total Bond", "category": "Bonds", "avg_volume": 5000000},
    "TIP": {"name": "TIPS", "category": "Bonds", "avg_volume": 5000000},

    # Fixed Income - Corporate
    "LQD": {"name": "Investment Grade", "category": "Bonds", "avg_volume": 15000000},
    "HYG": {"name": "High Yield", "category": "Bonds", "avg_volume": 20000000},
    "JNK": {"name": "High Yield Junk", "category": "Bonds", "avg_volume": 10000000},
    "VCSH": {"name": "Short-Term Corporate", "category": "Bonds", "avg_volume": 4000000},
    "VCIT": {"name": "Intermediate Corporate", "category": "Bonds", "avg_volume": 3000000},
    "VCLT": {"name": "Long-Term Corporate", "category": "Bonds", "avg_volume": 2000000},

    # Fixed Income - International
    "EMB": {"name": "Emerging Market Bonds", "category": "Bonds", "avg_volume": 15000000},
    "BWX": {"name": "International Treasury", "category": "Bonds", "avg_volume": 1000000},
    "BNDX": {"name": "Intl Aggregate Bond", "category": "Bonds", "avg_volume": 3000000},

    # Commodity ETFs
    "GLD": {"name": "Gold", "category": "Commodities", "avg_volume": 10000000},
    "SLV": {"name": "Silver", "category": "Commodities", "avg_volume": 20000000},
    "GDX": {"name": "Gold Miners", "category": "Commodities", "avg_volume": 25000000},
    "GDXJ": {"name": "Junior Gold Miners", "category": "Commodities", "avg_volume": 15000000},
    "UNG": {"name": "Natural Gas", "category": "Commodities", "avg_volume": 15000000},
    "DBA": {"name": "Agriculture", "category": "Commodities", "avg_volume": 500000},
    "DBB": {"name": "Base Metals", "category": "Commodities", "avg_volume": 300000},

    # Factor - Smart Beta
    "MTUM": {"name": "Momentum", "category": "Factor", "avg_volume": 3000000},
    "QUAL": {"name": "Quality", "category": "Factor", "avg_volume": 2000000},
    "SIZE": {"name": "Size Factor", "category": "Factor", "avg_volume": 500000},
    "VLUE": {"name": "Value", "category": "Factor", "avg_volume": 2000000},
    "USMV": {"name": "Low Volatility", "category": "Factor", "avg_volume": 5000000},
    "SPLV": {"name": "Low Volatility", "category": "Factor", "avg_volume": 3000000},
    "SPHD": {"name": "High Dividend", "category": "Factor", "avg_volume": 2000000},
    "VIG": {"name": "Dividend Appreciation", "category": "Factor", "avg_volume": 3000000},
    "VYM": {"name": "High Dividend Yield", "category": "Factor", "avg_volume": 5000000},
    "SCHD": {"name": "Dividend ETF", "category": "Factor", "avg_volume": 5000000},
    "DG": {"name": "Dividend Growth", "category": "Factor", "avg_volume": 1000000},

    # Leveraged & Inverse (for completeness)
    "TQQQ": {"name": "3x Nasdaq", "category": "Leveraged", "avg_volume": 80000000},
    "SQQQ": {"name": "-3x Nasdaq", "category": "Inverse", "avg_volume": 60000000},
    "SPXU": {"name": "-3x S&P 500", "category": "Inverse", "avg_volume": 10000000},
    "UPRO": {"name": "3x S&P 500", "category": "Leveraged", "avg_volume": 15000000},
    "TNA": {"name": "3x Russell 2000", "category": "Leveraged", "avg_volume": 10000000},
    "SOXL": {"name": "3x Semiconductors", "category": "Leveraged", "avg_volume": 80000000},
    "VXX": {"name": "VIX Short-Term", "category": "Volatility", "avg_volume": 50000000},

    # ===== ADDITIONAL ETFS (117+) =====

    # More Thematic - AI & Cloud
    "BOTZ": {"name": "Global X Robotics & AI", "category": "Thematic - AI", "avg_volume": 1000000},
    "AIQ": {"name": "AI Powered Equity", "category": "Thematic - AI", "avg_volume": 500000},
    "IRBO": {"name": "iShares Robotics & AI", "category": "Thematic - AI", "avg_volume": 300000},
    "SKYY": {"name": "Cloud Computing", "category": "Thematic - Cloud", "avg_volume": 800000},
    "WCLD": {"name": "WisdomTree Cloud", "category": "Thematic - Cloud", "avg_volume": 1200000},

    # Thematic - Semiconductor & Hardware
    "XSD": {"name": "Semiconductor", "category": "Thematic - Tech", "avg_volume": 2000000},
    "PSI": {"name": "Semiconductor Index", "category": "Thematic - Tech", "avg_volume": 300000},

    # Thematic - EV & Battery
    "LIT": {"name": "Lithium & Battery", "category": "Thematic - EV", "avg_volume": 3000000},
    "BATT": {"name": "Battery Tech", "category": "Thematic - EV", "avg_volume": 500000},
    "DRIV": {"name": "Autonomous Driving", "category": "Thematic - EV", "avg_volume": 200000},
    "IDRV": {"name": "Self-Driving EV", "category": "Thematic - EV", "avg_volume": 400000},

    # Thematic - ESG & Sustainable
    "ESGU": {"name": "ESG US Stock", "category": "Thematic - ESG", "avg_volume": 2000000},
    "ESGV": {"name": "Vanguard ESG", "category": "Thematic - ESG", "avg_volume": 1000000},
    "SUSL": {"name": "Sustainable Leaders", "category": "Thematic - ESG", "avg_volume": 500000},
    "DSI": {"name": "Social Index", "category": "Thematic - ESG", "avg_volume": 400000},
    "KRMA": {"name": "Global Sustainability", "category": "Thematic - ESG", "avg_volume": 300000},

    # Thematic - Infrastructure & Construction
    "PAVE": {"name": "US Infrastructure", "category": "Thematic - Infrastructure", "avg_volume": 1500000},
    "IFRA": {"name": "Global Infrastructure", "category": "Thematic - Infrastructure", "avg_volume": 500000},
    "PKB": {"name": "Building & Construction", "category": "Thematic - Infrastructure", "avg_volume": 200000},

    # Thematic - Healthcare Innovation
    "GNOM": {"name": "Genomics", "category": "Thematic - Healthcare", "avg_volume": 800000},
    "EDOC": {"name": "Telehealth", "category": "Thematic - Healthcare", "avg_volume": 400000},
    "XLV": {"name": "Longevity", "category": "Thematic - Healthcare", "avg_volume": 300000},

    # More International - Europe
    "EWQ": {"name": "France", "category": "International - Europe", "avg_volume": 1000000},
    "EWI": {"name": "Italy", "category": "International - Europe", "avg_volume": 800000},
    "EWP": {"name": "Spain", "category": "International - Europe", "avg_volume": 500000},
    "EWL": {"name": "Switzerland", "category": "International - Europe", "avg_volume": 600000},
    "EWN": {"name": "Netherlands", "category": "International - Europe", "avg_volume": 400000},
    "EWD": {"name": "Sweden", "category": "International - Europe", "avg_volume": 300000},
    "EDEN": {"name": "Denmark", "category": "International - Europe", "avg_volume": 200000},
    "NORW": {"name": "Norway", "category": "International - Europe", "avg_volume": 150000},

    # More International - Asia
    "EWS": {"name": "Singapore", "category": "International - Asia", "avg_volume": 500000},
    "EWM": {"name": "Malaysia", "category": "International - Asia", "avg_volume": 300000},
    "EWZ": {"name": "South Africa", "category": "International - Africa", "avg_volume": 1000000},
    "EWZ": {"name": "Turkey", "category": "International - EM", "avg_volume": 2000000},
    "ERUS": {"name": "Russia", "category": "International - EM", "avg_volume": 500000},

    # More Fixed Income - Duration Specific
    "VGSH": {"name": "Short-Term Treasury", "category": "Bonds - Duration", "avg_volume": 2000000},
    "VGIT": {"name": "Intermediate Treasury", "category": "Bonds - Duration", "avg_volume": 1500000},
    "VGLT": {"name": "Long-Term Treasury", "category": "Bonds - Duration", "avg_volume": 1000000},
    "EDV": {"name": "Extended Duration", "category": "Bonds - Duration", "avg_volume": 500000},

    # Fixed Income - Municipal
    "MUB": {"name": "National Muni", "category": "Bonds - Municipal", "avg_volume": 3000000},
    "HYD": {"name": "High Yield Muni", "category": "Bonds - Municipal", "avg_volume": 1000000},
    "VTEB": {"name": "Tax-Exempt Bond", "category": "Bonds - Municipal", "avg_volume": 2000000},

    # Fixed Income - International
    "EMLC": {"name": "EM Local Currency", "category": "Bonds - EM", "avg_volume": 1000000},
    "PCY": {"name": "EM Sovereign Debt", "category": "Bonds - EM", "avg_volume": 800000},
    "VWOB": {"name": "EM Govt Bonds", "category": "Bonds - EM", "avg_volume": 1500000},

    # More Commodity - Metals
    "PPLT": {"name": "Platinum", "category": "Commodities - Metals", "avg_volume": 500000},
    "PALL": {"name": "Palladium", "category": "Commodities - Metals", "avg_volume": 300000},
    "CPER": {"name": "Copper", "category": "Commodities - Metals", "avg_volume": 1000000},
    "URNM": {"name": "Uranium", "category": "Commodities - Metals", "avg_volume": 2000000},

    # Commodity - Agriculture
    "CORN": {"name": "Corn", "category": "Commodities - Agriculture", "avg_volume": 500000},
    "WEAT": {"name": "Wheat", "category": "Commodities - Agriculture", "avg_volume": 600000},
    "SOYB": {"name": "Soybeans", "category": "Commodities - Agriculture", "avg_volume": 300000},
    "NIB": {"name": "Cocoa", "category": "Commodities - Agriculture", "avg_volume": 100000},

    # More Sector - Subsectors
    "FHLC": {"name": "Healthcare Equipment", "category": "Sector - Healthcare", "avg_volume": 300000},
    "IHF": {"name": "Healthcare Providers", "category": "Sector - Healthcare", "avg_volume": 200000},
    "XES": {"name": "Oil Equipment & Services", "category": "Sector - Energy", "avg_volume": 1000000},
    "CRAK": {"name": "Oil Refiners", "category": "Sector - Energy", "avg_volume": 500000},
    "COPX": {"name": "Copper Miners", "category": "Sector - Materials", "avg_volume": 1500000},
    "SIL": {"name": "Silver Miners", "category": "Sector - Materials", "avg_volume": 2000000},

    # More Dividend & Income
    "DVY": {"name": "Dow Dividend", "category": "Dividend", "avg_volume": 2000000},
    "NOBL": {"name": "Dividend Aristocrats", "category": "Dividend", "avg_volume": 1500000},
    "SDY": {"name": "Dividend ETF", "category": "Dividend", "avg_volume": 1000000},
    "PFF": {"name": "Preferred Stock", "category": "Income", "avg_volume": 5000000},
    "PFFD": {"name": "Preferred Securities", "category": "Income", "avg_volume": 800000},
    "KBWD": {"name": "High Dividend Yield", "category": "Dividend", "avg_volume": 500000},

    # More Factor - Smart Beta
    "RSP": {"name": "S&P 500 Equal Weight", "category": "Factor - Equal Weight", "avg_volume": 5000000},
    "QQEW": {"name": "Nasdaq Equal Weight", "category": "Factor - Equal Weight", "avg_volume": 1000000},
    "EQWL": {"name": "Equal Weight", "category": "Factor - Equal Weight", "avg_volume": 300000},
    "IUSV": {"name": "Value Factor", "category": "Factor - Value", "avg_volume": 2000000},
    "IUSG": {"name": "Growth Factor", "category": "Factor - Growth", "avg_volume": 3000000},
    "IWF": {"name": "Russell 1000 Growth", "category": "Factor - Growth", "avg_volume": 4000000},
    "IWD": {"name": "Russell 1000 Value", "category": "Factor - Value", "avg_volume": 5000000},

    # More Growth & Style
    "VUG": {"name": "Vanguard Growth", "category": "Style - Growth", "avg_volume": 3000000},
    "MGK": {"name": "Mega Cap Growth", "category": "Style - Growth", "avg_volume": 1000000},
    "VTV": {"name": "Vanguard Value", "category": "Style - Value", "avg_volume": 2000000},
    "MGV": {"name": "Mega Cap Value", "category": "Style - Value", "avg_volume": 500000},

    # Currency ETFs
    "UUP": {"name": "US Dollar Bullish", "category": "Currency", "avg_volume": 3000000},
    "FXE": {"name": "Euro Currency", "category": "Currency", "avg_volume": 1000000},
    "FXY": {"name": "Japanese Yen", "category": "Currency", "avg_volume": 800000},
    "FXB": {"name": "British Pound", "category": "Currency", "avg_volume": 500000},
    "FXA": {"name": "Australian Dollar", "category": "Currency", "avg_volume": 600000},
    "FXC": {"name": "Canadian Dollar", "category": "Currency", "avg_volume": 400000},

    # More Leveraged - Sector Specific
    "TECL": {"name": "3x Technology", "category": "Leveraged - Sector", "avg_volume": 10000000},
    "TPOR": {"name": "3x Transportation", "category": "Leveraged - Sector", "avg_volume": 500000},
    "DUSL": {"name": "3x Industrials", "category": "Leveraged - Sector", "avg_volume": 300000},
    "CURE": {"name": "3x Healthcare", "category": "Leveraged - Sector", "avg_volume": 1500000},
    "FAS": {"name": "3x Financials", "category": "Leveraged - Sector", "avg_volume": 5000000},
    "ERX": {"name": "3x Energy", "category": "Leveraged - Sector", "avg_volume": 2000000},

    # Real Assets
    "REET": {"name": "Real Estate", "category": "Real Assets", "avg_volume": 500000},
    "USCI": {"name": "Commodity Index", "category": "Real Assets", "avg_volume": 1000000},
    "PDBC": {"name": "Optimum Yield Commodity", "category": "Real Assets", "avg_volume": 2000000},
    "DJP": {"name": "Commodity Index", "category": "Real Assets", "avg_volume": 300000},

    # Alternatives
    "MNA": {"name": "Merger Arbitrage", "category": "Alternatives", "avg_volume": 500000},
    "QAI": {"name": "Alternative Strategies", "category": "Alternatives", "avg_volume": 300000},
    "TAIL": {"name": "Tail Risk", "category": "Alternatives", "avg_volume": 200000}
}

# Factor definitions
FACTOR_DEFINITIONS = {
    "Market": {"description": "Market risk premium", "benchmark": "SPY"},
    "Size": {"description": "Small cap minus large cap", "benchmark": "IWM"},
    "Value": {"description": "Value minus growth", "benchmark": "IWD"},
    "Momentum": {"description": "Winners minus losers", "benchmark": "MTUM"},
    "Quality": {"description": "High quality minus low quality", "benchmark": "QUAL"},
    "Volatility": {"description": "Low vol minus high vol", "benchmark": "USMV"}
}

# ETF sectors
ETF_SECTORS = {
    "QQQ": "Technology", "XLK": "Technology", "VGT": "Technology",
    "XLF": "Financial Services", "KRE": "Financial Services",
    "XLV": "Healthcare", "IBB": "Healthcare", "XBI": "Healthcare",
    "XLE": "Energy", "XOP": "Energy", "USO": "Energy",
    "XLB": "Basic Materials", "GDX": "Basic Materials",
    "XLY": "Consumer Cyclical", "XLP": "Consumer Defensive",
    "XLI": "Industrials", "IYT": "Industrials",
    "VNQ": "Real Estate", "XLRE": "Real Estate",
    "XLU": "Utilities",
    "SPY": "Broad Market", "VOO": "Broad Market", "VTI": "Broad Market"
}

# ============================================================================
# HELPER FUNCTIONS
# ============================================================================

def format_percentage(value, decimals=2):
    if pd.isna(value) or value is None:
        return "N/A"
    return f"{value:.{decimals}f}%"

def format_currency(value):
    if pd.isna(value) or value is None:
        return "N/A"
    return f"${value:,.2f}"

def format_large_number(value):
    """Format large numbers with B/M/K suffix"""
    if pd.isna(value) or value is None:
        return "N/A"
    if abs(value) >= 1e9:
        return f"${value/1e9:.2f}B"
    elif abs(value) >= 1e6:
        return f"${value/1e6:.2f}M"
    elif abs(value) >= 1e3:
        return f"${value/1e3:.2f}K"
    return f"${value:.2f}"

def add_arrow_indicator(value):
    try:
        val = float(str(value).replace('%', '').replace('$', '').replace(',', ''))
        if val > 0:
            return f"‚ñ≤ {value}"
        elif val < 0:
            return f"‚ñº {value}"
        return f"‚îÄ {value}"
    except:
        return value

def show_toast(message, toast_type="info", duration=3000):
    """Display a professional toast notification"""
    toast_styles = {
        "success": {"bg": "rgba(0, 255, 136, 0.95)", "border": "#00ff88", "icon": "‚úì"},
        "error": {"bg": "rgba(255, 0, 68, 0.95)", "border": "#ff0044", "icon": "‚úï"},
        "warning": {"bg": "rgba(255, 170, 0, 0.95)", "border": "#ffaa00", "icon": "‚ö†"},
        "info": {"bg": "rgba(0, 212, 255, 0.95)", "border": "#00d4ff", "icon": "‚Ñπ"}
    }
    style = toast_styles.get(toast_type, toast_styles["info"])
    toast_id = f"toast_{int(time.time() * 1000)}_{random.randint(1000, 9999)}"

    toast_html = f"""
    <style>
        .atlas-toast-container {{ position: fixed; top: 80px; right: 20px; z-index: 999999; }}
        .atlas-toast {{ min-width: 300px; max-width: 500px; margin-bottom: 12px; padding: 16px 20px;
                       background: {style['bg']}; border: 2px solid {style['border']}; border-radius: 12px;
                       color: #000; font-family: 'Inter', sans-serif; font-size: 14px; font-weight: 600;
                       animation: slideIn 0.4s ease-out, fadeOut 0.3s ease-in {duration-300}ms forwards; }}
        .atlas-toast-content {{ display: flex; align-items: center; gap: 12px; }}
        .atlas-toast-icon {{ font-size: 20px; }}
        @keyframes slideIn {{ from {{ transform: translateX(400px); opacity: 0; }}
                             to {{ transform: translateX(0); opacity: 1; }} }}
        @keyframes fadeOut {{ to {{ opacity: 0; transform: translateX(100px); }} }}
    </style>
    <div id="{toast_id}" class="atlas-toast">
        <div class="atlas-toast-content">
            <div class="atlas-toast-icon">{style['icon']}</div>
            <div>{message}</div>
        </div>
    </div>
    <script>
        (function() {{
            let container = document.querySelector('.atlas-toast-container');
            if (!container) {{
                container = document.createElement('div');
                container.className = 'atlas-toast-container';
                document.body.appendChild(container);
            }}
            const toast = document.getElementById('{toast_id}');
            if (toast) {{
                container.appendChild(toast);
                setTimeout(() => toast.remove(), {duration});
            }}
        }})();
    </script>
    """
    st.markdown(toast_html, unsafe_allow_html=True)


def display_trap_warnings(trap_summary: dict, ticker: str):
    """
    Display DCF trap detection warnings in user-friendly format

    Args:
        trap_summary: Summary dictionary from DCFTrapDetector.get_summary()
        ticker: Stock ticker symbol
    """
    if not trap_summary or trap_summary.get('total_warnings', 0) == 0:
        # No warnings - display success message
        st.success("""
        ‚úÖ **No Value Trap Patterns Detected**

        The DCF valuation appears sound with no significant red flags. Assumptions look reasonable given the company's risk profile.
        """)
        return

    # Display warnings section
    st.markdown("---")
    st.markdown("### üö® DCF Trap Detection Analysis")

    # Overall summary
    max_severity = trap_summary.get('max_severity', 'LOW')
    overall_confidence = trap_summary.get('overall_confidence', 0)
    total_warnings = trap_summary.get('total_warnings', 0)

    # Severity color coding
    severity_colors = {
        'CRITICAL': 'üî¥',
        'HIGH': 'üü†',
        'MEDIUM': 'üü°',
        'LOW': 'üü¢'
    }

    severity_icon = severity_colors.get(max_severity, 'üü¢')

    # Display summary card
    col1, col2, col3 = st.columns(3)

    with col1:
        st.metric(
            "Overall Risk Level",
            f"{severity_icon} {max_severity}",
            delta=f"{total_warnings} warning(s)"
        )

    with col2:
        st.metric(
            "Detection Confidence",
            f"{overall_confidence*100:.0f}%"
        )

    with col3:
        severity_counts = trap_summary.get('severity_counts', {})
        critical_high = severity_counts.get('CRITICAL', 0) + severity_counts.get('HIGH', 0)
        status = "‚ö†Ô∏è Review Required" if critical_high > 0 else "‚úÖ Monitor"
        st.metric("Action Required", status)

    # Overall recommendation
    recommendation = trap_summary.get('recommendation', '')

    if max_severity == 'CRITICAL':
        st.error(f"""
        **üö® CRITICAL ISSUES DETECTED**

        {recommendation}
        """)
    elif max_severity == 'HIGH':
        st.warning(f"""
        **‚ö†Ô∏è HIGH RISK PATTERNS DETECTED**

        {recommendation}
        """)
    elif max_severity == 'MEDIUM':
        st.warning(f"""
        **‚ö†Ô∏è MODERATE RISK DETECTED**

        {recommendation}
        """)
    else:
        st.info(f"""
        **‚ÑπÔ∏è MINOR CONCERNS DETECTED**

        {recommendation}
        """)

    # Display individual warnings
    st.markdown("#### üìã Detailed Warning Breakdown")

    warnings_list = trap_summary.get('warnings', [])

    for idx, warning in enumerate(warnings_list, 1):
        trap_type = warning.get('trap_type', 'UNKNOWN')
        severity = warning.get('severity', 'LOW')
        confidence = warning.get('confidence', 0)
        title = warning.get('title', 'Warning')
        description = warning.get('description', '')
        recommendation = warning.get('recommendation', '')
        metrics = warning.get('metrics', {})

        # Icon based on severity
        severity_icon = severity_colors.get(severity, 'üü¢')

        # Create expander for each warning
        with st.expander(f"{severity_icon} **{title}** (Confidence: {confidence*100:.0f}%)", expanded=(severity in ['CRITICAL', 'HIGH'])):
            st.markdown(f"**Severity:** {severity_icon} {severity}")
            st.markdown(f"**Confidence:** {confidence*100:.0f}%")

            st.markdown("---")
            st.markdown("**Description:**")
            st.markdown(description)

            # Display relevant metrics
            if metrics:
                st.markdown("---")
                st.markdown("**Key Metrics:**")

                # Format metrics nicely
                metrics_cols = st.columns(min(3, len(metrics)))

                metric_items = list(metrics.items())
                for i, (key, value) in enumerate(metric_items[:6]):  # Show max 6 metrics
                    col_idx = i % 3

                    # Format value based on type
                    if isinstance(value, float):
                        if 'percent' in key.lower() or 'growth' in key.lower() or 'margin' in key.lower():
                            formatted_value = f"{value*100:.1f}%"
                        elif value > 1000:
                            formatted_value = f"${value:,.0f}"
                        else:
                            formatted_value = f"{value:.2f}"
                    elif isinstance(value, dict) or isinstance(value, list):
                        formatted_value = str(value)[:50] + "..." if len(str(value)) > 50 else str(value)
                    else:
                        formatted_value = str(value)

                    # Format key (make it readable)
                    readable_key = key.replace('_', ' ').title()

                    with metrics_cols[col_idx]:
                        st.metric(readable_key, formatted_value)

            st.markdown("---")
            st.markdown("**Recommendation:**")
            st.info(recommendation)

    # Add actionable next steps
    st.markdown("---")
    st.markdown("#### üéØ Recommended Actions")

    if max_severity in ['CRITICAL', 'HIGH']:
        st.markdown("""
        1. **Re-examine DCF assumptions** - Focus on flagged parameters
        2. **Run sensitivity analysis** - Test impact of adjusting problematic assumptions
        3. **Consider alternative valuation** - Use relative valuation or sum-of-parts
        4. **Seek additional validation** - Review with peers or use external benchmarks
        5. **Apply discount to valuation** - Haircut DCF result by 15-30% for safety margin
        """)
    elif max_severity == 'MEDIUM':
        st.markdown("""
        1. **Review flagged assumptions** - Verify they reflect economic reality
        2. **Run stress tests** - Model downside scenarios
        3. **Cross-check with peers** - Compare assumptions to industry benchmarks
        4. **Monitor catalysts** - Track whether assumed improvements materialize
        """)
    else:
        st.markdown("""
        1. **Monitor flagged metrics** - Keep eye on mentioned concerns
        2. **Validate with sensitivity analysis** - Test robustness of valuation
        3. **Proceed with normal diligence** - Valuation appears reasonable
        """)


# ============================================================================
# PROFESSIONAL ENHANCEMENTS - ATLAS v9.4 EXCELLENCE EDITION
# ============================================================================

# Enhanced Formatting Standards with Strict Rules
class ATLASFormatter:
    """
    Centralized professional formatting with strict standards:
    - Prices: $ with 2 decimals
    - Yields/Returns: % with 2 decimals
    - Ratios: 1 decimal, no units
    - Missing data: "‚Äì"
    - Color rules: Green positive, Red negative, Grey zero
    """

    @staticmethod
    def format_price(value, decimals=2):
        """Prices: Always $ with exactly 2 decimals"""
        if pd.isna(value) or value is None:
            return "‚Äì"
        return f"${value:,.{decimals}f}"

    @staticmethod
    def format_yield(value, decimals=2):
        """Yields/Returns: Always % with exactly 2 decimals"""
        if pd.isna(value) or value is None:
            return "‚Äì"
        return f"{value:.{decimals}f}%"

    @staticmethod
    def format_ratio(value, decimals=1):
        """Ratios: 1 decimal place, no units"""
        if pd.isna(value) or value is None:
            return "‚Äì"
        return f"{value:.{decimals}f}"

    @staticmethod
    def get_color(value):
        """Color rules: Green positive, Red negative, Grey zero"""
        if pd.isna(value) or value is None:
            return COLORS['text_muted']
        if value > 0:
            return COLORS['success']
        elif value < 0:
            return COLORS['danger']
        return COLORS['text_muted']

    @staticmethod
    def format_timestamp(dt=None):
        """Data freshness indicator with precise timestamp"""
        if dt is None:
            dt = datetime.now()
        return dt.strftime("%Y-%m-%d %H:%M:%S")

    @staticmethod
    def get_freshness_badge(minutes_ago):
        """Visual freshness indicator based on age"""
        if minutes_ago < 5:
            return f"üü¢ Live ({minutes_ago}m ago)"
        elif minutes_ago < 30:
            return f"üü° Recent ({minutes_ago}m ago)"
        else:
            return f"üî¥ Stale ({minutes_ago}m ago)"

# Valuation Scenario System
VALUATION_SCENARIOS = {
    'BEAR': {
        'name': 'üêª Bear Case',
        'revenue_growth': -0.05,
        'terminal_growth': 0.015,
        'risk_premium': 0.08,
        'capex_pct': 0.07,
        'description': 'Conservative: Negative growth, higher risk premium, elevated capex'
    },
    'BASE': {
        'name': 'üìä Base Case',
        'revenue_growth': 0.05,
        'terminal_growth': 0.025,
        'risk_premium': 0.06,
        'capex_pct': 0.05,
        'description': 'Realistic: Moderate growth assumptions, normal operating conditions'
    },
    'BULL': {
        'name': 'üöÄ Bull Case',
        'revenue_growth': 0.15,
        'terminal_growth': 0.035,
        'risk_premium': 0.05,
        'capex_pct': 0.04,
        'description': 'Optimistic: High growth, lower risk premium, efficient capex'
    }
}

def create_risk_snapshot(df, portfolio_returns):
    """
    Professional Risk Snapshot Dashboard Widget
    Displays: Portfolio Beta, Volatility, Max Drawdown, Top 3 Exposures
    """
    # Calculate aggregate portfolio beta
    weighted_beta = (df['Beta'].fillna(1.0) * df['Weight %'] / 100).sum()

    # Calculate annualized volatility
    vol = portfolio_returns.std() * np.sqrt(252) * 100 if is_valid_series(portfolio_returns) else 0

    # Calculate max drawdown
    if is_valid_series(portfolio_returns) and len(portfolio_returns) > 0:
        cumulative = (1 + portfolio_returns).cumprod()
        running_max = cumulative.expanding().max()
        drawdown = ((cumulative - running_max) / running_max * 100).min()
    else:
        drawdown = 0

    # Top 3 exposures by weight
    top_3 = df.nlargest(3, 'Weight %')[['Ticker', 'Weight %']]

    # Create compact, professional HTML widget
    snapshot_html = f"""
    <div style='background: linear-gradient(135deg, {COLORS['card_background']} 0%, {COLORS['card_background_alt']} 100%);
                border: 2px solid {COLORS['neon_blue']}; border-radius: 12px; padding: 20px; margin: 10px 0;
                box-shadow: 0 0 30px {COLORS['shadow']};'>
        <h3 style='color: {COLORS['neon_blue']}; margin: 0 0 15px 0; font-size: 18px;'>‚ö° Risk Snapshot</h3>
        <div style='display: grid; grid-template-columns: repeat(4, 1fr); gap: 15px;'>
            <div>
                <div style='color: {COLORS['text_muted']}; font-size: 11px; text-transform: uppercase;'>Portfolio Beta</div>
                <div style='color: {COLORS['text_primary']}; font-size: 24px; font-weight: 600;'>{ATLASFormatter.format_ratio(weighted_beta)}</div>
            </div>
            <div>
                <div style='color: {COLORS['text_muted']}; font-size: 11px; text-transform: uppercase;'>Volatility (Ann.)</div>
                <div style='color: {COLORS['warning']}; font-size: 24px; font-weight: 600;'>{ATLASFormatter.format_yield(vol)}</div>
            </div>
            <div>
                <div style='color: {COLORS['text_muted']}; font-size: 11px; text-transform: uppercase;'>Max Drawdown</div>
                <div style='color: {COLORS['danger']}; font-size: 24px; font-weight: 600;'>{ATLASFormatter.format_yield(drawdown)}</div>
            </div>
            <div>
                <div style='color: {COLORS['text_muted']}; font-size: 11px; text-transform: uppercase;'>Top Exposures</div>
                <div style='color: {COLORS['text_primary']}; font-size: 13px; line-height: 1.6; margin-top: 5px;'>
                    {'<br>'.join([f"‚Ä¢ {row['Ticker']} ({row['Weight %']:.1f}%)" for _, row in top_3.iterrows()])}
                </div>
            </div>
        </div>
    </div>
    """
    return snapshot_html

def calculate_signal_health(metrics):
    """
    Calculate overall portfolio health score with traffic light system
    Returns: (status, percentage, label)
    GREEN: 80%+, YELLOW: 50-79%, RED: <50%
    """
    score = 0
    max_score = 5

    # Check 1: Positive returns
    if metrics.get('Total Return', 0) > 0:
        score += 1

    # Check 2: Sharpe > 1.0 (good risk-adjusted returns)
    if metrics.get('Sharpe Ratio', 0) > 1.0:
        score += 1

    # Check 3: Drawdown > -20% (manageable losses)
    if metrics.get('Max Drawdown', -100) > -20:
        score += 1

    # Check 4: Win rate > 55% (more winning days)
    if metrics.get('Win Rate', 0) > 55:
        score += 1

    # Check 5: Volatility < 25% (controlled risk)
    if metrics.get('Annualized Volatility', 100) < 25:
        score += 1

    percentage = (score / max_score) * 100

    if percentage >= 80:
        status = 'GREEN'
        emoji = 'üü¢'
        label = 'HEALTHY'
    elif percentage >= 50:
        status = 'YELLOW'
        emoji = 'üü°'
        label = 'CAUTION'
    else:
        status = 'RED'
        emoji = 'üî¥'
        label = 'AT RISK'

    return status, percentage, f"{emoji} {label}"

def create_signal_health_badge(metrics):
    """Create visual health indicator badge for portfolio"""
    status, percentage, label = calculate_signal_health(metrics)

    color_map = {
        'GREEN': COLORS['success'],
        'YELLOW': COLORS['warning'],
        'RED': COLORS['danger']
    }

    badge_html = f"""
    <div style='display: inline-block; background: {color_map[status]};
                color: #ffffff; padding: 10px 20px; border-radius: 20px;
                font-weight: 700; font-size: 15px; margin: 10px 0;
                box-shadow: 0 4px 12px rgba(0,0,0,0.3);'>
        {label} ({percentage:.0f}%)
    </div>
    """
    return badge_html

def create_pnl_attribution_sector(df):
    """v9.7 ENHANCED: P&L Attribution by Sector - Now showing % contribution"""
    # Calculate sector P&L in dollars
    sector_pnl_dollars = df.groupby('Sector')['Total Gain/Loss $'].sum()

    # v9.7 FIX: Convert to percentage contribution of total portfolio P&L
    total_pnl = sector_pnl_dollars.sum()
    if total_pnl != 0:
        sector_pnl_pct = (sector_pnl_dollars / abs(total_pnl)) * 100
    else:
        sector_pnl_pct = sector_pnl_dollars * 0  # All zeros if no P&L

    sector_pnl_pct = sector_pnl_pct.sort_values(ascending=False)

    fig = go.Figure(go.Waterfall(
        name="Sector P&L %",
        orientation="v",
        x=sector_pnl_pct.index,
        y=sector_pnl_pct.values,
        connector={"line": {"color": COLORS['neon_blue'], "width": 2}},
        decreasing={"marker": {"color": COLORS['danger']}},
        increasing={"marker": {"color": COLORS['success']}},
        textposition="outside",
        text=[f"{v:+.1f}%" for v in sector_pnl_pct.values],
        textfont=dict(size=12, color=COLORS['text_primary'])
    ))

    fig.update_layout(
        title="üíº P&L Attribution by Sector (%)",
        yaxis_title="P&L Contribution (%)",
        xaxis_title="",
        height=CHART_HEIGHT_STANDARD,  # P1-4: Standardized height
        showlegend=False
    )

    apply_chart_theme(fig)
    return fig

def create_pnl_attribution_position(df, top_n=10):
    """v9.7 ENHANCED: P&L Attribution by Position - Now showing % returns"""
    # v9.7 FIX: Use Total Gain/Loss % instead of dollars
    top_contributors = df.nlargest(top_n // 2, 'Total Gain/Loss %')
    top_detractors = df.nsmallest(top_n // 2, 'Total Gain/Loss %')
    combined = pd.concat([top_contributors, top_detractors]).sort_values('Total Gain/Loss %')

    colors = [COLORS['success'] if x > 0 else COLORS['danger'] for x in combined['Total Gain/Loss %']]

    # Create labels with ticker and percentage
    labels = [f"{ticker}" for ticker in combined['Ticker']]

    fig = go.Figure(go.Bar(
        x=combined['Total Gain/Loss %'],
        y=labels,
        orientation='h',
        marker=dict(
            color=colors,
            line=dict(color=COLORS['border'], width=2),
            opacity=0.9
        ),
        text=[f"{v:+.1f}%" for v in combined['Total Gain/Loss %']],
        textposition='outside',
        textfont=dict(size=11, color=COLORS['text_primary']),
        hovertemplate='<b>%{y}</b><br>Return: %{x:.2f}%<extra></extra>'
    ))

    fig.update_layout(
        title=f"üéØ Top {top_n} P&L Contributors & Detractors (%)",
        xaxis_title="Return (%)",
        yaxis_title="",
        height=CHART_HEIGHT_STANDARD,  # P1-4: Standardized height
        showlegend=False,
        xaxis=dict(zeroline=True, zerolinewidth=2, zerolinecolor=COLORS['text_muted'])
    )

    apply_chart_theme(fig)
    return fig

def create_sparkline(ticker, days=30):
    """Generate mini sparkline chart for ticker (last 30 days)"""
    # ATLAS Refactoring - Use cached market data fetcher
    try:
        if REFACTORED_MODULES_AVAILABLE:
            # Map days to period string
            period_map = {30: "1mo", 90: "3mo", 7: "5d", 5: "5d"}
            period = period_map.get(days, f"{days}d")
            hist = market_data.get_stock_history(ticker, period=period, interval="1d")
        else:
            # Fallback to old method
            stock = yf.Ticker(ticker)
            hist = stock.history(period=f"{days}d")

        if hist.empty:
            return None

        # Convert timezone-aware index to timezone-naive
        if hist.index.tz is not None:
            hist.index = hist.index.tz_localize(None)

        prices = hist['Close'].values

        # Determine color based on overall trend
        color = COLORS['success'] if prices[-1] > prices[0] else COLORS['danger']

        fig = go.Figure()
        fig.add_trace(go.Scatter(
            y=prices,
            mode='lines',
            line=dict(color=color, width=1.5),
            fill='tozeroy',
            fillcolor=f"rgba{tuple(list(int(color.lstrip('#')[i:i+2], 16) for i in (0, 2, 4)) + [0.2])}",
            showlegend=False
        ))

        fig.update_layout(
            height=60,
            width=150,
            margin=dict(l=0, r=0, t=0, b=0),
            xaxis=dict(visible=False),
            yaxis=dict(visible=False),
            paper_bgcolor='rgba(0,0,0,0)',
            plot_bgcolor='rgba(0,0,0,0)',
            hovermode=False
        )

        return fig
    except:
        return None

def calculate_forward_rates(maturities, spot_rates):
    """Calculate forward rates from spot rates"""
    forward_rates = []
    forward_maturities = []

    for i in range(len(maturities) - 1):
        t1 = maturities[i]
        t2 = maturities[i + 1]
        s1 = spot_rates[i] / 100  # Convert to decimal
        s2 = spot_rates[i + 1] / 100

        # Forward rate formula: f(t1,t2) = [(1 + s2)^t2 / (1 + s1)^t1]^(1/(t2-t1)) - 1
        forward_rate = (((1 + s2) ** t2) / ((1 + s1) ** t1)) ** (1 / (t2 - t1)) - 1
        forward_rates.append(forward_rate * 100)  # Convert back to percentage
        forward_maturities.append(f"{int(t1)}Y-{int(t2)}Y")

    return forward_maturities, forward_rates

def create_yield_curve():
    """
    Professional US Treasury Yield Curve visualization with multi-source data.

    Data sources (in priority order):
    1. FRED API (Federal Reserve) - Most accurate and comprehensive
    2. Yahoo Finance - Backup source
    3. Fallback data - If all sources fail
    """
    # Fetch yields from multi-source function
    maturities, yields_data, data_source = fetch_us_treasury_yields_fred()

    if not yields_data:
        return None

    # Create labels for display
    label_map = {
        1/12: "1M", 0.25: "3M", 0.5: "6M",
        1: "1Y", 2: "2Y", 3: "3Y", 5: "5Y",
        7: "7Y", 10: "10Y", 20: "20Y", 30: "30Y"
    }
    labels = [label_map.get(m, f"{m:.1f}Y") for m in maturities]

    # Sort by maturity
    sorted_data = sorted(zip(maturities, yields_data, labels))
    maturities, yields_data, labels = zip(*sorted_data)

    # Calculate forward rates
    forward_labels, forward_rates = calculate_forward_rates(list(maturities), list(yields_data))

    # Create positions for forward rates (plot at midpoint between maturities)
    forward_x = []
    for i in range(len(maturities) - 1):
        forward_x.append((maturities[i] + maturities[i+1]) / 2)

    fig = go.Figure()

    # Spot yield curve
    fig.add_trace(go.Scatter(
        x=maturities,
        y=yields_data,
        mode='lines+markers',
        line=dict(color=COLORS['neon_blue'], width=3),
        marker=dict(size=12, color=COLORS['electric_blue'], line=dict(color=COLORS['border'], width=2)),
        text=[f"{l}: {y:.2f}%" for l, y in zip(labels, yields_data)],
        hovertemplate='<b>Spot %{text}</b><extra></extra>',
        name='Spot Yield Curve'
    ))

    # Forward rate curve overlaid
    if forward_rates:
        fig.add_trace(go.Scatter(
            x=forward_x,
            y=forward_rates,
            mode='lines+markers',
            line=dict(color=COLORS['success'], width=2, dash='dash'),
            marker=dict(size=8, color=COLORS['success'], symbol='diamond'),
            text=[f"{label}: {rate:.2f}%" for label, rate in zip(forward_labels, forward_rates)],
            hovertemplate='<b>Forward %{text}</b><extra></extra>',
            name='Implied Forward Rates'
        ))

    # Add data source indicator to title
    source_icon = {
        "FRED API": "üèõÔ∏è",
        "Yahoo Finance": "üìä",
        "Fallback Data": "‚ö†Ô∏è"
    }.get(data_source, "üìà")

    fig.update_layout(
        title=f"{source_icon} US Treasury Yield Curve with Forward Rates<br><sub>Data Source: {data_source}</sub>",
        xaxis_title="Maturity (Years)",
        yaxis_title="Yield (%)",
        height=500,
        showlegend=True,
        legend=dict(
            orientation="h",
            yanchor="bottom",
            y=1.02,
            xanchor="right",
            x=1
        )
    )

    apply_chart_theme(fig)
    return fig, list(maturities), list(yields_data), data_source

@st.cache_data(ttl=3600)  # Cache for 1 hour
def fetch_uk_gilt_yields():
    """Fetch live UK Gilt yields from Yahoo Finance"""
    # UK Government Bond Yield tickers (Yahoo Finance format)
    uk_bond_tickers = {
        "^FTGB03M": {"maturity": 0.25, "name": "3M"},   # 3-month
        "^FTGB06M": {"maturity": 0.5, "name": "6M"},    # 6-month
        "^FTGB01Y": {"maturity": 1, "name": "1Y"},      # 1-year
        "^FTGB02Y": {"maturity": 2, "name": "2Y"},      # 2-year
        "^FTGB03Y": {"maturity": 3, "name": "3Y"},      # 3-year
        "^FTGB05Y": {"maturity": 5, "name": "5Y"},      # 5-year
        "^FTGB07Y": {"maturity": 7, "name": "7Y"},      # 7-year
        "^FTGB10Y": {"maturity": 10, "name": "10Y"},    # 10-year
        "^FTGB15Y": {"maturity": 15, "name": "15Y"},    # 15-year
        "^FTGB20Y": {"maturity": 20, "name": "20Y"},    # 20-year
        "^FTGB30Y": {"maturity": 30, "name": "30Y"}     # 30-year
    }

    yields_data = []
    maturities = []

    for ticker, info in uk_bond_tickers.items():
        try:
            bond = yf.Ticker(ticker)
            hist = bond.history(period="5d")  # Get last 5 days in case today's data isn't available
            if not hist.empty:
                current_yield = hist['Close'].iloc[-1]
                yields_data.append(current_yield)
                maturities.append(info['maturity'])
        except:
            continue

    # If we got live data, use it
    if len(yields_data) >= 4:
        # Sort by maturity
        sorted_data = sorted(zip(maturities, yields_data))
        maturities, yields_data = zip(*sorted_data)
        return list(maturities), list(yields_data)

    # Fallback to sample data if live fetch fails
    maturities = [0.25, 0.5, 1, 2, 3, 5, 7, 10, 15, 20, 30]
    yields = [4.8, 4.6, 4.5, 4.2, 4.1, 4.0, 4.05, 4.1, 4.3, 4.4, 4.5]
    return maturities, yields

@st.cache_data(ttl=3600)  # Cache for 1 hour
def fetch_german_bund_yields():
    """Fetch live German Bund yields from Yahoo Finance"""
    # German Government Bond Yield tickers
    de_bond_tickers = {
        "^DEBM03M": {"maturity": 0.25, "name": "3M"},
        "^DEBM06M": {"maturity": 0.5, "name": "6M"},
        "^DEBM01Y": {"maturity": 1, "name": "1Y"},
        "^DEBM02Y": {"maturity": 2, "name": "2Y"},
        "^DEBM03Y": {"maturity": 3, "name": "3Y"},
        "^DEBM05Y": {"maturity": 5, "name": "5Y"},
        "^DEBM07Y": {"maturity": 7, "name": "7Y"},
        "^DEBM10Y": {"maturity": 10, "name": "10Y"},
        "^DEBM15Y": {"maturity": 15, "name": "15Y"},
        "^DEBM20Y": {"maturity": 20, "name": "20Y"},
        "^DEBM30Y": {"maturity": 30, "name": "30Y"}
    }

    yields_data = []
    maturities = []

    for ticker, info in de_bond_tickers.items():
        try:
            bond = yf.Ticker(ticker)
            hist = bond.history(period="5d")
            if not hist.empty:
                current_yield = hist['Close'].iloc[-1]
                yields_data.append(current_yield)
                maturities.append(info['maturity'])
        except:
            continue

    # If we got live data, use it
    if len(yields_data) >= 4:
        sorted_data = sorted(zip(maturities, yields_data))
        maturities, yields_data = zip(*sorted_data)
        return list(maturities), list(yields_data)

    # Fallback to sample data
    maturities = [0.25, 0.5, 1, 2, 3, 5, 7, 10, 15, 20, 30]
    yields = [3.2, 3.0, 2.9, 2.8, 2.7, 2.5, 2.55, 2.6, 2.75, 2.85, 2.9]
    return maturities, yields

@st.cache_data(ttl=3600)  # Cache for 1 hour
def fetch_sa_government_bond_yields():
    """Fetch live South African Government Bond yields"""
    # Try South African bond tickers (JSE)
    sa_bond_tickers = {
        "R2030.JO": {"maturity": 6, "name": "R2030"},   # R186 - 2030 maturity
        "R2032.JO": {"maturity": 8, "name": "R2032"},   # R2032
        "R2035.JO": {"maturity": 11, "name": "R2035"},  # R2035
        "R2040.JO": {"maturity": 16, "name": "R2040"},  # R2040
        "R2048.JO": {"maturity": 24, "name": "R2048"}   # R2048
    }

    yields_data = []
    maturities = []

    for ticker, info in sa_bond_tickers.items():
        try:
            bond = yf.Ticker(ticker)
            hist = bond.history(period="5d")
            if not hist.empty and 'Close' in hist.columns:
                # For bonds, we need to convert price to yield (approximate)
                # This is a simplified calculation
                price = hist['Close'].iloc[-1]
                # Rough yield approximation: higher price = lower yield
                # This is simplified - real calculation would need coupon rate
                continue  # Skip for now
        except:
            continue

    # Use sample data for SA bonds (JSE bond data is tricky to fetch directly)
    maturities = [0.25, 0.5, 1, 2, 3, 5, 7, 10, 15, 20, 30]
    yields = [8.5, 9.0, 9.5, 10.0, 10.3, 10.8, 11.0, 11.2, 11.4, 11.5, 11.6]
    return maturities, yields

def create_yield_curve_with_forwards(maturities, yields, title, color='#FF6B6B'):
    """Create yield curve with overlaid forward rates for any country"""
    # Calculate forward rates
    forward_labels, forward_rates = calculate_forward_rates(maturities, yields)

    # Create positions for forward rates (plot at midpoint between maturities)
    forward_x = []
    for i in range(len(maturities) - 1):
        forward_x.append((maturities[i] + maturities[i+1]) / 2)

    fig = go.Figure()

    # Spot yield curve
    labels = [f"{int(m)}Y" if m >= 1 else f"{int(m*12)}M" for m in maturities]
    fig.add_trace(go.Scatter(
        x=maturities,
        y=yields,
        mode='lines+markers',
        line=dict(color=color, width=3),
        marker=dict(size=12, line=dict(color=COLORS['border'], width=2)),
        text=[f"{l}: {y:.2f}%" for l, y in zip(labels, yields)],
        hovertemplate='<b>Spot %{text}</b><extra></extra>',
        name='Spot Yield Curve'
    ))

    # Forward rate curve overlaid
    if forward_rates:
        fig.add_trace(go.Scatter(
            x=forward_x,
            y=forward_rates,
            mode='lines+markers',
            line=dict(color=COLORS['success'], width=2, dash='dash'),
            marker=dict(size=8, color=COLORS['success'], symbol='diamond'),
            text=[f"{label}: {rate:.2f}%" for label, rate in zip(forward_labels, forward_rates)],
            hovertemplate='<b>Forward %{text}</b><extra></extra>',
            name='Implied Forward Rates'
        ))

    fig.update_layout(
        title=f"üìà {title}",
        xaxis_title="Maturity (Years)",
        yaxis_title="Yield (%)",
        height=500,
        showlegend=True,
        legend=dict(
            orientation="h",
            yanchor="bottom",
            y=1.02,
            xanchor="right",
            x=1
        )
    )

    apply_chart_theme(fig)
    return fig

def get_data_freshness(cache_time=None):
    """Calculate and format data age for freshness indicators"""
    if cache_time is None:
        return ATLASFormatter.format_timestamp(), 0

    now = datetime.now()
    age_seconds = (now - cache_time).total_seconds()
    age_minutes = int(age_seconds / 60)

    timestamp = ATLASFormatter.format_timestamp(cache_time)
    badge = ATLASFormatter.get_freshness_badge(age_minutes)

    return timestamp, age_minutes, badge

# ============================================================================
# DATA FUNCTIONS
# ============================================================================

def save_portfolio_data(data):
    """
    Save portfolio data to BOTH database and pickle cache
    Database is primary storage, pickle is backup
    """
    # Save to pickle (backwards compatibility)
    with open(PORTFOLIO_CACHE, "wb") as f:
        pickle.dump(data, f)

    # PHASE 4: Auto-save to database
    if SQL_AVAILABLE:
        try:
            db = get_db()
            # Convert list of dicts to DataFrame
            df = pd.DataFrame(data)

            # Ensure required columns exist
            if 'Ticker' in df.columns and 'Shares' in df.columns:
                # Prepare DataFrame for database
                portfolio_df = df.copy()

                # Rename columns to match database schema
                column_mapping = {
                    'Ticker': 'ticker',
                    'Shares': 'quantity',
                    'Avg Price': 'avg_cost',  # From account imports
                    'Avg Cost': 'avg_cost',   # From trade imports (Phoenix Parser)
                    'Current Price': 'current_price'
                }

                # Only rename columns that exist
                portfolio_df = portfolio_df.rename(columns={
                    k: v for k, v in column_mapping.items() if k in portfolio_df.columns
                })

                # Ensure required columns
                required_cols = ['ticker', 'quantity', 'avg_cost']
                if all(col in portfolio_df.columns for col in required_cols):
                    # Select only relevant columns
                    save_cols = [col for col in ['ticker', 'quantity', 'avg_cost', 'current_price']
                                 if col in portfolio_df.columns]
                    portfolio_df = portfolio_df[save_cols]

                    # Save to database
                    db.save_portfolio(portfolio_df)
                    print(f"‚úÖ Portfolio saved to database ({len(portfolio_df)} positions)")
                else:
                    missing = [col for col in required_cols if col not in portfolio_df.columns]
                    print(f"‚ö†Ô∏è Cannot save to database: missing columns {missing}")
                    print(f"   Available columns: {list(portfolio_df.columns)}")
        except Exception as e:
            print(f"‚ö†Ô∏è Database save failed (pickle still saved): {e}")
            import traceback
            print(traceback.format_exc())

def load_portfolio_data():
    """
    Load portfolio data from DATABASE FIRST, fallback to pickle
    This implements Phase 4: SQL-first loading
    """
    # PHASE 4: Try database first
    if SQL_AVAILABLE:
        try:
            db = get_db()
            df = db.get_portfolio()

            if len(df) > 0:
                # Convert database format back to app format
                column_mapping = {
                    'ticker': 'Ticker',
                    'quantity': 'Shares',
                    'avg_cost': 'Avg Cost',  # Standard column name in app
                    'current_price': 'Current Price'
                }

                df = df.rename(columns={
                    k: v for k, v in column_mapping.items() if k in df.columns
                })

                print(f"‚úÖ Loaded {len(df)} positions from database")
                return df  # ‚úÖ FIX: Return DataFrame instead of list
        except Exception as e:
            print(f"‚ö†Ô∏è Database load failed, falling back to pickle: {e}")

    # Fallback to pickle
    if PORTFOLIO_CACHE.exists():
        with open(PORTFOLIO_CACHE, "rb") as f:
            data = pickle.load(f)
            print(f"‚úÖ Loaded {len(data)} positions from pickle cache")
            # ‚úÖ FIX: Convert to DataFrame if it's a list
            if isinstance(data, list):
                return pd.DataFrame(data)
            return data

    return pd.DataFrame()  # ‚úÖ FIX: Return empty DataFrame instead of empty list

def save_trade_history(df):
    """
    Save trade history to BOTH database and pickle cache
    """
    # Save to pickle (backwards compatibility)
    with open(TRADE_HISTORY_CACHE, "wb") as f:
        pickle.dump(df, f)

    # Check if SQL is available
    if not SQL_AVAILABLE:
        print("‚ö†Ô∏è SQL not available - trades saved to pickle only")
        import streamlit as st
        st.warning("‚ö†Ô∏è Trades saved to local file only (database not available)")
        return

    if df is None or len(df) == 0:
        print("‚ö†Ô∏è No trades to save")
        return

    try:
        db = get_db()
        trades_df = df.copy()

        # IMPROVED COLUMN MAPPING - Add all variations including "Trade Type"
        column_mapping = {}

        # Date column - ALL POSSIBLE NAMES
        date_cols = [
            'Date', 'date', 'DATE',
            'Trade Date', 'Execution Date', 'Exec Date',
            'Transaction Date', 'Settlement Date'
        ]
        for col in date_cols:
            if col in trades_df.columns:
                column_mapping[col] = 'date'
                break

        # Ticker/Symbol column - ALL POSSIBLE NAMES
        ticker_cols = [
            'Ticker', 'ticker', 'TICKER',
            'Symbol', 'symbol', 'SYMBOL',
            'Underlying', 'Security', 'Instrument'
        ]
        for col in ticker_cols:
            if col in trades_df.columns:
                column_mapping[col] = 'ticker'
                break

        # Action column - ALL POSSIBLE NAMES (INCLUDING "Trade Type") ‚≠ê CRITICAL FIX
        action_cols = [
            'Action', 'action', 'ACTION',
            'Trade Type', 'TradeType', 'TRADE TYPE',  # ‚Üê FIX: Added these!
            'Type', 'type', 'TYPE',
            'Side', 'side', 'SIDE',
            'Buy/Sell', 'BUY/SELL',
            'Transaction Type', 'Trade Action'
        ]
        for col in action_cols:
            if col in trades_df.columns:
                column_mapping[col] = 'action'
                break

        # Quantity column - ALL POSSIBLE NAMES
        qty_cols = [
            'Quantity', 'quantity', 'QUANTITY',
            'Qty', 'qty', 'QTY',
            'Shares', 'shares', 'SHARES',
            'Amount', 'amount', 'AMOUNT',
            'Volume', 'volume', 'VOLUME',
            'Size', 'size', 'SIZE'
        ]
        for col in qty_cols:
            if col in trades_df.columns:
                column_mapping[col] = 'quantity'
                break

        # Price column - ALL POSSIBLE NAMES
        price_cols = [
            'Price', 'price', 'PRICE',
            'Exec Price', 'Execution Price', 'Fill Price',
            'Trade Price', 'Avg Price', 'Average Price'
        ]
        for col in price_cols:
            if col in trades_df.columns:
                column_mapping[col] = 'price'
                break

        # Apply mapping
        print(f"üìã Column mapping found: {column_mapping}")
        trades_df = trades_df.rename(columns=column_mapping)

        # Check if we have all required columns
        required = ['date', 'ticker', 'action', 'quantity', 'price']
        missing = [col for col in required if col not in trades_df.columns]

        if missing:
            error_msg = f"‚ö†Ô∏è Cannot save to database - missing columns: {missing}"
            print(error_msg)
            print(f"üìã Available columns after mapping: {list(trades_df.columns)}")
            import streamlit as st
            st.error(f"‚ùå {error_msg}")
            st.info(f"""
            **Columns in uploaded file:**
            {', '.join(df.columns)}

            **Missing after mapping:**
            {', '.join(missing)}

            Trades saved to local file, but not database.
            """)
            return

        # Select only required columns
        trades_df = trades_df[required]

        # Clean and validate data
        # Convert date to string if it's datetime
        if pd.api.types.is_datetime64_any_dtype(trades_df['date']):
            trades_df['date'] = trades_df['date'].dt.strftime('%Y-%m-%d')

        # Ensure numeric types
        trades_df['quantity'] = pd.to_numeric(trades_df['quantity'], errors='coerce')
        trades_df['price'] = pd.to_numeric(trades_df['price'], errors='coerce')

        # Remove rows with NaN values
        trades_df = trades_df.dropna()

        if len(trades_df) == 0:
            print("‚ö†Ô∏è No valid trades after cleaning")
            return

        # CRITICAL FIX: Normalize action values to 'BUY' or 'SELL'
        # Database has CHECK constraint: action IN ('BUY', 'SELL')
        # Investopedia uses values like "Stock: Buy at Market Open"
        def normalize_action(action_str):
            """Extract BUY or SELL from action string"""
            action_lower = str(action_str).lower()
            if 'buy' in action_lower:
                return 'BUY'
            elif 'sell' in action_lower or 'short' in action_lower:
                return 'SELL'
            else:
                # Default fallback - should not happen with proper mapping
                print(f"‚ö†Ô∏è Unknown action format: {action_str}, defaulting to BUY")
                return 'BUY'

        trades_df['action'] = trades_df['action'].apply(normalize_action)
        print(f"üìã Normalized actions - sample: {trades_df['action'].head().tolist()}")

        # Save to database
        db.bulk_insert('trades', trades_df, if_exists='append')
        print(f"‚úÖ Saved {len(trades_df)} trades to database")
        import streamlit as st
        st.success(f"‚úÖ Saved {len(trades_df)} trades to database permanently!")

    except Exception as e:
        error_msg = f"‚ö†Ô∏è Database save failed: {e}"
        print(error_msg)
        import streamlit as st
        st.error(error_msg)
        import traceback
        st.code(traceback.format_exc())
        st.info("Trades are saved to local pickle file as backup")


def load_trade_history():
    if TRADE_HISTORY_CACHE.exists():
        with open(TRADE_HISTORY_CACHE, "rb") as f:
            return pickle.load(f)
    return None

def save_account_history(df):
    with open(ACCOUNT_HISTORY_CACHE, "wb") as f:
        pickle.dump(df, f)

def load_account_history():
    if ACCOUNT_HISTORY_CACHE.exists():
        with open(ACCOUNT_HISTORY_CACHE, "rb") as f:
            return pickle.load(f)
    return None

# v9.7 NEW FEATURE: Data Validation & Integrity Checks
def validate_portfolio_data(portfolio_data):
    """
    NEW IN v9.7: Comprehensive data validation and integrity checking
    Returns validation metrics and quality scores
    """
    if portfolio_data is None or (isinstance(portfolio_data, pd.DataFrame) and portfolio_data.empty):
        return {
            'is_valid': False,
            'total_holdings': 0,
            'data_quality_score': 0,
            'issues': ['No portfolio data available'],
            'warnings': [],
            'null_counts': {},
            'total_rows': 0,
            'complete_rows': 0
        }

    df = pd.DataFrame(portfolio_data)
    issues = []
    warnings = []

    # Check required columns - use flexible column names
    required_columns = ['Ticker']
    optional_columns = ['Quantity', 'Current Price', 'Shares', 'Price', 'Last Price']

    missing_columns = [col for col in required_columns if col not in df.columns]
    if missing_columns:
        issues.append(f"Missing required columns: {', '.join(missing_columns)}")

    # Check for null values only on existing columns
    existing_check_cols = [col for col in required_columns if col in df.columns]
    null_counts = {}

    if existing_check_cols:
        null_counts = df[existing_check_cols].isnull().sum().to_dict()
        for col, count in null_counts.items():
            if count > 0:
                warnings.append(f"{col}: {count} missing values")

    # Check for negative quantities (flexible column names)
    qty_col = None
    for col in ['Quantity', 'Shares', 'Qty']:
        if col in df.columns:
            qty_col = col
            break

    if qty_col:
        negative_qty = (df[qty_col] < 0).sum()
        if negative_qty > 0:
            warnings.append(f"{negative_qty} holdings with negative quantities (short positions)")

    # Check for zero/negative prices (flexible column names)
    price_col = None
    for col in ['Current Price', 'Price', 'Last Price', 'Close']:
        if col in df.columns:
            price_col = col
            break

    if price_col:
        invalid_prices = (df[price_col] <= 0).sum()
        if invalid_prices > 0:
            issues.append(f"{invalid_prices} holdings with invalid prices (‚â§0)")

    # Check for duplicate tickers
    if 'Ticker' in df.columns:
        duplicates = df['Ticker'].duplicated().sum()
        if duplicates > 0:
            warnings.append(f"{duplicates} duplicate ticker entries")

    # Calculate data quality score (0-100)
    quality_score = 100
    quality_score -= len(issues) * 15  # Severe penalty for issues
    quality_score -= len(warnings) * 5  # Moderate penalty for warnings
    quality_score = max(0, min(100, quality_score))

    # Calculate complete rows
    complete_rows = len(df)
    if existing_check_cols:
        complete_rows = len(df.dropna(subset=existing_check_cols))

    return {
        'is_valid': len(issues) == 0,
        'total_holdings': len(df),
        'data_quality_score': quality_score,
        'issues': issues,
        'warnings': warnings,
        'null_counts': null_counts,
        'total_rows': len(df),
        'complete_rows': complete_rows
    }

def get_leverage_info():
    account_df = load_account_history()
    if account_df is not None:
        latest_cash = account_df.get('Cash Balance', account_df.get('Cash', pd.Series([0]))).iloc[-1]
        
        if isinstance(latest_cash, str):
            latest_cash = latest_cash.replace('$', '').replace(',', '')
            if '(' in latest_cash and ')' in latest_cash:
                latest_cash = '-' + latest_cash.replace('(', '').replace(')', '')
            try:
                latest_cash = float(latest_cash)
            except:
                latest_cash = 0
        
        latest_margin = 0
        
        if 'Margin Used' in account_df.columns:
            latest_margin = account_df['Margin Used'].iloc[-1]
            if isinstance(latest_margin, str):
                latest_margin = latest_margin.replace('$', '').replace(',', '')
                if '(' in latest_margin and ')' in latest_margin:
                    latest_margin = '-' + latest_margin.replace('(', '').replace(')', '')
                try:
                    latest_margin = float(latest_margin)
                except:
                    latest_margin = 0
        
        if latest_cash < 0:
            latest_margin = abs(latest_cash)
            
        total_value = 0
        if 'Total Value' in account_df.columns:
            total_value = account_df['Total Value'].iloc[-1]
            if isinstance(total_value, str):
                total_value = total_value.replace('$', '').replace(',', '')
                if '(' in total_value and ')' in total_value:
                    total_value = '-' + total_value.replace('(', '').replace(')', '')
                try:
                    total_value = float(total_value)
                except:
                    total_value = abs(latest_cash) + latest_margin
        else:
            total_value = abs(latest_cash) + latest_margin

        # FIX #4: Correct leverage formula - Gross Exposure / Net Equity
        # (aligned with Leverage Tracker page calculation)
        net_equity = total_value - latest_margin if total_value > latest_margin else total_value
        leverage_ratio = (total_value / net_equity) if net_equity > 0 else 1.0

        return {
            'margin_used': latest_margin,
            'cash_balance': latest_cash,
            'leverage_ratio': leverage_ratio,
            'total_value': total_value,
            'net_equity': net_equity  # Added for clarity
        }
    return None

@st.cache_data(ttl=300)
def fetch_market_data(ticker):
    # ATLAS Refactoring - Use cached market data fetcher
    try:
        if REFACTORED_MODULES_AVAILABLE:
            info = market_data.get_company_info(ticker)
            hist = market_data.get_stock_history(ticker, period="5d", interval="1d")
        else:
            # Fallback to old method
            stock = yf.Ticker(ticker)
            info = stock.info
            hist = stock.history(period="5d")

        if hist.empty:
            return None

        # Convert timezone-aware index to timezone-naive
        if hist.index.tz is not None:
            hist.index = hist.index.tz_localize(None)

        current_price = hist['Close'].iloc[-1]
        prev_close = hist['Close'].iloc[-2] if len(hist) > 1 else current_price
        daily_change = current_price - prev_close
        daily_change_pct = (daily_change / prev_close * 100) if prev_close else 0

        five_day_return = ((current_price / hist['Close'].iloc[0]) - 1) * 100 if len(hist) >= 5 else 0

        company_name = info.get('longName', info.get('shortName', ticker))
        
        return {
            "price": current_price,
            "daily_change": daily_change,
            "daily_change_pct": daily_change_pct,
            "five_day_return": five_day_return,
            "volume": info.get('volume', 0),
            "avg_volume": info.get('averageVolume', 0),
            "sector": info.get('sector', 'Unknown'),
            "beta": info.get('beta', None),
            "market_cap": info.get('marketCap', 0),
            "company_name": company_name,
            "52_week_high": info.get('fiftyTwoWeekHigh', None),
            "52_week_low": info.get('fiftyTwoWeekLow', None)
        }
    except:
        return None

def is_option_ticker(ticker):
    """
    Detect if ticker is an option symbol
    Options typically have format: TICKER[DATE][TYPE][STRIKE]
    Examples: AU2520F50, META2405D482.5, AAPL240119C150
    """
    import re

    # Skip if too short
    if len(ticker) <= 6:
        return False

    # Specific known options to exclude
    known_options = ['AU2520F50', 'META2405D482.5']
    if ticker.upper() in known_options:
        return True

    # General option pattern detection
    # Pattern: Letters + 4-digit year (20XX, 24XX, etc) + optional letter + decimals
    # Examples: META2405D482.5 = META + 2405 + D + 482.5
    #           AU2520F50 = AU + 2520 + F + 50
    option_pattern = r'^[A-Z]+\d{4}[A-Z]\d+\.?\d*$'
    if re.match(option_pattern, ticker.upper()):
        return True

    # Standard options format (older logic)
    has_year = any(str(y) in ticker for y in range(2020, 2030))
    has_strike = any(c.isdigit() for c in ticker[6:])
    has_type = ticker[-1] in ['C', 'P'] or 'C' in ticker[6:] or 'P' in ticker[6:]
    return has_year and has_strike and has_type

def classify_ticker_sector(ticker, default_sector):
    if pd.notna(default_sector) and default_sector != "Unknown":
        return default_sector
    
    if ticker in ETF_SECTORS:
        return ETF_SECTORS[ticker]
    
    return "Other"

@st.cache_data(ttl=600)
def fetch_historical_data(ticker, start_date, end_date):
    try:
        stock = yf.Ticker(ticker)
        hist = stock.history(start=start_date, end=end_date)
        if not hist.empty:
            # Convert timezone-aware index to timezone-naive to prevent comparison errors
            if hist.index.tz is not None:
                hist.index = hist.index.tz_localize(None)
            return hist
    except:
        pass
    return None

@st.cache_data(ttl=3600)
def fetch_stock_info(ticker):
    """Fetch stock information from yfinance"""
    # ATLAS Refactoring - Use cached market data fetcher
    if REFACTORED_MODULES_AVAILABLE:
        return market_data.get_company_info(ticker)
    else:
        # Fallback to old method
        try:
            stock = yf.Ticker(ticker)
            info = stock.info
            return info
        except:
            return None

@st.cache_data(ttl=3600)
def fetch_analyst_data(ticker):
    # ATLAS Refactoring - Use cached market data fetcher
    try:
        if REFACTORED_MODULES_AVAILABLE:
            info = market_data.get_company_info(ticker)
        else:
            # Fallback to old method
            stock = yf.Ticker(ticker)
            info = stock.info

        rating = info.get('recommendationKey', 'none')
        if rating == 'none' or rating is None:
            rating = "No Coverage"
        
        return {
            'rating': rating.upper() if rating != "No Coverage" else rating,
            'target_price': info.get('targetMeanPrice'),
            'num_analysts': info.get('numberOfAnalystOpinions', 0),
            'success': True
        }
    except:
        return {'success': False, 'rating': 'No Coverage', 'target_price': None}

# ============================================================================
# VALUATION HOUSE - ENHANCED WITH SMART ASSUMPTIONS
# ============================================================================

@st.cache_data(ttl=3600)
def fetch_company_financials(ticker):
    """Fetch comprehensive financial data for valuation"""
    # ATLAS Refactoring - Use cached market data fetcher
    try:
        if REFACTORED_MODULES_AVAILABLE:
            info = market_data.get_company_info(ticker)
            income_stmt = market_data.get_financials(ticker, statement_type="income")
            balance_sheet = market_data.get_financials(ticker, statement_type="balance")
            cash_flow = market_data.get_financials(ticker, statement_type="cashflow")
        else:
            # Fallback to old method
            stock = yf.Ticker(ticker)
            info = stock.info
            income_stmt = stock.income_stmt
            balance_sheet = stock.balance_sheet
            cash_flow = stock.cash_flow

        # Basic company info
        company_data = {
            'ticker': ticker,
            'name': info.get('longName', ticker),
            'sector': info.get('sector', 'Unknown'),
            'industry': info.get('industry', 'Unknown'),
            'current_price': info.get('currentPrice', 0),
            'market_cap': info.get('marketCap', 0),
            'shares_outstanding': info.get('sharesOutstanding', 0),
            'beta': info.get('beta', 1.0),
            'forward_pe': info.get('forwardPE'),
            'trailing_pe': info.get('trailingPE'),
        }
        
        # Parse financials (most recent 3 years)
        financials = {}
        
        if not income_stmt.empty:
            # Get most recent year
            latest_col = income_stmt.columns[0]
            
            financials['revenue'] = income_stmt.loc['Total Revenue', latest_col] if 'Total Revenue' in income_stmt.index else 0
            financials['ebit'] = income_stmt.loc['EBIT', latest_col] if 'EBIT' in income_stmt.index else 0
            financials['net_income'] = income_stmt.loc['Net Income', latest_col] if 'Net Income' in income_stmt.index else 0
            financials['tax_expense'] = income_stmt.loc['Tax Provision', latest_col] if 'Tax Provision' in income_stmt.index else 0
            
            # Calculate tax rate
            if financials['ebit'] != 0:
                financials['tax_rate'] = abs(financials['tax_expense'] / financials['ebit'])
            else:
                financials['tax_rate'] = 0.21  # Default US corporate tax rate
                
        if not balance_sheet.empty:
            latest_col = balance_sheet.columns[0]
            
            financials['total_debt'] = balance_sheet.loc['Total Debt', latest_col] if 'Total Debt' in balance_sheet.index else 0
            financials['cash'] = balance_sheet.loc['Cash And Cash Equivalents', latest_col] if 'Cash And Cash Equivalents' in balance_sheet.index else 0
            financials['total_equity'] = balance_sheet.loc['Total Equity Gross Minority Interest', latest_col] if 'Total Equity Gross Minority Interest' in balance_sheet.index else 0
            
        if not cash_flow.empty:
            latest_col = cash_flow.columns[0]
            
            financials['capex'] = abs(cash_flow.loc['Capital Expenditure', latest_col]) if 'Capital Expenditure' in cash_flow.index else 0
            financials['depreciation'] = cash_flow.loc['Depreciation And Amortization', latest_col] if 'Depreciation And Amortization' in cash_flow.index else 0
            financials['operating_cf'] = cash_flow.loc['Operating Cash Flow', latest_col] if 'Operating Cash Flow' in cash_flow.index else 0
        
        # Calculate working capital change (simplified)
        financials['change_wc'] = 0  # User can adjust
        
        return {
            'company': company_data,
            'financials': financials,
            'success': True
        }
        
    except Exception as e:
        return {
            'success': False,
            'error': str(e)
        }

def calculate_smart_assumptions(company_data, financials):
    """
    NEW: Calculate realistic, economically grounded assumptions
    based on company fundamentals, sector averages, and economic reality
    """
    sector = company_data.get('sector', 'Unknown')
    revenue = financials.get('revenue', 0)
    ebit = financials.get('ebit', 0)
    
    # Smart revenue growth (based on sector and size)
    sector_growth_rates = {
        'Technology': 0.08,
        'Healthcare': 0.06,
        'Financial Services': 0.05,
        'Consumer Cyclical': 0.04,
        'Consumer Defensive': 0.03,
        'Energy': 0.03,
        'Industrials': 0.04,
        'Basic Materials': 0.03,
        'Real Estate': 0.03,
        'Utilities': 0.02,
        'Communication Services': 0.05,
        'Unknown': 0.04
    }
    
    base_growth = sector_growth_rates.get(sector, 0.04)
    
    # Adjust for company size (larger = slower growth)
    market_cap = company_data.get('market_cap', 0)
    if market_cap > 500e9:  # Mega cap
        size_adjustment = -0.02
    elif market_cap > 100e9:  # Large cap
        size_adjustment = -0.01
    elif market_cap > 10e9:  # Mid cap
        size_adjustment = 0
    else:  # Small cap
        size_adjustment = 0.01
    
    smart_revenue_growth = base_growth + size_adjustment
    
    # Smart EBIT margin (sector averages)
    sector_ebit_margins = {
        'Technology': 0.25,
        'Healthcare': 0.20,
        'Financial Services': 0.30,
        'Consumer Cyclical': 0.10,
        'Consumer Defensive': 0.08,
        'Energy': 0.15,
        'Industrials': 0.12,
        'Basic Materials': 0.15,
        'Real Estate': 0.40,
        'Utilities': 0.20,
        'Communication Services': 0.18,
        'Unknown': 0.15
    }
    
    smart_ebit_margin = sector_ebit_margins.get(sector, 0.15)
    
    # Smart CapEx (as % of revenue, sector-based)
    sector_capex_rates = {
        'Technology': 0.03,
        'Healthcare': 0.04,
        'Financial Services': 0.02,
        'Consumer Cyclical': 0.05,
        'Consumer Defensive': 0.04,
        'Energy': 0.12,
        'Industrials': 0.06,
        'Basic Materials': 0.10,
        'Real Estate': 0.08,
        'Utilities': 0.15,
        'Communication Services': 0.07,
        'Unknown': 0.05
    }
    
    smart_capex_pct = sector_capex_rates.get(sector, 0.05)
    
    # Smart Depreciation (typically 60-80% of CapEx for mature companies)
    smart_depreciation_pct = smart_capex_pct * 0.7
    
    # Smart Terminal Growth (conservative)
    smart_terminal_growth = 0.025  # Long-term GDP growth
    
    # Smart Tax Rate (based on geography and sector)
    smart_tax_rate = 0.21  # US corporate rate
    
    return {
        'revenue_growth': smart_revenue_growth,
        'ebit_margin': smart_ebit_margin,
        'capex_pct': smart_capex_pct,
        'depreciation_pct': smart_depreciation_pct,
        'terminal_growth': smart_terminal_growth,
        'tax_rate': smart_tax_rate,
        'wc_change': 0,  # Assume neutral
        'forecast_years': 5
    }

def calculate_wacc(cost_equity, cost_debt, tax_rate, debt, equity):
    """Calculate Weighted Average Cost of Capital"""
    total_value = debt + equity
    if total_value == 0:
        return cost_equity
    
    weight_equity = equity / total_value
    weight_debt = debt / total_value
    
    wacc = (cost_equity * weight_equity) + (cost_debt * (1 - tax_rate) * weight_debt)
    return wacc

def calculate_cost_of_equity(risk_free_rate, beta, market_risk_premium):
    """Calculate Cost of Equity using CAPM"""
    return risk_free_rate + (beta * market_risk_premium)

def calculate_terminal_value(final_fcf, discount_rate, terminal_growth):
    """Calculate Terminal Value using Gordon Growth Model"""
    if discount_rate <= terminal_growth:
        return 0
    return final_fcf * (1 + terminal_growth) / (discount_rate - terminal_growth)

def project_fcff_enhanced(base_revenue, base_ebit, revenue_growth, ebit_margin, tax_rate,
                         depreciation_pct, capex_pct, change_wc, forecast_years, multistage_config=None):
    """
    ENHANCED: Project FCFF with D&A and CapEx scaling with revenue
    Supports multi-stage growth modeling
    """
    projections = []

    current_revenue = base_revenue

    for year in range(1, forecast_years + 1):
        # Determine growth rate for this year (multi-stage or single-stage)
        if multistage_config and multistage_config.get('enabled'):
            stage1_years = multistage_config['stage1_years']
            stage2_years = multistage_config['stage2_years']

            if year <= stage1_years:
                current_growth = multistage_config['stage1_growth']
            elif year <= stage1_years + stage2_years:
                current_growth = multistage_config['stage2_growth']
            else:
                current_growth = multistage_config['stage3_growth']
        else:
            current_growth = revenue_growth

        # Grow revenue
        current_revenue = current_revenue * (1 + current_growth)

        # Calculate EBIT based on margin
        current_ebit = current_revenue * ebit_margin
        
        # Calculate NOPAT
        nopat = current_ebit * (1 - tax_rate)
        
        # FIXED: Scale D&A and CapEx with revenue
        depreciation = current_revenue * depreciation_pct
        capex = current_revenue * capex_pct
        
        # Calculate FCFF
        fcff = nopat + depreciation - capex - change_wc
        
        projections.append({
            'year': year,
            'revenue': current_revenue,
            'ebit': current_ebit,
            'nopat': nopat,
            'depreciation': depreciation,
            'capex': capex,
            'change_wc': change_wc,
            'fcff': fcff
        })
    
    return projections

def project_fcfe_enhanced(base_revenue, base_net_income, revenue_growth, tax_rate,
                         depreciation_pct, capex_pct, change_wc, net_borrowing, forecast_years, multistage_config=None):
    """
    ENHANCED: Project FCFE with D&A and CapEx scaling with revenue
    Supports multi-stage growth modeling
    """
    projections = []

    current_revenue = base_revenue
    current_ni = base_net_income

    # Calculate initial NI margin
    ni_margin = current_ni / current_revenue if current_revenue > 0 else 0

    for year in range(1, forecast_years + 1):
        # Determine growth rate for this year (multi-stage or single-stage)
        if multistage_config and multistage_config.get('enabled'):
            stage1_years = multistage_config['stage1_years']
            stage2_years = multistage_config['stage2_years']

            if year <= stage1_years:
                current_growth = multistage_config['stage1_growth']
            elif year <= stage1_years + stage2_years:
                current_growth = multistage_config['stage2_growth']
            else:
                current_growth = multistage_config['stage3_growth']
        else:
            current_growth = revenue_growth

        # Grow revenue
        current_revenue = current_revenue * (1 + current_growth)

        # Grow net income
        current_ni = current_revenue * ni_margin
        
        # FIXED: Scale D&A and CapEx with revenue
        depreciation = current_revenue * depreciation_pct
        capex = current_revenue * capex_pct
        
        # Calculate FCFE
        fcfe = current_ni + depreciation - capex - change_wc + net_borrowing
        
        projections.append({
            'year': year,
            'revenue': current_revenue,
            'net_income': current_ni,
            'depreciation': depreciation,
            'capex': capex,
            'change_wc': change_wc,
            'net_borrowing': net_borrowing,
            'fcfe': fcfe
        })
    
    return projections

def calculate_dcf_value(projections, discount_rate, terminal_value, shares_outstanding, 
                       net_debt=0, method='FCFF'):
    """Calculate DCF valuation"""
    # Discount projected cash flows
    pv_cash_flows = []
    total_pv = 0
    
    for proj in projections:
        year = proj['year']
        cf = proj['fcff'] if method == 'FCFF' else proj['fcfe']
        pv = cf / ((1 + discount_rate) ** year)
        pv_cash_flows.append(pv)
        total_pv += pv
    
    # Discount terminal value
    pv_terminal = terminal_value / ((1 + discount_rate) ** len(projections))
    
    # Calculate enterprise/equity value
    enterprise_value = total_pv + pv_terminal
    
    if method == 'FCFF':
        # For FCFF, subtract net debt to get equity value
        equity_value = enterprise_value - net_debt
    else:
        # For FCFE, enterprise value IS equity value
        equity_value = enterprise_value
    
    # Calculate per share value
    intrinsic_value_per_share = equity_value / shares_outstanding if shares_outstanding > 0 else 0
    
    return {
        'pv_cash_flows': pv_cash_flows,
        'total_pv_cash_flows': total_pv,
        'terminal_value': terminal_value,
        'pv_terminal': pv_terminal,
        'enterprise_value': enterprise_value,
        'equity_value': equity_value,
        'intrinsic_value_per_share': intrinsic_value_per_share
    }

# ============================================================================
# VALUATION HOUSE RENOVATION - NEW MODULAR METHODS
# Following Damodaran / McKinsey Standards
# ============================================================================

# Industry-Standard Constraints
VALUATION_CONSTRAINTS = {
    'max_terminal_growth': 0.04,  # 4% (long-term GDP growth)
    'max_payout_ratio': 1.0,      # 100%
    'min_roe': 0.0,               # 0%
    'max_roe': 0.50,              # 50% (sanity check)
    'max_pe_multiple': 100,       # Outlier filter
    'min_pe_multiple': 3,         # Outlier filter
}

def apply_damodaran_constraints(value, constraint_type):
    """Apply industry-standard Damodaran constraints"""
    if constraint_type == 'terminal_growth':
        return min(value, VALUATION_CONSTRAINTS['max_terminal_growth'])
    elif constraint_type == 'payout_ratio':
        return min(max(value, 0), VALUATION_CONSTRAINTS['max_payout_ratio'])
    elif constraint_type == 'roe':
        return min(max(value, VALUATION_CONSTRAINTS['min_roe']), VALUATION_CONSTRAINTS['max_roe'])
    return value

# ============================================================================
# DIVIDEND DISCOUNT MODELS (DDM)
# ============================================================================

def calculate_gordon_growth_ddm(current_dividend, cost_of_equity, growth_rate, shares_outstanding):
    """
    Gordon Growth Model (Constant Growth DDM)
    Value = D1 / (r - g)
    Where D1 = D0 * (1 + g)
    """
    # Apply constraint: growth < cost of equity
    if growth_rate >= cost_of_equity:
        growth_rate = cost_of_equity * 0.9  # Safety margin

    # Constrain terminal growth
    growth_rate = apply_damodaran_constraints(growth_rate, 'terminal_growth')

    # Calculate next year's dividend
    d1 = current_dividend * (1 + growth_rate)

    # Gordon Growth formula
    equity_value = d1 / (cost_of_equity - growth_rate)
    intrinsic_value_per_share = equity_value / shares_outstanding if shares_outstanding > 0 else 0

    return {
        'method': 'Gordon Growth DDM',
        'current_dividend': current_dividend,
        'd1': d1,
        'cost_of_equity': cost_of_equity,
        'growth_rate': growth_rate,
        'equity_value': equity_value,
        'intrinsic_value_per_share': intrinsic_value_per_share,
        'shares_outstanding': shares_outstanding
    }

def calculate_multistage_ddm(current_dividend, cost_of_equity, high_growth_rate,
                             high_growth_years, stable_growth_rate, shares_outstanding):
    """
    Multi-Stage DDM (H-Model or 2-Stage)
    Phase 1: High growth period
    Phase 2: Transition to stable growth
    """
    # Apply constraints
    stable_growth_rate = apply_damodaran_constraints(stable_growth_rate, 'terminal_growth')

    if stable_growth_rate >= cost_of_equity:
        stable_growth_rate = cost_of_equity * 0.9

    pv_dividends = 0
    current_div = current_dividend

    # Phase 1: High growth dividends
    for year in range(1, high_growth_years + 1):
        current_div = current_div * (1 + high_growth_rate)
        pv = current_div / ((1 + cost_of_equity) ** year)
        pv_dividends += pv

    # Terminal value using Gordon Growth
    terminal_dividend = current_div * (1 + stable_growth_rate)
    terminal_value = terminal_dividend / (cost_of_equity - stable_growth_rate)
    pv_terminal = terminal_value / ((1 + cost_of_equity) ** high_growth_years)

    equity_value = pv_dividends + pv_terminal
    intrinsic_value_per_share = equity_value / shares_outstanding if shares_outstanding > 0 else 0

    return {
        'method': 'Multi-Stage DDM',
        'pv_high_growth_dividends': pv_dividends,
        'terminal_value': terminal_value,
        'pv_terminal': pv_terminal,
        'equity_value': equity_value,
        'intrinsic_value_per_share': intrinsic_value_per_share,
        'high_growth_years': high_growth_years,
        'stable_growth_rate': stable_growth_rate,
        'shares_outstanding': shares_outstanding
    }

# ============================================================================
# RESIDUAL INCOME (ECONOMIC PROFIT) MODEL
# ============================================================================

def calculate_residual_income(book_value_equity, roe, cost_of_equity, growth_rate,
                              forecast_years, shares_outstanding):
    """
    Residual Income Model (Edwards-Bell-Ohlson)
    Value = Book Value + PV(Residual Income)
    RI = (ROE - Cost of Equity) √ó Book Value
    """
    # Apply ROE constraints
    roe = apply_damodaran_constraints(roe, 'roe')
    growth_rate = apply_damodaran_constraints(growth_rate, 'terminal_growth')

    pv_residual_income = 0
    current_bv = book_value_equity

    for year in range(1, forecast_years + 1):
        # Calculate residual income
        residual_income = (roe - cost_of_equity) * current_bv

        # Discount to present value
        pv_ri = residual_income / ((1 + cost_of_equity) ** year)
        pv_residual_income += pv_ri

        # Grow book value
        current_bv = current_bv * (1 + roe)

    # Terminal value of residual income
    terminal_ri = (roe - cost_of_equity) * current_bv
    terminal_value = terminal_ri / (cost_of_equity - growth_rate) if (cost_of_equity - growth_rate) > 0 else 0
    pv_terminal = terminal_value / ((1 + cost_of_equity) ** forecast_years)

    equity_value = book_value_equity + pv_residual_income + pv_terminal
    intrinsic_value_per_share = equity_value / shares_outstanding if shares_outstanding > 0 else 0

    return {
        'method': 'Residual Income',
        'book_value_equity': book_value_equity,
        'roe': roe,
        'cost_of_equity': cost_of_equity,
        'pv_residual_income': pv_residual_income,
        'pv_terminal': pv_terminal,
        'equity_value': equity_value,
        'intrinsic_value_per_share': intrinsic_value_per_share,
        'shares_outstanding': shares_outstanding
    }

# ============================================================================
# RELATIVE VALUATION - PEER MULTIPLES
# ============================================================================

def fetch_peer_companies(ticker, sector, max_peers=10):
    """
    Fetch comparable companies for relative valuation
    Uses sector peers with similar market cap
    """
    # Sector peer mapping (simplified - can be enhanced)
    sector_peers = {
        'Technology': ['AAPL', 'MSFT', 'GOOGL', 'META', 'NVDA', 'ORCL', 'CRM', 'ADBE', 'INTC', 'AMD'],
        'Financial Services': ['JPM', 'BAC', 'WFC', 'C', 'GS', 'MS', 'BLK', 'V', 'MA'],
        'Healthcare': ['JNJ', 'UNH', 'PFE', 'ABBV', 'TMO', 'LLY', 'MRK', 'ABT'],
        'Consumer Cyclical': ['AMZN', 'TSLA', 'NKE', 'MCD', 'SBUX', 'HD', 'LOW'],
        'Consumer Defensive': ['WMT', 'PG', 'KO', 'PEP', 'COST', 'CL', 'GIS'],
        'Energy': ['XOM', 'CVX', 'COP', 'SLB', 'EOG', 'PXD'],
        'Industrials': ['BA', 'CAT', 'GE', 'UPS', 'HON', 'LMT', 'RTX'],
        'Communication Services': ['GOOGL', 'META', 'DIS', 'NFLX', 'CMCSA', 'T', 'VZ'],
    }

    peers = sector_peers.get(sector, [])
    # Remove the target ticker from peers
    peers = [p for p in peers if p != ticker]

    return peers[:max_peers]

def calculate_peer_multiples(peers):
    """
    Calculate median multiples from peer companies
    Returns: P/E, EV/EBITDA, EV/EBIT, P/B, EV/Sales, PEG
    """
    multiples_data = []

    for peer in peers:
        try:
            stock = yf.Ticker(peer)
            info = stock.info

            pe = info.get('trailingPE')
            pb = info.get('priceToBook')
            ps = info.get('priceToSalesTrailing12Months')
            peg = info.get('pegRatio')

            # Calculate EV multiples
            market_cap = info.get('marketCap', 0)
            total_debt = info.get('totalDebt', 0)
            cash = info.get('totalCash', 0)
            ev = market_cap + total_debt - cash

            ebitda = info.get('ebitda')
            ebit = info.get('ebit')
            revenue = info.get('totalRevenue')

            ev_ebitda = ev / ebitda if ebitda and ebitda > 0 else None
            ev_ebit = ev / ebit if ebit and ebit > 0 else None
            ev_sales = ev / revenue if revenue and revenue > 0 else None

            # Apply outlier filters
            if pe and VALUATION_CONSTRAINTS['min_pe_multiple'] <= pe <= VALUATION_CONSTRAINTS['max_pe_multiple']:
                multiples_data.append({
                    'ticker': peer,
                    'pe': pe,
                    'pb': pb,
                    'ps': ps,
                    'peg': peg,
                    'ev_ebitda': ev_ebitda,
                    'ev_ebit': ev_ebit,
                    'ev_sales': ev_sales
                })
        except:
            continue

    if not multiples_data:
        return None

    # Calculate median multiples
    df = pd.DataFrame(multiples_data)

    median_multiples = {
        'pe': df['pe'].median(),
        'pb': df['pb'].median(),
        'ps': df['ps'].median(),
        'peg': df['peg'].median(),
        'ev_ebitda': df['ev_ebitda'].median(),
        'ev_ebit': df['ev_ebit'].median(),
        'ev_sales': df['ev_sales'].median(),
        'num_peers': len(multiples_data),
        'peer_data': multiples_data
    }

    return median_multiples

def apply_relative_valuation(company_financials, median_multiples, shares_outstanding):
    """
    Apply peer multiples to company financials
    Returns valuation for each multiple
    """
    results = {}

    # Extract company metrics
    eps = company_financials.get('eps', 0)
    book_value_per_share = company_financials.get('book_value_per_share', 0)
    sales_per_share = company_financials.get('sales_per_share', 0)
    ebitda = company_financials.get('ebitda', 0)
    ebit = company_financials.get('ebit', 0)
    revenue = company_financials.get('revenue', 0)
    total_debt = company_financials.get('total_debt', 0)
    cash = company_financials.get('cash', 0)

    # P/E Valuation
    if median_multiples['pe'] and eps:
        results['pe_value'] = eps * median_multiples['pe']

    # P/B Valuation
    if median_multiples['pb'] and book_value_per_share:
        results['pb_value'] = book_value_per_share * median_multiples['pb']

    # P/S Valuation
    if median_multiples['ps'] and sales_per_share:
        results['ps_value'] = sales_per_share * median_multiples['ps']

    # EV/EBITDA Valuation
    if median_multiples['ev_ebitda'] and ebitda and ebitda > 0:
        ev = ebitda * median_multiples['ev_ebitda']
        equity_value = ev - total_debt + cash
        results['ev_ebitda_value'] = equity_value / shares_outstanding if shares_outstanding > 0 else 0

    # EV/EBIT Valuation
    if median_multiples['ev_ebit'] and ebit and ebit > 0:
        ev = ebit * median_multiples['ev_ebit']
        equity_value = ev - total_debt + cash
        results['ev_ebit_value'] = equity_value / shares_outstanding if shares_outstanding > 0 else 0

    # EV/Sales Valuation
    if median_multiples['ev_sales'] and revenue and revenue > 0:
        ev = revenue * median_multiples['ev_sales']
        equity_value = ev - total_debt + cash
        results['ev_sales_value'] = equity_value / shares_outstanding if shares_outstanding > 0 else 0

    # Calculate average relative valuation
    valid_values = [v for v in results.values() if v is not None and v > 0]
    results['average_relative_value'] = np.median(valid_values) if valid_values else 0
    results['median_multiples'] = median_multiples

    return results

# ============================================================================
# SUM-OF-THE-PARTS (SOTP) VALUATION
# ============================================================================

def calculate_sotp_valuation(segments, discount_rate, shares_outstanding):
    """
    Sum-of-the-Parts valuation for multi-segment companies
    segments = [{'name': 'Segment A', 'revenue': X, 'ebitda_margin': Y, 'multiple': Z}, ...]
    """
    total_value = 0
    segment_values = []

    for segment in segments:
        name = segment.get('name', 'Unnamed')
        revenue = segment.get('revenue', 0)
        ebitda_margin = segment.get('ebitda_margin', 0)
        ev_revenue_multiple = segment.get('ev_revenue_multiple', 0)

        # Calculate segment EBITDA
        ebitda = revenue * ebitda_margin

        # Value segment using EV/Revenue multiple
        segment_ev = revenue * ev_revenue_multiple

        segment_values.append({
            'name': name,
            'revenue': revenue,
            'ebitda': ebitda,
            'ev': segment_ev
        })

        total_value += segment_ev

    # Convert to equity value (simplified - assumes segments share same debt structure)
    intrinsic_value_per_share = total_value / shares_outstanding if shares_outstanding > 0 else 0

    return {
        'method': 'Sum-of-the-Parts',
        'segment_values': segment_values,
        'total_enterprise_value': total_value,
        'intrinsic_value_per_share': intrinsic_value_per_share,
        'shares_outstanding': shares_outstanding
    }

# ============================================================================
# CONSOLIDATED VALUATION SUMMARY
# ============================================================================

def create_valuation_summary_table(valuations_dict, current_price):
    """
    Create consolidated summary table from all valuation methods
    valuations_dict = {'FCFF': result, 'FCFE': result, 'DDM': result, ...}
    """
    summary_data = []

    for method, result in valuations_dict.items():
        if result and 'intrinsic_value_per_share' in result:
            intrinsic_value = result['intrinsic_value_per_share']

            if intrinsic_value > 0:
                upside = ((intrinsic_value - current_price) / current_price) * 100

                summary_data.append({
                    'Method': method,
                    'Intrinsic Value': intrinsic_value,
                    'Current Price': current_price,
                    'Upside/Downside (%)': upside,
                    'Rating': 'BUY' if upside > 20 else ('HOLD' if upside > -10 else 'SELL')
                })

    if not summary_data:
        return None

    df = pd.DataFrame(summary_data)

    # Add summary statistics
    avg_intrinsic = df['Intrinsic Value'].mean()
    median_intrinsic = df['Intrinsic Value'].median()
    avg_upside = df['Upside/Downside (%)'].mean()

    # Consensus rating
    buy_count = len(df[df['Rating'] == 'BUY'])
    hold_count = len(df[df['Rating'] == 'HOLD'])
    sell_count = len(df[df['Rating'] == 'SELL'])

    if buy_count > max(hold_count, sell_count):
        consensus = 'BUY'
    elif sell_count > max(buy_count, hold_count):
        consensus = 'SELL'
    else:
        consensus = 'HOLD'

    summary_stats = {
        'average_intrinsic_value': avg_intrinsic,
        'median_intrinsic_value': median_intrinsic,
        'average_upside': avg_upside,
        'consensus_rating': consensus,
        'num_methods': len(df),
        'buy_count': buy_count,
        'hold_count': hold_count,
        'sell_count': sell_count
    }

    return df, summary_stats

# ============================================================================
# CONSENSUS VALUATION - MULTI-METHOD AGGREGATION
# ============================================================================

def get_industry_average_pe(ticker):
    """Get industry average P/E ratio for comparison"""
    # ATLAS Refactoring - Use cached market data fetcher
    try:
        if REFACTORED_MODULES_AVAILABLE:
            info = market_data.get_company_info(ticker)
        else:
            # Fallback to old method
            stock = yf.Ticker(ticker)
            info = stock.info
        industry = info.get('industry', '')

        # Industry average P/E ratios (approximate benchmarks)
        industry_pe_map = {
            'Software': 30.0,
            'Technology': 25.0,
            'Semiconductors': 22.0,
            'Biotechnology': 20.0,
            'Healthcare': 18.0,
            'Financial Services': 12.0,
            'Banks': 10.0,
            'Insurance': 11.0,
            'Retail': 15.0,
            'Consumer Cyclical': 16.0,
            'Consumer Defensive': 18.0,
            'Energy': 12.0,
            'Utilities': 16.0,
            'Real Estate': 20.0,
            'Industrials': 17.0,
            'Materials': 14.0,
            'Communication Services': 19.0
        }

        # Try to match industry
        for key, pe in industry_pe_map.items():
            if key.lower() in industry.lower():
                return pe

        # Default market average
        return 18.0

    except:
        return 18.0

def get_industry_average_pb(ticker):
    """Get industry average P/B ratio"""
    # ATLAS Refactoring - Use cached market data fetcher
    try:
        if REFACTORED_MODULES_AVAILABLE:
            info = market_data.get_company_info(ticker)
        else:
            # Fallback to old method
            stock = yf.Ticker(ticker)
            info = stock.info
        industry = info.get('industry', '')

        # Industry average P/B ratios
        industry_pb_map = {
            'Software': 8.0,
            'Technology': 6.0,
            'Biotechnology': 4.0,
            'Healthcare': 3.5,
            'Financial Services': 1.5,
            'Banks': 1.2,
            'Insurance': 1.3,
            'Retail': 3.0,
            'Consumer Cyclical': 2.5,
            'Consumer Defensive': 3.0,
            'Energy': 1.5,
            'Utilities': 1.8,
            'Real Estate': 2.0,
            'Industrials': 2.8,
            'Materials': 2.0
        }

        for key, pb in industry_pb_map.items():
            if key.lower() in industry.lower():
                return pb

        return 3.0

    except:
        return 3.0

def get_industry_average_ev_ebitda(ticker):
    """Get industry average EV/EBITDA multiple"""
    # ATLAS Refactoring - Use cached market data fetcher
    try:
        if REFACTORED_MODULES_AVAILABLE:
            info = market_data.get_company_info(ticker)
        else:
            # Fallback to old method
            stock = yf.Ticker(ticker)
            info = stock.info
        industry = info.get('industry', '')

        # Industry average EV/EBITDA multiples
        industry_ev_ebitda_map = {
            'Software': 20.0,
            'Technology': 16.0,
            'Biotechnology': 15.0,
            'Healthcare': 14.0,
            'Financial Services': 10.0,
            'Banks': 8.0,
            'Retail': 10.0,
            'Consumer Cyclical': 11.0,
            'Consumer Defensive': 12.0,
            'Energy': 8.0,
            'Utilities': 10.0,
            'Real Estate': 15.0,
            'Industrials': 11.0,
            'Materials': 9.0
        }

        for key, ev_ebitda in industry_ev_ebitda_map.items():
            if key.lower() in industry.lower():
                return ev_ebitda

        return 12.0

    except:
        return 12.0

def calculate_consensus_valuation(ticker, company_data, financials):
    """
    Calculate consensus valuation from multiple methods with intelligent weighting
    Includes DCF (FCFF & FCFE) using smart assumptions

    Returns:
    --------
    dict with:
        - consensus_value: weighted average valuation
        - confidence_score: 0-100 based on method agreement
        - contributing_methods: dict of methods and values used
        - excluded_methods: dict of methods excluded and why
    """

    # Define method weights (sum to 1.0) - DCF gets highest weight as most comprehensive
    METHOD_WEIGHTS = {
        'FCFF DCF': 0.25,        # Most comprehensive - firm valuation
        'FCFE DCF': 0.20,        # Equity valuation
        'P/E Multiple': 0.15,    # Reduced from 0.25
        'EV/EBITDA': 0.15,       # Reduced from 0.25
        'PEG Ratio': 0.10,       # Reduced from 0.20
        'P/B Multiple': 0.10,    # Reduced from 0.15
        'P/S Multiple': 0.05     # Reduced from 0.15
    }

    valuations = {}
    excluded_methods = {}

    current_price = company_data.get('current_price', 0)
    shares_outstanding = company_data.get('shares_outstanding', 0)

    # Get smart assumptions for DCF methods
    smart_params = calculate_smart_assumptions(company_data, financials)

    # =================================================================
    # DCF METHODS - FCFF and FCFE with Smart Assumptions
    # =================================================================

    # 0A. FCFF DCF Valuation
    try:
        revenue = financials.get('revenue', 0)
        ebit = financials.get('ebit', 0)
        total_debt = financials.get('total_debt', 0)
        cash = financials.get('cash', 0)
        total_equity = financials.get('total_equity', 0)
        beta = company_data.get('beta', 1.0)

        if revenue > 0 and ebit > 0 and shares_outstanding > 0:
            # Calculate discount rate (WACC)
            risk_free_rate = 0.04  # 4% risk-free rate
            market_risk_premium = 0.06  # 6% market risk premium
            cost_of_equity = calculate_cost_of_equity(risk_free_rate, beta, market_risk_premium)
            cost_of_debt = 0.05  # Assume 5% cost of debt

            net_debt = total_debt - cash
            wacc = calculate_wacc(cost_of_equity, cost_of_debt, smart_params['tax_rate'],
                                 total_debt, total_equity)

            # Project FCFF
            projections = project_fcff_enhanced(
                base_revenue=revenue,
                base_ebit=ebit,
                revenue_growth=smart_params['revenue_growth'],
                ebit_margin=smart_params['ebit_margin'],
                tax_rate=smart_params['tax_rate'],
                depreciation_pct=smart_params['depreciation_pct'],
                capex_pct=smart_params['capex_pct'],
                change_wc=smart_params['wc_change'],
                forecast_years=smart_params['forecast_years']
            )

            if projections and len(projections) > 0:
                final_fcf = projections[-1]['fcff']

                # Calculate terminal value
                terminal_value = calculate_terminal_value(
                    final_fcf, wacc, smart_params['terminal_growth']
                )

                # Calculate DCF value
                dcf_result = calculate_dcf_value(
                    projections=projections,
                    discount_rate=wacc,
                    terminal_value=terminal_value,
                    shares_outstanding=shares_outstanding,
                    net_debt=net_debt,
                    method='FCFF'
                )

                intrinsic_value = dcf_result['intrinsic_value_per_share']

                if intrinsic_value > 0 and intrinsic_value < current_price * 10:  # Sanity check
                    valuations['FCFF DCF'] = intrinsic_value
                else:
                    excluded_methods['FCFF DCF'] = f"Unrealistic DCF value: ${intrinsic_value:.2f}"
            else:
                excluded_methods['FCFF DCF'] = "Failed to generate projections"
        else:
            excluded_methods['FCFF DCF'] = "Missing revenue, EBIT, or shares data"
    except Exception as e:
        excluded_methods['FCFF DCF'] = f"Calculation error: {str(e)}"

    # 0B. FCFE DCF Valuation
    try:
        revenue = financials.get('revenue', 0)
        net_income = financials.get('net_income', 0)
        beta = company_data.get('beta', 1.0)

        if revenue > 0 and net_income > 0 and shares_outstanding > 0:
            # Calculate discount rate (cost of equity)
            risk_free_rate = 0.04
            market_risk_premium = 0.06
            cost_of_equity = calculate_cost_of_equity(risk_free_rate, beta, market_risk_premium)

            # Project FCFE
            projections = project_fcfe_enhanced(
                base_revenue=revenue,
                base_net_income=net_income,
                revenue_growth=smart_params['revenue_growth'],
                tax_rate=smart_params['tax_rate'],
                depreciation_pct=smart_params['depreciation_pct'],
                capex_pct=smart_params['capex_pct'],
                change_wc=smart_params['wc_change'],
                net_borrowing=0,  # Assume neutral
                forecast_years=smart_params['forecast_years']
            )

            if projections and len(projections) > 0:
                final_fcf = projections[-1]['fcfe']

                # Calculate terminal value
                terminal_value = calculate_terminal_value(
                    final_fcf, cost_of_equity, smart_params['terminal_growth']
                )

                # Calculate DCF value
                dcf_result = calculate_dcf_value(
                    projections=projections,
                    discount_rate=cost_of_equity,
                    terminal_value=terminal_value,
                    shares_outstanding=shares_outstanding,
                    net_debt=0,  # Already in equity value
                    method='FCFE'
                )

                intrinsic_value = dcf_result['intrinsic_value_per_share']

                if intrinsic_value > 0 and intrinsic_value < current_price * 10:  # Sanity check
                    valuations['FCFE DCF'] = intrinsic_value
                else:
                    excluded_methods['FCFE DCF'] = f"Unrealistic DCF value: ${intrinsic_value:.2f}"
            else:
                excluded_methods['FCFE DCF'] = "Failed to generate projections"
        else:
            excluded_methods['FCFE DCF'] = "Missing revenue, net income, or shares data"
    except Exception as e:
        excluded_methods['FCFE DCF'] = f"Calculation error: {str(e)}"

    # =================================================================
    # MULTIPLES-BASED VALUATION METHODS
    # =================================================================

    # 1. P/E Multiple Valuation
    try:
        # Get EPS
        net_income = financials.get('net_income', 0)
        if shares_outstanding > 0 and net_income > 0:
            eps = net_income / shares_outstanding
            industry_pe = get_industry_average_pe(ticker)

            if eps > 0 and industry_pe > 0:
                pe_value = eps * industry_pe

                # Sanity check
                if current_price > 0:
                    implied_pe = pe_value / eps
                    if 0 < implied_pe < 100:  # Reasonable P/E range
                        valuations['P/E Multiple'] = pe_value
                    else:
                        excluded_methods['P/E Multiple'] = f"Unrealistic P/E ratio: {implied_pe:.1f}"
                else:
                    valuations['P/E Multiple'] = pe_value
            else:
                excluded_methods['P/E Multiple'] = "Negative or missing EPS data"
        else:
            excluded_methods['P/E Multiple'] = "Negative earnings or missing shares data"
    except Exception as e:
        excluded_methods['P/E Multiple'] = f"Calculation error: {str(e)}"

    # 2. P/B Multiple Valuation
    try:
        total_equity = financials.get('total_equity', 0)
        if shares_outstanding > 0 and total_equity > 0:
            book_value_per_share = total_equity / shares_outstanding
            industry_pb = get_industry_average_pb(ticker)

            if book_value_per_share > 0 and industry_pb > 0:
                pb_value = book_value_per_share * industry_pb

                # Sanity check
                if pb_value > 0 and pb_value < book_value_per_share * 15:
                    valuations['P/B Multiple'] = pb_value
                else:
                    excluded_methods['P/B Multiple'] = "Unrealistic P/B multiple"
            else:
                excluded_methods['P/B Multiple'] = "Negative or missing book value"
        else:
            excluded_methods['P/B Multiple'] = "Missing equity or shares data"
    except Exception as e:
        excluded_methods['P/B Multiple'] = f"Calculation error: {str(e)}"

    # 3. EV/EBITDA Valuation
    try:
        ebit = financials.get('ebit', 0)
        depreciation = financials.get('depreciation', 0)
        ebitda = ebit + depreciation

        total_debt = financials.get('total_debt', 0)
        cash = financials.get('cash', 0)
        net_debt = total_debt - cash

        industry_ev_ebitda = get_industry_average_ev_ebitda(ticker)

        if ebitda > 0 and industry_ev_ebitda > 0 and shares_outstanding > 0:
            enterprise_value = ebitda * industry_ev_ebitda
            equity_value = enterprise_value - net_debt
            ev_ebitda_value = equity_value / shares_outstanding

            if ev_ebitda_value > 0:
                valuations['EV/EBITDA'] = ev_ebitda_value
            else:
                excluded_methods['EV/EBITDA'] = "Negative equity value (high debt)"
        else:
            excluded_methods['EV/EBITDA'] = "Missing EBITDA or shares data"
    except Exception as e:
        excluded_methods['EV/EBITDA'] = f"Calculation error: {str(e)}"

    # 4. PEG Ratio Valuation (with comprehensive fallbacks)
    try:
        stock = yf.Ticker(ticker)
        info = stock.info
        peg_value = None
        growth_rate = None
        eps_value = None

        # Get available data points
        peg_ratio = info.get('pegRatio')
        forward_eps = info.get('forwardEps')
        trailing_eps = info.get('trailingEps')
        earnings_growth = info.get('earningsGrowth')  # Forward earnings growth
        earnings_quarterly_growth = info.get('earningsQuarterlyGrowth')
        revenue_growth = info.get('revenueGrowth')
        current_pe = info.get('trailingPE')
        forward_pe = info.get('forwardPE')

        # FALLBACK 1: Use forward EPS and earnings growth (primary method)
        if forward_eps and forward_eps > 0 and earnings_growth and earnings_growth > 0:
            growth_rate = earnings_growth
            eps_value = forward_eps
        # FALLBACK 2: Use trailing EPS and earnings growth
        elif trailing_eps and trailing_eps > 0 and earnings_growth and earnings_growth > 0:
            growth_rate = earnings_growth
            eps_value = trailing_eps
        # FALLBACK 3: Use forward EPS and quarterly growth as proxy
        elif forward_eps and forward_eps > 0 and earnings_quarterly_growth and earnings_quarterly_growth > 0:
            growth_rate = earnings_quarterly_growth
            eps_value = forward_eps
        # FALLBACK 4: Use trailing EPS and revenue growth as proxy (conservative)
        elif trailing_eps and trailing_eps > 0 and revenue_growth and revenue_growth > 0:
            # Use 70% of revenue growth as earnings growth proxy (conservative)
            growth_rate = revenue_growth * 0.7
            eps_value = trailing_eps
        # FALLBACK 5: Back-calculate from existing PEG ratio and P/E
        elif peg_ratio and peg_ratio > 0 and (forward_pe or current_pe):
            pe_value = forward_pe if forward_pe and forward_pe > 0 else current_pe
            if pe_value and pe_value > 0:
                # PEG = P/E / Growth, so Growth = P/E / PEG
                growth_rate = pe_value / peg_ratio / 100  # Convert to decimal
                eps_value = forward_eps if forward_eps and forward_eps > 0 else trailing_eps

        # Calculate PEG-based valuation if we have both growth rate and EPS
        if growth_rate and growth_rate > 0 and eps_value and eps_value > 0:
            # Fair PEG ratio is typically around 1.0
            fair_peg = 1.0
            fair_pe = (growth_rate * 100) * fair_peg  # Convert growth to percentage
            peg_value = eps_value * fair_pe

            # Sanity checks
            if not (0 < fair_pe < 50):  # Reasonable P/E range
                excluded_methods['PEG Ratio'] = f"Unrealistic implied P/E: {fair_pe:.1f}"
            elif not (0 < peg_value < current_price * 5):  # Not more than 5x current price
                excluded_methods['PEG Ratio'] = f"Unrealistic PEG value: ${peg_value:.2f}"
            else:
                valuations['PEG Ratio'] = peg_value
        else:
            excluded_methods['PEG Ratio'] = "Missing EPS or growth data (all fallbacks exhausted)"
    except Exception as e:
        excluded_methods['PEG Ratio'] = f"Calculation error: {str(e)}"

    # 5. P/S (Price-to-Sales) Multiple
    try:
        revenue = financials.get('revenue', 0)
        if shares_outstanding > 0 and revenue > 0:
            sales_per_share = revenue / shares_outstanding

            # Get sector-appropriate P/S ratio
            stock = yf.Ticker(ticker)
            sector = stock.info.get('sector', '')

            sector_ps_map = {
                'Technology': 6.0,
                'Healthcare': 4.0,
                'Financial': 2.5,
                'Consumer Cyclical': 1.5,
                'Consumer Defensive': 1.8,
                'Energy': 1.2,
                'Industrials': 1.5,
                'Utilities': 2.0,
                'Real Estate': 5.0
            }

            ps_multiple = 2.0  # Default
            for key, ps in sector_ps_map.items():
                if key.lower() in sector.lower():
                    ps_multiple = ps
                    break

            ps_value = sales_per_share * ps_multiple

            if ps_value > 0:
                valuations['P/S Multiple'] = ps_value
            else:
                excluded_methods['P/S Multiple'] = "Negative valuation"
        else:
            excluded_methods['P/S Multiple'] = "Missing revenue or shares data"
    except Exception as e:
        excluded_methods['P/S Multiple'] = f"Calculation error: {str(e)}"

    # Filter outliers using IQR method if we have at least 3 methods
    if len(valuations) >= 3:
        values = list(valuations.values())
        q1 = np.percentile(values, 25)
        q3 = np.percentile(values, 75)
        iqr = q3 - q1
        lower_bound = q1 - 1.5 * iqr
        upper_bound = q3 + 1.5 * iqr

        # Remove outliers
        for method, value in list(valuations.items()):
            if value < lower_bound or value > upper_bound:
                excluded_methods[method] = f"Statistical outlier (value: ${value:.2f}, bounds: ${lower_bound:.2f}-${upper_bound:.2f})"
                del valuations[method]

    # Calculate weighted consensus
    if valuations:
        # Normalize weights for available methods
        total_weight = sum(METHOD_WEIGHTS.get(m, 0.1) for m in valuations.keys())

        if total_weight > 0:
            consensus_value = sum(
                valuations[method] * (METHOD_WEIGHTS.get(method, 0.1) / total_weight)
                for method in valuations.keys()
            )

            # Calculate confidence score (0-100)
            # Based on: 1) number of methods, 2) convergence of values
            method_count_score = (len(valuations) / len(METHOD_WEIGHTS)) * 50

            # Convergence score: how tightly clustered are the valuations?
            if len(valuations) > 1:
                cv = np.std(list(valuations.values())) / np.mean(list(valuations.values()))
                convergence_score = max(0, (1 - cv) * 50)
            else:
                convergence_score = 25

            confidence_score = min(100, method_count_score + convergence_score)

            return {
                'consensus_value': consensus_value,
                'confidence_score': confidence_score,
                'contributing_methods': valuations,
                'excluded_methods': excluded_methods,
                'method_count': len(valuations)
            }

    # If no valid valuations
    return {
        'consensus_value': None,
        'confidence_score': 0,
        'contributing_methods': {},
        'excluded_methods': excluded_methods,
        'method_count': 0
    }

# ============================================================================
# PHOENIX PARSER
# ============================================================================

def parse_trade_history_file(uploaded_file):
    try:
        df = pd.read_html(uploaded_file)[0]
        required_cols = ['Date', 'Symbol', 'Trade Type', 'Quantity', 'Price']
        if not all(col in df.columns for col in required_cols):
            return None
        df['Price'] = df['Price'].astype(str).str.replace('$', '').str.replace(',', '').astype(float)
        df['Date'] = pd.to_datetime(df['Date'])
        df = df.sort_values('Date')
        return df
    except:
        return None

def parse_account_history_file(uploaded_file):
    try:
        df = pd.read_html(uploaded_file)[0]
        df['Date'] = pd.to_datetime(df['Date'])
        df = df.sort_values('Date')
        return df
    except:
        return None

def calculate_portfolio_from_trades(trade_df):
    holdings = {}
    for _, row in trade_df.iterrows():
        symbol = row['Symbol']
        trade_type = row['Trade Type']
        quantity = row['Quantity']
        price = row['Price']
        
        if is_option_ticker(symbol):
            continue
        
        if symbol not in holdings:
            holdings[symbol] = {'total_shares': 0, 'total_cost': 0, 'trades': []}
        
        is_buy = 'Buy' in trade_type
        
        if is_buy:
            holdings[symbol]['total_shares'] += quantity
            holdings[symbol]['total_cost'] += (quantity * price)
            holdings[symbol]['trades'].append({'type': 'BUY', 'quantity': quantity, 'price': price})
        else:
            remaining_to_sell = quantity
            for trade in holdings[symbol]['trades']:
                if trade['type'] == 'BUY' and remaining_to_sell > 0:
                    if trade['quantity'] <= remaining_to_sell:
                        holdings[symbol]['total_cost'] -= (trade['quantity'] * trade['price'])
                        holdings[symbol]['total_shares'] -= trade['quantity']
                        remaining_to_sell -= trade['quantity']
                        trade['quantity'] = 0
                    else:
                        holdings[symbol]['total_cost'] -= (remaining_to_sell * trade['price'])
                        holdings[symbol]['total_shares'] -= remaining_to_sell
                        trade['quantity'] -= remaining_to_sell
                        remaining_to_sell = 0
    
    portfolio_data = []
    for symbol, data in holdings.items():
        if data['total_shares'] > 0:
            avg_cost = data['total_cost'] / data['total_shares']
            portfolio_data.append({
                'Ticker': symbol,
                'Shares': data['total_shares'],
                'Avg Cost': avg_cost
            })
    
    if portfolio_data is None or (isinstance(portfolio_data, pd.DataFrame) and portfolio_data.empty):
        return pd.DataFrame(columns=['Ticker', 'Shares', 'Avg Cost'])
    return pd.DataFrame(portfolio_data).sort_values('Ticker')

# ============================================================================
# PORTFOLIO CALCULATIONS
# ============================================================================

@st.cache_data(ttl=600)
def calculate_portfolio_returns(df, start_date, end_date, equity=None):
    """
    Calculate portfolio returns correctly accounting for leverage

    CRITICAL FIX: Returns calculated on EQUITY basis, not gross exposure.
    With leverage, pct_change() on gross exposure understates returns.

    Args:
        df: Portfolio dataframe with positions
        start_date: Start date for historical data
        end_date: End date for historical data
        equity: User's equity capital (default: from session state)

    Returns:
        Returns series calculated on equity basis (leverage amplified)
    """
    try:
        valid_positions = []
        for _, row in df.iterrows():
            if not is_option_ticker(row['Ticker']):
                valid_positions.append(row)

        if not valid_positions:
            return None

        valid_df = pd.DataFrame(valid_positions)
        all_data = {}

        for _, row in valid_df.iterrows():
            ticker = row['Ticker']
            data = fetch_historical_data(ticker, start_date, end_date)
            if data is not None and len(data) > 0:
                all_data[ticker] = data

        if not all_data:
            return None

        common_dates = None
        for ticker, data in all_data.items():
            dates = set(data.index)
            common_dates = dates if common_dates is None else common_dates.intersection(dates)

        common_dates = sorted(list(common_dates))
        if len(common_dates) < 2:
            return None

        # Calculate daily portfolio gross values
        portfolio_values = []
        for date in common_dates:
            daily_value = 0
            for _, row in valid_df.iterrows():
                ticker = row['Ticker']
                if ticker in all_data:
                    try:
                        price = all_data[ticker].loc[date, 'Close']
                        daily_value += price * row['Shares']
                    except KeyError:
                        continue
            portfolio_values.append(daily_value)

        portfolio_series = pd.Series(portfolio_values, index=common_dates)

        # CRITICAL FIX: Calculate returns on EQUITY basis, not gross exposure
        # Get equity from session state if not provided
        if equity is None:
            # Try to get from session state, fallback to initial portfolio value
            equity = st.session_state.get('equity_capital', portfolio_values[0])

        # Calculate dollar changes in portfolio value
        portfolio_changes = portfolio_series.diff()

        # Returns = dollar change / equity (not / previous gross value)
        # This correctly amplifies returns with leverage
        returns = portfolio_changes / equity

        # Drop first NaN value
        returns = returns.dropna()

        return returns
    except:
        return None

# ============================================================================
# BRINSON ATTRIBUTION ANALYSIS - NEW IN v9.7
# ============================================================================

# S&P 500 Sector Weights (Benchmark)
SP500_SECTOR_WEIGHTS = {
    'Technology': 28.5,
    'Healthcare': 13.2,
    'Financial Services': 12.8,
    'Consumer Cyclical': 10.5,
    'Communication Services': 8.7,
    'Industrials': 8.3,
    'Consumer Defensive': 6.8,
    'Energy': 4.2,
    'Real Estate': 2.5,
    'Basic Materials': 2.3,
    'Utilities': 2.2
}

@st.cache_data(ttl=3600)
def get_benchmark_sector_returns(period='1Y'):
    """
    Fetch sector ETF returns as proxy for benchmark sector performance
    """
    sector_etfs = {
        'Technology': 'XLK',
        'Healthcare': 'XLV',
        'Financial Services': 'XLF',
        'Consumer Cyclical': 'XLY',
        'Communication Services': 'XLC',
        'Industrials': 'XLI',
        'Consumer Defensive': 'XLP',
        'Energy': 'XLE',
        'Real Estate': 'XLRE',
        'Basic Materials': 'XLB',
        'Utilities': 'XLU'
    }

    benchmark_returns = {}

    # Calculate date range based on period
    end_date = datetime.now()
    if period == '1Y':
        start_date = end_date - timedelta(days=365)
    elif period == 'YTD':
        start_date = datetime(end_date.year, 1, 1)
    elif period == '3M':
        start_date = end_date - timedelta(days=90)
    else:
        start_date = end_date - timedelta(days=365)

    for sector, etf in sector_etfs.items():
        try:
            data = fetch_historical_data(etf, start_date=start_date, end_date=end_date)
            if data is not None and len(data) > 0:
                total_return = ((data['Close'].iloc[-1] / data['Close'].iloc[0]) - 1) * 100
                benchmark_returns[sector] = total_return
            else:
                benchmark_returns[sector] = 0.0
        except:
            benchmark_returns[sector] = 0.0

    return benchmark_returns

def calculate_skill_score(effect_value):
    """
    Convert attribution effect to skill score (0-10 scale)

    Positive effects = higher scores
    Scale: -5% to +5% maps to 0-10
    """
    # Normalize to 0-10 scale
    if effect_value >= 5:
        return 10.0
    elif effect_value <= -5:
        return 0.0
    else:
        return 5.0 + (effect_value / 5.0) * 5.0

def calculate_brinson_attribution(portfolio_df, benchmark_weights, benchmark_returns, period='YTD'):
    """
    Calculate Brinson attribution: Allocation, Selection, and Interaction effects

    Parameters:
    -----------
    portfolio_df : pd.DataFrame
        Portfolio holdings with columns: Ticker, Sector, Weight %, Total Gain/Loss %
    benchmark_weights : dict
        Benchmark sector weights {sector: weight}
    benchmark_returns : dict
        Benchmark sector returns {sector: return}
    period : str
        Time period for analysis (YTD, 1Y, etc.)

    Returns:
    --------
    dict with attribution_df, total_allocation_effect, total_selection_effect,
    total_interaction_effect, total_attribution, allocation_skill_score, selection_skill_score
    """

    # Group portfolio by sector
    portfolio_sectors = portfolio_df.groupby('Sector').agg({
        'Weight %': 'sum',
        'Total Gain/Loss %': 'mean'  # Average return in sector
    }).reset_index()

    portfolio_sectors.columns = ['Sector', 'Portfolio Weight', 'Portfolio Return']
    portfolio_sectors['Portfolio Weight'] = portfolio_sectors['Portfolio Weight'] / 100

    results = []

    # Calculate benchmark total return (weighted average)
    rb_total = sum([benchmark_weights.get(s, 0) / 100 * benchmark_returns.get(s, 0) / 100
                   for s in benchmark_weights.keys()])

    for sector in portfolio_sectors['Sector']:
        # Get weights
        wp = portfolio_sectors[portfolio_sectors['Sector'] == sector]['Portfolio Weight'].iloc[0]
        wb = benchmark_weights.get(sector, 0) / 100

        # Get returns
        rp = portfolio_sectors[portfolio_sectors['Sector'] == sector]['Portfolio Return'].iloc[0] / 100
        rb = benchmark_returns.get(sector, 0) / 100

        # Brinson Attribution Formula:
        # Allocation Effect = (wp - wb) √ó (rb - rb_total)
        # Selection Effect = wb √ó (rp - rb)
        # Interaction Effect = (wp - wb) √ó (rp - rb)

        allocation_effect = (wp - wb) * (rb - rb_total) * 100
        selection_effect = wb * (rp - rb) * 100
        interaction_effect = (wp - wb) * (rp - rb) * 100

        results.append({
            'Sector': sector,
            'Portfolio Weight': wp * 100,
            'Benchmark Weight': wb * 100,
            'Weight Diff': (wp - wb) * 100,
            'Portfolio Return': rp * 100,
            'Benchmark Return': rb * 100,
            'Return Diff': (rp - rb) * 100,
            'Allocation Effect': allocation_effect,
            'Selection Effect': selection_effect,
            'Interaction Effect': interaction_effect,
            'Total Effect': allocation_effect + selection_effect + interaction_effect
        })

    attribution_df = pd.DataFrame(results)

    # Calculate totals
    total_allocation = attribution_df['Allocation Effect'].sum()
    total_selection = attribution_df['Selection Effect'].sum()
    total_interaction = attribution_df['Interaction Effect'].sum()
    total_attribution = total_allocation + total_selection + total_interaction

    return {
        'attribution_df': attribution_df,
        'total_allocation_effect': total_allocation,
        'total_selection_effect': total_selection,
        'total_interaction_effect': total_interaction,
        'total_attribution': total_attribution,
        'allocation_skill_score': calculate_skill_score(total_allocation),
        'selection_skill_score': calculate_skill_score(total_selection)
    }

def create_brinson_attribution_chart(attribution_results):
    """
    Create waterfall chart showing allocation, selection, and interaction effects
    """

    # Aggregate by effect type
    total_allocation = attribution_results['total_allocation_effect']
    total_selection = attribution_results['total_selection_effect']
    total_interaction = attribution_results['total_interaction_effect']
    total = attribution_results['total_attribution']

    fig = go.Figure(go.Waterfall(
        name="Attribution",
        orientation="v",
        x=['Allocation<br>Effect', 'Selection<br>Effect', 'Interaction<br>Effect', 'Total<br>Attribution'],
        y=[total_allocation, total_selection, total_interaction, total],
        measure=['relative', 'relative', 'relative', 'total'],
        text=[f"{total_allocation:+.2f}%", f"{total_selection:+.2f}%",
              f"{total_interaction:+.2f}%", f"{total:.2f}%"],
        textposition="outside",
        connector={"line": {"color": COLORS['neon_blue'], "width": 2}},
        decreasing={"marker": {"color": COLORS['danger']}},
        increasing={"marker": {"color": COLORS['success']}},
        totals={"marker": {"color": COLORS['electric_blue']}}
    ))

    fig.update_layout(
        title="üìä Brinson Attribution: Portfolio Outperformance Breakdown",
        yaxis_title="Effect (%)",
        height=500,
        showlegend=False
    )

    apply_chart_theme(fig)
    return fig

def create_skill_assessment_card(attribution_results):
    """
    Create visual skill assessment comparing allocation vs selection
    Uses glassmorphism styling to match ATLAS dashboard theme
    """

    allocation_score = attribution_results['allocation_skill_score']
    selection_score = attribution_results['selection_skill_score']

    allocation_effect = attribution_results['total_allocation_effect']
    selection_effect = attribution_results['total_selection_effect']

    # Determine primary skill
    if allocation_score > selection_score + 2:
        primary_skill = "Sector Timing (Allocation)"
        recommendation = "Focus on sector rotation strategies. Consider using sector ETFs."
    elif selection_score > allocation_score + 2:
        primary_skill = "Stock Picking (Selection)"
        recommendation = "Focus on fundamental analysis. Your stock picks add value."
    else:
        primary_skill = "Balanced"
        recommendation = "Continue current strategy - both skills are comparable."

    # Status emojis and colors
    alloc_color = '#00ff9d' if allocation_effect > 0 else '#ff006b'
    select_color = '#00ff9d' if selection_effect > 0 else '#ff006b'
    alloc_status = '‚úì Strong sector rotation' if allocation_effect > 1 else '‚óã Neutral sector timing' if allocation_effect > -1 else '‚úó Poor sector allocation'
    select_status = '‚úì Strong stock picks' if selection_effect > 1 else '‚óã Neutral stock selection' if selection_effect > -1 else '‚úó Stocks underperform sector'

    html = f"""
    <style>
        @import url('https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700;800&family=JetBrains+Mono:wght@400;500;600;700&display=swap');
    </style>
    <div style="
        background: rgba(26, 35, 50, 0.7);
        backdrop-filter: blur(10px);
        -webkit-backdrop-filter: blur(10px);
        border: 1px solid rgba(0, 212, 255, 0.2);
        border-radius: 12px;
        padding: 24px;
        margin: 20px 0;
        font-family: 'Inter', -apple-system, BlinkMacSystemFont, sans-serif;
    ">
        <h3 style="
            font-family: 'Inter', sans-serif;
            font-size: 1.2rem;
            font-weight: 700;
            color: #00d4ff;
            text-transform: uppercase;
            letter-spacing: 0.1em;
            margin: 0 0 20px 0;
            text-shadow: 0 0 10px rgba(0, 212, 255, 0.3);
        ">
            üéØ Portfolio Management Skill Assessment
        </h3>

        <div style="display: grid; grid-template-columns: 1fr 1fr; gap: 20px;">

            <!-- Allocation Skill -->
            <div style="
                background: rgba(10, 15, 26, 0.6);
                border: 1px solid rgba(0, 212, 255, 0.15);
                border-radius: 8px;
                padding: 16px;
            ">
                <div style="
                    font-family: 'Inter', sans-serif;
                    font-size: 0.75rem;
                    font-weight: 600;
                    color: #8890a0;
                    text-transform: uppercase;
                    letter-spacing: 0.1em;
                    margin-bottom: 8px;
                ">ALLOCATION SKILL (Sector Timing)</div>

                <div style="
                    font-family: 'JetBrains Mono', monospace;
                    font-size: 2.5rem;
                    font-weight: 700;
                    color: {alloc_color};
                    text-shadow: 0 0 15px {alloc_color}40;
                    margin: 8px 0;
                ">{allocation_score:.1f}/10</div>

                <div style="
                    font-family: 'Inter', sans-serif;
                    font-size: 0.9rem;
                    color: #c0c8d0;
                    margin-top: 8px;
                ">Effect: {allocation_effect:+.2f}%</div>

                <div style="
                    font-family: 'Inter', sans-serif;
                    font-size: 0.75rem;
                    color: {alloc_color};
                    margin-top: 8px;
                ">{alloc_status}</div>
            </div>

            <!-- Selection Skill -->
            <div style="
                background: rgba(10, 15, 26, 0.6);
                border: 1px solid rgba(0, 212, 255, 0.15);
                border-radius: 8px;
                padding: 16px;
            ">
                <div style="
                    font-family: 'Inter', sans-serif;
                    font-size: 0.75rem;
                    font-weight: 600;
                    color: #8890a0;
                    text-transform: uppercase;
                    letter-spacing: 0.1em;
                    margin-bottom: 8px;
                ">SELECTION SKILL (Stock Picking)</div>

                <div style="
                    font-family: 'JetBrains Mono', monospace;
                    font-size: 2.5rem;
                    font-weight: 700;
                    color: {select_color};
                    text-shadow: 0 0 15px {select_color}40;
                    margin: 8px 0;
                ">{selection_score:.1f}/10</div>

                <div style="
                    font-family: 'Inter', sans-serif;
                    font-size: 0.9rem;
                    color: #c0c8d0;
                    margin-top: 8px;
                ">Effect: {selection_effect:+.2f}%</div>

                <div style="
                    font-family: 'Inter', sans-serif;
                    font-size: 0.75rem;
                    color: {select_color};
                    margin-top: 8px;
                ">{select_status}</div>
            </div>
        </div>

        <!-- Recommendation -->
        <div style="
            background: linear-gradient(90deg, rgba(0, 212, 255, 0.1) 0%, transparent 100%);
            border-left: 3px solid #00d4ff;
            padding: 12px 16px;
            margin-top: 20px;
            border-radius: 4px;
        ">
            <div style="
                font-family: 'Inter', sans-serif;
                font-size: 0.75rem;
                font-weight: 700;
                color: #00d4ff;
                text-transform: uppercase;
                letter-spacing: 0.1em;
                margin-bottom: 4px;
            ">üí° Primary Strength: {primary_skill}</div>
            <div style="
                font-family: 'Inter', sans-serif;
                font-size: 0.85rem;
                color: #c0c8d0;
            ">{recommendation}</div>
        </div>
    </div>
    """

    return html

def validate_and_map_sectors(df):
    """
    Ensure all securities are properly classified into standard sectors
    Map any non-standard sectors to standard GICS sectors
    """
    STANDARD_SECTORS = [
        'Technology', 'Healthcare', 'Financial Services', 'Consumer Cyclical',
        'Communication Services', 'Industrials', 'Consumer Defensive',
        'Energy', 'Real Estate', 'Basic Materials', 'Utilities'
    ]

    SECTOR_MAPPING = {
        'Information Technology': 'Technology',
        'Health Care': 'Healthcare',
        'Financials': 'Financial Services',
        'Consumer Discretionary': 'Consumer Cyclical',
        'Communication': 'Communication Services',
        'Consumer Staples': 'Consumer Defensive',
        'Materials': 'Basic Materials',
        'Technology ': 'Technology',  # Trim whitespace
        'Financial': 'Financial Services',
    }

    # Apply mapping
    df['Sector'] = df['Sector'].replace(SECTOR_MAPPING)

    # Check for unmapped sectors
    unmapped = df[~df['Sector'].isin(STANDARD_SECTORS)]['Sector'].unique()
    if len(unmapped) > 0:
        st.warning(f"‚ö†Ô∏è Unmapped sectors found: {', '.join(unmapped)}. These will be grouped as 'Other'.")
        df.loc[~df['Sector'].isin(STANDARD_SECTORS), 'Sector'] = 'Other'

    return df

def validate_brinson_calculations(attribution_df, portfolio_weights, benchmark_weights,
                                  portfolio_returns, benchmark_returns):
    """
    Validate Brinson attribution calculations with detailed checks
    Returns validation results dict
    """
    validation_output = []

    validation_output.append("=" * 60)
    validation_output.append("BRINSON ATTRIBUTION VALIDATION")
    validation_output.append("=" * 60)

    # Check 1: Weights sum to 100%
    port_weight_sum = sum(portfolio_weights.values())
    bench_weight_sum = sum(benchmark_weights.values())

    validation_output.append("\n1. WEIGHT VALIDATION:")
    validation_output.append(f"   Portfolio weights sum: {port_weight_sum:.2f}%")
    validation_output.append(f"   Benchmark weights sum: {bench_weight_sum:.2f}%")

    weight_check_passed = True
    if abs(port_weight_sum - 100) > 0.1:
        validation_output.append("   ‚ö†Ô∏è WARNING: Portfolio weights don't sum to 100%")
        weight_check_passed = False
    if abs(bench_weight_sum - 100) > 0.1:
        validation_output.append("   ‚ö†Ô∏è WARNING: Benchmark weights don't sum to 100%")
        weight_check_passed = False

    # Check 2: Attribution effects sum correctly
    total_allocation = attribution_df['Allocation Effect'].sum()
    total_selection = attribution_df['Selection Effect'].sum()
    total_interaction = attribution_df['Interaction Effect'].sum()
    total_attribution = total_allocation + total_selection + total_interaction

    validation_output.append(f"\n2. ATTRIBUTION DECOMPOSITION:")
    validation_output.append(f"   Allocation Effect: {total_allocation:+.2f}%")
    validation_output.append(f"   Selection Effect: {total_selection:+.2f}%")
    validation_output.append(f"   Interaction Effect: {total_interaction:+.2f}%")
    validation_output.append(f"   Total Attribution: {total_attribution:+.2f}%")

    # Check 3: Compare to actual excess return
    portfolio_return = sum(portfolio_weights.get(s, 0) * portfolio_returns.get(s, 0) / 100
                          for s in portfolio_weights.keys())
    benchmark_return = sum(benchmark_weights.get(s, 0) * benchmark_returns.get(s, 0) / 100
                          for s in benchmark_weights.keys())
    actual_excess = portfolio_return - benchmark_return

    validation_output.append(f"\n3. EXCESS RETURN VALIDATION:")
    validation_output.append(f"   Portfolio Return: {portfolio_return * 100:.2f}%")
    validation_output.append(f"   Benchmark Return: {benchmark_return * 100:.2f}%")
    validation_output.append(f"   Actual Excess Return: {actual_excess * 100:.2f}%")
    validation_output.append(f"   Attribution Total: {total_attribution:.2f}%")
    validation_output.append(f"   Difference: {abs(actual_excess * 100 - total_attribution):.4f}%")

    attribution_matches = abs(actual_excess * 100 - total_attribution) < 0.5
    if not attribution_matches:
        validation_output.append("   ‚ö†Ô∏è WARNING: Attribution doesn't match excess return")

    # Check 4: Sector-level sanity checks
    validation_output.append(f"\n4. SECTOR-LEVEL CHECKS:")
    for _, row in attribution_df.iterrows():
        sector = row['Sector']
        alloc = row['Allocation Effect']
        selection = row['Selection Effect']
        validation_output.append(f"   {sector}:")
        validation_output.append(f"      Allocation: {alloc:+.2f}% | Selection: {selection:+.2f}%")

    validation_output.append("\n" + "=" * 60)

    # Print to console for debugging
    for line in validation_output:
        print(line)

    return {
        'weight_check_passed': weight_check_passed,
        'attribution_matches': attribution_matches,
        'total_attribution': total_attribution,
        'actual_excess': actual_excess * 100,
        'validation_output': '\n'.join(validation_output)
    }

def create_sector_attribution_table(attribution_df):
    """
    Create detailed sector-by-sector attribution table
    """

    # Format for display
    display_df = attribution_df[[
        'Sector', 'Weight Diff', 'Return Diff',
        'Allocation Effect', 'Selection Effect', 'Total Effect'
    ]].copy()

    # Sort by total effect
    display_df = display_df.sort_values('Total Effect', ascending=False)

    # Format percentages
    for col in ['Weight Diff', 'Return Diff', 'Allocation Effect', 'Selection Effect', 'Total Effect']:
        display_df[col] = display_df[col].apply(lambda x: f"{x:+.2f}%")

    return display_df

@st.cache_data(ttl=600)
def calculate_benchmark_returns(benchmark_ticker, start_date, end_date):
    try:
        data = fetch_historical_data(benchmark_ticker, start_date, end_date)
        if data is None or data.empty:
            return None
        returns = data['Close'].pct_change().dropna()
        return returns
    except:
        return None

# ============================================================================
# ENHANCED HOLDINGS TABLE
# ============================================================================

def create_enhanced_holdings_table(df):
    enhanced_df = df.copy()
    
    for idx, row in enhanced_df.iterrows():
        ticker = row['Ticker']
        market_data = fetch_market_data(ticker)
        
        if market_data:
            enhanced_df.at[idx, 'Asset Name'] = market_data['company_name']
            enhanced_df.at[idx, 'Current Price'] = market_data['price']
            enhanced_df.at[idx, 'Daily Change'] = market_data['daily_change']
            enhanced_df.at[idx, 'Daily Change %'] = market_data['daily_change_pct']
            enhanced_df.at[idx, '5D Return %'] = market_data['five_day_return']
            enhanced_df.at[idx, 'Beta'] = market_data.get('beta', 'N/A')
            enhanced_df.at[idx, 'Volume'] = market_data.get('volume', 0)
            base_sector = market_data.get('sector', 'Unknown')
            enhanced_df.at[idx, 'Sector'] = classify_ticker_sector(ticker, base_sector)
        else:
            enhanced_df.at[idx, 'Asset Name'] = ticker
            enhanced_df.at[idx, 'Sector'] = 'Other'
        
        analyst_data = fetch_analyst_data(ticker)
        if analyst_data['success']:
            enhanced_df.at[idx, 'Analyst Rating'] = analyst_data['rating']
            enhanced_df.at[idx, 'Price Target'] = analyst_data['target_price']
        else:
            enhanced_df.at[idx, 'Analyst Rating'] = 'No Coverage'

        # Calculate Quality Score
        info = fetch_stock_info(ticker)
        if info:
            enhanced_df.at[idx, 'Quality Score'] = calculate_quality_score(ticker, info)
        else:
            enhanced_df.at[idx, 'Quality Score'] = 5.0

    enhanced_df['Sector'] = enhanced_df['Sector'].fillna('Other')
    enhanced_df['Shares'] = enhanced_df['Shares'].round(0).astype(int)

    enhanced_df['Total Cost'] = enhanced_df['Shares'] * enhanced_df['Avg Cost']
    enhanced_df['Total Value'] = enhanced_df['Shares'] * enhanced_df['Current Price']
    enhanced_df['Total Gain/Loss $'] = enhanced_df['Total Value'] - enhanced_df['Total Cost']
    enhanced_df['Total Gain/Loss %'] = ((enhanced_df['Current Price'] - enhanced_df['Avg Cost']) / enhanced_df['Avg Cost']) * 100
    enhanced_df['Daily P&L $'] = enhanced_df['Shares'] * enhanced_df['Daily Change']

    # CRITICAL FIX: Add DUAL weight columns (equity-based AND gross-based)
    gross_exposure = enhanced_df['Total Value'].sum()

    # Get equity from session state
    equity = st.session_state.get('equity_capital', gross_exposure)  # Fallback to gross if no equity set

    # Weight % of Equity - can exceed 100% with leverage!
    enhanced_df['Weight % of Equity'] = (enhanced_df['Total Value'] / equity * 100) if equity > 0 else 0

    # Weight % of Gross Exposure - always sums to 100%
    enhanced_df['Weight % of Gross'] = (enhanced_df['Total Value'] / gross_exposure * 100) if gross_exposure > 0 else 0

    # Keep legacy 'Weight %' for backwards compatibility (use gross-based)
    enhanced_df['Weight %'] = enhanced_df['Weight % of Gross']

    return enhanced_df

def calculate_quality_score(ticker, info):
    """
    Calculate comprehensive quality score (0-10)
    Based on: Profitability, Growth, Financial Health, Valuation
    """
    score = 5.0  # Start at neutral

    try:
        # Profitability metrics
        roe = info.get('returnOnEquity', 0)
        if roe and roe > 0.15:
            score += 1
        elif roe and roe > 0.10:
            score += 0.5

        # Growth metrics
        revenue_growth = info.get('revenueGrowth', 0)
        if revenue_growth and revenue_growth > 0.15:
            score += 1
        elif revenue_growth and revenue_growth > 0.05:
            score += 0.5

        # Financial health
        debt_to_equity = info.get('debtToEquity', 0)
        if debt_to_equity and debt_to_equity < 50:
            score += 1
        elif debt_to_equity and debt_to_equity < 100:
            score += 0.5

        # Profitability
        profit_margin = info.get('profitMargins', 0)
        if profit_margin and profit_margin > 0.20:
            score += 1
        elif profit_margin and profit_margin > 0.10:
            score += 0.5

        # Current ratio (liquidity)
        current_ratio = info.get('currentRatio', 0)
        if current_ratio and current_ratio > 2:
            score += 0.5
        elif current_ratio and current_ratio > 1:
            score += 0.25

        # Analyst recommendations
        recommendation = info.get('recommendationKey', '')
        if recommendation in ['strong_buy', 'buy']:
            score += 0.5

        # Cap at 10
        score = min(10.0, score)

    except Exception as e:
        score = 5.0

    return round(score, 1)

def style_holdings_dataframe(df):
    display_df = df[[
        'Ticker', 'Asset Name', 'Shares', 'Avg Cost', 'Current Price',
        'Daily Change %', '5D Return %', 'Weight %', 'Daily P&L $', 
        'Total Gain/Loss $', 'Total Gain/Loss %', 'Beta', 'Analyst Rating'
    ]].copy()
    
    pct_cols = ['Daily Change %', '5D Return %', 'Weight %', 'Total Gain/Loss %']
    for col in pct_cols:
        display_df[col] = display_df[col].apply(lambda x: format_percentage(x))
    
    currency_cols = ['Avg Cost', 'Current Price', 'Daily P&L $', 'Total Gain/Loss $']
    for col in currency_cols:
        display_df[col] = display_df[col].apply(format_currency)
    
    display_df['Daily Change %'] = display_df['Daily Change %'].apply(add_arrow_indicator)
    display_df['Total Gain/Loss %'] = display_df['Total Gain/Loss %'].apply(add_arrow_indicator)

    return display_df

def style_holdings_dataframe_with_optimization(df):
    """Style holdings dataframe with optimization columns"""
    display_df = df[[
        'Ticker', 'Asset Name', 'Shares', 'Current Price',
        'Weight %', 'Optimal Weight %', 'Weight Diff %',
        'Shares to Trade', 'Action', 'Total Gain/Loss %'
    ]].copy()

    # Format percentages
    pct_cols = ['Weight %', 'Optimal Weight %', 'Weight Diff %', 'Total Gain/Loss %']
    for col in pct_cols:
        if col in display_df.columns:
            display_df[col] = display_df[col].apply(lambda x: format_percentage(x) if pd.notna(x) else '')

    # Format currency
    display_df['Current Price'] = display_df['Current Price'].apply(format_currency)

    # Format shares to trade with sign
    display_df['Shares to Trade'] = display_df['Shares to Trade'].apply(
        lambda x: f"+{int(x):,}" if x > 0 else f"{int(x):,}" if x < 0 else "0" if pd.notna(x) else ''
    )

    # Add indicators to action column
    def style_action(val):
        if val == 'BUY':
            return 'üü¢ BUY'
        elif val == 'SELL':
            return 'üî¥ SELL'
        elif val == 'HOLD':
            return '‚ö™ HOLD'
        return val

    if 'Action' in display_df.columns:
        display_df['Action'] = display_df['Action'].apply(style_action)

    return display_df

# ============================================================================
# RISK METRICS
# ============================================================================

def calculate_sharpe_ratio(returns, risk_free_rate=RISK_FREE_RATE):
    if not is_valid_series(returns) or len(returns) < 2:
        return None
    total_return = (1 + returns).prod() - 1
    n_years = len(returns) / 252
    annualized_return = (1 + total_return) ** (1/n_years) - 1 if n_years > 0 else 0
    annualized_vol = returns.std() * np.sqrt(252)
    sharpe = (annualized_return - risk_free_rate) / annualized_vol if annualized_vol > 0 else 0
    return sharpe

def calculate_sortino_ratio(returns, risk_free_rate=RISK_FREE_RATE):
    if not is_valid_series(returns) or len(returns) < 2:
        return None
    total_return = (1 + returns).prod() - 1
    n_years = len(returns) / 252
    annualized_return = (1 + total_return) ** (1/n_years) - 1 if n_years > 0 else 0
    downside_returns = returns[returns < 0]
    if len(downside_returns) < 2:
        return None
    downside_std = downside_returns.std() * np.sqrt(252)
    sortino = (annualized_return - risk_free_rate) / downside_std if downside_std > 0 else 0
    return sortino

def calculate_information_ratio(portfolio_returns, benchmark_returns):
    if not is_valid_series(portfolio_returns) or not is_valid_series(benchmark_returns):
        return None
    if len(portfolio_returns) < 2 or len(benchmark_returns) < 2:
        return None
    common_dates = portfolio_returns.index.intersection(benchmark_returns.index)
    portfolio_returns = portfolio_returns.loc[common_dates]
    benchmark_returns = benchmark_returns.loc[common_dates]
    excess_returns = portfolio_returns - benchmark_returns
    if len(excess_returns) < 2:
        return None
    total_excess = (1 + excess_returns).prod() - 1
    n_years = len(excess_returns) / 252
    annualized_excess = (1 + total_excess) ** (1/n_years) - 1 if n_years > 0 else 0
    tracking_error = excess_returns.std() * np.sqrt(252)
    info_ratio = annualized_excess / tracking_error if tracking_error > 0 else 0
    return info_ratio

# v9.7 ENHANCEMENT: Added caching for performance optimization
@st.cache_data(ttl=300)
def calculate_var(returns, confidence=0.95, equity=None):
    """
    Calculate Value at Risk with caching for improved performance

    CRITICAL FIX: Returns VaR as percentage. If equity provided, also returns dollar VaR.
    VaR dollar amount is calculated on EQUITY, not gross exposure.

    Args:
        returns: Return series (should be on equity basis from calculate_portfolio_returns)
        confidence: Confidence level (e.g., 0.95 = 95%)
        equity: Optional equity capital to calculate dollar VaR

    Returns:
        VaR percentage (or None if error)
    """
    if not is_valid_series(returns) or len(returns) < 2:
        return None
    try:
        var = np.percentile(returns, (1 - confidence) * 100)
        # Note: returns are already on equity basis (from fixed calculate_portfolio_returns)
        # so var percentile correctly represents risk to equity
        return var * 100
    except Exception as e:
        return None

@st.cache_data(ttl=300)
def calculate_cvar(returns, confidence=0.95, equity=None):
    """
    Calculate Conditional VaR (Expected Shortfall) with caching

    CRITICAL FIX: Returns CVaR as percentage. If equity provided, also returns dollar CVaR.
    CVaR dollar amount is calculated on EQUITY, not gross exposure.

    Args:
        returns: Return series (should be on equity basis from calculate_portfolio_returns)
        confidence: Confidence level (e.g., 0.95 = 95%)
        equity: Optional equity capital to calculate dollar CVaR

    Returns:
        CVaR percentage (or None if error)
    """
    if not is_valid_series(returns) or len(returns) < 2:
        return None
    try:
        var = np.percentile(returns, (1 - confidence) * 100)
        cvar = returns[returns <= var].mean()
        # Note: returns are already on equity basis (from fixed calculate_portfolio_returns)
        # so cvar correctly represents expected tail loss to equity
        return cvar * 100
    except Exception as e:
        return None

def calculate_historical_stress_test(enhanced_df):
    """
    Calculate portfolio performance during historical stress periods vs S&P 500.

    Returns performance data for visualization of portfolio resilience during major market events.

    Historical Stress Periods:
    - 2008 Financial Crisis: Sep 2008 - Mar 2009
    - 2011 Euro Crisis: Jul 2011 - Oct 2011
    - 2015-16 China Slowdown: Aug 2015 - Feb 2016
    - Dec 2018 Selloff: Oct 2018 - Dec 2018
    - COVID-19 Crash: Feb 2020 - Mar 2020

    Returns:
        dict: Contains period data, cumulative returns, and stress metrics
    """

    # Define historical stress periods
    stress_periods = {
        '2008 Financial Crisis': {'start': '2008-09-01', 'end': '2009-03-31', 'color': '#FF4136'},
        '2011 Euro Crisis': {'start': '2011-07-01', 'end': '2011-10-31', 'color': '#FF851B'},
        '2015-16 China Slowdown': {'start': '2015-08-01', 'end': '2016-02-29', 'color': '#FFDC00'},
        'Dec 2018 Selloff': {'start': '2018-10-01', 'end': '2018-12-31', 'color': '#39CCCC'},
        'COVID-19 Crash': {'start': '2020-02-01', 'end': '2020-03-31', 'color': '#B10DC9'}
    }

    results = {}

    # Get portfolio tickers and weights
    tickers = enhanced_df['Ticker'].tolist()
    weights = (enhanced_df['Weight %'] / 100).tolist()

    for period_name, period_info in stress_periods.items():
        try:
            # Fetch S&P 500 data for this period
            spy_data = fetch_historical_data('^GSPC', period_info['start'], period_info['end'])

            if spy_data is None or spy_data.empty:
                continue

            # Fetch portfolio holdings data for this period
            portfolio_returns = []
            valid_weights = []

            for ticker, weight in zip(tickers, weights):
                ticker_data = fetch_historical_data(ticker, period_info['start'], period_info['end'])
                if ticker_data is not None and not ticker_data.empty and len(ticker_data) > 0:
                    # Calculate cumulative return for this ticker
                    ticker_returns = ticker_data['Close'].pct_change().fillna(0)
                    portfolio_returns.append(ticker_returns)
                    valid_weights.append(weight)

            if not portfolio_returns:
                continue

            # Normalize weights
            valid_weights = np.array(valid_weights)
            valid_weights = valid_weights / valid_weights.sum()

            # Calculate weighted portfolio returns
            returns_df = pd.DataFrame(portfolio_returns).T
            portfolio_daily_returns = (returns_df * valid_weights).sum(axis=1)

            # Calculate cumulative returns
            portfolio_cumulative = (1 + portfolio_daily_returns).cumprod()
            spy_cumulative = (1 + spy_data['Close'].pct_change().fillna(0)).cumprod()

            # Align indices
            common_index = portfolio_cumulative.index.intersection(spy_cumulative.index)
            if len(common_index) == 0:
                continue

            portfolio_cumulative = portfolio_cumulative.loc[common_index]
            spy_cumulative = spy_cumulative.loc[common_index]

            # Normalize to start at 100
            portfolio_cumulative = (portfolio_cumulative / portfolio_cumulative.iloc[0]) * 100
            spy_cumulative = (spy_cumulative / spy_cumulative.iloc[0]) * 100

            # Calculate stress metrics
            total_return_portfolio = ((portfolio_cumulative.iloc[-1] / 100) - 1) * 100
            total_return_spy = ((spy_cumulative.iloc[-1] / 100) - 1) * 100

            max_drawdown_portfolio = ((portfolio_cumulative / portfolio_cumulative.cummax()) - 1).min() * 100
            max_drawdown_spy = ((spy_cumulative / spy_cumulative.cummax()) - 1).min() * 100

            volatility_portfolio = portfolio_daily_returns.std() * np.sqrt(252) * 100
            volatility_spy = spy_data['Close'].pct_change().std() * np.sqrt(252) * 100

            results[period_name] = {
                'dates': common_index,
                'portfolio_cumulative': portfolio_cumulative,
                'spy_cumulative': spy_cumulative,
                'metrics': {
                    'portfolio_return': total_return_portfolio,
                    'spy_return': total_return_spy,
                    'portfolio_drawdown': max_drawdown_portfolio,
                    'spy_drawdown': max_drawdown_spy,
                    'portfolio_volatility': volatility_portfolio,
                    'spy_volatility': volatility_spy,
                    'outperformance': total_return_portfolio - total_return_spy
                },
                'color': period_info['color']
            }

        except Exception as e:
            # Skip periods where data is unavailable
            continue

    return results

def calculate_var_cvar_portfolio_optimization(enhanced_df, confidence_level=0.95, lookback_days=252, max_position=0.25, min_position=0.02, target_leverage=1.0):
    """
    Calculate optimal portfolio weights to minimize CVaR (Conditional Value at Risk)

    This function implements portfolio optimization from Quantitative Risk Management
    to find weights that minimize tail risk while maintaining diversification.

    FIXED v11.0: Added leverage constraint support. Leverage = sum of absolute weights.

    Args:
        enhanced_df: Enhanced holdings dataframe with current positions
        confidence_level: Confidence level for VaR/CVaR calculation (default 95%)
        lookback_days: Days of historical data to use (default 252 = 1 year)
        max_position: Maximum position size per security (default 25%)
        min_position: Minimum meaningful position size (default 2%)
        target_leverage: Target portfolio leverage (default 1.0 = no leverage)

    Returns:
        tuple: (rebalancing_df, optimization_metrics)
    """
    from scipy.optimize import minimize

    # Get current portfolio composition
    tickers = enhanced_df['Ticker'].tolist()
    current_values = enhanced_df['Total Value'].values
    total_portfolio_value = current_values.sum()

    # CRITICAL FIX: Calculate weights relative to EQUITY, not gross exposure
    # Get equity from session state
    equity = st.session_state.get('equity_capital', total_portfolio_value)
    current_weights = current_values / equity  # Can sum > 1.0 with leverage!

    # Fetch historical returns for all tickers
    end_date = datetime.now()
    start_date = end_date - timedelta(days=lookback_days)

    # Build returns matrix
    returns_dict = {}
    for ticker in tickers:
        hist_data = fetch_historical_data(ticker, start_date, end_date)
        if hist_data is not None and len(hist_data) > 1:
            returns = hist_data['Close'].pct_change().dropna()
            returns_dict[ticker] = returns

    # Align all returns to common dates
    returns_df = pd.DataFrame(returns_dict)
    returns_df = returns_df.dropna()

    if len(returns_df) < 30:
        st.warning("Insufficient historical data for optimization (need 30+ days)")
        return None, None

    # CRITICAL FIX: Only keep tickers that have valid data
    valid_tickers = returns_df.columns.tolist()
    returns_matrix = returns_df.values
    n_assets = len(valid_tickers)

    # Update enhanced_df to only include valid tickers
    enhanced_df = enhanced_df[enhanced_df['Ticker'].isin(valid_tickers)].copy()
    tickers = valid_tickers
    current_values = enhanced_df['Total Value'].values
    total_portfolio_value = current_values.sum()

    # CRITICAL FIX: Use equity for current weights (already set above)
    current_weights = current_values / equity  # Can sum > 1.0 with leverage!

    # Define CVaR calculation with production-grade regularization
    def calculate_portfolio_cvar(weights, returns, alpha):
        """
        Calculate CVaR (Expected Shortfall) for given weights

        FIXED v10.3: Removed aggressive penalties causing equal-weight portfolios.
        Now uses gentle regularization scaled appropriately.
        """
        portfolio_returns = returns @ weights
        var_threshold = np.percentile(portfolio_returns, (1-alpha) * 100)
        cvar = portfolio_returns[portfolio_returns <= var_threshold].mean()

        # GENTLE regularization - tiny penalty to avoid extreme concentration
        # CVaR is typically -0.05 to -0.20, so penalty should be ~0.0001 to 0.001
        hhi = np.sum(weights ** 2)
        gentle_regularization = 0.0005 * (hhi - 1/n_assets)

        return -cvar + gentle_regularization

    # Optimization objective
    def objective(weights):
        return calculate_portfolio_cvar(weights, returns_matrix, confidence_level)

    # FIXED v11.0: Leverage constraint using absolute sum of weights
    def leverage_constraint(w, target_lev):
        """Leverage = sum of absolute weights"""
        return np.abs(w).sum() - target_lev

    # Production-grade constraints
    constraints = [
        {'type': 'eq', 'fun': leverage_constraint, 'args': (target_leverage,)}
    ]

    # Use user-specified bounds
    bounds = tuple((0.0, max_position) for _ in range(n_assets))

    # Initial guess (scaled by leverage)
    initial_weights = np.ones(n_assets) * (target_leverage / n_assets)

    # Run optimization
    result = minimize(
        objective,
        initial_weights,
        method='SLSQP',
        bounds=bounds,
        constraints=constraints,
        options={'maxiter': 1000, 'ftol': 1e-9}
    )

    if not result.success:
        st.warning(f"Optimization converged with warning: {result.message}")

    optimal_weights = result.x

    # Calculate current and optimal risk metrics
    current_portfolio_returns = returns_matrix @ current_weights
    optimal_portfolio_returns = returns_matrix @ optimal_weights

    current_var = np.percentile(current_portfolio_returns, (1-confidence_level) * 100)
    optimal_var = np.percentile(optimal_portfolio_returns, (1-confidence_level) * 100)

    current_cvar = current_portfolio_returns[current_portfolio_returns <= current_var].mean()
    optimal_cvar = optimal_portfolio_returns[optimal_portfolio_returns <= optimal_var].mean()

    # Calculate Sharpe ratios
    current_sharpe = (current_portfolio_returns.mean() / current_portfolio_returns.std()) * np.sqrt(252)
    optimal_sharpe = (optimal_portfolio_returns.mean() / optimal_portfolio_returns.std()) * np.sqrt(252)

    # Build rebalancing dataframe
    rebalancing_data = []
    for i, ticker in enumerate(tickers):
        current_value = enhanced_df[enhanced_df['Ticker'] == ticker]['Total Value'].values[0]
        current_shares = enhanced_df[enhanced_df['Ticker'] == ticker]['Shares'].values[0]
        current_price = enhanced_df[enhanced_df['Ticker'] == ticker]['Current Price'].values[0]

        optimal_value = optimal_weights[i] * total_portfolio_value
        optimal_shares = optimal_value / current_price
        shares_to_trade = optimal_shares - current_shares
        trade_value = shares_to_trade * current_price

        rebalancing_data.append({
            'Ticker': ticker,
            'Asset Name': enhanced_df[enhanced_df['Ticker'] == ticker]['Asset Name'].values[0],
            'Current Weight %': (current_value / total_portfolio_value) * 100,
            'Optimal Weight %': optimal_weights[i] * 100,
            'Weight Diff %': (optimal_weights[i] * 100) - (current_value / total_portfolio_value * 100),
            'Current Shares': int(current_shares),
            'Target Shares': int(optimal_shares),
            'Shares to Trade': int(shares_to_trade),
            'Current Price': current_price,
            'Trade Value': trade_value,
            'Action': 'BUY' if shares_to_trade > 5 else 'SELL' if shares_to_trade < -5 else 'HOLD',
            'Priority': abs(trade_value)  # Sort by impact
        })

    rebalancing_df = pd.DataFrame(rebalancing_data)
    rebalancing_df = rebalancing_df.sort_values('Priority', ascending=False)

    # Calculate optimization metrics
    optimization_metrics = {
        'current_var': current_var * 100,
        'optimal_var': optimal_var * 100,
        'var_reduction_pct': abs((optimal_var - current_var) / abs(current_var)) * 100,
        'current_cvar': current_cvar * 100,
        'optimal_cvar': optimal_cvar * 100,
        'cvar_reduction_pct': abs((optimal_cvar - current_cvar) / abs(current_cvar)) * 100,
        'current_sharpe': current_sharpe,
        'optimal_sharpe': optimal_sharpe,
        'sharpe_improvement': optimal_sharpe - current_sharpe,
        'total_trades': len(rebalancing_df[rebalancing_df['Action'] != 'HOLD']),
        'rebalancing_cost': abs(rebalancing_df['Trade Value'].sum()),
        'buy_trades': len(rebalancing_df[rebalancing_df['Action'] == 'BUY']),
        'sell_trades': len(rebalancing_df[rebalancing_df['Action'] == 'SELL'])
    }

    return rebalancing_df, optimization_metrics

# ============================================================================
# PRODUCTION-GRADE PORTFOLIO OPTIMIZATION SYSTEM v10.3
# ============================================================================
# PM/Developer Hybrid Approach - Built for Trust & Transparency
#
# Key Components:
# 1. RiskProfile - Translate user intent to optimization parameters
# 2. RobustPortfolioOptimizer - Handle estimation uncertainty
# 3. OptimizationExplainer - Generate transparent insights
# 4. Production workflow - Complete end-to-end optimization
# ============================================================================

class RiskProfile:
    """
    Translate user risk tolerance into optimization parameters

    Instead of asking users to set 47 parameters, provide 3 clear risk profiles:
    - Conservative: Capital preservation, steady returns
    - Moderate: Balance growth and risk
    - Aggressive: Maximize returns, accept volatility
    """

    PROFILES = {
        'conservative': {
            'name': 'Conservative',
            'description': 'Maximum diversification with capital preservation',
            'philosophy': 'Prioritize diversification - accept 5-10% lower performance for 2-3x more holdings',

            # MUCH STRICTER POSITION LIMITS (Diversification-First)
            'max_position_base': 0.06,         # Max 6% in any single asset (was 15%)
            'typical_position_target': 0.04,   # Aim for 4% positions
            'max_sector_concentration': 0.25,  # Tight sector limits

            # FORCE BROAD DIVERSIFICATION
            'min_diversification': 18,         # Force at least 18 holdings (was 10)
            'target_holdings': 25,             # Aim for 25+ holdings
            'min_position_to_count': 0.02,     # Only count positions >2%

            # VERY TIGHT CONCENTRATION LIMITS
            'max_top_3_concentration': 0.15,   # Top 3 can't exceed 15%
            'max_top_5_concentration': 0.25,   # Top 5 can't exceed 25%
            'max_top_10_concentration': 0.50,  # Top 10 can't exceed 50%

            # RISK DISTRIBUTION
            'max_drawdown_tolerance': 0.15,    # 15% max drawdown
            'turnover_sensitivity': 'low',     # Avoid frequent trading
            'risk_budget_per_asset': 0.08,     # No asset >8% of portfolio risk (was 12%)
            'target_effective_n': 20,          # Target 20 "effective" holdings

            # DIVERSIFICATION PRIORITY
            'acceptable_sharpe_ratio': 0.90,   # Accept 90% of max Sharpe for diversification
            'diversification_priority': 'maximum',
        },

        'moderate': {
            'name': 'Moderate',
            'description': 'Strong diversification with balanced growth',
            'philosophy': 'Balance performance and diversification - accept 3-5% lower performance for better diversification',

            # MODERATE POSITION LIMITS (Still Diversified)
            'max_position_base': 0.10,         # Max 10% in any single asset (was 20%)
            'typical_position_target': 0.06,   # Aim for 6% positions
            'max_sector_concentration': 0.35,

            # GOOD DIVERSIFICATION
            'min_diversification': 12,         # Force at least 12 holdings (was 8)
            'target_holdings': 18,             # Aim for 18+ holdings
            'min_position_to_count': 0.025,

            # REASONABLE CONCENTRATION LIMITS
            'max_top_3_concentration': 0.25,   # Top 3 can't exceed 25%
            'max_top_5_concentration': 0.40,   # Top 5 can't exceed 40%
            'max_top_10_concentration': 0.70,  # Top 10 can't exceed 70%

            # RISK DISTRIBUTION
            'max_drawdown_tolerance': 0.25,
            'turnover_sensitivity': 'medium',
            'risk_budget_per_asset': 0.12,     # No asset >12% of portfolio risk
            'target_effective_n': 12,          # Target 12 "effective" holdings

            # DIVERSIFICATION PRIORITY
            'acceptable_sharpe_ratio': 0.95,   # Accept 95% of max Sharpe
            'diversification_priority': 'high',
        },

        'aggressive': {
            'name': 'Aggressive',
            'description': 'Growth-focused but still properly diversified',
            'philosophy': 'Allow concentration where justified, but maintain meaningful diversification',

            # STILL REASONABLE LIMITS
            'max_position_base': 0.15,         # Max 15% in any single asset (was 25%)
            'typical_position_target': 0.08,   # Aim for 8% positions
            'max_sector_concentration': 0.50,

            # MEANINGFUL DIVERSIFICATION
            'min_diversification': 10,         # Force at least 10 holdings (was 6)
            'target_holdings': 15,             # Aim for 15+ holdings
            'min_position_to_count': 0.03,

            # LOOSER BUT STILL BOUNDED
            'max_top_3_concentration': 0.35,   # Top 3 can't exceed 35%
            'max_top_5_concentration': 0.55,   # Top 5 can't exceed 55%
            'max_top_10_concentration': 0.85,  # Top 10 can't exceed 85%

            # RISK DISTRIBUTION
            'max_drawdown_tolerance': 0.35,
            'turnover_sensitivity': 'high',
            'risk_budget_per_asset': 0.15,     # No asset >15% of portfolio risk
            'target_effective_n': 10,          # Target 10 "effective" holdings

            # DIVERSIFICATION PRIORITY
            'acceptable_sharpe_ratio': 0.98,   # Accept 98% of max Sharpe
            'diversification_priority': 'moderate',
        }
    }

    @classmethod
    def get_config(cls, risk_tolerance, strategy_type):
        """
        Get optimization config based on user risk profile + strategy

        This is the KEY translation layer - from user intent to math parameters

        DIVERSIFICATION-FIRST PHILOSOPHY:
        We no longer adjust limits by strategy. Instead, we maintain strict
        diversification requirements and let the two-stage optimization find
        the most diversified solution on the efficient frontier.
        """
        base_config = cls.PROFILES[risk_tolerance].copy()

        # All strategies now use the same diversification-first constraints
        # The two-stage optimizer will find the most diversified solution
        # that achieves acceptable performance for the chosen strategy

        return base_config


def calculate_risk_adjusted_limits(returns_df, max_position_base, risk_budget_per_asset):
    """
    Calculate risk-adjusted position limits for each asset

    Idea: Higher volatility assets should have lower maximum position sizes
    to prevent them from dominating portfolio risk

    Args:
        returns_df: Historical returns dataframe
        max_position_base: Base maximum position size
        risk_budget_per_asset: Maximum risk contribution per asset

    Returns:
        List of (min, max) tuples for each asset
    """
    # Calculate annualized volatilities
    vols = returns_df.std() * np.sqrt(252)
    avg_vol = vols.mean()

    position_limits = []
    for vol in vols:
        # Adjust max position based on relative volatility
        # High vol ‚Üí lower max position
        vol_adjustment = avg_vol / vol if vol > 0 else 1.0
        adjusted_max = min(max_position_base * vol_adjustment, max_position_base * 1.5)
        adjusted_max = min(adjusted_max, 0.50)  # Hard cap at 50%

        position_limits.append((0, adjusted_max))

    return position_limits


def calculate_max_risk_contrib(weights, returns_df):
    """Calculate maximum risk contribution from any single asset"""
    cov_matrix = returns_df.cov() * 252
    port_vol = np.sqrt(weights @ cov_matrix @ weights)

    if port_vol == 0:
        return 0

    # Marginal contribution to risk
    marginal_contrib = (cov_matrix @ weights) / port_vol

    # Total risk contribution
    risk_contrib = weights * marginal_contrib

    # Return max contribution as fraction of total risk
    return np.max(np.abs(risk_contrib)) / np.sum(np.abs(risk_contrib)) if np.sum(np.abs(risk_contrib)) > 0 else 0


class RobustPortfolioOptimizer:
    """
    Optimization that acknowledges we don't know future returns/correlations

    Approach: Generate multiple scenarios, find portfolio that performs well
    across ALL scenarios (not just average)
    """

    def __init__(self, returns_df, confidence_level=0.95):
        self.returns_df = returns_df
        self.confidence_level = confidence_level

    def estimate_returns_with_uncertainty(self):
        """
        Instead of point estimates, get confidence intervals

        Uses bootstrapping to estimate uncertainty in mean returns
        """
        n_bootstrap = 500  # Reduced for performance
        n_samples = len(self.returns_df)

        bootstrap_means = []
        for _ in range(n_bootstrap):
            # Resample with replacement
            sample = self.returns_df.sample(n=n_samples, replace=True)
            bootstrap_means.append(sample.mean())

        bootstrap_means = pd.DataFrame(bootstrap_means)

        return {
            'mean': self.returns_df.mean(),
            'lower_bound': bootstrap_means.quantile((1 - self.confidence_level) / 2),
            'upper_bound': bootstrap_means.quantile((1 + self.confidence_level) / 2),
            'std_error': bootstrap_means.std()
        }

    def estimate_covariance_with_shrinkage(self):
        """
        Sample covariance is noisy - shrink toward diagonal

        Ledoit-Wolf shrinkage: blend sample cov with simple structure
        """
        sample_cov = self.returns_df.cov() * 252

        # Target: diagonal matrix (assume zero correlations)
        target = np.diag(np.diag(sample_cov))

        # Optimal shrinkage intensity (simplified Ledoit-Wolf formula)
        n_samples = len(self.returns_df)
        shrinkage = min(0.5, (n_samples - 2) / (n_samples * (n_samples + 2)))

        # Shrunk covariance
        shrunk_cov = shrinkage * target + (1 - shrinkage) * sample_cov

        return shrunk_cov, shrinkage

    def generate_scenarios(self):
        """
        Generate multiple plausible future scenarios

        Scenarios:
        1. Base case (historical means)
        2. Pessimistic (lower bound returns)
        3. Optimistic (upper bound returns)
        4. High correlation (crisis scenario)
        5. Low correlation (diversification works)
        """
        returns_with_ci = self.estimate_returns_with_uncertainty()
        base_cov, _ = self.estimate_covariance_with_shrinkage()

        scenarios = {
            'base': {
                'returns': returns_with_ci['mean'],
                'cov_matrix': base_cov,
                'probability': 0.40,
                'description': 'Historical averages'
            },

            'pessimistic': {
                'returns': returns_with_ci['lower_bound'],
                'cov_matrix': base_cov * 1.5,  # Higher volatility in downturns
                'probability': 0.20,
                'description': 'Below-average returns, higher volatility'
            },

            'optimistic': {
                'returns': returns_with_ci['upper_bound'],
                'cov_matrix': base_cov * 0.8,
                'probability': 0.20,
                'description': 'Above-average returns, lower volatility'
            },

            'crisis': {
                'returns': returns_with_ci['lower_bound'] * 1.5,
                'cov_matrix': self._increase_correlations(base_cov, target_corr=0.8),
                'probability': 0.10,
                'description': 'Market stress - high correlations'
            },

            'goldilocks': {
                'returns': returns_with_ci['mean'] * 1.2,
                'cov_matrix': self._decrease_correlations(base_cov, target_corr=0.3),
                'probability': 0.10,
                'description': 'Low correlation, steady growth'
            }
        }

        return scenarios

    def _increase_correlations(self, cov_matrix, target_corr=0.8):
        """Simulate crisis scenario with high correlations"""
        corr_matrix = cov_matrix / np.outer(np.sqrt(np.diag(cov_matrix)),
                                            np.sqrt(np.diag(cov_matrix)))

        # Push correlations toward target
        crisis_corr = 0.7 * corr_matrix + 0.3 * target_corr * np.ones_like(corr_matrix)
        np.fill_diagonal(crisis_corr, 1.0)

        # Convert back to covariance
        stds = np.sqrt(np.diag(cov_matrix))
        crisis_cov = np.outer(stds, stds) * crisis_corr

        return crisis_cov

    def _decrease_correlations(self, cov_matrix, target_corr=0.3):
        """Simulate goldilocks scenario with low correlations"""
        corr_matrix = cov_matrix / np.outer(np.sqrt(np.diag(cov_matrix)),
                                            np.sqrt(np.diag(cov_matrix)))

        # Push correlations toward target
        good_corr = 0.5 * corr_matrix + 0.5 * target_corr * np.ones_like(corr_matrix)
        np.fill_diagonal(good_corr, 1.0)

        stds = np.sqrt(np.diag(cov_matrix))
        good_cov = np.outer(stds, stds) * good_corr

        return good_cov


class OptimizationExplainer:
    """
    Translate optimization results into human-readable insights

    Users need to understand:
    1. WHY these weights were chosen
    2. WHAT tradeoffs were made
    3. HOW sensitive is this to assumptions
    """

    def explain_portfolio_weights(self, weights, returns_df, strategy_type, scenarios=None, risk_profile_config=None, peak_performance=None):
        """
        Generate PM-level natural language explanation of optimization results

        PM-LEVEL TRANSPARENCY:
        - WHY each position was chosen (with quantitative support)
        - WHAT tradeoffs were made (explicit cost-benefit)
        - HOW confident we are (uncertainty ranges)
        - WHICH constraints were binding (and why)
        """
        explanations = {}
        tickers = returns_df.columns
        cov_matrix = returns_df.cov() * 252

        # ============================================================
        # 1. EXECUTIVE SUMMARY
        # ============================================================
        effective_n = 1 / np.sum(weights ** 2)
        max_position = np.max(weights)
        top_3_conc = np.sum(np.sort(weights)[-3:])

        port_return = np.sum(returns_df.mean() * weights) * 252
        port_vol = np.sqrt(weights @ cov_matrix @ weights)
        sharpe = (port_return - 0.02) / port_vol if port_vol > 0 else 0

        try:
            max_dd = calculate_portfolio_max_drawdown(weights, returns_df)
        except:
            max_dd = 0

        explanations['executive_summary'] = {
            'title': f'{strategy_type.upper().replace("_", " ")} OPTIMIZATION',
            'metrics': {
                'Expected Return': f"{port_return:.1%}",
                'Expected Volatility': f"{port_vol:.1%}",
                'Sharpe Ratio': f"{sharpe:.2f}",
                'Max Drawdown': f"{max_dd:.1%}",
                'Effective Holdings': f"{effective_n:.1f}",
                'Largest Position': f"{max_position:.1%}",
                'Top 3 Concentration': f"{top_3_conc:.1%}"
            }
        }

        # ============================================================
        # 2. TOP HOLDINGS WITH DETAILED REASONING
        # ============================================================
        top_holdings = []
        top_5_idx = np.argsort(weights)[-5:][::-1]
        for idx in top_5_idx:
            ticker = tickers[idx]
            weight = weights[idx]

            # Enhanced reasoning with quantitative support
            reasons = self._explain_single_holding_enhanced(
                ticker, weight, returns_df, cov_matrix, strategy_type
            )

            top_holdings.append({
                'ticker': ticker,
                'weight': weight,
                'weight_pct': f"{weight:.1%}",
                'reasons': reasons
            })

        explanations['top_holdings'] = top_holdings

        # ============================================================
        # 3. TRADEOFF ANALYSIS (Critical for PM trust)
        # ============================================================
        tradeoffs = []

        if risk_profile_config and peak_performance:
            # Calculate what was sacrificed for diversification
            current_performance = sharpe
            performance_cost = (1 - current_performance/peak_performance) * 100 if peak_performance > 0 else 0

            tradeoffs.append(
                f"Accepted {performance_cost:.1f}% lower Sharpe ratio to achieve "
                f"{effective_n:.0f} effective holdings (vs concentrated peak)"
            )

            if 'max_drawdown_tolerance' in risk_profile_config:
                dd_limit = risk_profile_config['max_drawdown_tolerance']
                dd_margin = dd_limit - max_dd
                tradeoffs.append(
                    f"Maximum drawdown: {max_dd:.1%} (within {dd_limit:.1%} limit, "
                    f"{dd_margin:.1%} margin of safety)"
                )

        explanations['tradeoffs'] = tradeoffs

        # ============================================================
        # 4. CONSTRAINT ANALYSIS (Which constraints were binding?)
        # ============================================================
        binding_constraints = []

        if risk_profile_config:
            # Check position limits
            if max_position > risk_profile_config.get('max_position_base', 1) * 0.95:
                binding_constraints.append(
                    f"Position limit binding: Largest position at {max_position:.1%} "
                    f"(limit: {risk_profile_config['max_position_base']:.1%})"
                )

            # Check concentration limits
            if top_3_conc > risk_profile_config.get('max_top_3_concentration', 1) * 0.95:
                binding_constraints.append(
                    f"Top-3 concentration binding: {top_3_conc:.1%} "
                    f"(limit: {risk_profile_config['max_top_3_concentration']:.1%})"
                )

            # Check drawdown constraint
            if 'max_drawdown_tolerance' in risk_profile_config:
                dd_limit = risk_profile_config['max_drawdown_tolerance']
                if max_dd > dd_limit * 0.90:
                    binding_constraints.append(
                        f"Drawdown constraint active: {max_dd:.1%} "
                        f"(limit: {dd_limit:.1%})"
                    )

        explanations['binding_constraints'] = binding_constraints if binding_constraints else [
            "No constraints binding - optimizer found unconstrained optimum"
        ]

        # ============================================================
        # 5. RISK BREAKDOWN (Where is risk coming from?)
        # ============================================================
        risk_contribs = self._calculate_risk_contributions(weights, cov_matrix)
        top_risk_idx = np.argsort(risk_contribs)[-5:][::-1]

        explanations['risk_breakdown'] = [
            {
                'ticker': tickers[i],
                'weight': f"{weights[i]:.1%}",
                'risk_contribution': f"{risk_contribs[i]:.1%}",
                'risk_to_weight_ratio': f"{(risk_contribs[i]/weights[i]):.2f}x" if weights[i] > 0 else "N/A"
            }
            for i in top_risk_idx
        ]

        # ============================================================
        # 6. UNCERTAINTY & ASSUMPTIONS
        # ============================================================
        explanations['assumptions'] = [
            f"Historical returns based on {len(returns_df)} trading days",
            "Assumes returns are normally distributed (actual returns may have fat tails)",
            "Past performance does not guarantee future results",
            "Correlations and volatilities may change during market stress"
        ]

        return explanations

    def _explain_single_holding_enhanced(self, ticker, weight, returns_df, cov_matrix, strategy_type):
        """
        PM-LEVEL EXPLANATION: WHY was this specific holding chosen?
        Provide quantitative support for every reason
        """
        returns = returns_df[ticker]
        ann_return = returns.mean() * 252
        ann_vol = returns.std() * np.sqrt(252)
        sharpe = ann_return / ann_vol if ann_vol > 0 else 0

        # Correlation with rest of portfolio
        correlations = returns_df.corr()[ticker].drop(ticker)
        avg_corr = correlations.mean()
        max_corr = correlations.max()

        # Risk contribution
        risk_contribs = self._calculate_risk_contributions(np.ones(len(returns_df.columns))/len(returns_df.columns), cov_matrix)

        reasons = []

        # Quantitative reasons based on strategy
        if strategy_type == 'max_sharpe':
            reasons.append(f"Return: {ann_return:.1%}/year, Vol: {ann_vol:.1%}, Sharpe: {sharpe:.2f}")
            if avg_corr < 0.6:
                reasons.append(f"Good diversifier (avg corr: {avg_corr:.2f}, max: {max_corr:.2f})")
            elif avg_corr >= 0.6:
                reasons.append(f"Higher correlation to portfolio (avg: {avg_corr:.2f}) justified by strong Sharpe")

        elif strategy_type == 'min_volatility':
            reasons.append(f"Low volatility: {ann_vol:.1%}/year")
            reasons.append(f"Avg correlation: {avg_corr:.2f} provides portfolio diversification")

        elif strategy_type == 'max_return':
            reasons.append(f"Strong historical return: {ann_return:.1%}/year")
            if ann_vol > 0.30:
                reasons.append(f"High volatility ({ann_vol:.1%}) tolerated for return potential")

        # Weight-based reasoning
        if weight > 0.10:
            reasons.append(f"Large {weight:.1%} allocation reflects strong contribution to objective")
        elif weight < 0.05:
            reasons.append(f"Modest {weight:.1%} allocation for diversification/risk balance")

        return reasons

    def _explain_single_holding(self, ticker, weight, returns_df, strategy_type):
        """WHY was this specific holding chosen?"""
        returns = returns_df[ticker]
        ann_return = returns.mean() * 252
        ann_vol = returns.std() * np.sqrt(252)
        sharpe = ann_return / ann_vol if ann_vol > 0 else 0

        avg_corr = returns_df.corr()[ticker].drop(ticker).mean()

        reasons = []

        if strategy_type == 'max_sharpe':
            if sharpe > 1.0:
                reasons.append(f"Strong risk-adjusted returns (Sharpe: {sharpe:.2f})")
            if avg_corr < 0.5:
                reasons.append(f"Low correlation with other holdings ({avg_corr:.2f})")

        elif strategy_type == 'min_volatility':
            if ann_vol < 0.20:
                reasons.append(f"Low volatility ({ann_vol:.1%} annual)")
            if avg_corr < 0.6:
                reasons.append(f"Provides diversification (avg corr: {avg_corr:.2f})")

        elif strategy_type == 'max_return':
            if ann_return > 0.15:
                reasons.append(f"High historical return ({ann_return:.1%} annual)")

        if weight > 0.15:
            reasons.append(f"Large allocation reflects strong fundamentals")

        if len(reasons) == 0:
            reasons.append("Contributes to overall portfolio optimization")

        return reasons

    def _calculate_risk_contributions(self, weights, cov_matrix):
        """Calculate risk contribution of each asset"""
        port_vol = np.sqrt(weights @ cov_matrix @ weights)

        if port_vol == 0:
            return np.zeros(len(weights))

        # Marginal contribution to risk
        marginal_contrib = (cov_matrix @ weights) / port_vol

        # Total risk contribution
        risk_contrib = weights * marginal_contrib

        return risk_contrib

    def generate_sensitivity_analysis(self, weights, returns_df, scenarios):
        """How sensitive is this portfolio to different scenarios?"""
        sensitivity = {}

        for scenario_name, scenario in scenarios.items():
            port_return = weights @ scenario['returns'] * 252
            port_vol = np.sqrt(weights @ scenario['cov_matrix'] @ weights)
            sharpe = port_return / port_vol if port_vol > 0 else 0

            sensitivity[scenario_name] = {
                'description': scenario['description'],
                'expected_return': port_return * 100,
                'volatility': port_vol * 100,
                'sharpe_ratio': sharpe,
                'probability': scenario['probability']
            }

        return sensitivity

    def identify_red_flags(self, weights, returns_df, config):
        """Automated sanity checks - warn user if something looks off"""
        red_flags = []
        yellow_flags = []

        # 1. Over-concentration
        max_weight = np.max(weights)
        if max_weight > 0.30:
            red_flags.append(f"‚ö†Ô∏è Single position at {max_weight:.1%} - consider reducing")
        elif max_weight > 0.25:
            yellow_flags.append(f"‚ö° Largest position at {max_weight:.1%} - monitor closely")

        # 2. Insufficient diversification
        effective_n = 1 / np.sum(weights ** 2)
        if effective_n < 5:
            red_flags.append(f"‚ö†Ô∏è Very concentrated ({effective_n:.1f} effective holdings)")
        elif effective_n < 7:
            yellow_flags.append(f"‚ö° Moderate concentration ({effective_n:.1f} effective holdings)")

        # 3. Check for extreme allocations
        tiny_positions = np.sum((weights > 0) & (weights < 0.02))
        if tiny_positions > 3:
            yellow_flags.append(f"‚ö° {tiny_positions} very small positions (<2%) - consider consolidating")

        return {'red_flags': red_flags, 'yellow_flags': yellow_flags}


def validate_portfolio_realism(weights, returns_df, strategy_type):
    """
    Score portfolio on realism scale 0-100

    Checks:
    - Diversification level
    - Position sizes
    - Risk concentration
    """
    score = 100
    issues = []

    # 1. Diversification check
    effective_n = 1 / np.sum(weights ** 2)
    if effective_n < 5:
        score -= 30
        issues.append("Very low diversification")
    elif effective_n < 7:
        score -= 15
        issues.append("Low diversification")

    # 2. Position size check
    max_weight = np.max(weights)
    if max_weight > 0.40:
        score -= 25
        issues.append("Excessive single position")
    elif max_weight > 0.30:
        score -= 10
        issues.append("Large single position")

    # 3. Number of tiny positions
    tiny = np.sum((weights > 0) & (weights < 0.02))
    if tiny > 5:
        score -= 15
        issues.append("Too many tiny positions")

    # 4. Equal weight check (bad sign)
    weights_nonzero = weights[weights > 0.01]
    if len(weights_nonzero) > 0:
        cv = np.std(weights_nonzero) / np.mean(weights_nonzero)
        if cv < 0.15:  # Very similar weights
            score -= 20
            issues.append("Near equal weighting detected")

    score = max(0, score)

    # Classification
    if score >= 80:
        classification = "Excellent - Realistic and well-diversified"
    elif score >= 60:
        classification = "Good - Some minor concerns"
    elif score >= 40:
        classification = "Fair - Notable issues present"
    else:
        classification = "Poor - Significant problems"

    return {
        'overall': score,
        'classification': classification,
        'issues': issues
    }


# ============================================================================
# TWO-STAGE DIVERSIFICATION-FIRST OPTIMIZATION SYSTEM
# ============================================================================
# Key Insight: Hundreds of portfolios on efficient frontier perform similarly.
# Choose the MOST DIVERSIFIED one, not the most concentrated.
# ============================================================================

def calculate_performance_metric(weights, returns_df, strategy_type, risk_free_rate=0.02):
    """Calculate the relevant performance metric for the strategy"""
    cov_matrix = returns_df.cov() * 252

    if strategy_type == 'max_sharpe':
        port_return = np.sum(returns_df.mean() * weights) * 252
        port_vol = np.sqrt(weights @ cov_matrix @ weights)
        return (port_return - risk_free_rate) / port_vol if port_vol > 0 else 0

    elif strategy_type == 'min_volatility':
        return -np.sqrt(weights @ cov_matrix @ weights)  # Negative for constraint

    elif strategy_type == 'cvar_minimization':
        portfolio_returns = returns_df.values @ weights
        var_threshold = np.percentile(portfolio_returns, 5)
        cvar = portfolio_returns[portfolio_returns <= var_threshold].mean()
        return -cvar  # Negative because we minimize CVaR

    elif strategy_type == 'max_return':
        mean_returns = returns_df.mean() * 252
        return np.sum(mean_returns * weights)

    elif strategy_type == 'risk_parity':
        # For risk parity, use negative of risk parity error as "performance"
        port_vol = np.sqrt(weights @ cov_matrix @ weights)
        if port_vol < 1e-10:
            return 0
        marginal_contrib = (cov_matrix @ weights) / port_vol
        risk_contrib = weights * marginal_contrib
        target_risk = port_vol / len(weights)
        risk_parity_error = np.sum((risk_contrib - target_risk) ** 2)
        return -risk_parity_error

    return 0


def calculate_portfolio_max_drawdown(weights, returns_df):
    """
    Calculate maximum drawdown for a portfolio with given weights

    Args:
        weights: Portfolio weights
        returns_df: Historical returns dataframe

    Returns:
        Maximum drawdown as a positive decimal (e.g., 0.20 for 20% drawdown)
    """
    try:
        # Calculate portfolio returns
        portfolio_returns = returns_df.values @ weights

        # Calculate cumulative returns
        cumulative = (1 + portfolio_returns).cumprod()

        # Calculate running maximum
        running_max = np.maximum.accumulate(cumulative)

        # Calculate drawdown at each point
        drawdown = (cumulative - running_max) / running_max

        # Return maximum drawdown as positive value
        max_dd = abs(np.min(drawdown))

        return max_dd
    except:
        return 0.0

def calculate_max_risk_contrib_pct(weights, returns_df):
    """Calculate maximum risk contribution from any single asset as percentage"""
    cov_matrix = returns_df.cov() * 252
    port_vol = np.sqrt(weights @ cov_matrix @ weights)

    if port_vol < 1e-10:
        return 0

    marginal_contrib = (cov_matrix @ weights) / port_vol
    risk_contribs = weights * marginal_contrib / port_vol
    return np.max(np.abs(risk_contribs))


def optimize_two_stage_diversification_first(
    returns_df,
    strategy_type,
    risk_profile_config,
    risk_free_rate=0.02,
    verbose=True,
    target_leverage=1.0
):
    """
    TWO-STAGE DIVERSIFICATION-FIRST OPTIMIZATION

    STAGE 1: Find peak performance (the "optimal" concentrated solution)
    STAGE 2: Maximize diversification while maintaining acceptable performance

    This finds the MOST DIVERSIFIED portfolio on the efficient frontier,
    not the most concentrated one.

    FIXED v11.0: Added leverage support

    Args:
        returns_df: Historical returns
        strategy_type: 'max_sharpe', 'min_volatility', etc.
        risk_profile_config: Configuration from RiskProfile
        risk_free_rate: Risk-free rate for Sharpe calculation
        verbose: Print optimization details
        target_leverage: Target portfolio leverage (default 1.0 = no leverage)

    Returns:
        Optimized weights (most diversified solution on efficient frontier)
    """
    from scipy.optimize import minimize

    n_assets = len(returns_df.columns)
    cov_matrix = returns_df.cov() * 252

    # ========================================
    # STAGE 1: FIND PEAK PERFORMANCE
    # ========================================

    if verbose:
        print(f"\n{'='*60}")
        print(f"STAGE 1: Finding peak performance...")
        print(f"{'='*60}")

    # Use relaxed constraints to find true optimum
    peak_weights = optimize_for_peak_performance(
        returns_df, strategy_type, risk_free_rate, max_position=0.30, target_leverage=target_leverage
    )

    peak_performance = calculate_performance_metric(
        peak_weights, returns_df, strategy_type, risk_free_rate
    )

    peak_effective_n = 1 / np.sum(peak_weights ** 2)
    peak_max_position = np.max(peak_weights)

    if verbose:
        print(f"Peak performance: {peak_performance:.4f}")
        print(f"Effective holdings: {peak_effective_n:.1f}")
        print(f"Max position: {peak_max_position:.1%}")

    # ========================================
    # STAGE 2: MAXIMIZE DIVERSIFICATION
    # ========================================

    if verbose:
        print(f"\n{'='*60}")
        print(f"STAGE 2: Maximizing diversification...")
        print(f"{'='*60}")

    # Set acceptable performance threshold
    min_acceptable_performance = peak_performance * risk_profile_config['acceptable_sharpe_ratio']

    if verbose:
        print(f"Min acceptable performance: {min_acceptable_performance:.4f}")
        print(f"(={risk_profile_config['acceptable_sharpe_ratio']:.0%} of peak)")

    def diversification_objective(weights):
        """
        Objective: MINIMIZE concentration (MAXIMIZE diversification)
        Using Herfindahl-Hirschman Index (HHI)
        Lower HHI = more diversified
        """
        hhi = np.sum(weights ** 2)

        # Penalize too few meaningful positions
        meaningful_positions = np.sum(weights >= risk_profile_config['min_position_to_count'])
        if meaningful_positions < risk_profile_config['target_holdings']:
            sparsity_penalty = (risk_profile_config['target_holdings'] - meaningful_positions) * 0.01
        else:
            sparsity_penalty = 0

        return hhi + sparsity_penalty

    # FIXED v11.0: Leverage constraint
    def leverage_constraint_stage2(w, target_lev):
        """Leverage = sum of absolute weights"""
        return np.abs(w).sum() - target_lev

    # Build constraints
    constraints = [
        {'type': 'eq', 'fun': leverage_constraint_stage2, 'args': (target_leverage,)},

        # CRITICAL: Performance must stay above threshold
        {'type': 'ineq',
         'fun': lambda w: calculate_performance_metric(w, returns_df, strategy_type, risk_free_rate) - min_acceptable_performance},

        # Minimum meaningful holdings
        {'type': 'ineq',
         'fun': lambda w: np.sum(w >= risk_profile_config['min_position_to_count']) - risk_profile_config['min_diversification']},

        # Top 3 concentration limit (adjusted for leverage)
        {'type': 'ineq',
         'fun': lambda w: risk_profile_config['max_top_3_concentration'] * target_leverage - np.sum(np.sort(w)[-3:])},

        # Top 5 concentration limit (adjusted for leverage)
        {'type': 'ineq',
         'fun': lambda w: risk_profile_config['max_top_5_concentration'] * target_leverage - np.sum(np.sort(w)[-5:])},

        # Risk contribution limit
        {'type': 'ineq',
         'fun': lambda w: risk_profile_config['risk_budget_per_asset'] - calculate_max_risk_contrib_pct(w, returns_df)},
    ]

    # DRAWDOWN AWARENESS: Add max drawdown constraint for conservative (and moderate) profiles
    if 'max_drawdown_tolerance' in risk_profile_config:
        max_dd_allowed = risk_profile_config['max_drawdown_tolerance']
        if verbose:
            print(f"Adding drawdown constraint: Max {max_dd_allowed:.1%} drawdown")

        constraints.append({
            'type': 'ineq',
            'fun': lambda w: max_dd_allowed - calculate_portfolio_max_drawdown(w, returns_df)
        })

    # Volatility-adjusted position limits
    volatilities = returns_df.std() * np.sqrt(252)
    median_vol = volatilities.median()
    vol_scalars = np.clip(median_vol / volatilities, 0.5, 1.5)

    position_limits = risk_profile_config['max_position_base'] * vol_scalars
    position_limits = np.clip(position_limits, 0.01, risk_profile_config['max_position_base'])

    bounds = [(0, limit) for limit in position_limits]

    # Initial guess: Equal weight scaled by leverage (most diversified starting point)
    initial_guess = np.ones(n_assets) * (target_leverage / n_assets)

    # Optimize for DIVERSIFICATION subject to performance constraint
    result = minimize(
        diversification_objective,
        initial_guess,
        method='SLSQP',
        bounds=bounds,
        constraints=constraints,
        options={'maxiter': 2000, 'ftol': 1e-10}
    )

    if not result.success:
        if verbose:
            print(f"Warning: {result.message}")
            print("Falling back to peak performance portfolio...")
        return peak_weights

    diversified_weights = result.x

    # Clean up tiny positions
    min_position = risk_profile_config.get('min_position_to_count', 0.02) / 2
    diversified_weights[diversified_weights < min_position] = 0

    # Renormalize to target leverage
    current_leverage = np.abs(diversified_weights).sum()
    if current_leverage > 0:
        diversified_weights = diversified_weights * (target_leverage / current_leverage)
    else:
        diversified_weights = peak_weights

    # ========================================
    # STAGE 3: VALIDATE & COMPARE
    # ========================================

    final_performance = calculate_performance_metric(
        diversified_weights, returns_df, strategy_type, risk_free_rate
    )
    performance_ratio = final_performance / peak_performance

    final_effective_n = 1 / np.sum(diversified_weights ** 2)
    final_max_position = np.max(diversified_weights)
    final_top_3 = np.sum(np.sort(diversified_weights)[-3:])

    # Calculate drawdowns for both portfolios
    peak_drawdown = calculate_portfolio_max_drawdown(peak_weights, returns_df)
    final_drawdown = calculate_portfolio_max_drawdown(diversified_weights, returns_df)

    if verbose:
        print(f"\n{'='*60}")
        print(f"DIVERSIFICATION OPTIMIZATION RESULTS")
        print(f"{'='*60}")
        print(f"\nPeak Performance Portfolio:")
        print(f"  Performance: {peak_performance:.4f}")
        print(f"  Effective Holdings: {peak_effective_n:.1f}")
        print(f"  Largest Position: {peak_max_position:.1%}")
        print(f"  Top 3 Total: {np.sum(np.sort(peak_weights)[-3:]):.1%}")
        print(f"  Max Drawdown: {peak_drawdown:.1%}")

        print(f"\nDiversified Portfolio:")
        print(f"  Performance: {final_performance:.4f} ({performance_ratio:.1%} of peak)")
        print(f"  Effective Holdings: {final_effective_n:.1f} ({final_effective_n/peak_effective_n:.1f}x more)")
        print(f"  Largest Position: {final_max_position:.1%}")
        print(f"  Top 3 Total: {final_top_3:.1%}")
        print(f"  Max Drawdown: {final_drawdown:.1%}")

        # Show drawdown constraint status if applicable
        if 'max_drawdown_tolerance' in risk_profile_config:
            max_dd_allowed = risk_profile_config['max_drawdown_tolerance']
            dd_margin = max_dd_allowed - final_drawdown
            print(f"  Drawdown Margin: {dd_margin:.1%} (limit: {max_dd_allowed:.1%})")

        print(f"\nTRADEOFF:")
        print(f"  Diversification Increase: {final_effective_n/peak_effective_n:.1f}x")
        print(f"  Performance Cost: {(1-performance_ratio)*100:.1f}%")
        print(f"  Drawdown Improvement: {(peak_drawdown-final_drawdown):.1%}")
        print(f"{'='*60}\n")

    return diversified_weights


def optimize_for_peak_performance(returns_df, strategy_type, risk_free_rate, max_position=0.30, target_leverage=1.0):
    """
    Find peak performance with minimal constraints

    This is STAGE 1 - find the best possible performance

    FIXED v11.0: Added leverage support
    """
    from scipy.optimize import minimize

    n_assets = len(returns_df.columns)

    # Use the original optimization functions with relaxed constraints
    if strategy_type == 'max_sharpe':
        weights = optimize_max_sharpe(returns_df, risk_free_rate, max_position, 0.01, target_leverage)
    elif strategy_type == 'min_volatility':
        weights = optimize_min_volatility(returns_df, max_position, 0.01, target_leverage)
    elif strategy_type == 'max_return':
        weights = optimize_max_return(returns_df, max_position, 0.01, target_leverage)
    elif strategy_type == 'risk_parity':
        weights = optimize_risk_parity(returns_df, max_position, 0.01, target_leverage)
    else:
        # Default: equal weight scaled by leverage
        weights = pd.Series(np.ones(n_assets) * (target_leverage / n_assets), index=returns_df.columns)

    return weights.values if isinstance(weights, pd.Series) else weights


# ============================================================================
# ORIGINAL OPTIMIZATION FUNCTIONS (Used for Stage 1 Peak Finding)
# ============================================================================

def optimize_max_sharpe(returns_df, risk_free_rate, max_position=0.25, min_position=0.02, target_leverage=1.0):
    """
    Optimize for maximum Sharpe ratio with production-grade constraints

    FIXED v10.3: Removed aggressive penalties that were causing equal-weight portfolios.
    Now uses proper constraints and gentle regularization.

    FIXED v11.0: Added leverage constraint support. Leverage = sum of absolute weights.

    NOTE: This function is now primarily used for STAGE 1 (peak finding).
    For diversification-first optimization, use optimize_two_stage_diversification_first()

    Args:
        target_leverage: Target portfolio leverage (default 1.0 = no leverage)
                        1.0x = sum(abs(weights)) = 1.0 (long only, fully invested)
                        2.0x = sum(abs(weights)) = 2.0 (2x leverage)
    """
    from scipy.optimize import minimize

    n_assets = len(returns_df.columns)

    def neg_sharpe(weights):
        port_return = np.sum(returns_df.mean() * weights) * 252
        port_vol = np.sqrt(np.dot(weights.T, np.dot(returns_df.cov() * 252, weights)))
        sharpe = (port_return - risk_free_rate) / port_vol if port_vol > 0 else 0

        # GENTLE regularization - tiny penalty to avoid extreme concentration
        # Scaled to be ~1% of typical Sharpe ratio magnitude
        hhi = np.sum(weights ** 2)
        gentle_regularization = 0.01 * (hhi - 1/n_assets)

        return -sharpe + gentle_regularization

    # FIXED v11.0: Leverage constraint using absolute sum of weights
    def leverage_constraint(w, target_lev):
        """Leverage = sum of absolute weights"""
        return np.abs(w).sum() - target_lev

    constraints = [
        {'type': 'eq', 'fun': leverage_constraint, 'args': (target_leverage,)}
    ]
    bounds = tuple((0, max_position) for _ in range(n_assets))
    initial_guess = np.array([target_leverage/n_assets] * n_assets)  # Scale initial guess by leverage

    result = minimize(neg_sharpe, initial_guess, method='SLSQP', bounds=bounds, constraints=constraints,
                     options={'maxiter': 1000, 'ftol': 1e-9})

    # Post-processing: Remove tiny positions
    optimized_weights = result.x.copy()
    optimized_weights[optimized_weights < min_position] = 0

    # Renormalize to target leverage
    current_leverage = np.abs(optimized_weights).sum()
    if current_leverage > 0:
        optimized_weights = optimized_weights * (target_leverage / current_leverage)
    else:
        optimized_weights = np.array([target_leverage/n_assets] * n_assets)

    return pd.Series(optimized_weights, index=returns_df.columns)

def optimize_min_volatility(returns_df, max_position=0.25, min_position=0.02, target_leverage=1.0):
    """
    Optimize for minimum volatility with production-grade constraints

    FIXED v10.3: Removed aggressive penalties that were causing equal-weight portfolios.
    Now uses proper constraints and gentle regularization.

    FIXED v11.0: Added leverage constraint support. Leverage = sum of absolute weights.

    Args:
        target_leverage: Target portfolio leverage (default 1.0 = no leverage)
    """
    from scipy.optimize import minimize

    n_assets = len(returns_df.columns)

    def portfolio_vol(weights):
        vol = np.sqrt(np.dot(weights.T, np.dot(returns_df.cov() * 252, weights)))

        # GENTLE regularization - tiny penalty to avoid extreme concentration
        # Scaled to be ~0.5% of typical volatility magnitude
        hhi = np.sum(weights ** 2)
        gentle_regularization = 0.001 * (hhi - 1/n_assets)

        return vol + gentle_regularization

    # FIXED v11.0: Leverage constraint using absolute sum of weights
    def leverage_constraint(w, target_lev):
        """Leverage = sum of absolute weights"""
        return np.abs(w).sum() - target_lev

    constraints = [
        {'type': 'eq', 'fun': leverage_constraint, 'args': (target_leverage,)}
    ]
    bounds = tuple((0, max_position) for _ in range(n_assets))
    initial_guess = np.array([target_leverage/n_assets] * n_assets)

    result = minimize(portfolio_vol, initial_guess, method='SLSQP', bounds=bounds, constraints=constraints,
                     options={'maxiter': 1000, 'ftol': 1e-9})

    # Post-processing: Remove tiny positions
    optimized_weights = result.x.copy()
    optimized_weights[optimized_weights < min_position] = 0

    # Renormalize to target leverage
    current_leverage = np.abs(optimized_weights).sum()
    if current_leverage > 0:
        optimized_weights = optimized_weights * (target_leverage / current_leverage)
    else:
        optimized_weights = np.array([target_leverage/n_assets] * n_assets)

    return pd.Series(optimized_weights, index=returns_df.columns)

def optimize_max_return(returns_df, max_position=0.25, min_position=0.02, target_leverage=1.0):
    """
    Optimize for maximum return with production-grade constraints

    FIXED v10.3: Removed aggressive penalties that were causing equal-weight portfolios.
    Now uses proper constraints and gentle regularization.

    FIXED v11.0: Added leverage constraint support. Leverage = sum of absolute weights.

    Args:
        target_leverage: Target portfolio leverage (default 1.0 = no leverage)
    """
    from scipy.optimize import minimize

    n_assets = len(returns_df.columns)
    mean_returns = returns_df.mean() * 252

    def neg_return(weights):
        portfolio_return = np.sum(mean_returns * weights)

        # GENTLE regularization - tiny penalty to avoid extreme concentration
        # Scaled to be ~1% of typical return magnitude
        hhi = np.sum(weights ** 2)
        gentle_regularization = 0.005 * (hhi - 1/n_assets)

        return -portfolio_return + gentle_regularization

    # FIXED v11.0: Leverage constraint using absolute sum of weights
    def leverage_constraint(w, target_lev):
        """Leverage = sum of absolute weights"""
        return np.abs(w).sum() - target_lev

    constraints = [
        {'type': 'eq', 'fun': leverage_constraint, 'args': (target_leverage,)}
    ]
    bounds = tuple((0, max_position) for _ in range(n_assets))
    initial_guess = np.array([target_leverage/n_assets] * n_assets)

    result = minimize(neg_return, initial_guess, method='SLSQP', bounds=bounds, constraints=constraints,
                     options={'maxiter': 1000, 'ftol': 1e-9})

    # Post-processing: Remove tiny positions
    optimized_weights = result.x.copy()
    optimized_weights[optimized_weights < min_position] = 0

    # Renormalize to target leverage
    current_leverage = np.abs(optimized_weights).sum()
    if current_leverage > 0:
        optimized_weights = optimized_weights * (target_leverage / current_leverage)
    else:
        optimized_weights = np.array([target_leverage/n_assets] * n_assets)

    return pd.Series(optimized_weights, index=returns_df.columns)

def optimize_risk_parity(returns_df, max_position=0.25, min_position=0.02, target_leverage=1.0):
    """
    Risk parity optimization with production-grade constraints

    FIXED v10.3: Removed aggressive penalties that were causing equal-weight portfolios.
    Now uses pure risk parity objective with proper constraints.

    FIXED v11.0: Added leverage constraint support. Leverage = sum of absolute weights.

    Args:
        target_leverage: Target portfolio leverage (default 1.0 = no leverage)
    """
    from scipy.optimize import minimize

    n_assets = len(returns_df.columns)
    cov_matrix = returns_df.cov() * 252

    def risk_parity_objective(weights):
        port_vol = np.sqrt(np.dot(weights.T, np.dot(cov_matrix, weights)))
        if port_vol == 0:
            return 1e10
        marginal_contrib = np.dot(cov_matrix, weights) / port_vol
        risk_contrib = weights * marginal_contrib
        target_risk = port_vol / n_assets
        risk_parity_error = np.sum((risk_contrib - target_risk) ** 2)

        return risk_parity_error

    # FIXED v11.0: Leverage constraint using absolute sum of weights
    def leverage_constraint(w, target_lev):
        """Leverage = sum of absolute weights"""
        return np.abs(w).sum() - target_lev

    constraints = [
        {'type': 'eq', 'fun': leverage_constraint, 'args': (target_leverage,)}
    ]
    bounds = tuple((0, max_position) for _ in range(n_assets))
    initial_guess = np.array([target_leverage/n_assets] * n_assets)

    result = minimize(risk_parity_objective, initial_guess, method='SLSQP', bounds=bounds, constraints=constraints,
                     options={'maxiter': 1000, 'ftol': 1e-9})

    # Post-processing: Remove tiny positions
    optimized_weights = result.x.copy()
    optimized_weights[optimized_weights < min_position] = 0

    # Renormalize to target leverage
    current_leverage = np.abs(optimized_weights).sum()
    if current_leverage > 0:
        optimized_weights = optimized_weights * (target_leverage / current_leverage)
    else:
        optimized_weights = np.array([target_leverage/n_assets] * n_assets)

    return pd.Series(optimized_weights, index=returns_df.columns)

@st.cache_data(ttl=300)
def calculate_max_drawdown(returns):
    """Calculate Maximum Drawdown with caching for improved performance"""
    if not is_valid_series(returns) or len(returns) < 2:
        return None
    try:
        cumulative = (1 + returns).cumprod()
        running_max = cumulative.expanding().max()
        drawdown = (cumulative - running_max) / running_max
        return drawdown.min() * 100
    except Exception as e:
        return None

def calculate_calmar_ratio(returns, risk_free_rate=RISK_FREE_RATE):
    if not is_valid_series(returns) or len(returns) < 2:
        return None
    total_return = (1 + returns).prod() - 1
    n_years = len(returns) / 252
    annualized_return = (1 + total_return) ** (1/n_years) - 1 if n_years > 0 else 0
    max_dd = abs(calculate_max_drawdown(returns))
    if max_dd == 0:
        return 0
    return (annualized_return - risk_free_rate) / (max_dd / 100)

def calculate_portfolio_correlations(df, period='90d'):
    """
    Calculate correlation matrix for portfolio holdings
    period: '30d', '90d', '1y'
    """
    # Parse period
    period_map = {
        '30d': 30,
        '90d': 90,
        '1y': 365
    }
    days = period_map.get(period, 90)

    # Fetch data for all tickers
    end_date = datetime.now()
    start_date = end_date - timedelta(days=days + 30)  # Extra buffer for data

    tickers = df['Ticker'].unique().tolist()

    # Collect returns for all tickers
    returns_dict = {}

    for ticker in tickers:
        try:
            hist_data = fetch_historical_data(ticker, start_date, end_date)
            if hist_data is not None and len(hist_data) > 20:
                ticker_returns = hist_data['Close'].pct_change().dropna()
                if len(ticker_returns) > 0:
                    returns_dict[ticker] = ticker_returns
        except:
            continue

    # Create DataFrame from returns
    if len(returns_dict) < 2:
        return None

    returns_df = pd.DataFrame(returns_dict)

    # Calculate correlation matrix
    correlation_matrix = returns_df.corr()

    return correlation_matrix

# ============================================================================
# CONTINUING IN PART 2...
# ============================================================================
# Part 2 will contain all visualizations and page implementations
# Save this file and paste Part 2 below it!


# ============================================================================
# WORLD-CLASS VISUALIZATIONS - ENHANCED WITH SEAMLESS THEMING
# ============================================================================

def create_top_contributors_chart(df, top_n=5):
    """FIXED: Top contributors in PERCENTAGE terms with improved spacing"""
    top_contributors = df.nlargest(top_n, 'Total Gain/Loss %')[['Ticker', 'Asset Name', 'Total Gain/Loss $', 'Total Gain/Loss %']]

    fig = go.Figure()

    fig.add_trace(go.Bar(
        x=top_contributors['Total Gain/Loss %'],
        y=top_contributors['Ticker'],
        orientation='h',
        marker=dict(
            color=COLORS['success'],
            line=dict(color=COLORS['border'], width=2)
        ),
        text=[f"{x:.1f}%" for x in top_contributors['Total Gain/Loss %']],
        textposition='outside',  # Changed from 'auto' for better visibility
        textfont=dict(size=12),
        hovertemplate='<b>%{y}</b><br>Return: %{x:.2f}%<extra></extra>',
        width=0.6  # Slightly thinner bars for better spacing
    ))

    fig.update_layout(
        title="üéØ Top 5 Contributors (%)",
        xaxis_title="Total Return (%)",
        yaxis_title="",
        height=CHART_HEIGHT_STANDARD,  # P1-4: Standardized height
        showlegend=False,
        margin=dict(l=100, r=80, t=80, b=50)  # Increased margins to prevent cutoff
    )

    # Ensure labels are fully visible
    fig.update_xaxes(tickfont=dict(size=12))
    fig.update_yaxes(tickfont=dict(size=12))

    apply_chart_theme(fig)
    return fig

def create_top_detractors_chart(df, top_n=5):
    """FIXED: Top detractors in PERCENTAGE terms with improved spacing"""
    top_detractors = df.nsmallest(top_n, 'Total Gain/Loss %')[['Ticker', 'Asset Name', 'Total Gain/Loss $', 'Total Gain/Loss %']]

    fig = go.Figure()

    fig.add_trace(go.Bar(
        x=top_detractors['Total Gain/Loss %'],
        y=top_detractors['Ticker'],
        orientation='h',
        marker=dict(
            color=COLORS['danger'],
            line=dict(color=COLORS['border'], width=2)
        ),
        text=[f"{x:.1f}%" for x in top_detractors['Total Gain/Loss %']],
        textposition='outside',  # Changed from 'auto' for better visibility
        textfont=dict(size=12),
        hovertemplate='<b>%{y}</b><br>Loss: %{x:.2f}%<extra></extra>',
        width=0.6  # Slightly thinner bars for better spacing
    ))

    fig.update_layout(
        title="‚ö†Ô∏è Top 5 Detractors (%)",
        xaxis_title="Total Return (%)",
        yaxis_title="",
        height=CHART_HEIGHT_STANDARD,  # P1-4: Standardized height
        showlegend=False,
        margin=dict(l=100, r=80, t=80, b=50)  # Increased margins to prevent cutoff
    )

    # Ensure labels are fully visible
    fig.update_xaxes(tickfont=dict(size=12))
    fig.update_yaxes(tickfont=dict(size=12))

    apply_chart_theme(fig)
    return fig

def create_sector_allocation_donut(df):
    """v9.7 ENHANCED: Sector allocation with better spacing and ETF classification"""
    # v9.7 FIX: Rename "Other" to "ETFs"
    df_copy = df.copy()
    df_copy['Sector'] = df_copy['Sector'].replace('Other', 'ETFs')

    sector_allocation = df_copy.groupby('Sector')['Total Value'].sum().reset_index()
    sector_allocation = sector_allocation.sort_values('Total Value', ascending=False)

    # Enhanced color palette for better distinction
    colors = ['#00d4ff', '#00ff88', '#ff6b00', '#b794f6', '#ff00ff',
              '#00ffcc', '#ffaa00', '#0080ff', '#ff0044', '#cyan']

    fig = go.Figure(data=[go.Pie(
        labels=sector_allocation['Sector'],
        values=sector_allocation['Total Value'],
        hole=0.55,  # v9.7: Larger hole for better spacing
        marker=dict(
            colors=colors,
            line=dict(color=COLORS['card_background'], width=3)
        ),
        textposition='inside',
        textinfo='percent',
        textfont=dict(size=14, color='white', family='Inter'),
        insidetextorientation='radial',
        hovertemplate='<b>%{label}</b><br>Value: $%{value:,.0f}<br>Share: %{percent}<extra></extra>',
        pull=[0.05 if i == 0 else 0 for i in range(len(sector_allocation))]  # Pull out largest sector
    )])

    fig.update_layout(
        title=dict(
            text="üìä Sector Allocation",
            font=dict(size=18, color=COLORS['neon_blue']),
            x=0.5,
            xanchor='center'
        ),
        height=CHART_HEIGHT_STANDARD,  # P1-4: Standardized height
        showlegend=True,
        legend=dict(
            orientation="v",
            yanchor="top",
            y=1,
            xanchor="left",
            x=1.05,
            font=dict(size=12, color=COLORS['text_primary']),
            bgcolor='rgba(10, 25, 41, 0.6)',
            bordercolor=COLORS['border'],
            borderwidth=1
        ),
        margin=dict(l=40, r=180, t=80, b=40),  # v9.7: More right margin for legend
        annotations=[dict(
            text='Portfolio<br>Sectors',
            x=0.5, y=0.5,
            font_size=16,
            font_color=COLORS['neon_blue'],
            showarrow=False
        )]
    )

    apply_chart_theme(fig)
    return fig

def create_professional_sector_allocation_pie(df):
    """
    PROFESSIONAL sector allocation pie chart - Institutional grade
    - Clean, modern design
    - Proper label positioning
    - Subtle gradients
    - No clutter
    """
    sector_allocation = df.groupby('Sector')['Total Value'].sum()
    total_value = sector_allocation.sum()
    sector_pct = (sector_allocation / total_value * 100).round(1)

    # Sort by value
    sector_pct = sector_pct.sort_values(ascending=False)

    # Professional color palette (consistent with ATLAS theme)
    colors = [
        '#00d4ff',  # Neon blue
        '#0080ff',  # Electric blue
        '#00ffcc',  # Teal
        '#00ff88',  # Success green
        '#ffaa00',  # Warning orange
        '#ff6b00',  # Orange
        '#b794f6',  # Purple
        '#ff00ff',  # Pink
        '#00d4ff',  # Loop back
        '#0080ff',
        '#00ffcc'
    ]

    fig = go.Figure(data=[go.Pie(
        labels=sector_pct.index,
        values=sector_pct.values,
        hole=0.5,  # Donut style - more modern
        marker=dict(
            colors=colors[:len(sector_pct)],
            line=dict(color='#000000', width=2)  # Clean borders
        ),
        textposition='auto',
        textinfo='label+percent',
        textfont=dict(
            size=13,
            color='#ffffff',
            family='Inter, sans-serif'
        ),
        hovertemplate=(
            '<b>%{label}</b><br>' +
            'Allocation: %{percent}<br>' +
            'Value: $%{value:,.0f}<br>' +
            '<extra></extra>'
        ),
        sort=False  # Keep our sorted order
    )])

    fig.update_layout(
        title=dict(
            text='Sector Allocation',
            font=dict(size=20, color='#ffffff', family='Inter'),
            x=0.5,
            xanchor='center'
        ),
        showlegend=True,
        legend=dict(
            orientation="v",
            yanchor="middle",
            y=0.5,
            xanchor="right",
            x=1.15,
            bgcolor='rgba(0,0,0,0)',
            font=dict(size=12, color='#ffffff')
        ),
        paper_bgcolor='rgba(0, 0, 0, 0)',
        plot_bgcolor='rgba(10, 25, 41, 0.3)',
        height=500,
        margin=dict(l=20, r=150, t=80, b=20)
    )

    return fig

def create_professional_sector_allocation_bar(df):
    """
    PROFESSIONAL sector allocation bar chart
    - Horizontal bars sorted by value
    - Clean labels
    - Professional color coding
    """
    sector_allocation = df.groupby('Sector')['Total Value'].sum()
    total_value = sector_allocation.sum()
    sector_pct = (sector_allocation / total_value * 100).round(1)

    # Sort by value
    sector_data = pd.DataFrame({
        'Sector': sector_pct.index,
        'Percentage': sector_pct.values,
        'Value': sector_allocation.values
    }).sort_values('Value', ascending=True)  # Ascending for horizontal bars

    # Color by size (gradient from small to large)
    colors_gradient = ['#ff3366' if p < 5 else '#ffaa00' if p < 10 else '#00ff88'
                       for p in sector_data['Percentage']]

    fig = go.Figure(go.Bar(
        x=sector_data['Value'],
        y=sector_data['Sector'],
        orientation='h',
        marker=dict(
            color=colors_gradient,
            line=dict(color='#000000', width=1)
        ),
        text=[f"${v:,.0f} ({p:.1f}%)" for v, p in zip(sector_data['Value'], sector_data['Percentage'])],
        textposition='outside',
        textfont=dict(size=11, color='#ffffff'),
        hovertemplate=(
            '<b>%{y}</b><br>' +
            'Value: $%{x:,.0f}<br>' +
            'Percentage: %{customdata:.1f}%<br>' +
            '<extra></extra>'
        ),
        customdata=sector_data['Percentage']
    ))

    fig.update_layout(
        title=dict(
            text='Sector Allocation - Ranked by Value',
            font=dict(size=20, color='#ffffff', family='Inter'),
            x=0.5,
            xanchor='center'
        ),
        xaxis=dict(
            title='Total Value ($)',
            gridcolor='#1a3a52',
            showgrid=True,
            zeroline=False,
            tickformat='$,.0f',
            tickfont=dict(size=11, color='#b0c4de')
        ),
        yaxis=dict(
            title='',
            tickfont=dict(size=12, color='#ffffff')
        ),
        paper_bgcolor='rgba(0, 0, 0, 0)',
        plot_bgcolor='rgba(10, 25, 41, 0.3)',
        height=500,
        margin=dict(l=150, r=100, t=80, b=60),
        showlegend=False
    )

    return fig

def create_rolling_metrics_chart(returns, window=60):
    """Rolling metrics visualization - ENHANCED THEMING"""
    if not is_valid_series(returns) or len(returns) < window:
        return None
    
    rolling_vol = returns.rolling(window).std() * np.sqrt(252) * 100
    rolling_sharpe = (returns.rolling(window).mean() * 252 - RISK_FREE_RATE) / (returns.rolling(window).std() * np.sqrt(252))
    
    fig = make_subplots(
        rows=2, cols=1,
        subplot_titles=('Rolling Volatility (60-Day)', 'Rolling Sharpe Ratio (60-Day)'),
        vertical_spacing=0.15
    )
    
    fig.add_trace(
        go.Scatter(
            x=rolling_vol.index,
            y=rolling_vol.values,
            fill='tozeroy',
            fillcolor='rgba(255, 0, 68, 0.2)',
            line=dict(color=COLORS['danger'], width=2),
            name='Volatility'
        ),
        row=1, col=1
    )
    
    fig.add_trace(
        go.Scatter(
            x=rolling_sharpe.index,
            y=rolling_sharpe.values,
            fill='tozeroy',
            fillcolor='rgba(0, 212, 255, 0.2)',
            line=dict(color=COLORS['neon_blue'], width=2),
            name='Sharpe Ratio'
        ),
        row=2, col=1
    )
    
    fig.add_hline(y=0, line_dash="dash", line_color=COLORS['text_muted'], row=2, col=1)
    
    fig.update_layout(
        height=600,
        showlegend=False,
        title_text="üìä Rolling Risk Metrics"
    )
    
    apply_chart_theme(fig)
    return fig

def create_underwater_plot(returns):
    """Underwater drawdown plot - ENHANCED THEMING"""
    if not is_valid_series(returns) or len(returns) < 2:
        return None
    
    cumulative = (1 + returns).cumprod()
    running_max = cumulative.expanding().max()
    drawdown = ((cumulative - running_max) / running_max) * 100
    
    fig = go.Figure()
    
    fig.add_trace(go.Scatter(
        x=drawdown.index,
        y=drawdown.values,
        fill='tozeroy',
        fillcolor='rgba(255, 0, 68, 0.3)',
        line=dict(color=COLORS['danger'], width=2),
        name='Drawdown'
    ))
    
    fig.add_hline(y=0, line_dash="solid", line_color=COLORS['text_primary'], line_width=1)
    
    max_dd_idx = drawdown.idxmin()
    max_dd_val = drawdown.min()
    
    fig.add_annotation(
        x=max_dd_idx,
        y=max_dd_val,
        text=f"Max DD: {max_dd_val:.2f}%",
        showarrow=True,
        arrowhead=2,
        arrowcolor=COLORS['danger'],
        ax=0,
        ay=-40,
        bgcolor=COLORS['card_background'],
        bordercolor=COLORS['danger'],
        borderwidth=2
    )
    
    fig.update_layout(
        title="üåä Underwater Plot",
        xaxis_title="Date",
        yaxis_title="Drawdown (%)",
        height=500
    )
    
    apply_chart_theme(fig)
    return fig

def create_var_waterfall(returns):
    """VaR/CVaR waterfall chart - ENHANCED THEMING"""
    if not is_valid_series(returns) or len(returns) < 2:
        return None
    
    var_90 = calculate_var(returns, 0.90)
    var_95 = calculate_var(returns, 0.95)
    var_99 = calculate_var(returns, 0.99)
    cvar_95 = calculate_cvar(returns, 0.95)
    
    categories = ['VaR 90%', 'VaR 95%', 'VaR 99%', 'CVaR 95%']
    values = [var_90, var_95, var_99, cvar_95]
    
    colors_list = [COLORS['warning'], COLORS['orange'], COLORS['danger'], COLORS['danger']]
    
    fig = go.Figure()
    
    fig.add_trace(go.Bar(
        x=categories,
        y=values,
        marker=dict(
            color=colors_list,
            line=dict(color=COLORS['border'], width=2)
        ),
        text=[f"{v:.2f}%" for v in values],
        textposition='outside'
    ))
    
    fig.update_layout(
        title="‚ö†Ô∏è Value at Risk Waterfall",
        xaxis_title="Risk Measure",
        yaxis_title="Expected Loss (%)",
        height=500
    )
    
    apply_chart_theme(fig)
    return fig

# v9.7 NEW FEATURE: VaR/CVaR on Return Distribution
def create_var_cvar_distribution(returns):
    """
    NEW IN v9.7: Visualize VaR and CVaR on the actual return distribution
    Shows histogram of returns with VaR and CVaR threshold lines
    """
    if not is_valid_series(returns) or len(returns) < 30:
        return None

    # Calculate risk metrics
    var_95 = calculate_var(returns, 0.95)
    cvar_95 = calculate_cvar(returns, 0.95)
    var_99 = calculate_var(returns, 0.99)

    if var_95 is None or cvar_95 is None:
        return None

    # Convert to decimal for distribution
    returns_pct = returns * 100

    fig = go.Figure()

    # Add histogram of returns
    fig.add_trace(go.Histogram(
        x=returns_pct,
        name='Return Distribution',
        nbinsx=50,
        marker=dict(
            color=COLORS['info'],
            opacity=0.7,
            line=dict(color=COLORS['border'], width=1)
        ),
        hovertemplate='Returns: %{x:.2f}%<br>Count: %{y}<extra></extra>'
    ))

    # Add VaR 95% line
    fig.add_vline(
        x=var_95,
        line_dash="dash",
        line_color=COLORS['warning'],
        line_width=3,
        annotation_text=f"VaR 95%: {var_95:.2f}%",
        annotation_position="top",
        annotation=dict(
            font=dict(size=12, color=COLORS['warning']),
            bgcolor='rgba(10, 25, 41, 0.8)',
            bordercolor=COLORS['warning'],
            borderwidth=2
        )
    )

    # Add CVaR 95% line
    fig.add_vline(
        x=cvar_95,
        line_dash="solid",
        line_color=COLORS['danger'],
        line_width=3,
        annotation_text=f"CVaR 95%: {cvar_95:.2f}%",
        annotation_position="bottom",
        annotation=dict(
            font=dict(size=12, color=COLORS['danger']),
            bgcolor='rgba(10, 25, 41, 0.8)',
            bordercolor=COLORS['danger'],
            borderwidth=2
        )
    )

    # Add VaR 99% line
    fig.add_vline(
        x=var_99,
        line_dash="dot",
        line_color=COLORS['danger'],
        line_width=2,
        annotation_text=f"VaR 99%: {var_99:.2f}%",
        annotation_position="top right",
        annotation=dict(
            font=dict(size=10, color=COLORS['danger']),
            bgcolor='rgba(10, 25, 41, 0.6)'
        )
    )

    # Shade the tail risk area (beyond CVaR)
    fig.add_vrect(
        x0=returns_pct.min(),
        x1=cvar_95,
        fillcolor=COLORS['danger'],
        opacity=0.15,
        layer="below",
        line_width=0,
        annotation_text="Tail Risk Zone",
        annotation_position="top left"
    )

    fig.update_layout(
        title="üìä v9.7: Return Distribution with VaR/CVaR Analysis",
        xaxis_title="Daily Returns (%)",
        yaxis_title="Frequency",
        height=500,
        showlegend=False,
        bargap=0.05
    )

    apply_chart_theme(fig)
    return fig

# v9.7 NEW FEATURE: Rolling VaR/CVaR Time Series
def create_rolling_var_cvar_chart(returns, window=60):
    """
    NEW IN v9.7: Rolling VaR and CVaR time series visualization
    Shows how tail risk metrics evolve over time
    """
    if not is_valid_series(returns) or len(returns) < window:
        return None

    # Calculate rolling VaR and CVaR
    rolling_var_95 = []
    rolling_cvar_95 = []
    dates = []

    for i in range(window, len(returns)):
        window_returns = returns.iloc[i-window:i]
        var = calculate_var(window_returns, 0.95)
        cvar = calculate_cvar(window_returns, 0.95)

        if var is not None and cvar is not None:
            rolling_var_95.append(var)
            rolling_cvar_95.append(cvar)
            dates.append(returns.index[i])

    if not rolling_var_95:
        return None

    fig = go.Figure()

    # Add VaR trace
    fig.add_trace(go.Scatter(
        x=dates,
        y=rolling_var_95,
        name='VaR 95%',
        line=dict(color=COLORS['orange'], width=2),
        mode='lines'
    ))

    # Add CVaR trace
    fig.add_trace(go.Scatter(
        x=dates,
        y=rolling_cvar_95,
        name='CVaR 95%',
        line=dict(color=COLORS['danger'], width=2, dash='dash'),
        mode='lines'
    ))

    # Add zero line
    fig.add_hline(y=0, line_dash="dot", line_color=COLORS['text_muted'], line_width=1)

    fig.update_layout(
        title=f"üìä Rolling VaR & CVaR Evolution ({window}-Day Window)",
        xaxis_title="Date",
        yaxis_title="Expected Loss (%)",
        height=500,
        hovermode='x unified',
        legend=dict(
            orientation="h",
            yanchor="bottom",
            y=1.02,
            xanchor="right",
            x=1
        )
    )

    apply_chart_theme(fig)
    return fig

def create_risk_contribution_sunburst(df):
    """Risk contribution sunburst - ENHANCED THEMING"""
    risk_data = []
    
    for _, row in df.iterrows():
        ticker = row['Ticker']
        weight = row['Weight %']
        sector = row['Sector']
        
        hist_data = fetch_historical_data(ticker, datetime.now() - timedelta(days=365), datetime.now())
        if hist_data is not None and len(hist_data) > 30:
            returns = hist_data['Close'].pct_change().dropna()
            vol = returns.std() * np.sqrt(252) * 100
            risk_contribution = weight * vol
            
            risk_data.append({
                'Ticker': ticker,
                'Sector': sector,
                'Weight': weight,
                'Volatility': vol,
                'Risk Contribution': risk_contribution
            })
    
    if not risk_data:
        return None
    
    risk_df = pd.DataFrame(risk_data)
    
    fig = px.sunburst(
        risk_df,
        path=['Sector', 'Ticker'],
        values='Risk Contribution',
        color='Volatility',
        color_continuous_scale='RdYlGn_r',
        title="‚òÄÔ∏è Risk Contribution Sunburst"
    )
    
    fig.update_layout(height=600)
    apply_chart_theme(fig)
    return fig

def create_risk_reward_plot(df):
    """Risk-reward scatter plot - ENHANCED THEMING"""
    risk_reward_data = []
    
    for _, row in df.iterrows():
        ticker = row['Ticker']
        hist_data = fetch_historical_data(ticker, datetime.now() - timedelta(days=365), datetime.now())
        
        if hist_data is not None and len(hist_data) > 30:
            returns = hist_data['Close'].pct_change().dropna()
            annual_return = ((1 + returns.mean()) ** 252 - 1) * 100
            annual_vol = returns.std() * np.sqrt(252) * 100
            
            risk_reward_data.append({
                'Ticker': ticker,
                'Asset Name': row['Asset Name'],
                'Return': annual_return,
                'Risk': annual_vol,
                'Weight': row['Weight %'],
                'Sector': row['Sector']
            })
    
    if not risk_reward_data:
        return None
    
    rr_df = pd.DataFrame(risk_reward_data)
    
    fig = px.scatter(
        rr_df,
        x='Risk',
        y='Return',
        size='Weight',
        color='Sector',
        text='Ticker',
        hover_data=['Asset Name'],
        color_discrete_sequence=px.colors.qualitative.Set3
    )
    
    fig.update_traces(
        textposition='top center',
        marker=dict(line=dict(width=2, color=COLORS['border']))
    )
    
    fig.update_layout(
        title="üìà Risk-Reward Analysis",
        xaxis_title="Risk (Annual Volatility %)",
        yaxis_title="Expected Return (Annual %)",
        height=CHART_HEIGHT_STANDARD  # P1-4: Standardized height
    )
    
    apply_chart_theme(fig)
    return fig

def should_display_monthly_heatmap(df):
    """
    Validate if monthly heatmap should be displayed.
    Returns True only if there are at least 2 complete months of meaningful data.
    """
    try:
        end_date = datetime.now()
        start_date = end_date - timedelta(days=365)
        current_month_start = end_date.replace(day=1, hour=0, minute=0, second=0, microsecond=0)

        monthly_data_count = 0
        has_meaningful_data = False

        for _, row in df.iterrows():
            ticker = row['Ticker']
            hist_data = fetch_historical_data(ticker, start_date, end_date)

            if hist_data is not None and len(hist_data) > 0:
                monthly_data = hist_data['Close'].resample('M').last()
                monthly_returns = monthly_data.pct_change()

                # Count complete months (excluding current month)
                complete_months = []
                for month, ret in monthly_returns.items():
                    month_start = month.replace(day=1, hour=0, minute=0, second=0, microsecond=0)
                    if month_start < current_month_start and pd.notna(ret):
                        complete_months.append(ret)
                        if abs(ret) > 0.001:  # At least 0.1% variation
                            has_meaningful_data = True

                if len(complete_months) > monthly_data_count:
                    monthly_data_count = len(complete_months)

        # Require at least 2 complete months with some meaningful variation
        return monthly_data_count >= 2 and has_meaningful_data
    except:
        return False

def create_performance_heatmap(df, period='monthly'):
    """v9.7 ENHANCED: Performance heatmap with improved incomplete month filtering"""
    try:
        portfolio_values = {}

        end_date = datetime.now()
        start_date = end_date - timedelta(days=365)
        current_month_start = end_date.replace(day=1, hour=0, minute=0, second=0, microsecond=0)

        for _, row in df.iterrows():
            ticker = row['Ticker']
            hist_data = fetch_historical_data(ticker, start_date, end_date)

            if hist_data is not None and len(hist_data) > 0:
                monthly_data = hist_data['Close'].resample('M').last()
                monthly_returns = monthly_data.pct_change() * 100

                for month, ret in monthly_returns.items():
                    # v9.7 FIX: More robust check for incomplete months
                    # Skip if this month is the current month or in the future
                    month_start = month.replace(day=1, hour=0, minute=0, second=0, microsecond=0)
                    if month_start >= current_month_start:
                        continue

                    month_str = month.strftime('%b %Y')
                    if month_str not in portfolio_values:
                        portfolio_values[month_str] = {}
                    if pd.notna(ret) and abs(ret) < 50:
                        portfolio_values[month_str][ticker] = ret

        if not portfolio_values:
            return None

        tickers = sorted(set(t for months in portfolio_values.values() for t in months))
        months_list = sorted(portfolio_values.keys(), key=lambda x: datetime.strptime(x, '%b %Y'))

        # v9.7 FIX: Double-check to remove any incomplete months that slipped through
        months = []
        for m in months_list:
            m_date = datetime.strptime(m, '%b %Y')
            if m_date < current_month_start:
                months.append(m)
        
        matrix = []
        for ticker in tickers:
            row = []
            for month in months:
                if ticker in portfolio_values[month]:
                    val = portfolio_values[month][ticker]
                    val = max(-50, min(50, val))
                    row.append(val)
                else:
                    row.append(0)
            matrix.append(row)

        # ===== FIX #6: Remove Empty Columns from Heatmap =====
        # Convert to numpy array for easier column operations
        matrix_array = np.array(matrix)

        # Find columns where all values are zero
        non_zero_cols = []
        filtered_months = []

        for i, month in enumerate(months):
            # Check if this column has any non-zero values
            if np.any(np.abs(matrix_array[:, i]) > 0.01):
                non_zero_cols.append(i)
                filtered_months.append(month)

        # Filter matrix to keep only non-zero columns
        if len(non_zero_cols) > 0:
            filtered_matrix = matrix_array[:, non_zero_cols].tolist()
            months = filtered_months
            matrix = filtered_matrix
            print(f"‚úÖ Filtered heatmap: kept {len(filtered_months)} non-empty months")

        fig = go.Figure(data=go.Heatmap(
            z=matrix,
            x=months,
            y=tickers,
            colorscale='RdYlGn',
            zmid=0,
            zmin=-20,
            zmax=20,
            text=np.round(matrix, 1),
            texttemplate='%{text}%',
            textfont={"size": 14},
            colorbar=dict(title="Return %")
        ))
        
        fig.update_layout(
            title="üî• Monthly Performance Heatmap",
            xaxis_title="Month",
            yaxis_title="Asset",
            height=CHART_HEIGHT_DEEP_DIVE,  # P1-4: Standardized height for detailed charts
            width=1200
        )
        
        apply_chart_theme(fig)
        return fig
    except Exception as e:
        st.error(f"Error: {str(e)}")
        return None

def create_portfolio_heatmap(df):
    """Portfolio treemap - ENHANCED THEMING"""
    df_viz = df[['Ticker', 'Asset Name', 'Weight %', 'Total Gain/Loss %', 'Sector']].copy()
    df_viz['Sector'] = df_viz['Sector'].fillna('Other')
    df_viz = df_viz.dropna()
    
    if df_viz.empty:
        return None
    
    fig = px.treemap(
        df_viz,
        path=[px.Constant("Portfolio"), 'Sector', 'Ticker'],
        values='Weight %',
        color='Total Gain/Loss %',
        color_continuous_scale='RdYlGn',
        color_continuous_midpoint=0,
        hover_data={'Asset Name': True, 'Total Gain/Loss %': ':.2f'}
    )
    
    fig.update_layout(
        title="üó∫Ô∏è Portfolio Heatmap",
        height=700
    )
    
    apply_chart_theme(fig)
    return fig

@st.cache_data(ttl=600)
def fetch_ticker_performance(ticker, start_date, end_date):
    try:
        data = fetch_historical_data(ticker, start_date, end_date)
        if data is not None and not data.empty:
            returns = data['Close'].pct_change().fillna(0)
            cumulative = (1 + returns).cumprod() - 1
            return cumulative * 100, data
        return None, None
    except:
        return None, None

def create_interactive_performance_chart(tickers, start_date, end_date):
    """Interactive performance chart - ENHANCED THEMING"""
    fig = go.Figure()
    
    colors = [COLORS['neon_blue'], COLORS['electric_blue'], COLORS['teal'], 
              COLORS['success'], COLORS['warning'], COLORS['danger'],
              COLORS['purple'], COLORS['pink'], COLORS['orange']]
    
    for idx, ticker in enumerate(tickers):
        cumulative, data = fetch_ticker_performance(ticker, start_date, end_date)
        if cumulative is not None:
            fig.add_trace(go.Scatter(
                x=cumulative.index,
                y=cumulative.values,
                mode='lines',
                name=ticker,
                line=dict(width=2.5, color=colors[idx % len(colors)])
            ))
    
    if not fig.data:
        return None
    
    fig.update_layout(
        title="üìà Interactive Performance Comparison",
        xaxis_title="Date",
        yaxis_title="Cumulative Return (%)",
        height=600,
        hovermode='x unified',
        legend=dict(x=0.01, y=0.99)
    )
    
    fig.add_hline(y=0, line_dash="dash", line_color=COLORS['text_muted'], line_width=1)
    
    apply_chart_theme(fig)
    return fig

def run_monte_carlo_simulation(returns, initial_value=100000, days=252, simulations=1000):
    if not is_valid_series(returns) or len(returns) < 30:
        return None
    
    daily_return = returns.mean()
    daily_vol = returns.std()
    
    simulation_results = []
    
    for _ in range(simulations):
        prices = [initial_value]
        for _ in range(days):
            price = prices[-1] * (1 + np.random.normal(daily_return, daily_vol))
            prices.append(price)
        simulation_results.append(prices)
    
    return np.array(simulation_results)

def create_monte_carlo_chart(simulation_results, initial_value=100000):
    if simulation_results is None:
        return None, None
    
    fig = go.Figure()
    
    for i in range(min(100, len(simulation_results))):
        fig.add_trace(go.Scatter(
            y=simulation_results[i],
            mode='lines',
            line=dict(width=0.5, color=COLORS['electric_blue']),
            opacity=0.1,
            showlegend=False
        ))
    
    percentiles = [5, 25, 50, 75, 95]
    colors_pct = [COLORS['danger'], COLORS['warning'], COLORS['info'], 
                  COLORS['teal'], COLORS['success']]
    
    for p, color in zip(percentiles, colors_pct):
        values = np.percentile(simulation_results, p, axis=0)
        fig.add_trace(go.Scatter(
            y=values,
            mode='lines',
            line=dict(width=3, color=color),
            name=f'{p}th Percentile'
        ))
    
    fig.update_layout(
        title="üé≤ Monte Carlo Simulation",
        xaxis_title="Trading Days",
        yaxis_title="Portfolio Value ($)",
        height=500
    )
    
    apply_chart_theme(fig)
    
    final_values = simulation_results[:, -1]
    stats = {
        'mean': np.mean(final_values),
        'median': np.median(final_values),
        'percentile_5': np.percentile(final_values, 5),
        'percentile_95': np.percentile(final_values, 95),
        'prob_profit': (final_values > initial_value).mean() * 100,
        'prob_loss_10': (final_values < initial_value * 0.9).mean() * 100,
        'prob_gain_20': (final_values > initial_value * 1.2).mean() * 100
    }
    
    return fig, stats

def create_risk_parity_analysis(df):
    risk_contributions = []
    
    for _, row in df.iterrows():
        ticker = row['Ticker']
        weight = row['Weight %'] / 100
        
        hist_data = fetch_historical_data(ticker, datetime.now() - timedelta(days=365), datetime.now())
        if hist_data is not None and len(hist_data) > 30:
            returns = hist_data['Close'].pct_change().dropna()
            vol = returns.std() * np.sqrt(252)
            risk_contribution = weight * vol
            
            risk_contributions.append({
                'Ticker': ticker,
                'Weight %': row['Weight %'],
                'Volatility': vol * 100,
                'Risk Contribution': risk_contribution * 100
            })
    
    if not risk_contributions:
        return None
    
    rc_df = pd.DataFrame(risk_contributions)
    total_risk = rc_df['Risk Contribution'].sum()
    rc_df['Risk %'] = (rc_df['Risk Contribution'] / total_risk) * 100
    
    fig = go.Figure()
    
    fig.add_trace(go.Bar(
        name='Weight %',
        x=rc_df['Ticker'],
        y=rc_df['Weight %'],
        marker_color=COLORS['electric_blue']
    ))
    
    fig.add_trace(go.Bar(
        name='Risk Contribution %',
        x=rc_df['Ticker'],
        y=rc_df['Risk %'],
        marker_color=COLORS['danger']
    ))
    
    fig.update_layout(
        title="‚öñÔ∏è Risk Parity Analysis",
        xaxis_title="Asset",
        yaxis_title="Percentage",
        barmode='group',
        height=500
    )
    
    apply_chart_theme(fig)
    return fig

def create_drawdown_distribution(returns):
    """NEW: Drawdown distribution histogram"""
    if not is_valid_series(returns) or len(returns) < 2:
        return None

    cumulative = (1 + returns).cumprod()
    running_max = cumulative.expanding().max()
    drawdowns = ((cumulative - running_max) / running_max) * 100

    # Remove zeros
    drawdowns = drawdowns[drawdowns < 0]

    if len(drawdowns) == 0:
        return None

    fig = go.Figure()

    fig.add_trace(go.Histogram(
        x=drawdowns,
        nbinsx=50,
        marker=dict(
            color=COLORS['danger'],
            line=dict(color=COLORS['border'], width=1)
        ),
        name='Drawdowns',
        hovertemplate='Drawdown: %{x:.2f}%<br>Count: %{y}<extra></extra>'
    ))

    # Add vertical line for mean
    mean_dd = drawdowns.mean()
    fig.add_vline(
        x=mean_dd,
        line_dash="dash",
        line_color=COLORS['warning'],
        annotation_text=f"Mean: {mean_dd:.2f}%",
        annotation_position="top"
    )

    fig.update_layout(
        title="üìâ Drawdown Distribution",
        xaxis_title="Drawdown (%)",
        yaxis_title="Frequency",
        height=400,
        showlegend=False
    )

    apply_chart_theme(fig)
    return fig

def create_correlation_network(df, start_date, end_date):
    returns_data = {}
    
    for _, row in df.iterrows():
        ticker = row['Ticker']
        hist_data = fetch_historical_data(ticker, start_date, end_date)
        if hist_data is not None and len(hist_data) > 30:
            returns_data[ticker] = hist_data['Close'].pct_change().dropna()
    
    if len(returns_data) < 2:
        return None
    
    returns_df = pd.DataFrame(returns_data)
    corr_matrix = returns_df.corr()
    
    fig = go.Figure()
    
    G = nx.Graph()
    for ticker in corr_matrix.columns:
        G.add_node(ticker)
    
    threshold = 0.5
    for i, ticker1 in enumerate(corr_matrix.columns):
        for j, ticker2 in enumerate(corr_matrix.columns):
            if i < j:
                corr = corr_matrix.iloc[i, j]
                if abs(corr) > threshold:
                    G.add_edge(ticker1, ticker2, weight=abs(corr))
    
    pos = nx.spring_layout(G)
    
    for edge in G.edges():
        x0, y0 = pos[edge[0]]
        x1, y1 = pos[edge[1]]
        weight = G[edge[0]][edge[1]]['weight']
        
        fig.add_trace(go.Scatter(
            x=[x0, x1],
            y=[y0, y1],
            mode='lines',
            line=dict(width=weight*5, color=COLORS['electric_blue']),
            opacity=0.5,
            showlegend=False
        ))
    
    node_x = []
    node_y = []
    node_text = []
    
    for node in G.nodes():
        x, y = pos[node]
        node_x.append(x)
        node_y.append(y)
        node_text.append(node)
    
    fig.add_trace(go.Scatter(
        x=node_x,
        y=node_y,
        mode='markers+text',
        text=node_text,
        textposition='top center',
        marker=dict(
            size=20,
            color=COLORS['neon_blue'],
            line=dict(width=2, color=COLORS['border'])
        ),
        showlegend=False
    ))
    
    fig.update_layout(
        title="üîó Correlation Network",
        showlegend=False,
        height=600,
        xaxis=dict(showgrid=False, zeroline=False, showticklabels=False),
        yaxis=dict(showgrid=False, zeroline=False, showticklabels=False)
    )
    
    apply_chart_theme(fig)
    return fig

def create_efficient_frontier(df):
    """FIXED BROADCASTING ERROR - ENHANCED THEMING"""
    returns_data = {}
    expected_returns = []
    volatilities = []
    tickers = []
    
    for _, row in df.iterrows():
        ticker = row['Ticker']
        hist_data = fetch_historical_data(ticker, datetime.now() - timedelta(days=365), datetime.now())
        
        if hist_data is not None and len(hist_data) > 30:
            returns = hist_data['Close'].pct_change().dropna()
            annual_return = ((1 + returns.mean()) ** 252 - 1)
            annual_vol = returns.std() * np.sqrt(252)
            
            expected_returns.append(annual_return)
            volatilities.append(annual_vol)
            tickers.append(ticker)
            returns_data[ticker] = returns
    
    if len(expected_returns) < 2:
        return None
    
    returns_df = pd.DataFrame(returns_data)
    cov_matrix = returns_df.cov() * 252
    
    num_portfolios = 5000
    results = np.zeros((3, num_portfolios))
    
    np.random.seed(42)
    
    for i in range(num_portfolios):
        weights = np.random.random(len(tickers))
        weights /= np.sum(weights)
        
        portfolio_return = np.sum(weights * np.array(expected_returns))
        portfolio_vol = np.sqrt(np.dot(weights.T, np.dot(cov_matrix, weights)))
        sharpe = (portfolio_return - RISK_FREE_RATE) / portfolio_vol if portfolio_vol > 0 else 0
        
        results[0, i] = portfolio_return * 100
        results[1, i] = portfolio_vol * 100
        results[2, i] = sharpe
    
    fig = go.Figure()
    
    fig.add_trace(go.Scatter(
        x=results[1],
        y=results[0],
        mode='markers',
        marker=dict(
            size=5,
            color=results[2],
            colorscale='Viridis',
            showscale=True,
            colorbar=dict(title="Sharpe Ratio")
        ),
        name='Efficient Frontier'
    ))
    
    # FIXED: Properly align weights and returns
    current_weights = df[df['Ticker'].isin(tickers)]['Weight %'].values / 100
    aligned_returns = np.array(expected_returns[:len(current_weights)])
    aligned_cov = cov_matrix.iloc[:len(current_weights), :len(current_weights)]
    
    current_return = np.sum(current_weights * aligned_returns) * 100
    current_vol = np.sqrt(np.dot(current_weights.T, np.dot(aligned_cov, current_weights))) * 100
    
    fig.add_trace(go.Scatter(
        x=[current_vol],
        y=[current_return],
        mode='markers',
        marker=dict(size=20, color=COLORS['danger'], symbol='star'),
        name='Current Portfolio'
    ))
    
    fig.update_layout(
        title="üìä Efficient Frontier",
        xaxis_title="Risk (Volatility %)",
        yaxis_title="Return %",
        height=600,
        showlegend=True,  # FIX: Enable legend
        legend=dict(
            yanchor="top",
            y=0.99,
            xanchor="right",
            x=0.99,
            bgcolor="rgba(10, 25, 41, 0.8)",
            bordercolor=COLORS['border'],
            borderwidth=1
        )
    )

    apply_chart_theme(fig)
    return fig

# ============================================================================
# MARKET WATCH - ENHANCED
# ============================================================================

@st.cache_data(ttl=300)
def fetch_market_watch_data(tickers_dict):
    """v9.7 ENHANCED: Fetches market data with cleaned symbol display"""
    market_data = []

    for ticker, info in tickers_dict.items():
        try:
            stock = yf.Ticker(ticker)
            hist = stock.history(period="5d")

            if not hist.empty:
                # Convert timezone-aware index to timezone-naive
                if hist.index.tz is not None:
                    hist.index = hist.index.tz_localize(None)

                current = hist['Close'].iloc[-1]
                prev = hist['Close'].iloc[-2] if len(hist) > 1 else current
                change = ((current - prev) / prev) * 100

                five_day = ((current / hist['Close'].iloc[0]) - 1) * 100 if len(hist) >= 5 else 0

                volume = hist['Volume'].iloc[-1]
                avg_volume = hist['Volume'].mean()

                # v9.7 FIX: Clean up symbol for display (remove ^, =F, etc.)
                clean_symbol = ticker.replace('^', '').replace('=F', '').replace('-USD', '')
                # For commodities, show descriptive name instead
                if '=F' in ticker or ticker.endswith('=F'):
                    display_symbol = info.get('name', clean_symbol)
                elif ticker.startswith('^'):
                    display_symbol = info.get('name', clean_symbol)
                else:
                    display_symbol = ticker

                market_data.append({
                    'Symbol': display_symbol,
                    'Name': info.get('name', ticker),
                    'Category': info.get('category', info.get('region', '')),
                    'Last': current,
                    'Change %': change,
                    '5D %': five_day,
                    'Volume': volume,
                    'Avg Volume': avg_volume,
                    'Vol/Avg': volume / avg_volume if avg_volume > 0 else 0,
                    '_raw_ticker': ticker  # Store original ticker for formatting logic
                })
        except:
            continue

    return pd.DataFrame(market_data)

def create_dynamic_market_table(df, filters=None):
    if filters:
        if 'category' in filters and filters['category']:
            df = df[df['Category'] == filters['category']]

        if 'min_change' in filters and filters['min_change']:
            df = df[df['Change %'] >= filters['min_change']]

        if 'sort_by' in filters and filters['sort_by']:
            ascending = filters.get('ascending', False)
            df = df.sort_values(filters['sort_by'], ascending=ascending)

    display_df = df.copy()

    # FIX: Format treasury yields as percentages, not dollars
    # Treasury yield INDICES (^TNX, ^TYX, etc.) show yield values as percentages
    # Bond ETFs show prices as dollars
    def format_last_value(row):
        raw_ticker = row.get('_raw_ticker', '')
        # Yield indices starting with ^ and containing treasury/yield info
        is_yield_index = (raw_ticker.startswith('^') and
                         row.get('Category') == 'Government Bonds')

        if is_yield_index:
            # Treasury yields are already in percentage points (e.g., 4.5 = 4.5%)
            return f"{row['Last']:.2f}%"
        else:
            return format_currency(row['Last'])

    display_df['Last'] = display_df.apply(format_last_value, axis=1)
    display_df['Change %'] = display_df['Change %'].apply(lambda x: add_arrow_indicator(format_percentage(x)))
    display_df['5D %'] = display_df['5D %'].apply(lambda x: add_arrow_indicator(format_percentage(x)))
    display_df['Volume'] = display_df['Volume'].apply(lambda x: f"{x:,.0f}")
    display_df['Vol/Avg'] = display_df['Vol/Avg'].apply(lambda x: f"{x:.2f}x")

    # Remove internal column before displaying
    if '_raw_ticker' in display_df.columns:
        display_df = display_df.drop('_raw_ticker', axis=1)

    return display_df

# ============================================================================
# PORTFOLIO DEEP DIVE - ENHANCED
# ============================================================================

def create_sector_rotation_heatmap(df, start_date, end_date):
    """Sector rotation heatmap - FIXED DATETIME COMPARISON"""
    sector_returns = {}

    # FIX: Make end_date_cutoff timezone-naive
    end_date_cutoff = pd.Timestamp(datetime.now().replace(day=1, hour=0, minute=0, second=0, microsecond=0))

    for _, row in df.iterrows():
        ticker = row['Ticker']
        sector = row['Sector']

        hist_data = fetch_historical_data(ticker, start_date, end_date)
        if hist_data is not None and len(hist_data) > 30:
            monthly_data = hist_data['Close'].resample('M').last()
            monthly_returns = monthly_data.pct_change() * 100

            # FIX: Convert index to timezone-naive before comparison
            monthly_returns.index = monthly_returns.index.tz_localize(None)
            monthly_returns = monthly_returns[monthly_returns.index < end_date_cutoff]
            
            if sector not in sector_returns:
                sector_returns[sector] = []
            
            sector_returns[sector].append(monthly_returns)
    
    if not sector_returns:
        return None
    
    sector_avg = {}
    for sector, returns_list in sector_returns.items():
        combined = pd.concat(returns_list, axis=1).mean(axis=1)
        sector_avg[sector] = combined
    
    sectors = list(sector_avg.keys())
    months = sector_avg[sectors[0]].index
    
    matrix = []
    for sector in sectors:
        matrix.append(sector_avg[sector].values)
    
    fig = go.Figure(data=go.Heatmap(
        z=matrix,
        x=[m.strftime('%b %Y') for m in months],
        y=sectors,
        colorscale='RdYlGn',
        zmid=0,
        text=np.round(matrix, 1),
        texttemplate='%{text}%',
        textfont={"size": 11},
        colorbar=dict(title="Return %")
    ))
    
    fig.update_layout(
        title="üîÑ Sector Rotation Heatmap",
        xaxis_title="Month",
        yaxis_title="Sector",
        height=500
    )
    
    apply_chart_theme(fig)
    return fig

def create_holdings_attribution_waterfall(df):
    """Holdings attribution waterfall - ENHANCED THEMING"""
    top_contributors = df.nlargest(10, 'Total Gain/Loss $')
    
    tickers = top_contributors['Ticker'].tolist()
    contributions = top_contributors['Total Gain/Loss $'].tolist()
    
    fig = go.Figure()
    
    fig.add_trace(go.Waterfall(
        name="Attribution",
        orientation="v",
        x=tickers,
        y=contributions,
        connector={"line": {"color": COLORS['neon_blue']}},
        decreasing={"marker": {"color": COLORS['danger']}},
        increasing={"marker": {"color": COLORS['success']}},
        totals={"marker": {"color": COLORS['electric_blue']}}
    ))
    
    fig.update_layout(
        title="üíß Holdings Attribution Waterfall",
        xaxis_title="Ticker",
        yaxis_title="Contribution ($)",
        height=500
    )
    
    apply_chart_theme(fig)
    return fig

def create_concentration_gauge(df):
    """Concentration gauge - ENHANCED THEMING"""
    top_5_weight = df.nlargest(5, 'Weight %')['Weight %'].sum()
    
    fig = go.Figure(go.Indicator(
        mode="gauge+number+delta",
        value=top_5_weight,
        title={'text': "Top 5 Concentration"},
        delta={'reference': 50, 'increasing': {'color': COLORS['warning']}},
        gauge={
            'axis': {'range': [None, 100]},
            'bar': {'color': COLORS['neon_blue']},
            'steps': [
                {'range': [0, 30], 'color': COLORS['success']},
                {'range': [30, 50], 'color': COLORS['warning']},
                {'range': [50, 100], 'color': COLORS['danger']}
            ],
            'threshold': {
                'line': {'color': "red", 'width': 4},
                'thickness': 0.75,
                'value': 70
            }
        }
    ))
    
    fig.update_layout(height=400)
    apply_chart_theme(fig)
    return fig

def create_concentration_analysis(df):
    """NEW: Enhanced concentration analysis with multiple visuals"""
    
    # Top 10 Holdings Bar Chart
    top_10 = df.nlargest(10, 'Weight %')
    
    fig = go.Figure()
    
    fig.add_trace(go.Bar(
        x=top_10['Weight %'],
        y=top_10['Ticker'],
        orientation='h',
        marker=dict(
            color=top_10['Weight %'],
            colorscale='Blues',
            line=dict(color=COLORS['border'], width=2)
        ),
        text=[f"{x:.1f}%" for x in top_10['Weight %']],
        textposition='auto'
    ))
    
    fig.update_layout(
        title="üìä Top 10 Holdings Concentration",
        xaxis_title="Weight (%)",
        yaxis_title="",
        height=500,
        showlegend=False
    )
    
    apply_chart_theme(fig)
    return fig

# ============================================================================
# MULTI-FACTOR ANALYSIS - ENHANCED
# ============================================================================

def create_factor_momentum_chart(factor_data):
    """Factor momentum chart - ENHANCED THEMING"""
    if factor_data is None or 'factor_returns' not in factor_data:
        return None
    
    factor_returns = factor_data['factor_returns']
    
    fig = go.Figure()
    
    colors = [COLORS['neon_blue'], COLORS['electric_blue'], COLORS['teal'], 
              COLORS['success'], COLORS['purple'], COLORS['pink']]
    
    for idx, factor in enumerate(FACTOR_DEFINITIONS.keys()):
        if factor in factor_returns.columns:
            cumulative = (1 + factor_returns[factor]).cumprod() - 1
            fig.add_trace(go.Scatter(
                x=cumulative.index,
                y=cumulative.values * 100,
                mode='lines',
                name=factor,
                line=dict(width=2, color=colors[idx % len(colors)])
            ))
    
    fig.update_layout(
        title="üìà Factor Momentum",
        xaxis_title="Date",
        yaxis_title="Cumulative Return (%)",
        height=600,
        hovermode='x unified',
        legend=dict(x=0.02, y=0.98)
    )
    
    apply_chart_theme(fig)
    return fig

def create_factor_exposure_radar(exposures):
    """Factor exposure radar - ENHANCED THEMING"""
    if exposures is None or 'exposures' not in exposures:
        return None
    
    exp = exposures['exposures']
    factors = [f for f in FACTOR_DEFINITIONS.keys() if f in exp.index]
    values = [exp[f] for f in factors]
    
    max_abs = max([abs(v) for v in values]) if values else 1
    normalized = [(v / max_abs) * 100 if max_abs > 0 else 0 for v in values]
    
    fig = go.Figure()
    
    fig.add_trace(go.Scatterpolar(
        r=normalized,
        theta=factors,
        fill='toself',
        fillcolor='rgba(0, 212, 255, 0.2)',
        line=dict(color=COLORS['neon_blue'], width=2),
        name='Factor Exposure'
    ))
    
    fig.update_layout(
        polar=dict(
            radialaxis=dict(
                visible=True,
                range=[0, 100],
                color=COLORS['text_secondary']
            ),
            bgcolor='rgba(10, 25, 41, 0.3)'
        ),
        title="üéØ Factor Exposure Radar",
        height=550
    )
    
    apply_chart_theme(fig)
    return fig

@st.cache_data(ttl=3600)
def calculate_factor_exposures(df, start_date, end_date):
    try:
        portfolio_returns = calculate_portfolio_returns(df, start_date, end_date)
        if not is_valid_series(portfolio_returns):
            return None
        
        factor_returns = {}
        for factor_name, factor_info in FACTOR_DEFINITIONS.items():
            benchmark = factor_info['benchmark']
            returns = calculate_benchmark_returns(benchmark, start_date, end_date)
            if is_valid_series(returns):
                factor_returns[factor_name] = returns
        
        if not factor_returns:
            return None
        
        common_dates = portfolio_returns.index
        for factor_name in factor_returns:
            common_dates = common_dates.intersection(factor_returns[factor_name].index)
        
        X = pd.DataFrame({name: returns.loc[common_dates] for name, returns in factor_returns.items()})
        y = portfolio_returns.loc[common_dates]
        
        X['Alpha'] = 1
        
        model = LinearRegression()
        model.fit(X, y)
        
        exposures = pd.Series(model.coef_, index=X.columns)
        r_squared = model.score(X, y)
        predicted_returns = model.predict(X)
        
        asset_exposures = {}
        for _, row in df.iterrows():
            ticker = row['Ticker']
            ticker_returns = calculate_benchmark_returns(ticker, start_date, end_date)
            if is_valid_series(ticker_returns):
                ticker_aligned = ticker_returns.loc[common_dates]
                
                asset_model = LinearRegression()
                asset_model.fit(X, ticker_aligned)
                
                asset_exposures[ticker] = pd.Series(asset_model.coef_, index=X.columns)
        
        return {
            'exposures': exposures,
            'r_squared': r_squared,
            'factor_returns': X,
            'portfolio_returns': y,
            'predicted_returns': predicted_returns,
            'asset_exposures': asset_exposures
        }
    except:
        return None

def create_factor_attribution_table(exposures, df):
    if exposures is None or 'asset_exposures' not in exposures:
        return None, None, None
    
    attribution_data = []
    
    for ticker, asset_exp in exposures['asset_exposures'].items():
        asset_row = df[df['Ticker'] == ticker]
        if asset_row.empty:
            continue
        
        weight = asset_row['Weight %'].values[0] / 100
        sector = asset_row['Sector'].values[0]
        
        for factor in FACTOR_DEFINITIONS.keys():
            if factor in asset_exp:
                contribution = weight * asset_exp[factor]
                attribution_data.append({
                    'Ticker': ticker,
                    'Sector': sector,
                    'Factor': factor,
                    'Weight': weight * 100,
                    'Factor Beta': asset_exp[factor],
                    'Contribution': contribution
                })
    
    if not attribution_data:
        return None, None, None
    
    attr_df = pd.DataFrame(attribution_data)
    
    factor_summary = attr_df.groupby('Factor').agg({
        'Contribution': 'sum'
    }).reset_index()
    factor_summary.columns = ['Factor', 'Total Contribution']
    
    sector_summary = attr_df.groupby(['Sector', 'Factor']).agg({
        'Contribution': 'sum'
    }).reset_index()
    
    return attr_df, factor_summary, sector_summary

# ============================================================================
# PERFORMANCE METRICS
# ============================================================================

def calculate_performance_metrics(df, portfolio_returns, benchmark_returns):
    if not is_valid_series(portfolio_returns):
        return None
    
    total_return = (1 + portfolio_returns).prod() - 1
    n_years = len(portfolio_returns) / 252
    annualized_return = (1 + total_return) ** (1/n_years) - 1 if n_years > 0 else 0
    annualized_vol = portfolio_returns.std() * np.sqrt(252)
    
    sharpe = calculate_sharpe_ratio(portfolio_returns)
    sortino = calculate_sortino_ratio(portfolio_returns)
    calmar = calculate_calmar_ratio(portfolio_returns)
    
    info_ratio = calculate_information_ratio(portfolio_returns, benchmark_returns)
    
    var_95 = calculate_var(portfolio_returns, 0.95)
    cvar_95 = calculate_cvar(portfolio_returns, 0.95)
    max_dd = calculate_max_drawdown(portfolio_returns)
    
    winning_days = (portfolio_returns > 0).sum()
    losing_days = (portfolio_returns < 0).sum()
    win_rate = winning_days / (winning_days + losing_days) * 100 if (winning_days + losing_days) > 0 else 0
    
    avg_win = portfolio_returns[portfolio_returns > 0].mean() * 100 if winning_days > 0 else 0
    avg_loss = portfolio_returns[portfolio_returns < 0].mean() * 100 if losing_days > 0 else 0
    
    best_day = portfolio_returns.max() * 100
    worst_day = portfolio_returns.min() * 100
    
    return {
        'Total Return': total_return * 100,
        'Annualized Return': annualized_return * 100,
        'Annualized Volatility': annualized_vol * 100,
        'Sharpe Ratio': sharpe,
        'Sortino Ratio': sortino,
        'Calmar Ratio': calmar,
        'Information Ratio': info_ratio,
        'VaR (95%)': var_95,
        'CVaR (95%)': cvar_95,
        'Max Drawdown': max_dd,
        'Win Rate': win_rate,
        'Avg Win': avg_win,
        'Avg Loss': avg_loss,
        'Best Day': best_day,
        'Worst Day': worst_day,
        'Winning Days': winning_days,
        'Losing Days': losing_days
    }

def create_performance_dashboard(metrics):
    fig = make_subplots(
        rows=2, cols=2,
        subplot_titles=('Returns Distribution', 'Risk Metrics', 
                       'Win/Loss Analysis', 'Risk-Adjusted Returns'),
        specs=[[{'type': 'bar'}, {'type': 'scatter'}],
               [{'type': 'pie'}, {'type': 'bar'}]]
    )
    
    fig.add_trace(
        go.Bar(x=['Total', 'Annualized'], 
               y=[metrics['Total Return'], metrics['Annualized Return']],
               marker_color=[COLORS['success'], COLORS['electric_blue']]),
        row=1, col=1
    )
    
    fig.add_trace(
        go.Scatter(x=['Volatility', 'VaR', 'CVaR', 'Max DD'],
                  y=[metrics['Annualized Volatility'], abs(metrics['VaR (95%)']), 
                     abs(metrics['CVaR (95%)']), abs(metrics['Max Drawdown'])],
                  mode='markers+lines',
                  marker=dict(size=15, color=COLORS['danger'])),
        row=1, col=2
    )
    
    fig.add_trace(
        go.Pie(labels=['Winning Days', 'Losing Days'],
               values=[metrics['Winning Days'], metrics['Losing Days']],
               marker=dict(colors=[COLORS['success'], COLORS['danger']])),
        row=2, col=1
    )
    
    fig.add_trace(
        go.Bar(x=['Sharpe', 'Sortino', 'Calmar', 'Info'],
               y=[metrics['Sharpe Ratio'], metrics['Sortino Ratio'], 
                  metrics['Calmar Ratio'], metrics['Information Ratio']],
               marker_color=COLORS['purple']),
        row=2, col=2
    )
    
    fig.update_layout(
        height=700,
        showlegend=False,
        title_text="üìä Performance Dashboard"
    )
    
    apply_chart_theme(fig)
    return fig

# ============================================================================
# VALUATION HOUSE VISUALIZATIONS - ENHANCED
# ============================================================================

def create_dcf_waterfall(dcf_results, method='FCFF'):
    """Create waterfall chart showing DCF buildup - ENHANCED THEMING"""
    
    categories = ['PV of Cash Flows', 'PV of Terminal Value']
    values = [dcf_results['total_pv_cash_flows'], dcf_results['pv_terminal']]
    
    if method == 'FCFF':
        categories.append('Enterprise Value')
        categories.append('Less: Net Debt')
        categories.append('Equity Value')
        values.append(dcf_results['enterprise_value'])
        values.append(-dcf_results.get('net_debt', 0))
        values.append(dcf_results['equity_value'])
    
    fig = go.Figure(go.Waterfall(
        name="DCF Buildup",
        orientation="v",
        x=categories,
        y=values,
        connector={"line": {"color": COLORS['neon_blue']}},
        decreasing={"marker": {"color": COLORS['danger']}},
        increasing={"marker": {"color": COLORS['success']}},
    ))
    
    fig.update_layout(
        title=f"üíé {method} Valuation Buildup",
        yaxis_title="Value ($)",
        height=500
    )
    
    apply_chart_theme(fig)
    return fig

def create_cash_flow_chart(projections, method='FCFF'):
    """Create bar chart of projected cash flows - ENHANCED THEMING"""
    
    cf_key = 'fcff' if method == 'FCFF' else 'fcfe'
    
    years = [proj['year'] for proj in projections]
    cash_flows = [proj[cf_key] for proj in projections]
    
    fig = go.Figure()
    
    fig.add_trace(go.Bar(
        x=years,
        y=cash_flows,
        marker_color=COLORS['electric_blue'],
        name=method,
        marker=dict(line=dict(color=COLORS['border'], width=2))
    ))
    
    fig.update_layout(
        title=f"üìä Projected {method} by Year",
        xaxis_title="Year",
        yaxis_title=f"{method} ($)",
        height=400
    )
    
    apply_chart_theme(fig)
    return fig

def create_sensitivity_table(base_price, base_discount, base_terminal):
    """Create sensitivity analysis table - ENHANCED THEMING"""
    
    discount_rates = np.linspace(base_discount - 0.02, base_discount + 0.02, 5)
    terminal_growth_rates = np.linspace(base_terminal - 0.01, base_terminal + 0.01, 5)
    
    # This is simplified - in real implementation would recalculate DCF
    sensitivity_matrix = []
    for tr in terminal_growth_rates:
        row = []
        for dr in discount_rates:
            # Simplified sensitivity calculation
            adjustment = (1 - (dr - base_discount)) * (1 + (tr - base_terminal))
            value = base_price * adjustment
            row.append(value)
        sensitivity_matrix.append(row)
    
    fig = go.Figure(data=go.Heatmap(
        z=sensitivity_matrix,
        x=[f"{dr:.1%}" for dr in discount_rates],
        y=[f"{tg:.1%}" for tg in terminal_growth_rates],
        colorscale='RdYlGn',
        text=[[f"${v:.2f}" for v in row] for row in sensitivity_matrix],
        texttemplate='%{text}',
        textfont={"size": 10},
        colorbar=dict(title="Price")
    ))
    
    fig.update_layout(
        title="üéØ Sensitivity Analysis",
        xaxis_title="Discount Rate",
        yaxis_title="Terminal Growth Rate",
        height=400
    )
    
    apply_chart_theme(fig)
    return fig

# ============================================================================
# ATLAS v11.0 ADVANCED FEATURES
# ============================================================================

class InvestopediaIntegration:
    """
    Investopedia Paper Trading API Integration - TWO-STAGE AUTHENTICATION

    FIXED: Proper 2FA flow with Selenium
    - Stage 1: Login with email/password ‚Üí triggers 2FA email
    - Stage 2: Submit 2FA code after user receives it
    - Live portfolio scraping after authentication
    """

    def __init__(self, email="davenompozolo@gmail.com"):
        self.email = email
        self.driver = None
        self.authenticated = False

    def attempt_login(self, password):
        """
        Stage 1: Attempt login with email/password to trigger 2FA email

        Returns:
            dict: {
                'status': '2fa_required' | 'error' | 'success',
                'message': str
            }
        """
        try:
            from selenium import webdriver
            from selenium.webdriver.common.by import By
            from selenium.webdriver.support.ui import WebDriverWait
            from selenium.webdriver.support import expected_conditions as EC
            from selenium.common.exceptions import TimeoutException, NoSuchElementException

            # COLAB-OPTIMIZED: System ChromeDriver setup
            # Auto-install Chromium and ChromeDriver if not present
            import subprocess
            import os

            # Check if ChromeDriver is installed, install if missing
            if not os.path.exists('/usr/bin/chromedriver'):
                st.info("üì¶ Installing Chrome/ChromeDriver for Colab...")
                try:
                    subprocess.run(['apt-get', 'update'], check=True, capture_output=True)
                    subprocess.run(['apt-get', 'install', '-y', 'chromium-chromedriver'], check=True, capture_output=True)
                    subprocess.run(['cp', '/usr/lib/chromium-browser/chromedriver', '/usr/bin'], check=True, capture_output=True)
                    subprocess.run(['chmod', '+x', '/usr/bin/chromedriver'], check=True, capture_output=True)
                    st.success("‚úÖ ChromeDriver installed successfully!")
                except Exception as e:
                    st.warning(f"‚ö†Ô∏è ChromeDriver installation failed: {e}")

            # COLAB-OPTIMIZED: Minimal Chrome options for stability
            options = webdriver.ChromeOptions()
            options.add_argument('--headless')
            options.add_argument('--no-sandbox')
            options.add_argument('--disable-dev-shm-usage')
            options.add_argument('--disable-gpu')

            # Explicit binary location for Colab
            options.binary_location = '/usr/bin/chromium-browser'

            # Use system ChromeDriver (no webdriver-manager needed)
            self.driver = webdriver.Chrome(options=options)

            # Navigate to Investopedia login page
            self.driver.get("https://www.investopedia.com/simulator/trade/login")

            # Wait for login form to load
            try:
                WebDriverWait(self.driver, 10).until(
                    EC.presence_of_element_located((By.ID, "edit-email"))
                )
            except TimeoutException:
                # Try alternative selectors
                WebDriverWait(self.driver, 10).until(
                    EC.presence_of_element_located((By.NAME, "email"))
                )

            # Enter credentials
            email_field = self.driver.find_element(By.ID, "edit-email") if self.driver.find_elements(By.ID, "edit-email") else self.driver.find_element(By.NAME, "email")
            password_field = self.driver.find_element(By.ID, "edit-password") if self.driver.find_elements(By.ID, "edit-password") else self.driver.find_element(By.NAME, "password")

            email_field.clear()
            email_field.send_keys(self.email)
            password_field.clear()
            password_field.send_keys(password)

            # Click login button
            login_button = self.driver.find_element(By.ID, "edit-submit") if self.driver.find_elements(By.ID, "edit-submit") else self.driver.find_element(By.CSS_SELECTOR, "button[type='submit']")
            login_button.click()

            # Wait for response (check for 2FA prompt, error, or success)
            import time
            time.sleep(3)  # Brief wait for page to react

            # Check for 2FA prompt
            try:
                WebDriverWait(self.driver, 5).until(
                    EC.presence_of_element_located((By.ID, "edit-otp"))
                )
                # 2FA field appeared - success! Email has been sent
                return {
                    'status': '2fa_required',
                    'message': '‚úì Login successful! Check your email for the 2FA code.'
                }
            except TimeoutException:
                pass

            # Check for error message
            try:
                error_element = self.driver.find_element(By.CLASS_NAME, "messages--error")
                error_text = error_element.text
                self.driver.quit()
                self.driver = None
                return {
                    'status': 'error',
                    'message': f'Login failed: {error_text}'
                }
            except NoSuchElementException:
                pass

            # Check if already on portfolio page (no 2FA needed)
            if "portfolio" in self.driver.current_url.lower() or "trade" in self.driver.current_url.lower():
                self.authenticated = True
                return {
                    'status': 'success',
                    'message': 'Login successful (no 2FA required)'
                }

            # Unknown state
            current_url = self.driver.current_url
            self.driver.quit()
            self.driver = None
            return {
                'status': 'error',
                'message': f'Unexpected page state after login. Current URL: {current_url}'
            }

        except Exception as e:
            if self.driver:
                self.driver.quit()
                self.driver = None
            return {
                'status': 'error',
                'message': f'Login error: {str(e)}'
            }

    def submit_2fa_code(self, code):
        """
        Stage 2: Submit 2FA code to complete authentication

        Args:
            code (str): 6-digit 2FA code from user's email

        Returns:
            dict: {'status': 'success' | 'error', 'message': str}
        """
        try:
            from selenium.webdriver.common.by import By
            from selenium.webdriver.support.ui import WebDriverWait
            from selenium.webdriver.support import expected_conditions as EC
            from selenium.common.exceptions import TimeoutException, NoSuchElementException

            if not self.driver:
                return {
                    'status': 'error',
                    'message': 'No active login session. Please start login again.'
                }

            # Find 2FA code input field
            try:
                code_field = WebDriverWait(self.driver, 5).until(
                    EC.presence_of_element_located((By.ID, "edit-otp"))
                )
            except TimeoutException:
                # Try alternative selectors
                code_field = self.driver.find_element(By.NAME, "otp")

            # Enter 2FA code
            code_field.clear()
            code_field.send_keys(code)

            # Click submit button
            submit_button = self.driver.find_element(By.ID, "edit-submit") if self.driver.find_elements(By.ID, "edit-submit") else self.driver.find_element(By.CSS_SELECTOR, "button[type='submit']")
            submit_button.click()

            # Wait for result
            import time
            time.sleep(3)

            # Check for error message
            try:
                error = self.driver.find_element(By.CLASS_NAME, "messages--error")
                return {
                    'status': 'error',
                    'message': f'Invalid 2FA code: {error.text}'
                }
            except NoSuchElementException:
                pass

            # Check if redirected to portfolio/trade page (success)
            try:
                WebDriverWait(self.driver, 10).until(
                    lambda driver: "portfolio" in driver.current_url.lower() or "trade" in driver.current_url.lower()
                )
                self.authenticated = True
                return {
                    'status': 'success',
                    'message': '‚úì Authentication complete! You can now sync your portfolio.'
                }
            except TimeoutException:
                return {
                    'status': 'error',
                    'message': '2FA code accepted but failed to reach portfolio page'
                }

        except Exception as e:
            return {
                'status': 'error',
                'message': f'2FA submission error: {str(e)}'
            }

    def scrape_portfolio(self):
        """Scrape live portfolio data from Investopedia after successful authentication"""
        if not self.authenticated or not self.driver:
            st.warning("‚ö†Ô∏è Please authenticate first")
            return None

        try:
            from selenium.webdriver.common.by import By
            from selenium.webdriver.support.ui import WebDriverWait
            from selenium.webdriver.support import expected_conditions as EC
            from bs4 import BeautifulSoup

            # Navigate to portfolio page (if not already there)
            if "portfolio" not in self.driver.current_url:
                self.driver.get("https://www.investopedia.com/simulator/portfolio")

            # Wait for portfolio table to load
            WebDriverWait(self.driver, 10).until(
                EC.presence_of_element_located((By.CSS_SELECTOR, "table.portfolio-table"))
            )

            # Parse page HTML
            soup = BeautifulSoup(self.driver.page_source, 'html.parser')

            # Extract positions from table
            positions = []
            table = soup.find('table', class_='portfolio-table')

            if table:
                rows = table.find('tbody').find_all('tr')

                for row in rows:
                    cells = row.find_all('td')
                    if len(cells) >= 6:
                        position = {
                            'Ticker': cells[0].text.strip(),
                            'Shares': float(cells[1].text.strip().replace(',', '')),
                            'Avg Cost': float(cells[2].text.strip().replace('$', '').replace(',', '')),
                            'Current Price': float(cells[3].text.strip().replace('$', '').replace(',', '')),
                            'Total Value': float(cells[4].text.strip().replace('$', '').replace(',', '')),
                            'Gain/Loss': float(cells[5].text.strip().replace('$', '').replace(',', ''))
                        }
                        positions.append(position)

            # Cleanup driver
            self.driver.quit()
            self.driver = None

            if positions:
                st.success(f"‚úÖ Successfully scraped {len(positions)} positions from Investopedia")
                return pd.DataFrame(positions)
            else:
                st.info("üìä Portfolio is empty or no positions found")
                return pd.DataFrame()

        except Exception as e:
            st.error(f"‚ùå Portfolio scraping error: {str(e)}")
            if self.driver:
                self.driver.quit()
                self.driver = None
            return None

    def cleanup(self):
        """Cleanup driver resources"""
        if self.driver:
            self.driver.quit()
            self.driver = None


class StochasticEngine:
    """
    Advanced Stochastic Modeling using Geometric Brownian Motion
    - Monte Carlo simulations with 10,000+ paths
    - Correlated asset movements
    - VaR/CVaR risk metrics
    """

    def __init__(self, tickers, returns_data=None):
        self.tickers = tickers
        self.returns_data = returns_data
        self.mu = None
        self.cov = None

        if returns_data is not None:
            self.mu = returns_data.mean().values
            self.cov = returns_data.cov().values

    def geometric_brownian_motion(self, S0, mu, sigma, T, dt, n_paths):
        """
        Generate price paths using Geometric Brownian Motion

        dS_t = Œº * S_t * dt + œÉ * S_t * dW_t

        where:
        - S_t = stock price at time t
        - Œº = drift (expected return)
        - œÉ = volatility
        - dW_t = Wiener process (random walk)
        """
        n_steps = int(T / dt)
        paths = np.zeros((n_paths, n_steps))
        paths[:, 0] = S0

        for t in range(1, n_steps):
            Z = np.random.standard_normal(n_paths)
            paths[:, t] = paths[:, t-1] * np.exp(
                (mu - 0.5 * sigma**2) * dt + sigma * np.sqrt(dt) * Z
            )

        return paths

    def monte_carlo_simulation(self, weights, S0_values, n_scenarios=10000, T=252):
        """
        Run full portfolio Monte Carlo simulation

        Returns:
        - portfolio_paths: simulated portfolio values over time
        - returns_dist: distribution of portfolio returns
        - metrics: VaR 95%, CVaR 95%, Expected Return, Volatility
        """
        dt = 1 / 252  # Daily time step
        n_assets = len(self.tickers)
        n_steps = T

        # Generate correlated random numbers using Cholesky decomposition
        L = np.linalg.cholesky(self.cov)

        # Initialize paths for each asset
        asset_paths = np.zeros((n_scenarios, n_steps, n_assets))

        for i in range(n_assets):
            asset_paths[:, 0, i] = S0_values[i]

        # Simulate paths
        for t in range(1, n_steps):
            Z = np.random.standard_normal((n_scenarios, n_assets))
            Z_corr = Z @ L.T

            for i in range(n_assets):
                asset_paths[:, t, i] = asset_paths[:, t-1, i] * np.exp(
                    (self.mu[i] - 0.5 * self.cov[i, i]) * dt +
                    np.sqrt(self.cov[i, i] * dt) * Z_corr[:, i]
                )

        # Calculate portfolio values
        portfolio_paths = np.sum(asset_paths * weights, axis=2)

        # Calculate returns distribution
        final_returns = (portfolio_paths[:, -1] - portfolio_paths[:, 0]) / portfolio_paths[:, 0]

        # Calculate risk metrics
        var_95 = np.percentile(final_returns, 5)
        cvar_95 = final_returns[final_returns <= var_95].mean()
        expected_return = final_returns.mean()
        volatility = final_returns.std()

        metrics = {
            'VaR 95%': var_95,
            'CVaR 95%': cvar_95,
            'Expected Return': expected_return,
            'Volatility': volatility
        }

        return portfolio_paths, final_returns, metrics


class QuantOptimizer:
    """
    Advanced Portfolio Optimization using Multivariable Calculus
    - Analytical gradient calculation: ‚àÇSharpe/‚àÇw_i
    - SLSQP optimization with Jacobian matrix
    - Maximum Sharpe Ratio objective
    - Leverage constraints
    """

    def __init__(self, returns_data, risk_free_rate=0.04):
        self.returns = returns_data
        self.mu = returns_data.mean().values * 252  # Annualized
        self.cov = returns_data.cov().values * 252  # Annualized
        self.rf = risk_free_rate
        self.n_assets = len(self.mu)

    def portfolio_metrics(self, weights):
        """Calculate portfolio return and volatility"""
        ret = np.dot(weights, self.mu)
        vol = np.sqrt(np.dot(weights, np.dot(self.cov, weights)))
        return ret, vol

    def sharpe_ratio(self, weights):
        """Calculate Sharpe Ratio"""
        ret, vol = self.portfolio_metrics(weights)
        return (ret - self.rf) / vol if vol != 0 else 0

    def negative_sharpe(self, weights):
        """Negative Sharpe for minimization"""
        return -self.sharpe_ratio(weights)

    def sharpe_gradient(self, weights):
        """
        Analytical gradient of Sharpe Ratio

        ‚àÇSharpe/‚àÇw_i = (1/œÉ_p) * [‚àÇr_p/‚àÇw_i - Sharpe * ‚àÇœÉ_p/‚àÇw_i]

        where:
        - ‚àÇr_p/‚àÇw_i = Œº_i (partial derivative of return)
        - ‚àÇœÉ_p/‚àÇw_i = (Œ£*w)_i / œÉ_p (partial derivative of volatility)
        """
        ret, vol = self.portfolio_metrics(weights)

        if vol == 0:
            return np.zeros(self.n_assets)

        sharpe = self.sharpe_ratio(weights)

        # Volatility gradient: ‚àÇœÉ_p/‚àÇw_i = (Œ£*w)_i / œÉ_p
        vol_grad = np.dot(self.cov, weights) / vol

        # Return gradient: ‚àÇr_p/‚àÇw_i = Œº_i
        ret_grad = self.mu

        # Sharpe gradient: ‚àÇSharpe/‚àÇw_i = (1/œÉ_p) * [Œº_i - Sharpe * (Œ£*w)_i/œÉ_p]
        sharpe_grad = (1 / vol) * (ret_grad - sharpe * vol_grad)

        return -sharpe_grad  # Negative for minimization

    def optimize_max_sharpe(self, min_weight=0.01, max_weight=0.40):
        """
        Optimize portfolio using SLSQP with analytical Jacobian

        Constraints:
        - Sum of weights = 1
        - Min/max weight bounds
        """
        from scipy.optimize import minimize

        # Initial guess (equal weights)
        w0 = np.ones(self.n_assets) / self.n_assets

        # Constraints
        constraints = [
            {'type': 'eq', 'fun': lambda w: np.sum(w) - 1.0}  # Sum to 1
        ]

        # Bounds
        bounds = tuple((min_weight, max_weight) for _ in range(self.n_assets))

        # Optimize using SLSQP with analytical gradient
        result = minimize(
            fun=self.negative_sharpe,
            x0=w0,
            method='SLSQP',
            jac=self.sharpe_gradient,  # Analytical gradient
            bounds=bounds,
            constraints=constraints,
            options={'maxiter': 1000, 'ftol': 1e-9}
        )

        optimal_weights = result.x
        optimal_sharpe = self.sharpe_ratio(optimal_weights)

        return optimal_weights, optimal_sharpe, result


class EnhancedDCFEngine:
    """
    Advanced DCF Valuation with WACC and FCF projections
    - WACC calculation using CAPM
    - 5-year FCF projections
    - Terminal value calculation
    - Sensitivity analysis
    """

    def __init__(self, ticker):
        self.ticker = ticker
        self.stock = yf.Ticker(ticker)
        self.info = self.stock.info

    def calculate_wacc(self, risk_free=0.04, market_return=0.10):
        """
        Calculate Weighted Average Cost of Capital

        WACC = (E/V) * Re + (D/V) * Rd * (1-T)

        where:
        - Re = Cost of Equity = Rf + Œ≤ * (Rm - Rf)  [CAPM]
        - Rd = Cost of Debt
        - E = Market value of equity
        - D = Market value of debt
        - V = E + D
        - T = Tax rate
        """
        info = self.info

        # Get values from info
        market_cap = info.get('marketCap', 0)
        total_debt = info.get('totalDebt', 0)
        beta = info.get('beta', 1.0)

        # Calculate cost of equity using CAPM
        re = risk_free + beta * (market_return - risk_free)

        # Cost of debt (simplified)
        interest_expense = info.get('interestExpense', 0)
        rd = abs(interest_expense) / total_debt if total_debt > 0 else 0.05

        # Tax rate
        tax_rate = info.get('effectiveTaxRate', 0.21)

        # Total value
        total_value = market_cap + total_debt

        if total_value == 0:
            return None

        # Calculate WACC
        wacc = (market_cap / total_value) * re + (total_debt / total_value) * rd * (1 - tax_rate)

        return {
            'WACC': wacc,
            'Cost of Equity': re,
            'Cost of Debt': rd,
            'Market Cap': market_cap,
            'Total Debt': total_debt,
            'Tax Rate': tax_rate,
            'Beta': beta
        }

    def calculate_enterprise_value(self, terminal_growth=0.03):
        """
        Calculate Enterprise Value using DCF

        EV = PV(FCF_1) + PV(FCF_2) + ... + PV(FCF_5) + PV(Terminal Value)

        Terminal Value = FCF_5 * (1 + g) / (WACC - g)
        """
        wacc_data = self.calculate_wacc()
        if wacc_data is None:
            return None

        wacc = wacc_data['WACC']

        # Get current free cash flow
        cash_flow = self.stock.cashflow
        if cash_flow.empty:
            return None

        fcf = cash_flow.loc['Free Cash Flow'].iloc[0] if 'Free Cash Flow' in cash_flow.index else 0

        if fcf <= 0:
            return None

        # Project 5 years of FCF (assuming 5% annual growth)
        fcf_growth = 0.05
        fcf_projections = []

        for year in range(1, 6):
            projected_fcf = fcf * ((1 + fcf_growth) ** year)
            pv_fcf = projected_fcf / ((1 + wacc) ** year)
            fcf_projections.append({
                'Year': year,
                'FCF': projected_fcf,
                'PV of FCF': pv_fcf
            })

        # Terminal value
        fcf_terminal = fcf_projections[-1]['FCF'] * (1 + terminal_growth)
        terminal_value = fcf_terminal / (wacc - terminal_growth)
        pv_terminal = terminal_value / ((1 + wacc) ** 5)

        # Enterprise Value
        pv_fcf_sum = sum([p['PV of FCF'] for p in fcf_projections])
        enterprise_value = pv_fcf_sum + pv_terminal

        # Equity value
        total_debt = wacc_data['Total Debt']
        cash = self.info.get('totalCash', 0)
        equity_value = enterprise_value - total_debt + cash

        # Shares outstanding
        shares_outstanding = self.info.get('sharesOutstanding', 1)
        fair_value_per_share = equity_value / shares_outstanding

        return {
            'FCF Projections': fcf_projections,
            'Terminal Value': terminal_value,
            'PV Terminal Value': pv_terminal,
            'Enterprise Value': enterprise_value,
            'Equity Value': equity_value,
            'Fair Value per Share': fair_value_per_share,
            'WACC': wacc
        }


class MultiSourceDataBroker:
    """
    Multi-Source Data Integration
    - Yahoo Finance (primary)
    - Alpha Vantage
    - Bloomberg (framework ready)
    """

    def __init__(self, alpha_vantage_key=None, bloomberg_available=False):
        self.alpha_vantage_key = alpha_vantage_key
        self.bloomberg_available = bloomberg_available

    def get_price_data(self, ticker, source='yahoo', period='1y'):
        """Get price data from specified source"""

        if source == 'yahoo':
            try:
                data = yf.download(ticker, period=period, progress=False)
                return data
            except Exception as e:
                st.error(f"Yahoo Finance error: {str(e)}")
                return None

        elif source == 'alpha_vantage' and self.alpha_vantage_key:
            try:
                import requests
                url = f"https://www.alphavantage.co/query?function=TIME_SERIES_DAILY_ADJUSTED&symbol={ticker}&apikey={self.alpha_vantage_key}&outputsize=full"
                response = requests.get(url)
                data = response.json()

                # Convert to DataFrame format similar to yfinance
                # (Placeholder - would need full implementation)
                st.info("Alpha Vantage integration ready")
                return None

            except Exception as e:
                st.error(f"Alpha Vantage error: {str(e)}")
                return None

        elif source == 'bloomberg' and self.bloomberg_available:
            # Placeholder for Bloomberg Terminal integration
            st.info("Bloomberg Terminal integration framework ready")
            return None

        else:
            st.warning(f"Source '{source}' not available")
            return None

    def get_multi_source_data(self, ticker, sources=['yahoo']):
        """Fetch data from multiple sources and aggregate"""
        data_dict = {}

        for source in sources:
            data = self.get_price_data(ticker, source=source)
            if data is not None:
                data_dict[source] = data

        return data_dict


# ============================================================================
# MAIN APP - EXCELLENCE EDITION
# ============================================================================

def main():
    # Ensure plotly.graph_objects is available in function scope
    import plotly.graph_objects as go

    # ============================================================================
    # EQUITY TRACKING INITIALIZATION - CRITICAL FIX FOR LEVERAGE CALCULATIONS
    # ============================================================================
    # Initialize equity tracking if not exists
    if 'equity_capital' not in st.session_state:
        st.session_state['equity_capital'] = 100000.0  # Default $100k

    if 'target_leverage' not in st.session_state:
        st.session_state['target_leverage'] = 1.0  # Default no leverage

    # ============================================================================
    # ATLAS TERMINAL HEADER - PROFESSIONAL BRANDING
    # ============================================================================

    def render_atlas_header():
        """Render ATLAS Terminal header with complete UI polish"""

        # Load BOTH CSS files - animations AND complete UI
        css_files = [
            'ui/branding/avengers_animations.css',
            'ui/branding/atlas_complete_ui.css'  # NEW - Complete UI system
        ]

        for css_file in css_files:
            css_path = Path(css_file)
            if css_path.exists():
                with open(css_path, 'r', encoding='utf-8') as f:
                    st.markdown(f'<style>{f.read()}</style>', unsafe_allow_html=True)

        # Load shield logo
        logo_path = Path('ui/branding/shield_logo.svg')
        if logo_path.exists():
            with open(logo_path, 'rb') as f:
                logo_base64 = base64.b64encode(f.read()).decode()

            # Header with seamless logo integration - NO INDENTATION to prevent code block
            header_html = f'''<div class="atlas-header-container">
<div class="atlas-shield-logo loaded">
<img src="data:image/svg+xml;base64,{logo_base64}" width="200" alt="ATLAS Shield">
</div>
<h1 style="font-family: var(--font-display, 'Inter', sans-serif); font-size: 3.5rem; font-weight: 800; color: var(--vibranium-primary, #00d4ff); margin: 30px 0 10px 0; letter-spacing: 0.05em; text-shadow: 0 0 30px var(--vibranium-glow, rgba(0, 212, 255, 0.5));">ATLAS TERMINAL</h1>
<p style="font-family: var(--font-display, 'Inter', sans-serif); font-size: 0.9rem; font-weight: 300; color: var(--silver-medium, #c0c8d0); margin: 10px 0 20px 0; letter-spacing: 0.2em; text-transform: uppercase;">INSTITUTIONAL EDITION v10.0</p>
<p style="font-family: var(--font-body, 'Inter', sans-serif); font-size: 1.1rem; font-weight: 400; color: var(--silver-bright, #ffffff); margin: 0 0 40px 0;">Institutional Intelligence. Personal Scale.</p>
</div>'''
            st.markdown(header_html, unsafe_allow_html=True)
        else:
            # Fallback if logo file missing
            fallback_html = '''<div class="atlas-header-container">
<h1 style="font-family: var(--font-display, 'Inter', sans-serif); font-size: 3.5rem; font-weight: 800; color: var(--vibranium-primary, #00d4ff); text-shadow: 0 0 30px var(--vibranium-glow, rgba(0, 212, 255, 0.5));">ATLAS TERMINAL</h1>
<p style="color: var(--silver-medium, #c0c8d0); letter-spacing: 0.2em; text-transform: uppercase;">INSTITUTIONAL EDITION v10.0</p>
<p style="color: var(--silver-bright, #ffffff);">Institutional Intelligence. Personal Scale.</p>
</div>'''
            st.markdown(fallback_html, unsafe_allow_html=True)

    # Call the header function
    render_atlas_header()

    # ============================================================================
    # CAPITAL SETTINGS - EQUITY & LEVERAGE CONFIGURATION
    # ============================================================================
    with st.expander("‚öôÔ∏è CAPITAL SETTINGS (Equity & Leverage)", expanded=False):
        st.markdown("### üí∞ Configure Your Capital Structure")

        col1, col2 = st.columns(2)

        with col1:
            equity_capital = st.number_input(
                "Your Equity Capital ($)",
                min_value=1000.0,
                max_value=100000000.0,
                value=st.session_state.get('equity_capital', 100000.0),
                step=1000.0,
                format="%.0f",
                help="Your actual capital invested (not including leverage)",
                key="equity_capital_input"
            )
            st.session_state['equity_capital'] = equity_capital

        with col2:
            target_leverage = st.slider(
                "Target Leverage",
                min_value=1.0,
                max_value=3.0,
                value=st.session_state.get('target_leverage', 1.0),
                step=0.1,
                help="Total exposure / Equity ratio (1.0x = no leverage, 2.0x = 2x leverage, 3.0x = 3x leverage)",
                key="target_leverage_input"
            )
            st.session_state['target_leverage'] = target_leverage

        # Display calculated structure
        gross_exposure_estimate = equity_capital * target_leverage

        st.markdown("---")
        st.markdown("### üìä Your Portfolio Structure")

        col1, col2, col3 = st.columns(3)

        with col1:
            st.metric(
                "üí∞ Equity Capital",
                f"${equity_capital:,.0f}",
                help="Your actual invested capital"
            )

        with col2:
            st.metric(
                "‚ö° Target Leverage",
                f"{target_leverage:.1f}x",
                help="Exposure multiplier"
            )

        with col3:
            st.metric(
                "üìä Target Gross Exposure",
                f"${gross_exposure_estimate:,.0f}",
                help="Total market exposure with leverage"
            )

        st.info(f"""
        **Understanding Your Settings:**
        - **Equity:** Your actual capital = ${equity_capital:,.0f}
        - **Leverage:** {target_leverage:.1f}x means ${target_leverage:.2f} of market exposure per $1 of equity
        - **Gross Exposure:** Total position values = ${gross_exposure_estimate:,.0f}
        - **Returns:** Calculated on your ${equity_capital:,.0f} equity (leverage amplifies % returns)
        - **Risk Metrics:** VaR/CVaR applied to your equity, not gross exposure
        """)

    # ============================================================================
    # HORIZONTAL NAVIGATION BAR - MAXIMUM SCREEN SPACE UTILIZATION
    # ============================================================================

    # Horizontal Navigation Menu (positioned at top for better hierarchy)
    page = option_menu(
        menu_title=None,
        options=[
            "üî• Phoenix Parser",
            "üè† Portfolio Home",
            "üöÄ v10.0 Analytics",
            "üìä R Analytics",
            "üíæ Database",
            "üåç Market Watch",
            "üìà Risk Analysis",
            "üíé Performance Suite",
            "üî¨ Portfolio Deep Dive",
            "üìä Multi-Factor Analysis",
            "üí∞ Valuation House",
            "üé≤ Monte Carlo Engine",
            "üßÆ Quant Optimizer",
            "üìä Leverage Tracker",
            "üì° Investopedia Live",
            "‚ÑπÔ∏è About"
        ],
        icons=["fire", "house-fill", "rocket-takeoff-fill", "graph-up-arrow", "database-fill", "globe", "graph-up", "gem", "microscope", "bar-chart-fill", "cash-coin", "dice-5-fill", "calculator-fill", "graph-up", "broadcast", "info-circle-fill"],
        menu_icon="cast",
        default_index=0,
        orientation="horizontal",  # KEY: Horizontal layout
        styles={
            "container": {
                "padding": "0!important",
                "background-color": "rgba(10, 25, 41, 0.4)",
                "border-radius": "10px",
                "margin-bottom": "20px"
            },
            "icon": {
                "color": "#00d4ff",
                "font-size": "18px"
            },
            "nav-link": {
                "font-size": "14px",
                "text-align": "center",
                "margin": "0px",
                "padding": "12px 16px",
                "border-radius": "8px",
                "--hover-color": "rgba(0, 212, 255, 0.15)",
                "color": "#ffffff",
                "white-space": "nowrap"
            },
            "nav-link-selected": {
                "background-color": "#00d4ff",
                "color": "#000000",
                "font-weight": "600",
                "box-shadow": "0 4px 12px rgba(0, 212, 255, 0.3)"
            }
        }
    )

    # ========================================================================
    # PHASE 2A: NAVIGATION ROUTING (Registry-Based)
    # ========================================================================
    # Map option_menu titles to registry keys
    PAGE_TITLE_TO_KEY = {
        "üî• Phoenix Parser": "phoenix_parser",
        "üè† Portfolio Home": "portfolio_home",
        "üöÄ v10.0 Analytics": "v10_analytics",
        "üìä R Analytics": "r_analytics",
        "üíæ Database": "database",
        "üåç Market Watch": "market_watch",
        "üìà Risk Analysis": "risk_analysis",
        "üíé Performance Suite": "performance_suite",
        "üî¨ Portfolio Deep Dive": "portfolio_deep_dive",
        "üìä Multi-Factor Analysis": "multi_factor_analysis",
        "üí∞ Valuation House": "valuation_house",
        "üé≤ Monte Carlo Engine": "monte_carlo_engine",
        "üßÆ Quant Optimizer": "quant_optimizer",
        "üìä Leverage Tracker": "leverage_tracker",
        "üì° Investopedia Live": "investopedia_live",
        "‚ÑπÔ∏è About": "about"
    }

    # Get page key from selected title
    selected_page_key = PAGE_TITLE_TO_KEY.get(page, "portfolio_home")

    st.markdown("---")

    # Time Range and Benchmark Controls (positioned below navigation)
    col1, col2 = st.columns(2)

    with col1:
        # Time Range Control
        date_options = ["1D", "1W", "1M", "3M", "6M", "YTD", "1Y", "3Y", "5Y", "MAX"]
        selected_range = st.selectbox(
            "üìÖ Time Range",
            date_options,
            index=6,  # Default to "1Y"
            key="time_range_selector"
        )

    with col2:
        # Benchmark Control
        benchmark_options = ["SPY", "QQQ", "DIA", "IWM", "VTI", "ACWI"]
        selected_benchmark = st.selectbox(
            "üéØ Benchmark",
            benchmark_options,
            index=0,  # Default to "SPY"
            key="benchmark_selector"
        )

    # ATLAS Refactoring - Phase 1: Cache Performance Stats
    if REFACTORED_MODULES_AVAILABLE:
        with st.expander("‚ö° Performance Stats", expanded=False):
            stats = cache_manager.get_stats()
            col_a, col_b, col_c = st.columns(3)

            with col_a:
                st.metric("Cache Hit Rate", stats['hit_rate'])
            with col_b:
                st.metric("Cache Hits", stats['hits'])
            with col_c:
                st.metric("Memory Keys", stats['memory_keys'])

            col_d, col_e = st.columns(2)
            with col_d:
                if st.button("üóëÔ∏è Clear Cache", use_container_width=True):
                    cache_manager.clear()
                    st.success("‚úÖ Cache cleared!")
                    st.rerun()
            with col_e:
                st.caption(f"Disk: {stats['disk_hits']} hits, {stats['disk_writes']} writes")

    st.markdown("---")

    if selected_range == "YTD":
        start_date = datetime(datetime.now().year, 1, 1)
        end_date = datetime.now()
    elif selected_range == "MAX":
        start_date = datetime(2000, 1, 1)
        end_date = datetime.now()
    else:
        days_map = {"1D": 1, "1W": 7, "1M": 30, "3M": 90, "6M": 180, "1Y": 365, "3Y": 1095, "5Y": 1825}
        days = days_map.get(selected_range, 365)
        end_date = datetime.now()
        start_date = end_date - timedelta(days=days)
    
    # ========================================================================
    # PHASE 2A: NAVIGATION V2 ROUTING (Experimental - can be toggled)
    # ========================================================================
    # Toggle between old monolithic routing and new modular navigation
    USE_NAVIGATION_V2 = st.sidebar.checkbox(
        "üß™ Use Navigation v2.0 (Experimental)",
        value=False,
        help="Enable new modular navigation system (Phase 2A)"
    )

    if USE_NAVIGATION_V2:
        # NEW: Registry-based routing
        st.info(f"üìç **Navigation v2.0 Active** - Routing to: `{selected_page_key}`")
        route_to_page(selected_page_key)

    else:
        # OLD: Monolithic if/elif routing (will be deprecated after Phase 2A testing)
        pass  # Fall through to old code below

    # ========================================================================
    # OLD NAVIGATION CODE (To be deprecated after Phase 2A complete)
    # ========================================================================
    if not USE_NAVIGATION_V2:  # Only run old code if v2 is disabled
        # ====================================================================
        # PHOENIX PARSER
        # ====================================================================
        if page == "üî• Phoenix Parser":
            st.markdown("## üî• PHOENIX MODE")
        
            col1, col2 = st.columns(2)
            
            with col1:
                st.markdown("### üìä Trade History")
                trade_file = st.file_uploader("Upload Trade History", type=['xls', 'xlsx'], key="trade")
                
                if trade_file:
                    with st.spinner("Parsing..."):
                        trade_df = parse_trade_history_file(trade_file)

                        if trade_df is not None:
                            # FIX #7: Add debug output to diagnose database save issues
                            with st.expander("üîç Debug Info - Trade File Columns", expanded=False):
                                st.write("**Columns in uploaded file:**")
                                st.write(list(trade_df.columns))
                                st.write(f"**SQL_AVAILABLE:** {SQL_AVAILABLE}")
                                if not SQL_AVAILABLE:
                                    st.warning("‚ö†Ô∏è Database not available - trades will save to cache file only")

                            save_trade_history(trade_df)
                            st.success(f"‚úÖ Parsed {len(trade_df)} trades!")

                            # CRITICAL FIX: Verify database save
                            if SQL_AVAILABLE:
                                try:
                                    db = get_db()
                                    db_count = db.read("SELECT COUNT(*) as count FROM trades").iloc[0]['count']
                                    st.success(f"üíæ Database now contains {db_count} total trade records (persistent across sessions)")

                                    # Show last 5 trades from database to confirm
                                    last_trades = db.read("SELECT * FROM trades ORDER BY date DESC LIMIT 5")
                                    if len(last_trades) > 0:
                                        with st.expander("üîç Last 5 Trades in Database", expanded=False):
                                            st.dataframe(last_trades, use_container_width=True)
                                except Exception as e:
                                    st.warning(f"‚ö†Ô∏è Could not verify database: {e}")

                            show_toast(f"Trade history imported: {len(trade_df)} trades parsed successfully", toast_type="success", duration=3000)
                            make_scrollable_table(trade_df.head(10), height=400, hide_index=True, use_container_width=True, column_config=None)

                            # Check for options that will be filtered
                            option_tickers = []
                            if 'Symbol' in trade_df.columns:
                                unique_symbols = trade_df['Symbol'].unique()
                                option_tickers = [ticker for ticker in unique_symbols if is_option_ticker(ticker)]

                            portfolio_df = calculate_portfolio_from_trades(trade_df)
                            if len(portfolio_df) > 0:
                                save_portfolio_data(portfolio_df.to_dict('records'))
                                st.success(f"üéâ Portfolio rebuilt! {len(portfolio_df)} positions")
                                show_toast(f"üî• Phoenix reconstruction complete: {len(portfolio_df)} positions rebuilt", toast_type="success", duration=4000)

                                # Show filtered options if any
                                if option_tickers:
                                    with st.expander(f"üóëÔ∏è Filtered {len(option_tickers)} option symbols"):
                                        st.info("""
                                        **Options automatically excluded from equity portfolio:**

                                        These option positions are excluded from equity analysis:
                                        """)
                                        for opt in option_tickers:
                                            st.write(f"- {opt}")

                                make_scrollable_table(portfolio_df, height=400, hide_index=True, use_container_width=True, column_config=None)
            
            with col2:
                st.markdown("### üí∞ Account History")
                account_file = st.file_uploader("Upload Account History", type=['xls', 'xlsx'], key="account")
                
                if account_file:
                    with st.spinner("Parsing..."):
                        account_df = parse_account_history_file(account_file)
                        
                        if account_df is not None:
                            save_account_history(account_df)
                            st.success(f"‚úÖ Parsed {len(account_df)} records!")
                            show_toast(f"Account history imported: {len(account_df)} records processed", toast_type="success", duration=3000)
                            make_scrollable_table(account_df.head(10), height=400, hide_index=True, use_container_width=True, column_config=None)
                            
                            leverage_info_parsed = get_leverage_info()
                            if leverage_info_parsed:
                                st.info(f"""
                                üí° Leverage Detected:
                                - Margin: ${leverage_info_parsed['margin_used']:,.2f}
                                - Leverage: {leverage_info_parsed['leverage_ratio']:.2f}x
                                """)

            # PHASE 4: Database Management Section
            st.markdown("---")
            st.markdown("### üíæ Database Management")

            col1, col2 = st.columns(2)

            with col1:
                st.markdown("#### üìä Database Status")

                if SQL_AVAILABLE:
                    try:
                        db = get_db()

                        # Check if portfolio exists in database
                        portfolio_db = db.get_portfolio()
                        portfolio_count = len(portfolio_db)

                        # Check if trades exist in database
                        trades_db = db.get_trades()
                        trades_count = len(trades_db)

                        st.success("‚úÖ Database Connected")
                        st.metric("Portfolio Positions", portfolio_count)
                        st.metric("Trade History Records", trades_count)

                        if portfolio_count > 0:
                            st.info(f"üí° Last updated: {portfolio_db['updated_at'].max() if 'updated_at' in portfolio_db.columns else 'Unknown'}")

                    except Exception as e:
                        st.error(f"‚ùå Database Error: {e}")
                else:
                    st.warning("‚ö†Ô∏è SQL database not available")
                    st.info("Portfolio data is saved to pickle cache only")

            with col2:
                st.markdown("#### üîÑ Manual Database Operations")

                # Manual save button
                if st.button("üíæ Save Current Portfolio to Database", type="primary"):
                    # Load current portfolio
                    portfolio_data = load_portfolio_data()

                    # ===== FIX #1: Robust validation =====
                    has_data = False

                    if portfolio_data is not None:
                        if isinstance(portfolio_data, pd.DataFrame):
                            has_data = not portfolio_data.empty
                        elif isinstance(portfolio_data, list):
                            has_data = len(portfolio_data) > 0

                    if not has_data:
                        st.error("‚ùå No portfolio data to save. Upload data via Phoenix Parser first.")
                    else:
                        # Convert to DataFrame if needed
                        if isinstance(portfolio_data, list):
                            df = pd.DataFrame(portfolio_data)
                        else:
                            df = portfolio_data

                        # DEBUG: Show what we're saving
                        st.info(f"üíæ Attempting to save {len(df)} positions...")

                        try:
                            import sqlite3
                            # datetime already imported globally at top of file

                            # Connect to database
                            conn = sqlite3.connect('atlas_portfolio.db', timeout=10)
                            cursor = conn.cursor()

                            # Create table if it doesn't exist
                            cursor.execute("""
                                CREATE TABLE IF NOT EXISTS portfolio_positions (
                                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                                    ticker TEXT NOT NULL,
                                    quantity REAL NOT NULL,
                                    avg_cost REAL NOT NULL,
                                    current_price REAL,
                                    total_value REAL,
                                    sector TEXT,
                                    last_updated TEXT
                                )
                            """)

                            # Clear existing positions
                            cursor.execute("DELETE FROM portfolio_positions")

                            # Save each position
                            saved_count = 0
                            for idx, row in df.iterrows():
                                try:
                                    # Handle different column name variations
                                    ticker = str(row.get('Ticker', row.get('Symbol', 'UNKNOWN')))
                                    quantity = float(row.get('Quantity', row.get('Shares', 0)))
                                    avg_cost = float(row.get('Avg Cost', row.get('Average Cost', row.get('Avg Price', 0))))
                                    current_price = float(row.get('Current Price', 0))
                                    total_value = float(row.get('Total Value', quantity * current_price if current_price else quantity * avg_cost))
                                    sector = str(row.get('Sector', 'Unknown'))

                                    cursor.execute("""
                                        INSERT INTO portfolio_positions
                                        (ticker, quantity, avg_cost, current_price, total_value, sector, last_updated)
                                        VALUES (?, ?, ?, ?, ?, ?, ?)
                                    """, (
                                        ticker,
                                        quantity,
                                        avg_cost,
                                        current_price,
                                        total_value,
                                        sector,
                                        datetime.now().strftime('%Y-%m-%d %H:%M:%S')
                                    ))
                                    saved_count += 1
                                except Exception as row_error:
                                    st.warning(f"‚ö†Ô∏è Skipped {row.get('Ticker', row.get('Symbol', 'unknown'))}: {row_error}")

                            conn.commit()
                            conn.close()

                            st.success(f"‚úÖ Successfully saved {saved_count} positions to database!")
                            st.balloons()

                        except Exception as e:
                            st.error(f"‚ùå Database save failed: {str(e)}")
                            import traceback
                            st.code(traceback.format_exc())

                # Debug database state button
                if st.button("üîç Debug Database State"):
                    try:
                        import sqlite3
                        conn = sqlite3.connect('atlas_portfolio.db')
                        result = pd.read_sql("SELECT * FROM portfolio_positions", conn)
                        st.write(f"**Database has {len(result)} positions**")
                        if len(result) > 0:
                            make_scrollable_table(result, height=400, hide_index=True, use_container_width=True)
                        else:
                            st.info("No positions found in database")
                        conn.close()
                    except Exception as e:
                        st.error(f"Error reading database: {e}")

                # Clear database button
                if st.button("üóëÔ∏è Clear Database (Keep Pickle Cache)"):
                    if SQL_AVAILABLE:
                        try:
                            db = get_db()
                            db.execute("DELETE FROM holdings")
                            st.success("‚úÖ Database cleared (pickle cache preserved)")
                            show_toast("Database cleared successfully", toast_type="info", duration=2000)
                        except Exception as e:
                            st.error(f"‚ùå Clear failed: {e}")
                    else:
                        st.error("‚ùå SQL database not available")

                st.info("""
                **‚ÑπÔ∏è Auto-Save:**
                Portfolio data is automatically saved to both:
                - üíæ SQL Database (persistent)
                - üì¶ Pickle Cache (backup)

                Use the manual save button to force a database update.
                """)

            # ===== FIX #8: LEVERAGE TRACKING FEATURE =====
            st.markdown("---")
            st.markdown("### üìä Leverage Tracking (Optional)")
            st.info("üìà Upload your Investopedia performance-history.xls file to enable leverage analysis")

            perf_history_file = st.file_uploader(
                "üìà Upload Performance History",
                type=['xls', 'xlsx', 'html'],
                help="Upload your Investopedia performance-history.xls file for leverage tracking",
                key="perf_history"
            )

            if perf_history_file is not None:
                try:
                    # Save uploaded file temporarily
                    import tempfile
                    with tempfile.NamedTemporaryFile(delete=False, suffix='.xls') as tmp_file:
                        tmp_file.write(perf_history_file.getvalue())
                        tmp_path = tmp_file.name

                    # Parse leverage data
                    from analytics.leverage_tracker import LeverageTracker

                    tracker = LeverageTracker(tmp_path)

                    if tracker.load_and_parse():
                        # Get current stats
                        stats = tracker.get_current_stats()

                        # Display current leverage
                        st.success("‚úÖ Performance history loaded!")

                        col1, col2, col3, col4 = st.columns(4)

                        with col1:
                            st.metric(
                                "Current Leverage",
                                f"{stats['current_leverage']:.2f}x",
                                help="Gross Exposure / Net Equity"
                            )

                        with col2:
                            st.metric(
                                "Net Equity",
                                f"${stats['current_equity']:,.0f}",
                                help="Account Value (Column F)"
                            )

                        with col3:
                            st.metric(
                                "Gross Exposure",
                                f"${stats['current_gross_exposure']:,.0f}",
                                help="Total position value"
                            )

                        with col4:
                            st.metric(
                                "Avg Leverage",
                                f"{stats['avg_leverage']:.2f}x",
                                help="Historical average"
                            )

                        # Store in session state for other pages
                        st.session_state.leverage_tracker = tracker

                        # FIX #5: Auto-update equity capital from performance history
                        if 'current_equity' in stats:
                            st.session_state['equity_capital'] = stats['current_equity']
                            st.info(f"üí∞ Equity capital auto-set to ${stats['current_equity']:,.0f} from performance history")

                        # Show dashboard
                        with st.expander("üìä View Leverage Dashboard", expanded=True):
                            fig = tracker.create_leverage_dashboard()
                            st.plotly_chart(fig, use_container_width=True)

                        # Show calculation workings
                        with st.expander("üßÆ Calculation Workings"):
                            workings = tracker.create_workings_display()
                            st.markdown(workings)

                        show_toast("Leverage tracking enabled! Visit the Leverage Tracker page for full analysis", toast_type="success", duration=4000)
                    else:
                        st.error("‚ùå Could not parse performance history file")

                except Exception as e:
                    st.error(f"Error loading performance history: {e}")
                    import traceback
                    st.code(traceback.format_exc())

        # ========================================================================
        # v10.0 ANALYTICS - NEW ADVANCED FEATURES
        # ========================================================================
        elif page == "üöÄ v10.0 Analytics":
            st.markdown("## üöÄ ATLAS v10.0 ADVANCED ANALYTICS")
    
            if not V10_MODULES_AVAILABLE:
                st.error("‚ùå v10.0 modules not available. Please check installation.")
                st.stop()
            st.success("‚úÖ All v10.0 Advanced Modules Loaded")
    
            # Create tabs for different v10.0 features
            tabs = st.tabs([
                "üé≤ Monte Carlo",
                "üìä Risk Metrics",
                "üí∞ DCF Valuation",
                "üî• Phoenix Mode",
                "üìà Attribution",
                "üé® Enhanced Charts"
            ])
    
            # Tab 1: Monte Carlo Simulation
            with tabs[0]:
                st.markdown("### üé≤ Monte Carlo Portfolio Simulation")
    
                portfolio_data = load_portfolio_data()
                if portfolio_data is None or (isinstance(portfolio_data, pd.DataFrame) and portfolio_data.empty):
                    st.warning("‚ö†Ô∏è Upload portfolio data via Phoenix Parser first")
                else:
                    df = pd.DataFrame(portfolio_data)
    
                    # Auto-populate from performance history
                    metrics = get_current_portfolio_metrics()
                    default_value = int(metrics['equity']) if metrics else 100000

                    if metrics:
                        st.success(f"üìä Using current portfolio equity: {format_currency(metrics['equity'])}")

                    col1, col2 = st.columns(2)
                    with col1:
                        n_simulations = st.slider("Number of Simulations", 1000, 20000, 5000, 1000)
                        n_days = st.slider("Time Horizon (days)", 30, 365, 252)
                    with col2:
                        confidence_level = st.slider("Confidence Level", 0.90, 0.99, 0.95, 0.01)
                        initial_value = st.number_input("Portfolio Value ($)", value=default_value, step=10000, help="Auto-populated from performance history" if metrics else "Upload performance history to auto-populate")
    
                    if st.button("üé≤ Run Monte Carlo Simulation", type="primary"):
                        with st.spinner("Running simulations..."):
                            try:
                                # Get historical returns (placeholder - use actual data)
                                tickers = df['Ticker'].tolist() if 'Ticker' in df.columns else []
                                if len(tickers) > 0:
                                    returns = yf.download(tickers, period="1y", progress=False)['Close'].pct_change().dropna()
                                    weights = np.array([1/len(tickers)] * len(tickers))
    
                                    mc = MonteCarloSimulation(returns, weights, initial_value=initial_value)
                                    var_result = mc.calculate_var_cvar(n_simulations=n_simulations, n_days=n_days, confidence_level=confidence_level)
    
                                    # Display results
                                    col1, col2, col3 = st.columns(3)
                                    col1.metric("VaR", f"${var_result['var_dollar']:,.0f}", f"{var_result['var_pct']:.2f}%")
                                    col2.metric("CVaR", f"${var_result['cvar_dollar']:,.0f}", f"{var_result['cvar_pct']:.2f}%")
                                    col3.metric("Simulations", f"{n_simulations:,}")
    
                                    st.success(f"‚úÖ Simulation complete! {n_simulations:,} paths analyzed")
                                else:
                                    st.warning("No tickers found in portfolio")
                            except Exception as e:
                                st.error(f"Error: {str(e)}")
    
            # Tab 2: Advanced Risk Metrics
            with tabs[1]:
                st.markdown("### üìä Advanced Risk Metrics")
    
                portfolio_data = load_portfolio_data()
                if portfolio_data is None or (isinstance(portfolio_data, pd.DataFrame) and portfolio_data.empty):
                    st.warning("‚ö†Ô∏è Upload portfolio data via Phoenix Parser first")
                else:
                    df = pd.DataFrame(portfolio_data)
    
                    if st.button("üìä Calculate Risk Metrics", type="primary"):
                        with st.spinner("Calculating metrics..."):
                            try:
                                tickers = df['Ticker'].tolist() if 'Ticker' in df.columns else []
                                if len(tickers) > 0:
                                    returns_data = yf.download(tickers, period="1y", progress=False)['Close'].pct_change().dropna()
                                    portfolio_returns = returns_data.mean(axis=1)
    
                                    # Benchmark (SPY)
                                    spy = yf.download('SPY', period="1y", progress=False)['Close'].pct_change().dropna()
    
                                    risk = RiskAnalytics(portfolio_returns, spy)
                                    metrics = risk.comprehensive_metrics(risk_free_rate=0.03)
    
                                    # Display metrics
                                    col1, col2, col3, col4 = st.columns(4)
                                    col1.metric("Sharpe Ratio", f"{metrics['sharpe_ratio']:.3f}")
                                    col2.metric("Sortino Ratio", f"{metrics['sortino_ratio']:.3f}")
                                    col3.metric("Beta", f"{metrics['beta']:.3f}")
                                    col4.metric("Alpha", f"{metrics['alpha']:.2f}%")
    
                                    col1, col2, col3 = st.columns(3)
                                    col1.metric("Max Drawdown", f"{metrics['max_drawdown']:.2f}%")
                                    col2.metric("Annual Return", f"{metrics['annual_return']:.2f}%")
                                    col3.metric("Annual Volatility", f"{metrics['annual_volatility']:.2f}%")
    
                                    st.success("‚úÖ Risk metrics calculated successfully")
                                else:
                                    st.warning("No tickers found in portfolio")
                            except Exception as e:
                                st.error(f"Error: {str(e)}")
    
            # Tab 3: DCF Valuation
            with tabs[2]:
                st.markdown("### üí∞ DCF Intrinsic Value Calculator")
    
                ticker = st.text_input("Enter Ticker Symbol", value="AAPL")
    
                col1, col2, col3 = st.columns(3)
                with col1:
                    projection_years = st.slider("Projection Years", 3, 10, 5)
                with col2:
                    growth_rate = st.slider("Growth Rate (%)", 0, 20, 8) / 100
                with col3:
                    terminal_growth = st.slider("Terminal Growth (%)", 0, 5, 3) / 100
    
                if st.button("üí∞ Calculate DCF", type="primary"):
                    with st.spinner(f"Analyzing {ticker}..."):
                        try:
                            dcf = DCFValuation(ticker)
                            result = dcf.calculate_intrinsic_value(
                                projection_years=projection_years,
                                growth_rate=growth_rate,
                                terminal_growth_rate=terminal_growth
                            )
    
                            col1, col2, col3 = st.columns(3)
                            col1.metric("Intrinsic Value", f"${result['intrinsic_value']:.2f}")
                            col2.metric("Current Price", f"${result['current_price']:.2f}")
                            col3.metric("Upside/Downside", f"{result['upside_pct']:.1f}%")
    
                            if result['upside_pct'] > 20:
                                st.success("üü¢ Signal: UNDERVALUED")
                            elif result['upside_pct'] < -20:
                                st.error("üî¥ Signal: OVERVALUED")
                            else:
                                st.info("üü° Signal: FAIRLY VALUED")
    
                            st.metric("WACC", f"{result['wacc']*100:.2f}%")
                        except Exception as e:
                            st.error(f"Error: {str(e)}")
    
            # Tab 4: Phoenix Mode
            with tabs[3]:
                st.markdown("### üî• Phoenix Mode - Portfolio Reconstruction")
    
                st.markdown("Upload a CSV file with trade history:")
                st.code("Required columns: Date, Ticker, Action, Quantity, Price", language="text")
    
                uploaded_file = st.file_uploader("Upload Trade History CSV", type=['csv'])
    
                if uploaded_file:
                    with st.spinner("Reconstructing portfolio..."):
                        try:
                            phoenix = PhoenixMode()
                            trades = phoenix.load_trade_history(uploaded_file)
    
                            st.success(f"‚úÖ Loaded {len(trades)} trades")
                            make_scrollable_table(trades, height=400, hide_index=True, use_container_width=True)
    
                            # Get current prices (you'd fetch these from API)
                            tickers = trades['Ticker'].unique()
                            current_prices = {}
                            for ticker in tickers:
                                try:
                                    price = yf.Ticker(ticker).history(period='1d')['Close'].iloc[-1]
                                    current_prices[ticker] = price
                                except:
                                    current_prices[ticker] = 0
    
                            portfolio = phoenix.reconstruct_portfolio(current_prices)
    
                            col1, col2, col3, col4 = st.columns(4)
                            col1.metric("Positions", portfolio['total_positions'])
                            col2.metric("Total Cost", f"${portfolio['total_cost']:,.2f}")
                            col3.metric("Current Value", f"${portfolio['current_value']:,.2f}")
                            col4.metric("Total P&L", f"${portfolio['total_pnl']:,.2f}", f"{portfolio['total_return_pct']:.2f}%")
    
                            summary = phoenix.get_portfolio_summary(current_prices)
                            make_scrollable_table(summary, height=400, hide_index=True, use_container_width=True)
    
                        except Exception as e:
                            st.error(f"Error: {str(e)}")
    
            # Tab 5: Performance Attribution
            with tabs[4]:
                st.markdown("### üìà Performance Attribution Analysis")
    
                portfolio_data = load_portfolio_data()
                if portfolio_data is None or (isinstance(portfolio_data, pd.DataFrame) and portfolio_data.empty):
                    st.warning("‚ö†Ô∏è Upload portfolio data via Phoenix Parser first")
                else:
                    df = pd.DataFrame(portfolio_data)
    
                    if st.button("üìà Calculate Attribution", type="primary"):
                        with st.spinner("Analyzing..."):
                            try:
                                # Prepare data
                                weights = {}
                                total_value = df['Total Value'].sum() if 'Total Value' in df.columns else 1
    
                                for _, row in df.iterrows():
                                    ticker = row['Ticker']
                                    value = row['Total Value'] if 'Total Value' in df.columns else 1
                                    weights[ticker] = value / total_value
    
                                # ===== FIX #4: Get returns, sectors, and include weights =====
                                asset_data_list = []
                                for ticker in weights.keys():
                                    try:
                                        stock = yf.Ticker(ticker)
                                        hist = stock.history(period='1mo')
                                        ret = (hist['Close'].iloc[-1] / hist['Close'].iloc[0] - 1)
                                        sector = stock.info.get('sector', 'Unknown')
                                        # ‚úÖ Include actual weight in asset data
                                        asset_data_list.append({
                                            'ticker': ticker,
                                            'sector': sector,
                                            'return': ret,
                                            'weight': weights[ticker] * 100  # Convert to percentage
                                        })
                                    except:
                                        pass
    
                                if len(asset_data_list) > 0:
                                    asset_data = pd.DataFrame(asset_data_list)
                                    attribution = PerformanceAttribution(weights, asset_data)
    
                                    st.markdown("#### Stock-Level Contribution")
                                    stock_contrib = attribution.stock_contribution()
                                    make_scrollable_table(stock_contrib, height=400, hide_index=True, use_container_width=True)
    
                                    st.markdown("#### Sector-Level Attribution (Brinson-Fachler Model)")
                                    sector_contrib = attribution.sector_attribution()
                                    make_scrollable_table(sector_contrib, height=400, hide_index=True, use_container_width=True)
    
                                    # ===== FIX #5: Calculate and Display Skill Scores =====
                                    if 'Allocation Effect' in sector_contrib.columns and 'Selection Effect' in sector_contrib.columns:
                                        st.markdown("---")

                                        # Calculate total effects
                                        total_allocation = sector_contrib['Allocation Effect'].sum()
                                        total_selection = sector_contrib['Selection Effect'].sum()
                                        total_interaction = sector_contrib['Interaction Effect'].sum() if 'Interaction Effect' in sector_contrib.columns else 0
                                        total_active_return = total_allocation + total_selection + total_interaction

                                        # Skill scoring: 0-10 scale where 5 = neutral (0% effect)
                                        allocation_score = max(0, min(10, 5 + total_allocation))
                                        selection_score = max(0, min(10, 5 + total_selection))

                                        # Determine colors and status
                                        alloc_color = '#00ff9d' if total_allocation > 0 else '#ff006b'
                                        select_color = '#00ff9d' if total_selection > 0 else '#ff006b'
                                        active_color = '#00ff9d' if total_active_return > 0 else '#ff006b'

                                        alloc_status = '‚úì Strong sector rotation' if total_allocation > 1 else '‚óã Neutral' if total_allocation > -1 else '‚úó Poor allocation'
                                        select_status = '‚úì Strong stock picks' if total_selection > 1 else '‚óã Neutral' if total_selection > -1 else '‚úó Poor selection'

                                        # Determine primary skill
                                        if allocation_score > selection_score + 2:
                                            primary_skill = "Sector Timing (Allocation)"
                                            recommendation = "Focus on sector rotation strategies. Consider using sector ETFs."
                                        elif selection_score > allocation_score + 2:
                                            primary_skill = "Stock Picking (Selection)"
                                            recommendation = "Focus on fundamental analysis. Your stock picks add value."
                                        else:
                                            primary_skill = "Balanced"
                                            recommendation = "Continue current strategy - both skills are comparable."

                                        # Glassmorphism styled skill assessment card
                                        skill_html = f"""
<div style="background: rgba(26, 35, 50, 0.7); backdrop-filter: blur(10px); -webkit-backdrop-filter: blur(10px); border: 1px solid rgba(0, 212, 255, 0.2); border-radius: 12px; padding: 24px; margin: 20px 0; font-family: 'Inter', -apple-system, BlinkMacSystemFont, sans-serif;">
<h3 style="font-family: 'Inter', sans-serif; font-size: 1.2rem; font-weight: 700; color: #00d4ff; text-transform: uppercase; letter-spacing: 0.1em; margin: 0 0 20px 0; text-shadow: 0 0 10px rgba(0, 212, 255, 0.3);">üéØ Portfolio Management Skill Assessment</h3>
<div style="display: grid; grid-template-columns: 1fr 1fr 1fr; gap: 16px;">
<div style="background: rgba(10, 15, 26, 0.6); border: 1px solid rgba(0, 212, 255, 0.15); border-radius: 8px; padding: 16px;">
<div style="font-family: 'Inter', sans-serif; font-size: 0.7rem; font-weight: 600; color: #8890a0; text-transform: uppercase; letter-spacing: 0.1em; margin-bottom: 8px;">ALLOCATION SKILL</div>
<div style="font-family: 'JetBrains Mono', monospace; font-size: 2rem; font-weight: 700; color: {alloc_color}; text-shadow: 0 0 15px {alloc_color}40;">{allocation_score:.1f}/10</div>
<div style="font-family: 'Inter', sans-serif; font-size: 0.85rem; color: #c0c8d0; margin-top: 6px;">Effect: {total_allocation:+.2f}%</div>
<div style="font-family: 'Inter', sans-serif; font-size: 0.7rem; color: {alloc_color}; margin-top: 6px;">{alloc_status}</div>
</div>
<div style="background: rgba(10, 15, 26, 0.6); border: 1px solid rgba(0, 212, 255, 0.15); border-radius: 8px; padding: 16px;">
<div style="font-family: 'Inter', sans-serif; font-size: 0.7rem; font-weight: 600; color: #8890a0; text-transform: uppercase; letter-spacing: 0.1em; margin-bottom: 8px;">SELECTION SKILL</div>
<div style="font-family: 'JetBrains Mono', monospace; font-size: 2rem; font-weight: 700; color: {select_color}; text-shadow: 0 0 15px {select_color}40;">{selection_score:.1f}/10</div>
<div style="font-family: 'Inter', sans-serif; font-size: 0.85rem; color: #c0c8d0; margin-top: 6px;">Effect: {total_selection:+.2f}%</div>
<div style="font-family: 'Inter', sans-serif; font-size: 0.7rem; color: {select_color}; margin-top: 6px;">{select_status}</div>
</div>
<div style="background: rgba(10, 15, 26, 0.6); border: 1px solid rgba(0, 212, 255, 0.15); border-radius: 8px; padding: 16px;">
<div style="font-family: 'Inter', sans-serif; font-size: 0.7rem; font-weight: 600; color: #8890a0; text-transform: uppercase; letter-spacing: 0.1em; margin-bottom: 8px;">TOTAL ACTIVE RETURN</div>
<div style="font-family: 'JetBrains Mono', monospace; font-size: 2rem; font-weight: 700; color: {active_color}; text-shadow: 0 0 15px {active_color}40;">{total_active_return:+.2f}%</div>
<div style="font-family: 'Inter', sans-serif; font-size: 0.85rem; color: #c0c8d0; margin-top: 6px;">Interaction: {total_interaction:+.2f}%</div>
<div style="font-family: 'Inter', sans-serif; font-size: 0.7rem; color: {active_color}; margin-top: 6px;">{'‚úì Outperforming' if total_active_return > 0 else '‚úó Underperforming'}</div>
</div>
</div>
<div style="background: linear-gradient(90deg, rgba(0, 212, 255, 0.1) 0%, transparent 100%); border-left: 3px solid #00d4ff; padding: 12px 16px; margin-top: 20px; border-radius: 4px;">
<div style="font-family: 'Inter', sans-serif; font-size: 0.75rem; font-weight: 700; color: #00d4ff; text-transform: uppercase; letter-spacing: 0.1em; margin-bottom: 4px;">üí° Primary Strength: {primary_skill}</div>
<div style="font-family: 'Inter', sans-serif; font-size: 0.85rem; color: #c0c8d0;">{recommendation}</div>
</div>
</div>
"""
                                        st.markdown(skill_html, unsafe_allow_html=True)
    
                                    st.success("‚úÖ Attribution analysis complete")
                                else:
                                    st.warning("Could not fetch data for analysis")
                            except Exception as e:
                                st.error(f"Error: {str(e)}")
    
            # ===== FIX #9: Enhanced Charts Quality =====
            # Tab 6: Truly Enhanced Charts
            with tabs[5]:
                # ===== FIX #2: Import required modules for this tab =====
                try:
                    import plotly.express as px
                    import plotly.graph_objects as go
                    import numpy as np
                    from scipy import stats
                except ImportError as e:
                    st.error(f"‚ùå Missing dependency: {e}")
                    st.code("pip install plotly scipy numpy")
                    st.stop()
    
                st.markdown("### üé® Enhanced Plotly Visualizations")
                st.markdown("Professional-grade charts with Bloomberg Terminal quality")
    
                portfolio_data = load_portfolio_data()
    
                if portfolio_data is None or (isinstance(portfolio_data, pd.DataFrame) and portfolio_data.empty):
                    st.warning("‚ö†Ô∏è Upload portfolio data via Phoenix Parser first")
                else:
                    df = pd.DataFrame(portfolio_data) if isinstance(portfolio_data, list) else portfolio_data
    
                    # ===== CHART 1: Advanced Portfolio Allocation =====
                    st.markdown("#### üìä Portfolio Allocation")
    
                    weights = {}
                    total_value = df['Total Value'].sum() if 'Total Value' in df.columns else 1
    
                    for _, row in df.iterrows():
                        ticker = row['Ticker']
                        value = row['Total Value'] if 'Total Value' in df.columns else 1
                        weights[ticker] = value / total_value
    
                    # Create sunburst chart (more advanced than donut)
                    allocation_data = []
                    for ticker, weight in weights.items():
                        ticker_data = df[df['Ticker'] == ticker].iloc[0]
                        sector = ticker_data.get('Sector', 'Unknown')
    
                        allocation_data.append({
                            'Ticker': ticker,
                            'Sector': sector,
                            'Weight': weight * 100,
                            'Value': weight * total_value
                        })
    
                    allocation_df = pd.DataFrame(allocation_data)
    
                    fig_allocation = px.sunburst(
                        allocation_df,
                        path=['Sector', 'Ticker'],
                        values='Weight',
                        color='Weight',
                        color_continuous_scale='Viridis',
                        title='Portfolio Allocation by Sector & Ticker'
                    )
    
                    fig_allocation.update_layout(
                        paper_bgcolor='rgba(0,0,0,0)',
                        plot_bgcolor='rgba(10,25,41,0.3)',
                        font=dict(color='white', size=12),
                        height=600
                    )
    
                    st.plotly_chart(fig_allocation, use_container_width=True)
    
                    # ===== CHART 2: Returns Distribution with Statistics =====
                    st.markdown("#### üìà Returns Distribution Analysis")
    
                    tickers = df['Ticker'].tolist() if 'Ticker' in df.columns else []
    
                    if len(tickers) > 0:
                        try:
                            # Fetch 1 year of data
                            hist_data = yf.download(tickers, period="1y", progress=False)['Close']
    
                            if isinstance(hist_data, pd.Series):
                                hist_data = hist_data.to_frame()
    
                            # Calculate daily returns
                            returns = hist_data.pct_change().dropna()
    
                            # Calculate portfolio returns (weighted average)
                            portfolio_returns = pd.Series(0, index=returns.index)
                            for ticker, weight in weights.items():
                                if ticker in returns.columns:
                                    portfolio_returns += returns[ticker] * weight
    
                            # Create distribution plot with annotations
                            from scipy import stats
    
                            fig_dist = go.Figure()
    
                            # Histogram
                            fig_dist.add_trace(go.Histogram(
                                x=portfolio_returns * 100,
                                name='Daily Returns',
                                nbinsx=50,
                                marker_color='rgba(0, 212, 255, 0.6)',
                                showlegend=False
                            ))
    
                            # Add normal distribution overlay
                            mu = portfolio_returns.mean() * 100
                            sigma = portfolio_returns.std() * 100
                            x_range = np.linspace(portfolio_returns.min() * 100,
                                                portfolio_returns.max() * 100, 100)
                            y_range = stats.norm.pdf(x_range, mu, sigma) * len(portfolio_returns) * \
                                    (portfolio_returns.max() - portfolio_returns.min()) * 100 / 50
    
                            fig_dist.add_trace(go.Scatter(
                                x=x_range,
                                y=y_range,
                                mode='lines',
                                name='Normal Distribution',
                                line=dict(color='#00ff9d', width=2, dash='dash')
                            ))
    
                            # Add statistics annotations
                            fig_dist.add_annotation(
                                x=0.02, y=0.98,
                                xref='paper', yref='paper',
                                text=f'<b>Statistics</b><br>Mean: {mu:.3f}%<br>Std Dev: {sigma:.3f}%<br>' + \
                                    f'Skew: {portfolio_returns.skew():.3f}<br>Kurtosis: {portfolio_returns.kurtosis():.3f}',
                                showarrow=False,
                                align='left',
                                bgcolor='rgba(10,25,41,0.8)',
                                bordercolor='#00d4ff',
                                borderwidth=1,
                                font=dict(color='white', size=11)
                            )
    
                            fig_dist.update_layout(
                                title='Portfolio Returns Distribution (1 Year)',
                                xaxis_title='Daily Return (%)',
                                yaxis_title='Frequency',
                                paper_bgcolor='rgba(0,0,0,0)',
                                plot_bgcolor='rgba(10,25,41,0.3)',
                                font=dict(color='white'),
                                height=500
                            )
    
                            st.plotly_chart(fig_dist, use_container_width=True)
    
                            # ===== CHART 3: Correlation Network Graph =====
                            st.markdown("#### üîó Correlation Network")
    
                            if len(tickers) > 1:
                                corr_matrix = returns.corr()
    
                                # Create network graph
                                fig_network = go.Figure()
    
                                # Add nodes
                                for i, ticker in enumerate(tickers):
                                    fig_network.add_trace(go.Scatter(
                                        x=[i],
                                        y=[0],
                                        mode='markers+text',
                                        marker=dict(size=30, color='#00d4ff'),
                                        text=[ticker],
                                        textposition='top center',
                                        name=ticker,
                                        showlegend=False
                                    ))
    
                                # Add edges for strong correlations (>0.5)
                                for i, ticker1 in enumerate(tickers):
                                    for j, ticker2 in enumerate(tickers):
                                        if i < j and ticker1 in corr_matrix.columns and ticker2 in corr_matrix.columns:
                                            if abs(corr_matrix.loc[ticker1, ticker2]) > 0.5:
                                                corr_val = corr_matrix.loc[ticker1, ticker2]
                                                color = '#00ff9d' if corr_val > 0 else '#ff0055'
    
                                                fig_network.add_trace(go.Scatter(
                                                    x=[i, j],
                                                    y=[0, 0],
                                                    mode='lines',
                                                    line=dict(
                                                        color=color,
                                                        width=abs(corr_val) * 3
                                                    ),
                                                    showlegend=False,
                                                    hovertext=f'{ticker1}-{ticker2}: {corr_val:.2f}'
                                                ))
    
                                fig_network.update_layout(
                                    title='Asset Correlation Network (|r| > 0.5)',
                                    xaxis=dict(visible=False),
                                    yaxis=dict(visible=False),
                                    paper_bgcolor='rgba(0,0,0,0)',
                                    plot_bgcolor='rgba(10,25,41,0.3)',
                                    height=400
                                )
    
                                st.plotly_chart(fig_network, use_container_width=True)
    
                            # ===== CHART 4: Rolling Metrics =====
                            st.markdown("#### üìâ Rolling Sharpe Ratio (90-Day)")
    
                            rolling_sharpe = (portfolio_returns.rolling(90).mean() /
                                            portfolio_returns.rolling(90).std() * np.sqrt(252))
    
                            fig_sharpe = go.Figure()
    
                            fig_sharpe.add_trace(go.Scatter(
                                x=rolling_sharpe.index,
                                y=rolling_sharpe,
                                mode='lines',
                                fill='tozeroy',
                                line=dict(color='#00d4ff', width=2),
                                fillcolor='rgba(0, 212, 255, 0.2)',
                                name='Rolling Sharpe'
                            ))
    
                            # Add reference line at Sharpe = 1
                            fig_sharpe.add_hline(
                                y=1,
                                line_dash="dash",
                                line_color="#00ff9d",
                                annotation_text="Sharpe = 1 (Good)"
                            )
    
                            fig_sharpe.update_layout(
                                title='Rolling 90-Day Sharpe Ratio',
                                xaxis_title='Date',
                                yaxis_title='Sharpe Ratio',
                                paper_bgcolor='rgba(0,0,0,0)',
                                plot_bgcolor='rgba(10,25,41,0.3)',
                                font=dict(color='white'),
                                height=400
                            )
    
                            st.plotly_chart(fig_sharpe, use_container_width=True)
    
                            st.success("‚úÖ All enhanced charts generated successfully")
    
                        except Exception as e:
                            st.error(f"Error generating charts: {str(e)}")
                            import traceback
                            st.code(traceback.format_exc())
    
        # ========================================================================
        # R ANALYTICS - ADVANCED QUANT MODELS (v11.0)
        # ========================================================================
        elif page == "üìä R Analytics":
            st.markdown("## üìä R ANALYTICS - ADVANCED QUANTITATIVE MODELS")
    
            if not R_AVAILABLE:
                st.error("‚ùå R Analytics Requires Manual Setup")
    
                st.markdown("""
                ### üìã R Analytics Setup Instructions
    
                R analytics requires packages that cannot be installed from within the app.
                You must install these dependencies **before** running the application.
    
                ---
    
                #### üîß For Google Colab Users:
    
                1. Create a new code cell **ABOVE** your Streamlit app cell
                2. Run this code:
    
                ```python
                # Install R and packages (takes 3-5 minutes)
                !apt-get update -qq
                !apt-get install -y r-base r-base-dev
                !R -e "install.packages(c('rugarch', 'copula', 'xts'), repos='https://cloud.r-project.org')"
                !pip install rpy2
                ```
    
                3. Wait for installation to complete
                4. Restart your Streamlit app
                5. R Analytics will then be available
    
                ---
    
                #### üíª For Local Deployment (Linux/MacOS):
    
                ```bash
                # Install R
                sudo apt-get update
                sudo apt-get install -y r-base r-base-dev
    
                # Install R packages
                R -e "install.packages(c('rugarch', 'copula', 'xts'), repos='https://cloud.r-project.org')"
    
                # Install Python bridge
                pip install rpy2
                ```
    
                ---
    
                #### ü™ü For Windows:
    
                1. Download and install R from: https://cran.r-project.org/bin/windows/base/
                2. Open R console and run:
                   ```r
                   install.packages(c('rugarch', 'copula', 'xts'))
                   ```
                3. Install rpy2:
                   ```bash
                   pip install rpy2
                   ```
    
                ---
                """)
    
                # Add status check
                st.markdown("### üîç Package Status Check")
    
                col1, col2, col3 = st.columns(3)
    
                with col1:
                    try:
                        import rpy2
                        st.success("‚úÖ rpy2 installed")
                    except ImportError:
                        st.error("‚ùå rpy2 missing")
                        st.caption("Run: `pip install rpy2`")
    
                with col2:
                    try:
                        from rpy2.robjects.packages import importr
                        importr('rugarch')
                        st.success("‚úÖ rugarch available")
                    except:
                        st.error("‚ùå rugarch missing")
                        st.caption("Install in R")
    
                with col3:
                    try:
                        from rpy2.robjects.packages import importr
                        importr('copula')
                        st.success("‚úÖ copula available")
                    except:
                        st.error("‚ùå copula missing")
                        st.caption("Install in R")
    
                return
    
            # Initialize R analytics
            try:
                r = get_r()
                st.success("‚úÖ R Analytics Engine Ready")
            except Exception as e:
                st.error(f"Error initializing R: {str(e)}")
                return
    
            # Create tabs
            tabs = st.tabs(["üìà GARCH Volatility", "üîó Copula Analysis", "üé≤ Custom R Code"])
    
            # Tab 1: GARCH Volatility Modeling
            with tabs[0]:
                st.markdown("### üìà GARCH Volatility Forecasting")
                st.markdown("Fit GARCH models to estimate conditional volatility and forecast future volatility")
    
                portfolio_data = load_portfolio_data()
                if portfolio_data is None or (isinstance(portfolio_data, pd.DataFrame) and portfolio_data.empty):
                    st.warning("‚ö†Ô∏è Upload portfolio data via Phoenix Parser first")
                else:
                    df = pd.DataFrame(portfolio_data)
    
                    # Ticker selection
                    ticker = st.selectbox("Select Ticker", df['Ticker'].tolist() if 'Ticker' in df.columns else [])
    
                    col1, col2 = st.columns(2)
                    with col1:
                        model_type = st.selectbox("GARCH Model", ["sGARCH", "eGARCH", "gjrGARCH"])
                    with col2:
                        forecast_days = st.number_input("Forecast Horizon (days)", 1, 30, 10)
    
                    if st.button("üéØ Fit GARCH Model", type="primary"):
                        with st.spinner(f"Fitting {model_type} model to {ticker}..."):
                            try:
                                # Get historical data
                                stock_data = yf.download(ticker, period="1y", progress=False)
                                returns = stock_data['Close'].pct_change().dropna()
    
                                # Fit GARCH model using R
                                result = r.garch_volatility(returns, model=model_type)
    
                                # Display metrics
                                col1, col2, col3 = st.columns(3)
                                col1.metric("Current Volatility", f"{result['last_volatility']*100:.2f}%")
                                col2.metric("Mean Volatility", f"{result['mean_volatility']*100:.2f}%")
                                col3.metric("Model Type", result['model'])
    
                                # Plot volatility
                                import plotly.graph_objects as go
                                fig = go.Figure()
                                fig.add_trace(go.Scatter(
                                    y=result['volatility'] * 100,
                                    mode='lines',
                                    name=f'{model_type} Volatility',
                                    line=dict(color='#00d4ff', width=2)
                                ))
                                fig.update_layout(
                                    title=f"{ticker} - Conditional Volatility ({model_type})",
                                    xaxis_title="Time",
                                    yaxis_title="Volatility (%)",
                                    height=400,
                                    template='plotly_dark',
                                    paper_bgcolor='rgba(0,0,0,0)',
                                    plot_bgcolor='rgba(10,25,41,0.3)'
                                )
                                st.plotly_chart(fig, use_container_width=True)
    
                                st.success(f"‚úÖ {model_type} model fitted successfully to {ticker}")
    
                            except Exception as e:
                                st.error(f"Error: {str(e)}")
                                st.info("Make sure rugarch package is installed in R: install.packages('rugarch')")
    
            # Tab 2: Copula Dependency Analysis
            with tabs[1]:
                st.markdown("### üîó Copula Dependency Analysis")
                st.markdown("Model the dependency structure between assets using copula functions")
    
                portfolio_data = load_portfolio_data()
                if portfolio_data is None or (isinstance(portfolio_data, pd.DataFrame) and portfolio_data.empty):
                    st.warning("‚ö†Ô∏è Upload portfolio data via Phoenix Parser first")
                else:
                    df = pd.DataFrame(portfolio_data)
    
                    # Multi-select tickers
                    all_tickers = df['Ticker'].tolist() if 'Ticker' in df.columns else []
                    selected_tickers = st.multiselect(
                        "Select Assets (min 2)",
                        all_tickers,
                        default=all_tickers[:min(3, len(all_tickers))]
                    )
    
                    copula_type = st.selectbox("Copula Type", ["t", "normal", "clayton", "gumbel"])
    
                    if len(selected_tickers) >= 2:
                        if st.button("üîó Fit Copula", type="primary"):
                            with st.spinner(f"Fitting {copula_type} copula..."):
                                try:
                                    # Get returns data
                                    returns_data = yf.download(selected_tickers, period="1y", progress=False)['Close'].pct_change().dropna()
    
                                    # Fit copula
                                    result = r.copula_dependency(returns_data, copula_type=copula_type)
    
                                    st.success(f"‚úÖ {copula_type.upper()} Copula fitted successfully")
    
                                    col1, col2 = st.columns(2)
                                    col1.metric("Copula Type", result['copula_type'].upper())
                                    col2.metric("Number of Assets", result['n_assets'])
    
                                    st.markdown("#### Copula Parameters")
                                    st.write(result['parameters'])
    
                                    # Correlation heatmap
                                    corr_matrix = returns_data.corr()
                                    import plotly.express as px
                                    fig = px.imshow(
                                        corr_matrix,
                                        labels=dict(color="Correlation"),
                                        x=corr_matrix.columns,
                                        y=corr_matrix.columns,
                                        color_continuous_scale='RdBu_r',
                                        zmin=-1, zmax=1
                                    )
                                    fig.update_layout(
                                        title="Asset Correlation Matrix",
                                        height=500,
                                        template='plotly_dark',
                                        paper_bgcolor='rgba(0,0,0,0)',
                                        plot_bgcolor='rgba(10,25,41,0.3)'
                                    )
                                    st.plotly_chart(fig, use_container_width=True)
    
                                except Exception as e:
                                    st.error(f"Error: {str(e)}")
                                    st.info("Make sure copula package is installed in R: install.packages('copula')")
                    else:
                        st.info("Please select at least 2 assets for copula analysis")
    
            # Tab 3: Custom R Code Execution
            with tabs[2]:
                st.markdown("### üé≤ Custom R Code Executor")
                st.markdown("Run custom R analytics with your portfolio data")
    
                st.markdown("**Portfolio data available as `df` variable in R**")
    
                r_code = st.text_area(
                    "R Code",
                    value="""# Example: Calculate correlation matrix
    cor(df)
    
    # Example: Summary statistics
    summary(df)""",
                    height=200
                )
    
                if st.button("‚ñ∂Ô∏è Run R Code", type="primary"):
                    portfolio_data = load_portfolio_data()
    
                    if portfolio_data is None or (isinstance(portfolio_data, pd.DataFrame) and portfolio_data.empty):
                        st.warning("‚ö†Ô∏è No portfolio data available")
                    else:
                        with st.spinner("Executing R code..."):
                            try:
                                df = pd.DataFrame(portfolio_data)
    
                                # Get returns for analysis
                                tickers = df['Ticker'].tolist() if 'Ticker' in df.columns else []
                                if len(tickers) > 0:
                                    returns_data = yf.download(tickers, period="1y", progress=False)['Close'].pct_change().dropna()
    
                                    # Execute custom R code
                                    result = r.run_custom_analysis(r_code, data=returns_data)
    
                                    st.success("‚úÖ R code executed successfully")
    
                                    st.markdown("#### Results:")
                                    st.write(result)
                                else:
                                    st.warning("No tickers found in portfolio")
    
                            except Exception as e:
                                st.error(f"Error executing R code: {str(e)}")
                                st.code(str(e))
    
        # ========================================================================
        # DATABASE PAGE - PROFESSIONAL SQL INTERFACE
        # ========================================================================
        elif page == "üíæ Database":
            st.markdown("## üíæ DATABASE MANAGEMENT")
    
            if not SQL_AVAILABLE:
                st.error("‚ùå SQL database not available")
                st.info("""
                **To enable database features:**
                1. Install SQLAlchemy: `pip install sqlalchemy`
                2. Database will be automatically created at: `data/atlas.db`
                3. Restart the application
                """)
                return
    
            try:
                db = get_db()
                st.success("‚úÖ Database Connected")
            except Exception as e:
                st.error(f"Error connecting to database: {str(e)}")
                return
    
            # Create 4 tabs as per Phase 5 specs
            tabs = st.tabs(["üìä Quick Stats", "üîç Custom Query", "üíæ Saved Queries", "‚ÑπÔ∏è Database Info"])
    
            # ====================================================================
            # TAB 1: QUICK STATS
            # ====================================================================
            with tabs[0]:
                st.markdown("### üìä Quick Stats & Overview")
    
                # Database metrics
                col1, col2, col3, col4 = st.columns(4)
    
                try:
                    # CRITICAL FIX: Query database directly, not pickle cache
                    portfolio_count = len(db.get_portfolio())
    
                    # Query trades table directly from database
                    try:
                        trades_result = db.read("SELECT COUNT(*) as count FROM trades")
                        trades_count = trades_result.iloc[0]['count'] if len(trades_result) > 0 else 0
                    except:
                        trades_count = 0
    
                    # Calculate additional metrics
                    if portfolio_count > 0:
                        portfolio_df = db.get_portfolio()
                        total_value = (portfolio_df['quantity'] * portfolio_df['current_price'].fillna(portfolio_df['avg_cost'])).sum()
                        total_cost = (portfolio_df['quantity'] * portfolio_df['avg_cost']).sum()
                    else:
                        total_value = 0
                        total_cost = 0
    
                    with col1:
                        st.metric("Portfolio Positions", portfolio_count)
    
                    with col2:
                        st.metric("Trade Records", trades_count)
    
                    with col3:
                        st.metric("Total Value", f"${total_value:,.0f}")
    
                    with col4:
                        pl = total_value - total_cost
                        pl_pct = (pl / total_cost * 100) if total_cost > 0 else 0
                        st.metric("Total P&L", f"${pl:,.0f}", f"{pl_pct:+.2f}%")
    
                except Exception as e:
                    st.error(f"Error calculating stats: {e}")
    
                st.markdown("---")
    
                # Recent activity
                st.markdown("#### üìà Recent Activity")
    
                col1, col2 = st.columns(2)
    
                with col1:
                    st.markdown("##### Current Portfolio Holdings")
                    try:
                        portfolio = db.get_portfolio()
                        if len(portfolio) > 0:
                            display_df = portfolio[['ticker', 'quantity', 'avg_cost', 'current_price']].copy()
                            display_df['value'] = display_df['quantity'] * display_df['current_price'].fillna(display_df['avg_cost'])
                            display_df = display_df.sort_values('value', ascending=False)
                            make_scrollable_table(display_df, height=400, hide_index=True, use_container_width=True)
                        else:
                            st.info("No positions in database")
                    except Exception as e:
                        st.error(f"Error: {e}")
    
                with col2:
                    st.markdown("##### Recent Trades")
                    try:
                        # CRITICAL FIX: Query database directly, not pickle
                        trades = db.read("SELECT * FROM trades ORDER BY date DESC LIMIT 10")
                        if len(trades) > 0:
                            display_trades = trades[['date', 'ticker', 'action', 'quantity', 'price']]
                            make_scrollable_table(display_trades, height=400, hide_index=True, use_container_width=True)
                            st.caption(f"üíæ Showing {len(trades)} most recent trades from database")
                        else:
                            st.info("No trades in database yet. Upload trade history in Phoenix Parser.")
                    except Exception as e:
                        st.error(f"Error querying database: {e}")
    
                st.markdown("---")
    
                # Performance summary
                st.markdown("#### üéØ Performance Summary")
    
                try:
                    portfolio = db.get_portfolio()
                    if len(portfolio) > 0:
                        # Calculate metrics
                        portfolio['position_value'] = portfolio['quantity'] * portfolio['current_price'].fillna(portfolio['avg_cost'])
                        portfolio['cost_basis'] = portfolio['quantity'] * portfolio['avg_cost']
                        portfolio['unrealized_pl'] = portfolio['position_value'] - portfolio['cost_basis']
                        portfolio['pl_pct'] = (portfolio['unrealized_pl'] / portfolio['cost_basis'] * 100).round(2)
    
                        # Sort by P&L percentage
                        portfolio_sorted = portfolio.sort_values('pl_pct', ascending=False)
    
                        # Top performers
                        col1, col2 = st.columns(2)
    
                        with col1:
                            st.markdown("##### üü¢ Top Performers")
                            top_performers = portfolio_sorted.head(3)
                            for _, row in top_performers.iterrows():
                                st.metric(
                                    row['ticker'],
                                    f"${row['position_value']:,.2f}",
                                    f"{row['pl_pct']:+.2f}%"
                                )
    
                        with col2:
                            st.markdown("##### üî¥ Bottom Performers")
                            bottom_performers = portfolio_sorted.tail(3)
                            for _, row in bottom_performers.iterrows():
                                st.metric(
                                    row['ticker'],
                                    f"${row['position_value']:,.2f}",
                                    f"{row['pl_pct']:+.2f}%"
                                )
                    else:
                        st.info("No portfolio data available for performance analysis")
    
                except Exception as e:
                    st.error(f"Error calculating performance: {e}")
    
            # ====================================================================
            # TAB 2: CUSTOM QUERY
            # ====================================================================
            with tabs[1]:
                st.markdown("### üîç Custom SQL Query")
                st.markdown("Execute custom SQL queries against the ATLAS database")
    
                # Query templates
                st.markdown("#### üìù Query Templates")
    
                col1, col2, col3 = st.columns(3)
    
                with col1:
                    if st.button("üìä All Holdings", use_container_width=True):
                        st.session_state['sql_query'] = "SELECT * FROM holdings ORDER BY ticker"
    
                with col2:
                    if st.button("üìà All Trades", use_container_width=True):
                        st.session_state['sql_query'] = "SELECT * FROM trades ORDER BY date DESC LIMIT 20"
    
                with col3:
                    if st.button("üí∞ Portfolio Value", use_container_width=True):
                        st.session_state['sql_query'] = """SELECT
        ticker,
        quantity,
        avg_cost,
        current_price,
        (quantity * COALESCE(current_price, avg_cost)) as position_value,
        (quantity * avg_cost) as cost_basis,
        ((quantity * COALESCE(current_price, avg_cost)) - (quantity * avg_cost)) as unrealized_pl
    FROM holdings
    ORDER BY position_value DESC"""
    
                st.markdown("---")
    
                # SQL editor
                default_query = st.session_state.get('sql_query', "SELECT * FROM holdings LIMIT 10")
    
                sql_query = st.text_area(
                    "SQL Query",
                    value=default_query,
                    height=200,
                    help="Write your SQL query here. Tables: holdings, trades, prices, analytics_cache"
                )
    
                col1, col2 = st.columns([1, 4])
    
                with col1:
                    execute_button = st.button("‚ñ∂Ô∏è Execute Query", type="primary", use_container_width=True)
    
                with col2:
                    st.info("**Available tables:** holdings, trades, prices, analytics_cache")
    
                if execute_button:
                    with st.spinner("Executing query..."):
                        try:
                            result_df = db.read(sql_query)
    
                            st.success(f"‚úÖ Query executed successfully - {len(result_df)} rows returned")
    
                            # Display results
                            st.markdown("#### Results:")
                            make_scrollable_table(result_df, height=600, hide_index=True, use_container_width=True)
    
                            # Export option
                            csv = result_df.to_csv(index=False).encode('utf-8')
                            st.download_button(
                                label="üì• Download as CSV",
                                data=csv,
                                file_name=f"query_results_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
                                mime="text/csv"
                            )
    
                        except Exception as e:
                            st.error(f"‚ùå Query failed: {str(e)}")
                            st.code(str(e))
    
                st.markdown("---")
    
                # Quick reference
                with st.expander("üìö SQL Quick Reference"):
                    st.markdown("""
                    **Common SQL Commands:**
                    - `SELECT * FROM table_name` - Get all records
                    - `WHERE column = value` - Filter results
                    - `ORDER BY column DESC` - Sort results
                    - `LIMIT 10` - Limit number of results
                    - `COUNT(*)` - Count rows
                    - `SUM(column)` - Sum values
                    - `AVG(column)` - Average values
                    - `GROUP BY column` - Group results
    
                    **Examples:**
                    ```sql
                    -- Get trades for a specific ticker
                    SELECT * FROM trades WHERE ticker = 'AAPL' ORDER BY date DESC
    
                    -- Calculate total invested per ticker
                    SELECT ticker, SUM(quantity * price) as total_invested
                    FROM trades
                    WHERE action = 'BUY'
                    GROUP BY ticker
    
                    -- Get portfolio summary
                    SELECT
                        COUNT(*) as num_positions,
                        SUM(quantity * avg_cost) as total_cost
                    FROM holdings
                    ```
                    """)
    
            # ====================================================================
            # TAB 3: SAVED QUERIES
            # ====================================================================
            with tabs[2]:
                st.markdown("### üíæ Saved Queries")
                st.markdown("Save and manage frequently used queries")
    
                # Initialize saved queries in session state
                if 'saved_queries' not in st.session_state:
                    st.session_state['saved_queries'] = {
                        'Portfolio Summary': "SELECT ticker, quantity, avg_cost, current_price FROM holdings ORDER BY ticker",
                        'Recent Trades': "SELECT date, ticker, action, quantity, price FROM trades ORDER BY date DESC LIMIT 20",
                        'Trade Volume by Ticker': "SELECT ticker, COUNT(*) as trade_count, SUM(quantity) as total_shares FROM trades GROUP BY ticker ORDER BY trade_count DESC",
                        'Buy vs Sell Summary': "SELECT action, COUNT(*) as trade_count, SUM(quantity * price) as total_value FROM trades GROUP BY action"
                    }
    
                # Add new query
                with st.expander("‚ûï Save New Query"):
                    new_query_name = st.text_input("Query Name")
                    new_query_sql = st.text_area("SQL Query", height=150)
    
                    if st.button("üíæ Save Query"):
                        if new_query_name and new_query_sql:
                            st.session_state['saved_queries'][new_query_name] = new_query_sql
                            st.success(f"‚úÖ Query '{new_query_name}' saved!")
                        else:
                            st.warning("Please provide both name and query")
    
                st.markdown("---")
    
                # Display saved queries
                st.markdown("#### üìã Your Saved Queries")
    
                for query_name, query_sql in st.session_state['saved_queries'].items():
                    with st.expander(f"üìå {query_name}"):
                        st.code(query_sql, language='sql')
    
                        col1, col2, col3 = st.columns(3)
    
                        with col1:
                            if st.button(f"‚ñ∂Ô∏è Run", key=f"run_{query_name}"):
                                try:
                                    result = db.read(query_sql)
                                    st.success(f"‚úÖ {len(result)} rows")
                                    make_scrollable_table(result, height=400, hide_index=True, use_container_width=True)
                                except Exception as e:
                                    st.error(f"Error: {e}")
    
                        with col2:
                            if st.button(f"üìã Copy", key=f"copy_{query_name}"):
                                st.session_state['sql_query'] = query_sql
                                st.info("Query copied to Custom Query tab")
    
                        with col3:
                            if st.button(f"üóëÔ∏è Delete", key=f"delete_{query_name}"):
                                if query_name in st.session_state['saved_queries']:
                                    del st.session_state['saved_queries'][query_name]
                                    st.rerun()
    
            # ====================================================================
            # TAB 4: DATABASE INFO
            # ====================================================================
            with tabs[3]:
                st.markdown("### ‚ÑπÔ∏è Database Information")
    
                # Database location
                st.markdown("#### üìÅ Database Location")
                db_path = "data/atlas.db"
                st.code(db_path)
    
                st.markdown("---")
    
                # Table schemas
                st.markdown("#### üìä Table Schemas")
    
                tables = [
                    {
                        'name': 'holdings',
                        'description': 'Current portfolio positions',
                        'columns': [
                            ('id', 'INTEGER', 'Primary key'),
                            ('portfolio_id', 'INTEGER', 'Portfolio identifier'),
                            ('ticker', 'TEXT', 'Stock ticker symbol'),
                            ('quantity', 'REAL', 'Number of shares'),
                            ('avg_cost', 'REAL', 'Average cost per share'),
                            ('current_price', 'REAL', 'Current market price'),
                            ('updated_at', 'TIMESTAMP', 'Last update time')
                        ]
                    },
                    {
                        'name': 'trades',
                        'description': 'Trade history',
                        'columns': [
                            ('id', 'INTEGER', 'Primary key'),
                            ('date', 'DATE', 'Trade date'),
                            ('ticker', 'TEXT', 'Stock ticker symbol'),
                            ('action', 'TEXT', 'BUY or SELL'),
                            ('quantity', 'REAL', 'Number of shares'),
                            ('price', 'REAL', 'Execution price'),
                            ('created_at', 'TIMESTAMP', 'Record creation time')
                        ]
                    },
                    {
                        'name': 'prices',
                        'description': 'Historical price data',
                        'columns': [
                            ('id', 'INTEGER', 'Primary key'),
                            ('date', 'DATE', 'Price date'),
                            ('ticker', 'TEXT', 'Stock ticker symbol'),
                            ('open_price', 'REAL', 'Opening price'),
                            ('high_price', 'REAL', 'High price'),
                            ('low_price', 'REAL', 'Low price'),
                            ('close_price', 'REAL', 'Closing price'),
                            ('volume', 'REAL', 'Trading volume'),
                            ('updated_at', 'TIMESTAMP', 'Last update time')
                        ]
                    },
                    {
                        'name': 'analytics_cache',
                        'description': 'Cached analysis results',
                        'columns': [
                            ('id', 'INTEGER', 'Primary key'),
                            ('analysis_type', 'TEXT', 'Type of analysis'),
                            ('parameters', 'TEXT', 'Analysis parameters (JSON)'),
                            ('result', 'TEXT', 'Analysis result (JSON)'),
                            ('created_at', 'TIMESTAMP', 'Cache creation time')
                        ]
                    }
                ]
    
                for table in tables:
                    with st.expander(f"üìã {table['name']} - {table['description']}"):
                        # Create DataFrame for columns
                        schema_df = pd.DataFrame(table['columns'], columns=['Column', 'Type', 'Description'])
                        make_scrollable_table(schema_df, height=400, hide_index=True, use_container_width=True)
    
                        # Show row count
                        try:
                            count_result = db.read(f"SELECT COUNT(*) as count FROM {table['name']}")
                            row_count = count_result.iloc[0]['count']
                            st.info(f"üìä Current rows: {row_count}")
                        except:
                            st.info("üìä Table not yet created")
    
                st.markdown("---")
    
                # Database statistics
                st.markdown("#### üìà Database Statistics")
    
                try:
                    col1, col2 = st.columns(2)
    
                    with col1:
                        # Get total records across all tables
                        total_holdings = len(db.read("SELECT * FROM holdings"))
                        total_trades = len(db.read("SELECT * FROM trades"))
    
                        st.metric("Total Holdings Records", total_holdings)
                        st.metric("Total Trade Records", total_trades)
    
                    with col2:
                        # Calculate database size (if possible)
                        import os
                        if os.path.exists('data/atlas.db'):
                            db_size = os.path.getsize('data/atlas.db') / 1024  # KB
                            st.metric("Database Size", f"{db_size:.2f} KB")
    
                        # Last update time
                        portfolio = db.get_portfolio()
                        if len(portfolio) > 0 and 'updated_at' in portfolio.columns:
                            last_update = portfolio['updated_at'].max()
                            st.metric("Last Portfolio Update", str(last_update))
    
                except Exception as e:
                    st.error(f"Error calculating statistics: {e}")
    
                st.markdown("---")
    
                # Database maintenance
                st.markdown("#### üõ†Ô∏è Database Maintenance")
    
                col1, col2 = st.columns(2)
    
                with col1:
                    if st.button("üîÑ Vacuum Database", help="Optimize database and reclaim space"):
                        try:
                            db.execute("VACUUM")
                            st.success("‚úÖ Database vacuumed successfully")
                        except Exception as e:
                            st.error(f"Error: {e}")
    
                with col2:
                    if st.button("üìä Analyze Tables", help="Update table statistics"):
                        try:
                            db.execute("ANALYZE")
                            st.success("‚úÖ Tables analyzed successfully")
                        except Exception as e:
                            st.error(f"Error: {e}")
    
                st.warning("‚ö†Ô∏è Maintenance operations may take a few seconds for large databases")
    
        # ========================================================================
        # PORTFOLIO HOME - ENHANCED WITH CONTRIBUTORS/DETRACTORS
        # ========================================================================
        elif page == "üè† Portfolio Home":
            st.markdown("## üè† PORTFOLIO HOME")
            
            portfolio_data = load_portfolio_data()
            
            if portfolio_data is None or (isinstance(portfolio_data, pd.DataFrame) and portfolio_data.empty):
                st.warning("‚ö†Ô∏è No portfolio data. Please upload via Phoenix Parser.")
                st.stop()
            
            df = pd.DataFrame(portfolio_data)
            
            with st.spinner("Loading..."):
                enhanced_df = create_enhanced_holdings_table(df)
    
            # CRITICAL FIX: Calculate equity, gross exposure, and leverage
            equity = st.session_state.get('equity_capital', 100000.0)
            gross_exposure = enhanced_df['Total Value'].sum()
            actual_leverage = gross_exposure / equity if equity > 0 else 1.0
            total_cost = enhanced_df['Total Cost'].sum()
    
            # CRITICAL FIX: Calculate G/L on EQUITY basis, not cost basis
            total_gl = gross_exposure - equity  # Profit/loss from initial equity
            total_gl_pct = (total_gl / equity) * 100 if equity > 0 else 0  # Return on equity
            daily_pl = enhanced_df['Daily P&L $'].sum()
    
            # First row: Capital Structure (NEW - shows equity vs gross distinction)
            st.markdown("### üí∞ Capital Structure")
            col1, col2, col3 = st.columns(3)
    
            with col1:
                st.metric(
                    "üí∞ Your Equity",
                    format_currency(equity),
                    help="Your actual capital invested"
                )
    
            with col2:
                st.metric(
                    "üìä Gross Exposure",
                    format_currency(gross_exposure),
                    delta=f"vs Equity: {((gross_exposure/equity - 1)*100):+.1f}%" if equity > 0 else None,
                    help="Total market value of all positions (includes leverage)"
                )
    
            with col3:
                target_lev = st.session_state.get('target_leverage', 1.0)
                leverage_delta = f"Target: {target_lev:.1f}x"
                st.metric(
                    "‚ö° Actual Leverage",
                    f"{actual_leverage:.2f}x",
                    delta=leverage_delta,
                    help="Gross Exposure √∑ Equity"
                )
    
            st.markdown("---")
    
            # Second row: Performance Metrics (ALL on equity basis)
            st.markdown("### üìà Performance (on Equity Basis)")
            col1, col2, col3, col4, col5 = st.columns(5)
    
            with col1:
                st.metric(
                    "Return on Equity",
                    format_percentage(total_gl_pct),
                    delta=format_currency(total_gl),
                    help="Total return calculated on YOUR equity (leverage amplified)"
                )
    
            with col2:
                st.metric(
                    "Daily P&L",
                    format_currency(daily_pl),
                    help="Today's profit/loss across all positions"
                )
    
            with col3:
                st.metric(
                    "Total Cost Basis",
                    format_currency(total_cost),
                    help="Total amount paid for all positions"
                )
    
            with col4:
                cost_gl = gross_exposure - total_cost
                cost_gl_pct = (cost_gl / total_cost) * 100 if total_cost > 0 else 0
                st.metric(
                    "Unrealized G/L",
                    format_currency(cost_gl),
                    delta=format_percentage(cost_gl_pct),
                    help="Current value vs cost basis"
                )
    
            with col5:
                st.metric(
                    "üìä Positions",
                    len(enhanced_df),
                    help="Number of holdings in portfolio"
                )
    
            # Info box explaining the metrics
            with st.expander("‚ÑπÔ∏è Understanding Your Leveraged Portfolio", expanded=False):
                st.info(f"""
                **Capital Structure:**
                - **Equity:** Your actual capital = ${equity:,.0f}
                - **Gross Exposure:** Total position values = ${gross_exposure:,.0f}
                - **Leverage:** {actual_leverage:.2f}x means ${actual_leverage:.2f} of market exposure per $1 of equity
    
                **Returns Calculation:**
                - **Return on Equity:** {total_gl_pct:.2f}% is calculated as (Current Value - Initial Equity) / Equity
                - With {actual_leverage:.2f}x leverage, market moves are amplified {actual_leverage:.2f}x
                - A 10% market gain becomes ~{actual_leverage*10:.1f}% return on your equity
    
                **Risk:**
                - VaR, CVaR, and all risk metrics are applied to your ${equity:,.0f} equity, not gross exposure
                - Leverage amplifies BOTH gains and losses proportionally
                """)
    
            # v9.7 NEW FEATURE: Data Quality Indicator
            validation_result = validate_portfolio_data(portfolio_data)
            quality_score = validation_result['data_quality_score']
    
            if quality_score >= 90:
                quality_color = COLORS['success']
                quality_status = "EXCELLENT"
            elif quality_score >= 75:
                quality_color = COLORS['info']
                quality_status = "GOOD"
            elif quality_score >= 60:
                quality_color = COLORS['warning']
                quality_status = "FAIR"
            else:
                quality_color = COLORS['danger']
                quality_status = "POOR"
    
            st.markdown(f"""
            <div style='background: linear-gradient(135deg, {COLORS['card_background']} 0%, {COLORS['card_background_alt']} 100%);
                        border-left: 4px solid {quality_color};
                        padding: 12px 20px;
                        border-radius: 8px;
                        margin: 15px 0;'>
                <div style='display: flex; align-items: center; justify-content: space-between;'>
                    <div>
                        <span style='color: {COLORS['text_muted']}; font-size: 12px;'>üÜï v9.7 DATA QUALITY SCORE</span>
                        <span style='color: {quality_color}; font-size: 24px; font-weight: 700; margin-left: 15px;'>{quality_score}/100</span>
                        <span style='color: {quality_color}; font-size: 14px; font-weight: 600; margin-left: 10px;'>{quality_status}</span>
                    </div>
                    <div style='text-align: right; color: {COLORS['text_secondary']}; font-size: 11px;'>
                        {validation_result['complete_rows']}/{validation_result['total_rows']} Complete Rows
                        {f"<br/><span style='color: {COLORS['danger']};'>‚ö†Ô∏è {len(validation_result['issues'])} Issues</span>" if validation_result['issues'] else ""}
                        {f"<br/><span style='color: {COLORS['warning']};'>‚ö° {len(validation_result['warnings'])} Warnings</span>" if validation_result['warnings'] else ""}
                    </div>
                </div>
            </div>
            """, unsafe_allow_html=True)
    
            if validation_result['issues'] or validation_result['warnings']:
                with st.expander("üîç View Data Quality Details", expanded=False):
                    if validation_result['issues']:
                        st.error("**Issues Found:**")
                        for issue in validation_result['issues']:
                            st.write(f"- {issue}")
                    if validation_result['warnings']:
                        st.warning("**Warnings:**")
                        for warning in validation_result['warnings']:
                            st.write(f"- {warning}")
    
            st.markdown("---")
    
            # Risk Snapshot & Signal Health
            portfolio_returns = calculate_portfolio_returns(df, start_date, end_date)
    
            col_health, col_snapshot = st.columns([1, 3])
    
            with col_health:
                # Calculate metrics for health indicator
                if is_valid_series(portfolio_returns):
                    metrics = calculate_performance_metrics(enhanced_df, portfolio_returns, None)
                    health_badge = create_signal_health_badge(metrics)
                    st.markdown("### üéØ Portfolio Health")
                    st.markdown(health_badge, unsafe_allow_html=True)
                    st.caption(f"**Last Updated:** {ATLASFormatter.format_timestamp()}")
    
            with col_snapshot:
                # Risk Snapshot
                risk_snapshot_html = create_risk_snapshot(enhanced_df, portfolio_returns)
                st.markdown(risk_snapshot_html, unsafe_allow_html=True)
    
            st.markdown("---")
            st.markdown("### üìã Holdings")
    
            # Column selector for interactive table customization
            with st.expander("‚öôÔ∏è Customize Columns", expanded=False):
                # Define all available columns
                ALL_COLUMNS = [
                    'Ticker', 'Asset Name', 'Shares', 'Avg Cost', 'Current Price',
                    'Daily Change %', '5D Return %', 'YTD Return %',
                    'Weight % of Equity', 'Weight % of Gross', 'Weight %',
                    'Daily P&L $', 'Total Gain/Loss $', 'Total Gain/Loss %',
                    'Beta', 'Analyst Rating', 'Quality Score', 'Sector',
                    'Price Target', 'Volume'
                ]
    
                # Default columns to show (include both new weight columns)
                DEFAULT_COLUMNS = [
                    'Ticker', 'Asset Name', 'Shares', 'Current Price',
                    'Daily Change %', '5D Return %',
                    'Weight % of Equity', 'Weight % of Gross',
                    'Total Gain/Loss $', 'Total Gain/Loss %', 'Quality Score'
                ]
    
                # Filter only columns that exist in enhanced_df
                available_columns = [col for col in ALL_COLUMNS if col in enhanced_df.columns]
                default_selected = [col for col in DEFAULT_COLUMNS if col in enhanced_df.columns]
    
                selected_columns = st.multiselect(
                    "Select Columns to Display",
                    options=available_columns,
                    default=default_selected,
                    help="Choose which columns to show in the holdings table"
                )
    
            # Display holdings table
            if selected_columns:
                # Create display dataframe with selected columns
                display_df = enhanced_df[selected_columns].copy()
    
                # Format columns appropriately
                pct_cols = [col for col in selected_columns if '%' in col]
                for col in pct_cols:
                    if col in display_df.columns:
                        display_df[col] = display_df[col].apply(lambda x: format_percentage(x) if pd.notna(x) else 'N/A')
    
                currency_cols = ['Avg Cost', 'Current Price', 'Daily P&L $', 'Total Gain/Loss $', 'Price Target']
                for col in currency_cols:
                    if col in display_df.columns:
                        display_df[col] = display_df[col].apply(lambda x: format_currency(x) if pd.notna(x) else 'N/A')
    
                # Add arrow indicators for change columns
                if 'Daily Change %' in display_df.columns:
                    display_df['Daily Change %'] = display_df['Daily Change %'].apply(add_arrow_indicator)
                if 'Total Gain/Loss %' in display_df.columns:
                    display_df['Total Gain/Loss %'] = display_df['Total Gain/Loss %'].apply(add_arrow_indicator)
    
                make_scrollable_table(display_df, height=500, hide_index=True, use_container_width=True, column_config=None)
    
                # Add explanation for dual weight columns
                if 'Weight % of Equity' in selected_columns or 'Weight % of Gross' in selected_columns:
                    st.caption(f"""
                    **Understanding Position Weights:**
                    - **Weight % of Equity**: Position value as % of your ${equity:,.0f} equity (can exceed 100% with {actual_leverage:.2f}x leverage!)
                    - **Weight % of Gross**: Position value as % of ${gross_exposure:,.0f} gross exposure (always sums to 100%)
                    - With {actual_leverage:.2f}x leverage, a 50% equity weight = {50/actual_leverage:.1f}% gross weight
                    """)
            else:
                st.warning("‚ö†Ô∏è Please select at least one column to display")
    
            st.info("üí° **Tip:** Head to the Valuation House to analyze intrinsic values of any ticker!")
    
            st.markdown("---")
            st.markdown("### üìä ANALYST DASHBOARD")
    
            # ===== SECTOR ATTRIBUTION =====
            st.markdown("#### üíº Sector Attribution")
            pnl_sector = create_pnl_attribution_sector(enhanced_df)
            if pnl_sector:
                st.plotly_chart(pnl_sector, use_container_width=True, key="sector_pnl")
            else:
                st.info("Sector P&L will display when holdings have sector data")
    
            # Additional position-level P&L analysis
            st.markdown("---")
            st.markdown("### üíº Top Contributors")
    
            pnl_position = create_pnl_attribution_position(enhanced_df, top_n=10)
            if pnl_position:
                st.plotly_chart(pnl_position, use_container_width=True)
    
            # Performance Heatmap (full width) - Only show if meaningful data exists
            st.markdown("---")
            if should_display_monthly_heatmap(enhanced_df):
                st.markdown("### üìÖ Monthly Performance")
                perf_heatmap = create_performance_heatmap(enhanced_df)
                if perf_heatmap:
                    st.plotly_chart(perf_heatmap, use_container_width=True)
            else:
                st.info("üìä Monthly performance heatmap will be available after 2+ months of portfolio history")
    
            # ===== ADVANCED TOOLS - Collapsed by default for analyst focus =====
            st.markdown("---")
            st.markdown("### üîß Advanced Tools")
    
            # VaR/CVaR Optimization in expander
            with st.expander("üéØ VaR/CVaR Portfolio Optimization", expanded=False):
                st.info("Calculate optimal portfolio weights to minimize tail risk (VaR/CVaR)")
    
                if st.button("‚ö° Run Optimization", type="primary", key="run_var_cvar_opt"):
                    with st.spinner("Calculating optimal portfolio weights..."):
                        rebalancing_df, opt_metrics = calculate_var_cvar_portfolio_optimization(enhanced_df)
    
                        if rebalancing_df is not None and opt_metrics is not None:
                            # Display optimization summary
                            st.markdown("#### üìä Optimization Results")
    
                            col1, col2, col3, col4 = st.columns(4)
                            with col1:
                                st.metric("VaR Reduction",
                                         f"{opt_metrics['var_reduction_pct']:.1f}%",
                                         f"{opt_metrics['current_var']:.2f}% ‚Üí {opt_metrics['optimal_var']:.2f}%",
                                         delta_color="inverse")
    
                            with col2:
                                st.metric("CVaR Reduction",
                                         f"{opt_metrics['cvar_reduction_pct']:.1f}%",
                                         f"{opt_metrics['current_cvar']:.2f}% ‚Üí {opt_metrics['optimal_cvar']:.2f}%",
                                         delta_color="inverse")
    
                            with col3:
                                st.metric("Sharpe Improvement",
                                         f"+{opt_metrics['sharpe_improvement']:.2f}",
                                         f"{opt_metrics['current_sharpe']:.2f} ‚Üí {opt_metrics['optimal_sharpe']:.2f}")
    
                            with col4:
                                st.metric("Trades Required",
                                         opt_metrics['total_trades'],
                                         f"Est. Cost: ${opt_metrics['rebalancing_cost']:,.0f}")
    
                            # Merge optimization data into enhanced_df for display
                            enhanced_df_with_opt = enhanced_df.merge(
                                rebalancing_df[['Ticker', 'Optimal Weight %', 'Weight Diff %',
                                               'Shares to Trade', 'Trade Value', 'Action']],
                                on='Ticker',
                                how='left'
                            )
    
                            # Display enhanced table with optimization columns
                            st.markdown("#### üìã Rebalancing Targets")
                            display_df_opt = style_holdings_dataframe_with_optimization(enhanced_df_with_opt)
                            make_scrollable_table(display_df_opt, height=500, hide_index=True, use_container_width=True)
                        else:
                            st.error("‚ö†Ô∏è Unable to calculate optimization. Ensure sufficient position data exists.")
    
            # System Test in expander
            with st.expander("üß™ System Test & Validation", expanded=False):
                st.info("Run diagnostic tests to verify ATLAS system components")
    
                if st.button("üß™ Run System Test", type="primary", key="run_system_test"):
                    st.markdown("#### üîç Test Results")
    
                    col1, col2, col3 = st.columns(3)
    
                    # Test 1: Database
                    with col1:
                        st.markdown("**Database Test**")
                        try:
                            conn = get_db()
                            portfolio = conn.get_portfolio()
                            pos_count = len(portfolio)
    
                            if pos_count > 0:
                                st.success(f"‚úÖ Database: {pos_count} positions")
                            else:
                                st.warning("‚ö†Ô∏è Database: No positions")
                        except Exception as e:
                            st.error(f"‚ùå Database: {str(e)}")
    
                    # Test 2: Imports
                    with col2:
                        st.markdown("**Import Tests**")
                        imports_ok = True
    
                        try:
                            import plotly.express as px
                            st.success("‚úÖ plotly.express")
                        except:
                            st.error("‚ùå plotly.express")
                            imports_ok = False
    
                        try:
                            import plotly.graph_objects as go
                            st.success("‚úÖ plotly.graph_objects")
                        except:
                            st.error("‚ùå plotly.graph_objects")
                            imports_ok = False
    
                        try:
                            from scipy import stats
                            st.success("‚úÖ scipy.stats")
                        except:
                            st.error("‚ùå scipy.stats")
                            imports_ok = False
    
                    # Test 3: Portfolio data
                    with col3:
                        st.markdown("**Portfolio Test**")
                        try:
                            portfolio_data = load_portfolio_data()
                            if portfolio_data is not None:
                                if isinstance(portfolio_data, pd.DataFrame):
                                    if not portfolio_data.empty:
                                        st.success(f"‚úÖ Portfolio: {len(portfolio_data)} positions")
                                    else:
                                        st.warning("‚ö†Ô∏è Portfolio: Empty")
                                else:
                                    st.warning("‚ö†Ô∏è Portfolio: Not a DataFrame")
                            else:
                                st.warning("‚ö†Ô∏è Portfolio: No data")
                        except Exception as e:
                            st.error(f"‚ùå Portfolio: {str(e)}")
    
                    st.markdown("---")
    
                    # Test 4: Options filtering
                    st.markdown("**Options Filtering Test**")
                    test_tickers = ['AAPL', 'AU2520F50', 'TSLA', 'META2405D482.5', 'MSFT']
                    filtered = [t for t in test_tickers if is_option_ticker(t)]
    
                    if len(filtered) == 2 and 'AU2520F50' in filtered and 'META2405D482.5' in filtered:
                        st.success(f"‚úÖ Options filtering working: {filtered}")
                    else:
                        st.error(f"‚ùå Options filtering failed: {filtered}")
    
        # ========================================================================
        # MARKET WATCH - COMPLETE REVAMP
        # ========================================================================
        elif page == "üåç Market Watch":
            st.markdown("## üåç MARKET WATCH - EXCELLENCE EDITION")
            st.markdown("*Your comprehensive window into global markets, crypto, bonds, and credit conditions*")
    
            st.markdown("---")
    
            # LIVE TICKER SEARCH
            st.markdown("### üîç Live Ticker Search")
            search_col1, search_col2 = st.columns([3, 1])
    
            with search_col1:
                search_query = st.text_input(
                    "Search any ticker or add to watchlist",
                    placeholder="Enter ticker symbol (e.g., AAPL, TSLA, BTC-USD)...",
                    key="ticker_search",
                    label_visibility="collapsed"
                )
    
            with search_col2:
                search_button = st.button("üîç Search", use_container_width=True, type="primary")
    
            # Display search results
            if (search_query and search_button) or (search_query and len(search_query) >= 2):
                with st.spinner(f"Searching for '{search_query}'..."):
                    results = search_yahoo_finance(search_query)
    
                    if results:
                        result = results[0]
                        st.success(f"‚úÖ Found: **{result['symbol']}** - {result['name']}")
    
                        # Display quick info
                        info_col1, info_col2, info_col3, info_col4 = st.columns(4)
                        with info_col1:
                            st.metric("Type", result['type'])
                        with info_col2:
                            st.metric("Exchange", result['exchange'])
                        with info_col3:
                            if result['market_cap'] > 0:
                                st.metric("Market Cap", f"${result['market_cap']/1e9:.1f}B")
                            else:
                                st.metric("Currency", result['currency'])
                        with info_col4:
                            # Add to watchlist button
                            if st.button(f"‚≠ê Add to Watchlist", key=f"add_{result['symbol']}"):
                                if add_to_watchlist(result['symbol'], result['name'], result['type']):
                                    st.success(f"‚úÖ Added {result['symbol']} to watchlist!")
                                    st.rerun()
                                else:
                                    st.warning(f"‚ö†Ô∏è {result['symbol']} already in watchlist")
                    else:
                        st.error(f"‚ùå No results found for '{search_query}'. Try a different ticker symbol.")
    
            st.markdown("---")
            st.markdown("### üîç Filters & Settings")
            col1, col2, col3, col4 = st.columns(4)
            
            with col1:
                filter_change = st.slider("Min Change %", -10.0, 10.0, -10.0)
            with col2:
                sort_by = st.selectbox("Sort By", ["Change %", "5D %", "Volume"])
            with col3:
                refresh = st.button("üîÑ Refresh Data")
                if refresh:
                    current_time = datetime.now().strftime("%H:%M:%S")
                    show_toast(f"Market data refreshed - updated at {current_time}", toast_type="info", duration=3000)
            with col4:
                auto_refresh = st.checkbox("Auto-Refresh (5min)")
    
            st.markdown("---")
    
            # EXPANDED TABS
            tab0, tab1, tab2, tab3, tab4, tab5, tab6, tab7 = st.tabs([
                "‚≠ê My Watchlist",
                "üìà Indices",
                "üí∞ Crypto",
                "üè¶ ETFs",
                "‚ö° Commodities",
                "üìä Stocks",
                "üíµ Bonds & Rates",
                "üéØ Credit Spreads"
            ])
    
            # PERSONAL WATCHLIST TAB
            with tab0:
                st.markdown("#### ‚≠ê Personal Watchlist")
    
                watchlist = get_watchlist()
    
                if not watchlist:
                    st.info("üìù Your watchlist is empty. Use the search bar above to add tickers!")
                else:
                    st.success(f"‚úÖ Tracking {len(watchlist)} securities")
    
                    # Fetch live data for watchlist
                    watchlist_data = []
    
                    with st.spinner("Loading watchlist prices..."):
                        for item in watchlist:
                            try:
                                ticker = yf.Ticker(item['ticker'])
                                hist = ticker.history(period='5d')
    
                                if not hist.empty:
                                    current_price = hist['Close'].iloc[-1]
                                    prev_close = hist['Close'].iloc[-2] if len(hist) > 1 else current_price
                                    change = current_price - prev_close
                                    change_pct = (change / prev_close * 100) if prev_close > 0 else 0
    
                                    # Get 5-day change
                                    if len(hist) >= 5:
                                        five_day_change = ((current_price - hist['Close'].iloc[0]) / hist['Close'].iloc[0] * 100)
                                    else:
                                        five_day_change = 0
    
                                    watchlist_data.append({
                                        'Ticker': item['ticker'],
                                        'Name': item['name'],
                                        'Type': item['type'],
                                        'Price': f"${current_price:.2f}",
                                        'Change': f"${change:+.2f}",
                                        'Change %': change_pct,
                                        '5D %': five_day_change,
                                        'Added': item['added_date']
                                    })
                            except:
                                # If data fetch fails, still show the item
                                watchlist_data.append({
                                    'Ticker': item['ticker'],
                                    'Name': item['name'],
                                    'Type': item['type'],
                                    'Price': 'N/A',
                                    'Change': 'N/A',
                                    'Change %': 0,
                                    '5D %': 0,
                                    'Added': item['added_date']
                                })
    
                    if watchlist_data:
                        watchlist_df = pd.DataFrame(watchlist_data)
                        make_scrollable_table(watchlist_df, height=600, hide_index=True, use_container_width=True)
    
                        # Remove from watchlist
                        st.markdown("---")
                        st.markdown("##### üóëÔ∏è Manage Watchlist")
    
                        remove_col1, remove_col2 = st.columns([3, 1])
    
                        with remove_col1:
                            ticker_to_remove = st.selectbox(
                                "Select ticker to remove",
                                options=[item['ticker'] for item in watchlist],
                                key="remove_ticker_select"
                            )
    
                        with remove_col2:
                            if st.button("üóëÔ∏è Remove", use_container_width=True, type="secondary"):
                                remove_from_watchlist(ticker_to_remove)
                                st.success(f"‚úÖ Removed {ticker_to_remove} from watchlist")
                                st.rerun()
    
            with tab1:
                st.markdown("#### üåç Global Indices")
    
                # Advanced filters for indices
                index_regions = st.multiselect(
                    "Filter by Region",
                    ["US", "Europe", "Asia-Pacific", "Americas", "Middle East & Africa", "UK", "Germany", "France",
                     "Japan", "Hong Kong", "China", "India", "Canada", "Brazil", "Australia"],
                    default=["US", "Europe", "Asia-Pacific"],
                    key="index_region_filter"
                )
    
                with st.spinner("Loading indices..."):
                    indices_df = fetch_market_watch_data(GLOBAL_INDICES)
                    if not indices_df.empty:
                        # Apply region filter
                        if index_regions and 'Region' in indices_df.columns:
                            indices_df = indices_df[indices_df['Region'].isin(index_regions)]
                        # Apply change filter
                        indices_df = indices_df[indices_df['Change %'] >= filter_change]
                        display_df = create_dynamic_market_table(indices_df, {'sort_by': sort_by, 'ascending': False})
                        make_scrollable_table(display_df, height=600, hide_index=True, use_container_width=True, column_config=None)
                    else:
                        st.warning("No data available")
            
            with tab2:
                st.markdown("#### ü™ô Cryptocurrency Markets")
    
                # Advanced filters for crypto
                col_crypto1, col_crypto2 = st.columns(2)
                with col_crypto1:
                    crypto_market_caps = st.multiselect(
                        "Filter by Market Cap",
                        ["Large", "Mid", "Small"],
                        default=["Large", "Mid"],
                        key="crypto_mcap_filter"
                    )
                with col_crypto2:
                    crypto_categories = st.multiselect(
                        "Filter by Type",
                        ["Crypto", "Stablecoin"],
                        default=["Crypto", "Stablecoin"],
                        key="crypto_cat_filter"
                    )
    
                with st.spinner("Loading crypto..."):
                    crypto_df = fetch_market_watch_data(CRYPTOCURRENCIES)
                    if not crypto_df.empty:
                        # Apply market cap filter
                        if crypto_market_caps and 'Market Cap' in crypto_df.columns:
                            crypto_df = crypto_df[crypto_df['Market Cap'].isin(crypto_market_caps)]
                        # Apply category filter
                        if crypto_categories and 'Category' in crypto_df.columns:
                            crypto_df = crypto_df[crypto_df['Category'].isin(crypto_categories)]
                        # Apply change filter
                        crypto_df = crypto_df[crypto_df['Change %'] >= filter_change]
                        display_df = create_dynamic_market_table(crypto_df, {'sort_by': sort_by, 'ascending': False})
                        make_scrollable_table(display_df, height=600, hide_index=True, use_container_width=True, column_config=None)
                    else:
                        st.warning("No data available")
            
            with tab3:
                st.markdown("#### üì¶ Exchange-Traded Funds")
    
                # Comprehensive ETF category filters
                etf_categories = st.multiselect(
                    "Filter by Category",
                    ["Broad Market", "Mid Cap", "Small Cap", "Sector", "Real Estate", "Thematic",
                     "International", "Bonds", "Commodities", "Factor", "Leveraged", "Inverse", "Volatility"],
                    default=["Broad Market", "Sector", "Thematic", "International"],
                    key="etf_cat_filter"
                )
    
                with st.spinner("Loading ETFs..."):
                    etf_df = fetch_market_watch_data(POPULAR_ETFS)
                    if not etf_df.empty:
                        if etf_categories:
                            etf_df = etf_df[etf_df['Category'].isin(etf_categories)]
                        # Apply change filter
                        etf_df = etf_df[etf_df['Change %'] >= filter_change]
                        display_df = create_dynamic_market_table(etf_df, {'sort_by': sort_by, 'ascending': False})
                        make_scrollable_table(display_df, height=600, hide_index=True, use_container_width=True, column_config=None)
                    else:
                        st.warning("No data available")
            
            with tab4:
                st.markdown("#### ‚õΩ Commodity Markets")
    
                # Commodity category filters
                commodity_cats = st.multiselect(
                    "Filter by Type",
                    ["Precious Metals", "Energy", "Industrial Metals", "Agriculture", "Livestock"],
                    default=["Precious Metals", "Energy", "Agriculture"],
                    key="commodity_cat_filter"
                )
    
                with st.spinner("Loading commodities..."):
                    comm_df = fetch_market_watch_data(COMMODITIES)
                    if not comm_df.empty:
                        if commodity_cats:
                            comm_df = comm_df[comm_df['Category'].isin(commodity_cats)]
                        # Apply change filter
                        comm_df = comm_df[comm_df['Change %'] >= filter_change]
                        display_df = create_dynamic_market_table(comm_df, {'sort_by': sort_by, 'ascending': False})
                        make_scrollable_table(display_df, height=600, hide_index=True, use_container_width=True, column_config=None)
                    else:
                        st.warning("No data available")
            
            with tab5:
                st.markdown("#### üìà Popular Stocks")
    
                # Comprehensive stock category filters
                stock_categories = st.multiselect(
                    "Filter by Category",
                    ["Mega Cap Tech", "Tech", "Semiconductors", "Software", "E-Commerce", "Payments", "Crypto",
                     "Financials", "Insurance", "Healthcare", "Biotech", "Medical Devices",
                     "Consumer", "Retail", "Automotive", "Travel", "Delivery",
                     "Energy", "Oil Services", "Industrials", "Aerospace", "Transportation", "Airlines",
                     "Materials", "Chemicals", "Mining", "Utilities", "REITs",
                     "Telecom", "Media", "Gaming", "Rideshare", "International"],
                    default=["Mega Cap Tech", "Semiconductors", "Software", "Financials", "Healthcare"],
                    key="stock_cat_filter"
                )
    
                with st.spinner("Loading stocks..."):
                    stocks_df = fetch_market_watch_data(POPULAR_STOCKS)
                    if not stocks_df.empty:
                        if stock_categories:
                            stocks_df = stocks_df[stocks_df['Category'].isin(stock_categories)]
                        # Apply change filter
                        stocks_df = stocks_df[stocks_df['Change %'] >= filter_change]
                        display_df = create_dynamic_market_table(stocks_df, {'sort_by': sort_by, 'ascending': False})
                        make_scrollable_table(display_df, height=600, hide_index=True, use_container_width=True, column_config=None)
                    else:
                        st.warning("No data available")
            
            with tab6:
                st.markdown("#### üíµ Global Bond Yields & Yield Curves")
                st.info("üìä **Key Insight:** Monitor yield curves for recession signals, inflation expectations, and relative value across markets")
    
                # Country/Region selector for yield curves
                selected_curve = st.selectbox(
                    "Select Yield Curve",
                    ["US Treasuries", "UK Gilts", "German Bunds", "SA Government Bonds"],
                    index=0,
                    help="Compare government bond yields across major economies"
                )
    
                # Display yield curve based on selection
                if selected_curve == "US Treasuries":
                    result = create_yield_curve()
                    if result:
                        yield_curve, maturities, spot_rates, data_source = result
    
                        # Display combined spot + forward curve
                        st.plotly_chart(yield_curve, use_container_width=True)
    
                        # Show data source indicator
                        freshness_color = {
                            "FRED API": "üü¢",
                            "Yahoo Finance": "üü°",
                            "Fallback Data": "üî¥"
                        }.get(data_source, "üü°")
    
                        st.caption(f"**Data Freshness:** {ATLASFormatter.format_timestamp()} ‚Ä¢ {freshness_color} {data_source}")
                        st.info("üí° **Blue line** = Spot yields | **Green dashed** = Implied forward rates showing market expectations")
    
                        # Calculate and display spread
                        treasuries_10y = yf.Ticker("^TNX")
                        treasuries_2y = yf.Ticker("^FVX")
                        try:
                            hist_10y = treasuries_10y.history(period="1d")
                            hist_2y = treasuries_2y.history(period="1d")
                            if not hist_10y.empty and not hist_2y.empty:
                                spread_10y_2y = hist_10y['Close'].iloc[-1] - hist_2y['Close'].iloc[-1]
                                if spread_10y_2y > 0:
                                    st.success(f"‚úÖ 10Y-5Y Spread: **+{spread_10y_2y:.2f}%** (Normal - Positive slope)")
                                else:
                                    st.error(f"‚ö†Ô∏è 10Y-5Y Spread: **{spread_10y_2y:.2f}%** (INVERTED - Potential recession signal)")
                        except:
                            pass
    
                elif selected_curve == "UK Gilts":
                    with st.spinner("Fetching UK Gilt yields..."):
                        maturities, yields = fetch_uk_gilt_yields()
    
                    fig_gilts = create_yield_curve_with_forwards(maturities, yields, "UK Gilt Yield Curve with Forward Rates", color='#FF6B6B')
                    st.plotly_chart(fig_gilts, use_container_width=True)
                    st.caption(f"**Data Freshness:** {ATLASFormatter.format_timestamp()} ‚Ä¢ Live data from Yahoo Finance")
                    st.info("üí° **Red line** = Spot yields | **Green dashed** = Implied forward rates showing market expectations")
    
                elif selected_curve == "German Bunds":
                    with st.spinner("Fetching German Bund yields..."):
                        maturities, yields = fetch_german_bund_yields()
    
                    fig_bunds = create_yield_curve_with_forwards(maturities, yields, "German Bund Yield Curve with Forward Rates", color='#FFD700')
                    st.plotly_chart(fig_bunds, use_container_width=True)
                    st.caption(f"**Data Freshness:** {ATLASFormatter.format_timestamp()} ‚Ä¢ Live data from Yahoo Finance")
                    st.info("üí° **Gold line** = Spot yields | **Green dashed** = Implied forward rates showing market expectations")
    
                elif selected_curve == "SA Government Bonds":
                    with st.spinner("Fetching SA Government Bond yields..."):
                        maturities, yields = fetch_sa_government_bond_yields()
    
                    fig_sagov = create_yield_curve_with_forwards(maturities, yields, "SA Government Bond Yield Curve with Forward Rates", color='#00D4FF')
                    st.plotly_chart(fig_sagov, use_container_width=True)
                    st.caption(f"**Data Freshness:** {ATLASFormatter.format_timestamp()} ‚Ä¢ South African government bond yields")
                    st.info("üí° **Cyan line** = Spot yields | **Green dashed** = Implied forward rates showing market expectations")
    
                st.markdown("---")
    
                with st.spinner("Loading bonds..."):
                    bonds_df = fetch_market_watch_data(BOND_YIELDS)
                    if not bonds_df.empty:
                        display_df = create_dynamic_market_table(bonds_df, {'sort_by': sort_by, 'ascending': False})
                        make_scrollable_table(display_df, height=400, hide_index=True, use_container_width=True, column_config=None)
                    else:
                        st.warning("No data available")
            
            with tab7:
                st.markdown("#### üéØ Credit Spreads & Conditions")
                st.info("üí° **Key Insight:** Widening spreads signal deteriorating credit conditions and rising risk premiums")
                
                with st.spinner("Loading credit spreads..."):
                    credit_df = fetch_market_watch_data(CREDIT_SPREADS)
                    if not credit_df.empty:
                        display_df = create_dynamic_market_table(credit_df, {'sort_by': sort_by, 'ascending': False})
                        make_scrollable_table(display_df, height=400, hide_index=True, use_container_width=True, column_config=None)
                        
                        st.markdown("---")
                        st.markdown("#### üìä Credit Market Interpretation")
                        st.markdown("""
                        **Investment Grade (LQD):** Corporate bonds rated BBB- or higher
                        **High Yield (HYG):** "Junk" bonds with higher risk and return potential
                        **Emerging Markets (EMB):** Sovereign and corporate debt from developing economies
                        **TIPS (TIP):** Treasury Inflation-Protected Securities
                        **MBS (MBB):** Mortgage-Backed Securities
                        """)
                    else:
                        st.warning("No data available")
        
        # Continue with remaining pages in next message...
        # (Risk Analysis, Performance Suite, Portfolio Deep Dive, Multi-Factor, Valuation House, About)
        
        # ========================================================================
        # RISK ANALYSIS - WORLD CLASS
        # ========================================================================
        elif page == "üìà Risk Analysis":
            st.markdown("## üìà RISK ANALYSIS - WORLD CLASS")
            
            portfolio_data = load_portfolio_data()
            
            if portfolio_data is None or (isinstance(portfolio_data, pd.DataFrame) and portfolio_data.empty):
                st.warning("‚ö†Ô∏è No portfolio data.")
                st.stop()
            
            df = pd.DataFrame(portfolio_data)
            enhanced_df = create_enhanced_holdings_table(df)
            
            with st.spinner("Calculating..."):
                portfolio_returns = calculate_portfolio_returns(df, start_date, end_date)
                benchmark_returns = calculate_benchmark_returns(selected_benchmark, start_date, end_date)
                
                if not is_valid_series(portfolio_returns):
                    st.warning("Insufficient data")
                    st.stop()
                sharpe = calculate_sharpe_ratio(portfolio_returns)
                sortino = calculate_sortino_ratio(portfolio_returns)
                calmar = calculate_calmar_ratio(portfolio_returns)
                var_95 = calculate_var(portfolio_returns, 0.95)
                max_dd = calculate_max_drawdown(portfolio_returns)
            
            # v9.7 ENHANCEMENT: Added CVaR metric
            cvar_95 = calculate_cvar(portfolio_returns, 0.95)
    
            # Risk Alerts - Check for threshold violations
            risk_alerts = []
    
            # VaR threshold (flag if > 15% daily loss)
            if var_95 and abs(var_95) > 15:
                risk_alerts.append(f"VaR 95% at {abs(var_95):.1f}% exceeds 15% threshold")
    
            # CVaR threshold (flag if > 20% daily loss)
            if cvar_95 and abs(cvar_95) > 20:
                risk_alerts.append(f"CVaR 95% at {abs(cvar_95):.1f}% exceeds 20% threshold")
    
            # Maximum Drawdown threshold (flag if > 30%)
            if max_dd and abs(max_dd) > 30:
                risk_alerts.append(f"Maximum Drawdown at {abs(max_dd):.1f}% exceeds 30% threshold")
    
            # Concentration risk - check if any single position > 25%
            if len(enhanced_df) > 0:
                total_value = enhanced_df['Total Value'].sum()
                for _, row in enhanced_df.iterrows():
                    position_pct = (row['Total Value'] / total_value) * 100
                    if position_pct > 25:
                        risk_alerts.append(f"{row['Ticker']} concentration at {position_pct:.1f}% exceeds 25% limit")
    
            # Display risk alerts as toasts
            if risk_alerts:
                for alert in risk_alerts[:3]:  # Limit to 3 toasts to avoid overwhelming
                    show_toast(f"‚ö†Ô∏è Risk Alert: {alert}", toast_type="warning", duration=6000)
    
            col1, col2, col3, col4, col5, col6 = st.columns(6)
            col1.metric("üî• Sharpe", ATLASFormatter.format_ratio(sharpe) if sharpe else "N/A")
            col2.metric("üíé Sortino", ATLASFormatter.format_ratio(sortino) if sortino else "N/A")
            col3.metric("‚öñÔ∏è Calmar", ATLASFormatter.format_ratio(calmar) if calmar else "N/A")
            col4.metric("üìâ VaR 95%", format_percentage(var_95) if var_95 else "N/A")
            col5.metric("üî¥ CVaR 95%", format_percentage(cvar_95) if cvar_95 else "N/A")
            col6.metric("‚ö†Ô∏è Max DD", format_percentage(max_dd) if max_dd else "N/A")
    
            st.markdown("---")
    
            # ===== RISK-REWARD POSITIONING =====
            st.markdown("### üéØ Risk-Reward Analysis")
            st.markdown("**Understand where each position sits on the risk-return spectrum**")
    
            col_chart, col_guide = st.columns([3, 1])
    
            with col_chart:
                risk_reward = create_risk_reward_plot(enhanced_df)
                if risk_reward:
                    st.plotly_chart(risk_reward, use_container_width=True, key="risk_reward_analysis")
                else:
                    st.info("Risk-reward chart will display when position data is available")
    
            with col_guide:
                st.markdown("#### üìñ Interpretation Guide")
    
                st.markdown("**üü¢ Top-Right Quadrant**")
                st.caption("High return, high risk - Growth plays")
    
                st.markdown("**üîµ Top-Left Quadrant**")
                st.caption("High return, low risk - IDEAL positions")
    
                st.markdown("**üü° Bottom-Left Quadrant**")
                st.caption("Low return, low risk - Defensive holds")
    
                st.markdown("**üî¥ Bottom-Right Quadrant**")
                st.caption("Low return, high risk - REVIEW URGENTLY")
    
                st.markdown("---")
                st.markdown("**‚ö° Action Items**")
                st.caption("‚Ä¢ Rotate bottom-right into top-left")
                st.caption("‚Ä¢ Size up low-risk winners")
                st.caption("‚Ä¢ Trim high-risk laggards")
    
            st.markdown("---")
    
            tab1, tab2, tab3, tab4, tab5 = st.tabs([
                "üìä Core Risk", "üé≤ Monte Carlo", "üî¨ Advanced Analytics", "‚ö° Stress Tests", "üéØ VaR/CVaR Optimization"
            ])
            
            with tab1:
                col1, col2 = st.columns(2)
                
                with col1:
                    var_chart = create_var_waterfall(portfolio_returns)
                    if var_chart:
                        st.plotly_chart(var_chart, use_container_width=True)
    
                    # v9.7 NEW: VaR/CVaR on Return Distribution
                    var_dist = create_var_cvar_distribution(portfolio_returns)
                    if var_dist:
                        st.plotly_chart(var_dist, use_container_width=True)
                    else:
                        st.info("Insufficient data for distribution analysis (requires 30+ observations)")
    
                    risk_parity = create_risk_parity_analysis(enhanced_df)
                    if risk_parity:
                        st.plotly_chart(risk_parity, use_container_width=True)
                
                with col2:
                    efficient = create_efficient_frontier(enhanced_df)
                    if efficient:
                        st.plotly_chart(efficient, use_container_width=True)
    
                    # FIX 7: Add Drawdown Distribution chart
                    drawdown_dist = create_drawdown_distribution(portfolio_returns)
                    if drawdown_dist:
                        st.plotly_chart(drawdown_dist, use_container_width=True)
    
                # v9.7 NEW FEATURE: Rolling VaR/CVaR Evolution
                st.markdown("#### üìà v9.7: Rolling Risk Metrics Evolution")
                rolling_var_cvar = create_rolling_var_cvar_chart(portfolio_returns, window=60)
                if rolling_var_cvar:
                    st.plotly_chart(rolling_var_cvar, use_container_width=True)
                else:
                    st.info("Insufficient data for rolling VaR/CVaR analysis (requires 60+ days)")
    
            with tab2:
                simulations = run_monte_carlo_simulation(portfolio_returns)
                if simulations is not None:
                    monte_carlo_chart, mc_stats = create_monte_carlo_chart(simulations, 100000)
                    
                    if monte_carlo_chart:
                        st.plotly_chart(monte_carlo_chart, use_container_width=True)
                    
                    if mc_stats:
                        st.markdown("#### üìä Simulation Results")
                        st.markdown(f"""
                        **Key Statistics:**
                        - Expected Value: ${mc_stats['mean']:,.2f}
                        - Median: ${mc_stats['median']:,.2f}
                        - Best Case (95th): ${mc_stats['percentile_95']:,.2f}
                        - Worst Case (5th): ${mc_stats['percentile_5']:,.2f}
                        - Prob of Profit: {mc_stats['prob_profit']:.1f}%
                        """)
            
            with tab3:
                col1, col2 = st.columns(2)
                
                with col1:
                    rolling = create_rolling_metrics_chart(portfolio_returns)
                    if rolling:
                        st.plotly_chart(rolling, use_container_width=True)
                
                with col2:
                    underwater = create_underwater_plot(portfolio_returns)
                    if underwater:
                        st.plotly_chart(underwater, use_container_width=True)
                
                sunburst = create_risk_contribution_sunburst(enhanced_df)
                if sunburst:
                    st.plotly_chart(sunburst, use_container_width=True)
                
                corr_network = create_correlation_network(enhanced_df, start_date, end_date)
                if corr_network:
                    st.plotly_chart(corr_network, use_container_width=True)
            
            with tab4:
                # ===== FIX #3: Stress Test 'go' Undefined Error =====
                import plotly.graph_objects as go
    
                st.markdown("#### ‚ö° Historical Stress Test Analysis")
                st.info("üí° **Historical Stress Testing:** See how your current portfolio would have performed during major market crises")
    
                # Run historical stress test calculation
                with st.spinner("Calculating historical stress scenarios..."):
                    stress_results = calculate_historical_stress_test(enhanced_df)
    
                if not stress_results:
                    st.warning("‚ö†Ô∏è Unable to calculate historical stress tests. This may be due to data availability for your holdings during historical periods.")
                else:
                    # Period selector
                    selected_period = st.selectbox(
                        "Select Historical Stress Period",
                        options=list(stress_results.keys()),
                        index=len(stress_results) - 1 if len(stress_results) > 0 else 0
                    )
    
                    if selected_period in stress_results:
                        period_data = stress_results[selected_period]
                        metrics = period_data['metrics']
    
                        # Display key metrics
                        st.markdown("##### üìä Performance Metrics")
                        metric_col1, metric_col2, metric_col3, metric_col4 = st.columns(4)
    
                        with metric_col1:
                            st.metric(
                                "Portfolio Return",
                                f"{metrics['portfolio_return']:+.2f}%",
                                delta=None
                            )
    
                        with metric_col2:
                            st.metric(
                                "S&P 500 Return",
                                f"{metrics['spy_return']:+.2f}%",
                                delta=None
                            )
    
                        with metric_col3:
                            outperf_color = "normal" if metrics['outperformance'] >= 0 else "inverse"
                            st.metric(
                                "Outperformance",
                                f"{metrics['outperformance']:+.2f}%",
                                delta=f"{metrics['outperformance']:+.2f}%",
                                delta_color=outperf_color
                            )
    
                        with metric_col4:
                            st.metric(
                                "Max Drawdown",
                                f"{metrics['portfolio_drawdown']:.2f}%",
                                delta=f"{metrics['portfolio_drawdown'] - metrics['spy_drawdown']:+.2f}% vs SPY"
                            )
    
                        # Create line graph showing cumulative returns
                        st.markdown("##### üìà Cumulative Returns Comparison")
    
                        fig_stress = go.Figure()
    
                        # Portfolio line
                        fig_stress.add_trace(go.Scatter(
                            x=period_data['dates'],
                            y=period_data['portfolio_cumulative'],
                            mode='lines',
                            name='Your Portfolio',
                            line=dict(color='#00D4FF', width=3),
                            hovertemplate='<b>Portfolio</b><br>Date: %{x|%Y-%m-%d}<br>Value: %{y:.2f}<extra></extra>'
                        ))
    
                        # S&P 500 line
                        fig_stress.add_trace(go.Scatter(
                            x=period_data['dates'],
                            y=period_data['spy_cumulative'],
                            mode='lines',
                            name='S&P 500',
                            line=dict(color='#FF4136', width=2, dash='dash'),
                            hovertemplate='<b>S&P 500</b><br>Date: %{x|%Y-%m-%d}<br>Value: %{y:.2f}<extra></extra>'
                        ))
    
                        fig_stress.update_layout(
                            title=f"{selected_period} - Portfolio vs S&P 500",
                            xaxis_title="Date",
                            yaxis_title="Cumulative Return (Base 100)",
                            height=500,
                            hovermode='x unified',
                            legend=dict(
                                orientation="h",
                                yanchor="bottom",
                                y=1.02,
                                xanchor="right",
                                x=1
                            )
                        )
    
                        # Add baseline at 100
                        fig_stress.add_hline(
                            y=100,
                            line_dash="dot",
                            line_color=COLORS['text_muted'],
                            line_width=1,
                            annotation_text="Starting Value"
                        )
    
                        apply_chart_theme(fig_stress)
                        st.plotly_chart(fig_stress, use_container_width=True)
    
                        # Summary metrics table
                        st.markdown("##### üìã Detailed Stress Metrics")
    
                        summary_data = []
                        for period_name, data in stress_results.items():
                            m = data['metrics']
                            summary_data.append({
                                'Period': period_name,
                                'Portfolio Return': f"{m['portfolio_return']:+.2f}%",
                                'S&P 500 Return': f"{m['spy_return']:+.2f}%",
                                'Outperformance': f"{m['outperformance']:+.2f}%",
                                'Portfolio Max DD': f"{m['portfolio_drawdown']:.2f}%",
                                'SPY Max DD': f"{m['spy_drawdown']:.2f}%",
                                'Portfolio Vol': f"{m['portfolio_volatility']:.2f}%"
                            })
    
                        summary_df = pd.DataFrame(summary_data)
                        make_scrollable_table(summary_df, height=400, hide_index=True, use_container_width=True, column_config=None)
    
                        # Methodology notes
                        st.markdown("---")
                        st.markdown("##### ‚ö†Ô∏è Methodology & Important Notes")
                        st.caption("""
                        **Calculation Method:**
                        - Uses current portfolio weights applied to historical price data
                        - Compares against S&P 500 (^GSPC) performance during same periods
                        - Cumulative returns normalized to base 100 at period start
                        - Maximum drawdown calculated as peak-to-trough decline
    
                        **Important Limitations:**
                        - ‚ö†Ô∏è **Survivorship Bias:** Analysis assumes current holdings existed during historical periods. Companies that failed or weren't publicly traded are excluded.
                        - ‚ö†Ô∏è **Hindsight Bias:** Current portfolio composition may differ significantly from what would have been held historically
                        - ‚ö†Ô∏è **Data Availability:** Some holdings may lack historical data for earlier periods, affecting accuracy
                        - ‚ö†Ô∏è **No Rebalancing:** Assumes static weights throughout each period (no tactical adjustments)
    
                        **Use Case:** This analysis provides directional insight into portfolio resilience during crises, but should not be interpreted as definitive historical performance.
                        """)
    
            with tab5:  # NEW VaR/CVaR Optimization Tab
                # ===== FIX #7: VaR/CVaR 'go' Error =====
                import plotly.graph_objects as go
    
                st.markdown("### üéØ VaR/CVaR Portfolio Optimization")
                st.info("Optimize portfolio weights to minimize Conditional Value at Risk (CVaR) - the expected loss beyond VaR")
    
                col1, col2, col3 = st.columns([2, 2, 1])
    
                with col1:
                    confidence = st.slider("Confidence Level", 90, 99, 95, 1) / 100
                    lookback = st.slider("Lookback Period (days)", 60, 504, 252, 21)
    
                with col2:
                    # üéØ NEW v10.3: Risk Profile Selector
                    st.markdown("**Risk Profile** - Choose your investment style")
                    risk_profile_var = st.radio(
                        "Risk Tolerance",
                        options=['conservative', 'moderate', 'aggressive'],
                        format_func=lambda x: {
                            'conservative': 'üõ°Ô∏è Conservative - Capital Preservation',
                            'moderate': '‚öñÔ∏è Moderate - Balanced Growth',
                            'aggressive': 'üöÄ Aggressive - Maximum Returns'
                        }[x],
                        index=1,  # Default to Moderate
                        key="risk_profile_var",
                        help="Your risk profile automatically sets optimal position limits and diversification requirements"
                    )
    
                    # Display what this risk profile means
                    config_var = RiskProfile.get_config(risk_profile_var, 'cvar_minimization')
                    st.caption(f"üìä **Auto-configured:** Max position {config_var['max_position_base']*100:.0f}%, Min {config_var['min_diversification']} holdings, Risk budget {config_var['risk_budget_per_asset']*100:.0f}% per asset")
    
                with col3:
                    if st.button("üîÑ Run Optimization", type="primary", key="run_var_opt"):
                        st.session_state['run_optimization'] = True
    
                # Advanced: Manual Override (collapsed by default)
                with st.expander("üîß Advanced: Manual Position Constraints Override"):
                    st.warning("‚ö†Ô∏è Advanced users only - Manual overrides bypass risk profile automation")
                    use_manual_var = st.checkbox("Use manual position constraints", value=False, key="use_manual_var")
    
                    if use_manual_var:
                        col_a, col_b = st.columns(2)
                        with col_a:
                            max_position_var = st.slider(
                                "Max Position Size (%)",
                                min_value=1,
                                max_value=50,
                                value=int(config_var['max_position_base']*100),
                                step=1,
                                key="max_pos_var_manual",
                                help="Maximum weight allowed per security (prevents over-concentration)"
                            ) / 100
    
                        with col_b:
                            min_position_var = st.slider(
                                "Min Position Size (%)",
                                min_value=1,
                                max_value=50,
                                value=2,
                                step=1,
                                key="min_pos_var_manual",
                                help="Minimum meaningful position size (smaller positions excluded)"
                            ) / 100
    
                        # Validation: Ensure min < max
                        if min_position_var >= max_position_var:
                            st.error(f"‚ö†Ô∏è Min position ({min_position_var*100:.0f}%) must be less than max position ({max_position_var*100:.0f}%)")
                    else:
                        # Use risk profile defaults
                        max_position_var = config_var['max_position_base']
                        min_position_var = 0.02  # Standard minimum
    
                if st.session_state.get('run_optimization', False):
                    # Validate constraints before optimization
                    if min_position_var >= max_position_var:
                        st.error("‚ùå Cannot optimize: Min position must be less than max position")
                    elif max_position_var * len(enhanced_df) < 1.0:
                        st.error(f"‚ùå Cannot optimize: Max position too small. With {len(enhanced_df)} assets and {max_position_var*100:.0f}% max, portfolio cannot reach 100%")
                    else:
                        with st.spinner("Running portfolio optimization..."):
                            rebalancing_df, opt_metrics = calculate_var_cvar_portfolio_optimization(
                                enhanced_df, confidence, lookback, max_position_var, min_position_var
                            )
    
                        if rebalancing_df is not None:
                            st.session_state['rebalancing_df'] = rebalancing_df
                            st.session_state['opt_metrics'] = opt_metrics
                            st.success("‚úÖ Optimization complete!")
    
                            # Toast with key metrics
                            var_reduction = opt_metrics['var_reduction_pct']
                            cvar_reduction = opt_metrics['cvar_reduction_pct']
                            sharpe_improvement = opt_metrics['sharpe_improvement']
                            show_toast(
                                f"VaR/CVaR Optimization: -{var_reduction:.1f}% VaR, -{cvar_reduction:.1f}% CVaR, +{sharpe_improvement:.2f} Sharpe",
                                toast_type="success",
                                duration=5000
                            )
    
                # Display results if available
                if 'rebalancing_df' in st.session_state:
                    rebalancing_df = st.session_state['rebalancing_df']
                    opt_metrics = st.session_state['opt_metrics']
    
                    # Risk metrics improvement
                    st.markdown("#### üìä Risk Metrics Improvement")
                    col1, col2, col3, col4 = st.columns(4)
    
                    with col1:
                        st.metric("Current VaR", f"{opt_metrics['current_var']:.2f}%")
                        st.metric("Optimal VaR", f"{opt_metrics['optimal_var']:.2f}%",
                                 f"-{opt_metrics['var_reduction_pct']:.1f}%", delta_color="inverse")
    
                    with col2:
                        st.metric("Current CVaR", f"{opt_metrics['current_cvar']:.2f}%")
                        st.metric("Optimal CVaR", f"{opt_metrics['optimal_cvar']:.2f}%",
                                 f"-{opt_metrics['cvar_reduction_pct']:.1f}%", delta_color="inverse")
    
                    with col3:
                        st.metric("Current Sharpe", f"{opt_metrics['current_sharpe']:.2f}")
                        st.metric("Optimal Sharpe", f"{opt_metrics['optimal_sharpe']:.2f}",
                                 f"+{opt_metrics['sharpe_improvement']:.2f}")
    
                    with col4:
                        st.metric("Buy Trades", opt_metrics['buy_trades'])
                        st.metric("Sell Trades", opt_metrics['sell_trades'])
    
                    # üéØ NEW v10.3: Realism Scoring & Portfolio Insights
                    st.markdown("---")
                    st.markdown("#### üéØ Portfolio Quality Assessment")
    
                    # Get optimal weights from rebalancing_df
                    optimal_weights_dict = dict(zip(rebalancing_df['Ticker'], rebalancing_df['Optimal Weight %'] / 100))
                    optimal_weights_series = pd.Series(optimal_weights_dict)
    
                    # Create a returns dataframe for validation (fetch historical data)
                    try:
                        end_date = datetime.now()
                        start_date = end_date - timedelta(days=252)
    
                        returns_dict = {}
                        for ticker in rebalancing_df['Ticker']:
                            hist_data = fetch_historical_data(ticker, start_date, end_date)
                            if hist_data is not None and len(hist_data) > 1:
                                returns = hist_data['Close'].pct_change().dropna()
                                returns_dict[ticker] = returns
    
                        if returns_dict:
                            returns_df_check = pd.DataFrame(returns_dict).dropna()
    
                            # Calculate realism score
                            realism = validate_portfolio_realism(
                                optimal_weights_series.values,
                                returns_df_check,
                                'cvar_minimization'
                            )
    
                            # Calculate explanations
                            explainer = OptimizationExplainer()
                            explanations = explainer.explain_portfolio_weights(
                                optimal_weights_series.values,
                                returns_df_check,
                                'cvar_minimization',
                                None
                            )
    
                            # Identify red/yellow flags
                            red_flags_data = explainer.identify_red_flags(
                                optimal_weights_series.values,
                                returns_df_check,
                                config_var
                            )
    
                            # Display realism score prominently
                            col_a, col_b, col_c = st.columns([1, 2, 2])
    
                            with col_a:
                                score_color = "üü¢" if realism['overall'] >= 80 else "üü°" if realism['overall'] >= 60 else "üî¥"
                                st.metric("Realism Score", f"{score_color} {realism['overall']}/100")
    
                            with col_b:
                                st.markdown(f"**Classification:** {realism['classification']}")
                                if realism['issues']:
                                    st.caption(f"‚ö†Ô∏è Issues: {', '.join(realism['issues'])}")
    
                            with col_c:
                                # Effective holdings
                                effective_n = explanations['diversification']['effective_holdings']
                                st.metric("Effective Holdings", f"{effective_n:.1f}")
                                st.caption(explanations['diversification']['explanation'])
    
                            # Display red/yellow flags if any
                            if red_flags_data['red_flags'] or red_flags_data['yellow_flags']:
                                st.markdown("**‚ö†Ô∏è Alerts:**")
                                for flag in red_flags_data['red_flags']:
                                    st.error(flag)
                                for flag in red_flags_data['yellow_flags']:
                                    st.warning(flag)
                            else:
                                st.success("‚úÖ No major concerns detected - portfolio looks healthy!")
    
                            # Portfolio insights in expander
                            with st.expander("üìä Why These Weights? - Portfolio Explanation"):
                                st.markdown("##### Top Holdings Analysis")
                                for holding in explanations['top_holdings']:
                                    st.markdown(f"**{holding['ticker']}** - {holding['weight']*100:.1f}%")
                                    for reason in holding['reasons']:
                                        st.markdown(f"  ‚Ä¢ {reason}")
                                    st.markdown("")
    
                                st.markdown("##### Risk Contributors")
                                st.markdown("Assets contributing most to portfolio risk:")
                                for contributor in explanations['risk']['top_risk_contributors']:
                                    risk_pct = contributor['risk_contribution'] * 100 if contributor['risk_contribution'] > 0 else 0
                                    st.markdown(f"  ‚Ä¢ **{contributor['ticker']}**: {risk_pct:.1f}% risk contribution (weight: {contributor['weight']*100:.1f}%)")
    
                    except Exception as e:
                        st.info("üí° Portfolio quality metrics will be displayed after optimization completes")
    
                    st.markdown("---")
    
                    # Rebalancing instructions
                    st.markdown("#### üìã Rebalancing Instructions")
                    trades_only = rebalancing_df[rebalancing_df['Action'] != 'HOLD'].copy()
    
                    if len(trades_only) > 0:
                        # Format for display
                        trades_only['Trade Value'] = trades_only['Trade Value'].apply(
                            lambda x: f"${x:,.0f}" if x > 0 else f"-${abs(x):,.0f}"
                        )
                        trades_only['Weight Diff %'] = trades_only['Weight Diff %'].apply(
                            lambda x: f"{x:+.1f}%"
                        )
    
                        make_scrollable_table(
                            trades_only[['Ticker', 'Asset Name', 'Action', 'Shares to Trade',
                                       'Trade Value', 'Current Weight %', 'Optimal Weight %',
                                       'Weight Diff %']],
                            height=600,
                            hide_index=True,
                            use_container_width=True
                        )
    
                        # Download button
                        csv = rebalancing_df.to_csv(index=False)
                        st.download_button(
                            "üì• Export Optimization Plan",
                            csv,
                            f"var_optimization_{datetime.now().strftime('%Y%m%d')}.csv",
                            "text/csv"
                        )
    
                    # Weight comparison chart
                    st.markdown("#### üìà Portfolio Weight Comparison")
    
                    # Create comparison chart
                    fig = go.Figure()
    
                    # Sort by current weight
                    df_sorted = rebalancing_df.sort_values('Current Weight %', ascending=True)
    
                    fig.add_trace(go.Bar(
                        name='Current',
                        y=df_sorted['Ticker'],
                        x=df_sorted['Current Weight %'],
                        orientation='h',
                        marker_color=COLORS['electric_blue'],
                        text=df_sorted['Current Weight %'].apply(lambda x: f"{x:.1f}%"),
                        textposition='auto',
                    ))
    
                    fig.add_trace(go.Bar(
                        name='Optimal',
                        y=df_sorted['Ticker'],
                        x=df_sorted['Optimal Weight %'],
                        orientation='h',
                        marker_color=COLORS['teal'],
                        text=df_sorted['Optimal Weight %'].apply(lambda x: f"{x:.1f}%"),
                        textposition='auto',
                    ))
    
                    fig.update_layout(
                        title="Current vs Optimal Portfolio Weights",
                        xaxis_title="Weight (%)",
                        yaxis_title="",
                        barmode='group',
                        height=max(400, len(df_sorted) * 40),
                        template="plotly_dark",
                        paper_bgcolor=COLORS['background'],
                        plot_bgcolor=COLORS['card_background'],
                        showlegend=True,
                        legend=dict(
                            orientation="h",
                            yanchor="bottom",
                            y=1.02,
                            xanchor="right",
                            x=1
                        )
                    )
    
                    st.plotly_chart(fig, use_container_width=True)
    
        # Continue with remaining pages...
        # ========================================================================
        # PERFORMANCE SUITE
        # ========================================================================
        elif page == "üíé Performance Suite":
            # ===== FIX #4 & #6: Performance Suite imports =====
            import plotly.graph_objects as go
            import plotly.express as px
            from scipy import stats
            import numpy as np
    
            st.title("üìä Performance Suite")
    
            portfolio_data = load_portfolio_data()
    
            if portfolio_data is None or (isinstance(portfolio_data, pd.DataFrame) and portfolio_data.empty):
                st.warning("‚ö†Ô∏è No portfolio data.")
                st.stop()
    
            df = pd.DataFrame(portfolio_data)
            enhanced_df = create_enhanced_holdings_table(df)
    
            with st.spinner("Calculating portfolio metrics..."):
                portfolio_returns = calculate_portfolio_returns(df, start_date, end_date)
                benchmark_returns = calculate_benchmark_returns(selected_benchmark, start_date, end_date)
    
            # === TAB STRUCTURE ===
            tab1, tab2, tab3, tab4 = st.tabs([
                "üìà Portfolio Performance",
                "üéØ Individual Securities",
                "‚ö†Ô∏è Risk Decomposition",
                "üìä Attribution & Benchmarking"
            ])
    
            # ============================================================
            # TAB 1: PORTFOLIO PERFORMANCE (Enhanced)
            # ============================================================
            with tab1:
                st.subheader("Portfolio Performance Metrics")
    
                if portfolio_returns is not None and len(portfolio_returns) > 0:
    
                    # === KEY METRICS GRID ===
                    col1, col2, col3, col4 = st.columns(4)
    
                    # Total Return
                    total_return = (1 + portfolio_returns).prod() - 1
                    n_years = len(portfolio_returns) / 252
                    annualized_return = (1 + total_return) ** (1/n_years) - 1 if n_years > 0 else 0
    
                    with col1:
                        st.metric(
                            "Annualized Return",
                            f"{annualized_return*100:.2f}%",
                            delta=f"{(total_return*100):.2f}% total"
                        )
    
                    # Volatility
                    annualized_vol = portfolio_returns.std() * np.sqrt(252)
    
                    with col2:
                        st.metric(
                            "Annualized Volatility",
                            f"{annualized_vol*100:.2f}%"
                        )
    
                    # Sharpe Ratio
                    sharpe = calculate_sharpe_ratio(portfolio_returns)
    
                    with col3:
                        sharpe_color = "normal" if sharpe and sharpe > 1.0 else "inverse"
                        sharpe_delta = "Excellent" if sharpe and sharpe > 1.5 else ("Good" if sharpe and sharpe > 1.0 else "Fair")
                        st.metric(
                            "Sharpe Ratio",
                            f"{sharpe:.2f}" if sharpe else "N/A",
                            delta=sharpe_delta if sharpe else None,
                            delta_color=sharpe_color if sharpe else "off"
                        )
    
                    # Max Drawdown
                    max_dd = calculate_max_drawdown(portfolio_returns)
    
                    with col4:
                        st.metric(
                            "Max Drawdown",
                            f"{max_dd:.2f}%" if max_dd else "N/A",
                            delta_color="inverse"
                        )
    
                    st.divider()
    
                    # === RETURNS DISTRIBUTION ===
                    col1, col2 = st.columns(2)
    
                    with col1:
                        st.subheader("Returns Distribution")
    
                        # Histogram
                        fig_hist = go.Figure()
    
                        fig_hist.add_trace(go.Histogram(
                            x=portfolio_returns * 100,
                            nbinsx=50,
                            marker_color='#00d4ff',
                            opacity=0.7,
                            name='Daily Returns'
                        ))
    
                        # Add normal distribution overlay
                        mean_return = portfolio_returns.mean() * 100
                        std_return = portfolio_returns.std() * 100
    
                        x_range = np.linspace(
                            portfolio_returns.min() * 100,
                            portfolio_returns.max() * 100,
                            100
                        )
    
                        normal_dist = stats.norm.pdf(x_range, mean_return, std_return)
                        # Scale to match histogram
                        normal_dist = normal_dist * len(portfolio_returns) * (x_range[1] - x_range[0])
    
                        fig_hist.add_trace(go.Scatter(
                            x=x_range,
                            y=normal_dist,
                            mode='lines',
                            line=dict(color='#ff3366', width=2),
                            name='Normal Distribution'
                        ))
    
                        fig_hist.update_layout(
                            title="Daily Returns Distribution",
                            xaxis_title="Return (%)",
                            yaxis_title="Frequency",
                            height=400,
                            showlegend=True,
                            paper_bgcolor='rgba(0, 0, 0, 0)',
                            plot_bgcolor='rgba(10, 25, 41, 0.3)',
                            font=dict(color='#ffffff')
                        )
    
                        st.plotly_chart(fig_hist, use_container_width=True)
    
                    with col2:
                        st.subheader("Rolling Performance")
    
                        # Rolling Sharpe Ratio (90-day)
                        rolling_window = min(90, len(portfolio_returns) // 2)
    
                        if rolling_window > 20:
                            rolling_sharpe = portfolio_returns.rolling(rolling_window).apply(
                                lambda x: (x.mean() / x.std() * np.sqrt(252)) if x.std() > 0 else 0
                            )
    
                            fig_rolling = go.Figure()
    
                            fig_rolling.add_trace(go.Scatter(
                                x=rolling_sharpe.index,
                                y=rolling_sharpe.values,
                                mode='lines',
                                line=dict(color='#00ff88', width=2),
                                fill='tozeroy',
                                fillcolor='rgba(0, 255, 136, 0.2)',
                                name='Rolling Sharpe'
                            ))
    
                            # Add 1.0 reference line
                            fig_rolling.add_hline(
                                y=1.0,
                                line_dash="dash",
                                line_color="#ffaa00",
                                annotation_text="Sharpe = 1.0 (Good)",
                                annotation_position="right"
                            )
    
                            fig_rolling.update_layout(
                                title=f"Rolling Sharpe Ratio ({rolling_window}-day)",
                                xaxis_title="Date",
                                yaxis_title="Sharpe Ratio",
                                height=400,
                                paper_bgcolor='rgba(0, 0, 0, 0)',
                                plot_bgcolor='rgba(10, 25, 41, 0.3)',
                                font=dict(color='#ffffff')
                            )
    
                            st.plotly_chart(fig_rolling, use_container_width=True)
    
                    st.divider()
    
                    # === ADVANCED METRICS ===
                    st.subheader("Advanced Performance Metrics")
    
                    metric_col1, metric_col2, metric_col3, metric_col4 = st.columns(4)
    
                    # Sortino Ratio
                    sortino = calculate_sortino_ratio(portfolio_returns)
    
                    with metric_col1:
                        st.metric("Sortino Ratio", f"{sortino:.2f}" if sortino else "N/A")
    
                    # Calmar Ratio
                    calmar = calculate_calmar_ratio(portfolio_returns)
    
                    with metric_col2:
                        st.metric("Calmar Ratio", f"{calmar:.2f}" if calmar else "N/A")
    
                    # Win Rate
                    win_rate = (portfolio_returns > 0).sum() / len(portfolio_returns) * 100
    
                    with metric_col3:
                        st.metric("Win Rate", f"{win_rate:.1f}%")
    
                    # VaR (95%)
                    var_95 = calculate_var(portfolio_returns, confidence=0.95)
    
                    with metric_col4:
                        st.metric("VaR (95%)", f"{var_95:.2f}%" if var_95 else "N/A")
    
            # ============================================================
            # TAB 2: INDIVIDUAL SECURITIES ANALYSIS (NEW - GAME CHANGER)
            # ============================================================
            with tab2:
                st.subheader("Individual Security Performance Analysis")
    
                st.info("üéØ Institutional-grade metrics for each holding - analyze like a professional fund manager")
    
                # Security selector
                selected_ticker = st.selectbox(
                    "Select Security to Analyze:",
                    options=enhanced_df['Ticker'].tolist(),
                    index=0
                )
    
                if selected_ticker:
                    # Get holding data
                    holding = enhanced_df[enhanced_df['Ticker'] == selected_ticker].iloc[0]
    
                    # Display header
                    col1, col2, col3 = st.columns([2, 1, 1])
    
                    with col1:
                        st.markdown(f"### {holding.get('Asset Name', selected_ticker)} ({selected_ticker})")
                        st.caption(f"Sector: {holding.get('Sector', 'Unknown')}")
    
                    with col2:
                        current_price = holding.get('Current Price', 0)
                        st.metric("Current Price", f"${current_price:.2f}")
    
                    with col3:
                        weight = holding.get('Weight %', 0)
                        st.metric("Portfolio Weight", f"{weight:.2f}%")
    
                    st.divider()
    
                    # === CHART CONTROLS ===
                    st.markdown("#### ‚öôÔ∏è Chart Settings")
    
                    ctrl_col1, ctrl_col2, ctrl_col3, ctrl_col4 = st.columns([2, 2, 2, 2])
    
                    with ctrl_col1:
                        time_range = st.selectbox(
                            "Time Period",
                            options=["1M", "3M", "6M", "YTD", "1Y", "2Y", "5Y", "Max"],
                            index=4  # Default to 1Y
                        )
    
                    with ctrl_col2:
                        chart_type = st.selectbox(
                            "Chart Type",
                            options=["Candlestick", "Line"],
                            index=0
                        )
    
                    with ctrl_col3:
                        show_volume = st.checkbox("Show Volume", value=True)
    
                    with ctrl_col4:
                        show_indicators = st.checkbox("Show Indicators", value=True)
    
                    # Multi-security comparison
                    st.markdown("#### üìä Multi-Security Comparison")
                    compare_mode = st.checkbox("Enable Comparison Mode", value=False)
    
                    compare_tickers = [selected_ticker]
                    if compare_mode:
                        available_tickers = [t for t in enhanced_df['Ticker'].tolist() if t != selected_ticker]
                        additional_tickers = st.multiselect(
                            "Add securities to compare:",
                            options=available_tickers,
                            max_selections=4,
                            help="Compare up to 5 securities total"
                        )
                        compare_tickers.extend(additional_tickers)
    
                    # === CALCULATE DATE RANGE ===
                    end_date_ticker = datetime.now()
    
                    if time_range == "1M":
                        start_date_ticker = end_date_ticker - timedelta(days=30)
                    elif time_range == "3M":
                        start_date_ticker = end_date_ticker - timedelta(days=90)
                    elif time_range == "6M":
                        start_date_ticker = end_date_ticker - timedelta(days=180)
                    elif time_range == "YTD":
                        start_date_ticker = datetime(end_date_ticker.year, 1, 1)
                    elif time_range == "1Y":
                        start_date_ticker = end_date_ticker - timedelta(days=365)
                    elif time_range == "2Y":
                        start_date_ticker = end_date_ticker - timedelta(days=730)
                    elif time_range == "5Y":
                        start_date_ticker = end_date_ticker - timedelta(days=1825)
                    else:  # Max
                        start_date_ticker = end_date_ticker - timedelta(days=3650)  # 10 years
    
                    # === FETCH COMPREHENSIVE DATA FOR TICKER ===
                    ticker_hist = fetch_historical_data(selected_ticker, start_date_ticker, end_date_ticker)
    
                    if ticker_hist is not None and len(ticker_hist) > 20:
    
                        # Calculate returns
                        ticker_returns = ticker_hist['Close'].pct_change().dropna()
    
                        # === PERFORMANCE METRICS ===
                        st.subheader("üìà Performance Metrics (1 Year)")
    
                        perf_col1, perf_col2, perf_col3, perf_col4, perf_col5 = st.columns(5)
    
                        # Total Return
                        total_ret = ((ticker_hist['Close'].iloc[-1] / ticker_hist['Close'].iloc[0]) - 1) * 100
    
                        with perf_col1:
                            st.metric("Total Return", f"{total_ret:+.2f}%")
    
                        # Annualized Return
                        n_years_ticker = len(ticker_returns) / 252
                        ann_ret = ((1 + total_ret/100) ** (1/n_years_ticker) - 1) * 100 if n_years_ticker > 0 else 0
    
                        with perf_col2:
                            st.metric("Annualized Return", f"{ann_ret:.2f}%")
    
                        # Volatility
                        ann_vol_ticker = ticker_returns.std() * np.sqrt(252) * 100
    
                        with perf_col3:
                            st.metric("Volatility (Ann.)", f"{ann_vol_ticker:.2f}%")
    
                        # Sharpe Ratio
                        sharpe_ticker = calculate_sharpe_ratio(ticker_returns)
    
                        with perf_col4:
                            st.metric("Sharpe Ratio", f"{sharpe_ticker:.2f}" if sharpe_ticker else "N/A")
    
                        # Max Drawdown
                        max_dd_ticker = calculate_max_drawdown(ticker_returns)
    
                        with perf_col5:
                            st.metric("Max Drawdown", f"{max_dd_ticker:.2f}%" if max_dd_ticker else "N/A")
    
                        st.divider()
    
                        # === PRICE CHART WITH TECHNICAL INDICATORS ===
                        if compare_mode and len(compare_tickers) > 1:
                            st.subheader("üìä Multi-Security Comparison")
    
                            # Fetch data for all comparison tickers
                            comparison_data = {}
                            colors = ['#00D4FF', '#FF4136', '#2ECC40', '#FFDC00', '#B10DC9']
    
                            for idx, ticker in enumerate(compare_tickers):
                                ticker_data = fetch_historical_data(ticker, start_date_ticker, end_date_ticker)
                                if ticker_data is not None and len(ticker_data) > 0:
                                    # Normalize to base 100
                                    normalized = (ticker_data['Close'] / ticker_data['Close'].iloc[0]) * 100
                                    comparison_data[ticker] = {
                                        'data': normalized,
                                        'color': colors[idx % len(colors)]
                                    }
    
                            # Create comparison chart
                            fig_compare = go.Figure()
    
                            for ticker, info in comparison_data.items():
                                fig_compare.add_trace(go.Scatter(
                                    x=info['data'].index,
                                    y=info['data'],
                                    mode='lines',
                                    name=ticker,
                                    line=dict(color=info['color'], width=2),
                                    hovertemplate=f'<b>{ticker}</b><br>Date: %{{x|%Y-%m-%d}}<br>Value: %{{y:.2f}}<extra></extra>'
                                ))
    
                            fig_compare.update_layout(
                                title=f"Normalized Price Comparison ({time_range}) - Base 100",
                                xaxis_title="Date",
                                yaxis_title="Normalized Value (Base 100)",
                                height=600,
                                hovermode='x unified',
                                legend=dict(
                                    orientation="h",
                                    yanchor="bottom",
                                    y=1.02,
                                    xanchor="right",
                                    x=1
                                )
                            )
    
                            fig_compare.add_hline(
                                y=100,
                                line_dash="dot",
                                line_color=COLORS['text_muted'],
                                line_width=1,
                                annotation_text="Starting Value"
                            )
    
                            apply_chart_theme(fig_compare)
                            st.plotly_chart(fig_compare, use_container_width=True)
    
                            # Comparison metrics table
                            st.markdown("##### Performance Comparison")
                            comparison_metrics = []
    
                            for ticker in compare_tickers:
                                ticker_data = fetch_historical_data(ticker, start_date_ticker, end_date_ticker)
                                if ticker_data is not None and len(ticker_data) > 5:
                                    total_return = ((ticker_data['Close'].iloc[-1] / ticker_data['Close'].iloc[0]) - 1) * 100
                                    returns = ticker_data['Close'].pct_change().dropna()
                                    volatility = returns.std() * np.sqrt(252) * 100
                                    sharpe = calculate_sharpe_ratio(returns)
    
                                    comparison_metrics.append({
                                        'Ticker': ticker,
                                        'Total Return': f"{total_return:+.2f}%",
                                        'Volatility': f"{volatility:.2f}%",
                                        'Sharpe Ratio': f"{sharpe:.2f}" if sharpe else "N/A",
                                        'Current Price': f"${ticker_data['Close'].iloc[-1]:.2f}"
                                    })
    
                            if comparison_metrics:
                                comp_df = pd.DataFrame(comparison_metrics)
                                make_scrollable_table(comp_df, height=400, hide_index=True, use_container_width=True, column_config=None)
    
                        else:
                            # Single security analysis with technical indicators
                            st.subheader("üìä Price Chart & Technical Analysis")
    
                            # Calculate technical indicators
                            ticker_hist['MA_50'] = ticker_hist['Close'].rolling(50).mean()
                            ticker_hist['MA_200'] = ticker_hist['Close'].rolling(200).mean()
    
                            # Bollinger Bands
                            ticker_hist['BB_middle'] = ticker_hist['Close'].rolling(20).mean()
                            ticker_hist['BB_std'] = ticker_hist['Close'].rolling(20).std()
                            ticker_hist['BB_upper'] = ticker_hist['BB_middle'] + (2 * ticker_hist['BB_std'])
                            ticker_hist['BB_lower'] = ticker_hist['BB_middle'] - (2 * ticker_hist['BB_std'])
    
                            # Create subplots if volume is enabled
                            if show_volume:
                                from plotly.subplots import make_subplots
                                fig_price = make_subplots(
                                    rows=2, cols=1,
                                    shared_xaxes=True,
                                    vertical_spacing=0.03,
                                    row_heights=[0.7, 0.3],
                                    subplot_titles=(f"{selected_ticker} - {chart_type} Chart ({time_range})", "Volume")
                                )
                            else:
                                fig_price = go.Figure()
    
                            # Add price chart based on selected type
                            if chart_type == "Candlestick":
                                price_trace = go.Candlestick(
                                    x=ticker_hist.index,
                                    open=ticker_hist['Open'],
                                    high=ticker_hist['High'],
                                    low=ticker_hist['Low'],
                                    close=ticker_hist['Close'],
                                    name='Price',
                                    increasing_line_color='#00ff88',
                                    decreasing_line_color='#ff3366'
                                )
                            else:  # Line chart
                                price_trace = go.Scatter(
                                    x=ticker_hist.index,
                                    y=ticker_hist['Close'],
                                    mode='lines',
                                    name='Price',
                                    line=dict(color='#00D4FF', width=2),
                                    fill='tozeroy',
                                    fillcolor='rgba(0, 212, 255, 0.1)'
                                )
    
                            if show_volume:
                                fig_price.add_trace(price_trace, row=1, col=1)
                            else:
                                fig_price.add_trace(price_trace)
    
                            # Add technical indicators if enabled
                            if show_indicators:
                                row_num = 1 if show_volume else None
                                col_num = 1 if show_volume else None
    
                                # Moving averages
                                fig_price.add_trace(go.Scatter(
                                    x=ticker_hist.index,
                                    y=ticker_hist['MA_50'],
                                    mode='lines',
                                    line=dict(color='#00d4ff', width=1.5),
                                    name='MA 50'
                                ), row=row_num, col=col_num)
    
                                fig_price.add_trace(go.Scatter(
                                    x=ticker_hist.index,
                                    y=ticker_hist['MA_200'],
                                    mode='lines',
                                    line=dict(color='#ffaa00', width=1.5),
                                    name='MA 200'
                                ), row=row_num, col=col_num)
    
                                # Bollinger Bands
                                fig_price.add_trace(go.Scatter(
                                    x=ticker_hist.index,
                                    y=ticker_hist['BB_upper'],
                                    mode='lines',
                                    line=dict(color='#b794f6', width=1, dash='dash'),
                                    name='BB Upper',
                                    showlegend=False
                                ), row=row_num, col=col_num)
    
                                fig_price.add_trace(go.Scatter(
                                    x=ticker_hist.index,
                                    y=ticker_hist['BB_lower'],
                                    mode='lines',
                                    line=dict(color='#b794f6', width=1, dash='dash'),
                                    name='BB Lower',
                                    fill='tonexty',
                                    fillcolor='rgba(183, 148, 246, 0.1)'
                                ), row=row_num, col=col_num)
    
                            # Add volume bars if enabled
                            if show_volume:
                                colors_vol = ['#00ff88' if ticker_hist['Close'].iloc[i] >= ticker_hist['Open'].iloc[i]
                                             else '#ff3366' for i in range(len(ticker_hist))]
    
                                fig_price.add_trace(go.Bar(
                                    x=ticker_hist.index,
                                    y=ticker_hist['Volume'],
                                    name='Volume',
                                    marker=dict(color=colors_vol),
                                    showlegend=False
                                ), row=2, col=1)
    
                            # Update layout
                            if show_volume:
                                fig_price.update_layout(
                                    height=700,
                                    hovermode='x unified',
                                    xaxis_rangeslider_visible=False,
                                    xaxis2_title="Date",
                                    yaxis_title="Price ($)",
                                    yaxis2_title="Volume"
                                )
                            else:
                                fig_price.update_layout(
                                    title=f"{selected_ticker} - {chart_type} Chart ({time_range})",
                                    xaxis_title="Date",
                                    yaxis_title="Price ($)",
                                    height=600,
                                    xaxis_rangeslider_visible=False
                                )
    
                            apply_chart_theme(fig_price)
                            st.plotly_chart(fig_price, use_container_width=True)
    
                        st.divider()
    
                        # === RISK METRICS ===
                        st.subheader("‚ö†Ô∏è Risk Analysis")
    
                        risk_col1, risk_col2 = st.columns(2)
    
                        with risk_col1:
                            # VaR and CVaR
                            var_95_ticker = calculate_var(ticker_returns, confidence=0.95)
                            cvar_95_ticker = calculate_cvar(ticker_returns, confidence=0.95)
    
                            st.markdown("**Value at Risk (VaR)**")
                            st.metric("VaR 95%", f"{var_95_ticker:.2f}%" if var_95_ticker else "N/A",
                                     help="Maximum expected loss on 95% of days")
                            st.metric("CVaR 95%", f"{cvar_95_ticker:.2f}%" if cvar_95_ticker else "N/A",
                                     help="Expected loss when VaR is breached")
    
                        with risk_col2:
                            # Beta and correlation to SPY
                            try:
                                spy_hist = fetch_historical_data('SPY', start_date_ticker, end_date_ticker)
    
                                if spy_hist is not None and len(spy_hist) > 20:
                                    spy_returns = spy_hist['Close'].pct_change().dropna()
    
                                    # Align dates
                                    common_dates = ticker_returns.index.intersection(spy_returns.index)
                                    ticker_aligned = ticker_returns.loc[common_dates]
                                    spy_aligned = spy_returns.loc[common_dates]
    
                                    # Calculate beta
                                    covariance = np.cov(ticker_aligned, spy_aligned)[0][1]
                                    market_variance = np.var(spy_aligned)
                                    beta = covariance / market_variance if market_variance > 0 else 1.0
    
                                    # Calculate correlation
                                    correlation = ticker_aligned.corr(spy_aligned)
    
                                    st.markdown("**Market Relationship**")
                                    st.metric("Beta (vs SPY)", f"{beta:.2f}",
                                             help="Sensitivity to market movements")
                                    st.metric("Correlation (vs SPY)", f"{correlation:.2f}",
                                             help="How closely it tracks the market")
                            except:
                                st.warning("Unable to calculate market relationship metrics")
    
                        st.divider()
    
                        # === CONTRIBUTION TO PORTFOLIO ===
                        st.subheader("üìä Portfolio Contribution")
    
                        contrib_col1, contrib_col2, contrib_col3 = st.columns(3)
    
                        with contrib_col1:
                            position_value = holding.get('Total Value', 0)
                            st.metric("Position Value", f"${position_value:,.2f}")
    
                        with contrib_col2:
                            gain_loss_pct = holding.get('Total Gain/Loss %', 0)
                            st.metric("Position Return", f"{gain_loss_pct:+.2f}%")
    
                        with contrib_col3:
                            # Contribution to portfolio return
                            portfolio_contribution = (weight / 100) * gain_loss_pct
                            st.metric("Portfolio Contribution", f"{portfolio_contribution:+.2f}%",
                                     help="This position's contribution to total portfolio return")
    
                    else:
                        st.warning(f"Insufficient historical data for {selected_ticker}")
    
            # ============================================================
            # TAB 3: RISK DECOMPOSITION (NEW)
            # ============================================================
            with tab3:
                st.subheader("Risk Decomposition Analysis")
    
                st.info("Understand WHERE your portfolio risk comes from")
    
                if portfolio_returns is not None and len(portfolio_returns) > 20:
    
                    # Calculate portfolio volatility
                    portfolio_vol = portfolio_returns.std() * np.sqrt(252) * 100
    
                    st.metric("Portfolio Volatility (Annualized)", f"{portfolio_vol:.2f}%")
    
                    st.divider()
    
                    # === POSITION-LEVEL RISK CONTRIBUTION ===
                    st.subheader("üìä Risk Contribution by Position")
    
                    st.markdown("""
                    **Marginal Contribution to Risk (MCR):** How much each position contributes to total portfolio risk.
    
                    - High MCR = This position drives a lot of portfolio volatility
                    - Positions with similar weights can have very different MCRs due to correlations
                    """)
    
                    # Calculate for each position
                    risk_contributions = []
    
                    for _, holding_item in enhanced_df.iterrows():
                        ticker_risk = holding_item['Ticker']
                        weight_risk = holding_item['Weight %'] / 100
    
                        # Get ticker returns
                        ticker_hist_risk = fetch_historical_data(ticker_risk,
                                                            datetime.now() - timedelta(days=365),
                                                            datetime.now())
    
                        if ticker_hist_risk is not None and len(ticker_hist_risk) > 20:
                            ticker_returns_risk = ticker_hist_risk['Close'].pct_change().dropna()
                            ticker_vol_risk = ticker_returns_risk.std() * np.sqrt(252)
    
                            # Simplified MCR: weight * volatility (proper MCR requires covariance matrix)
                            mcr = weight_risk * ticker_vol_risk * 100
    
                            risk_contributions.append({
                                'Ticker': ticker_risk,
                                'Weight %': weight_risk * 100,
                                'Volatility %': ticker_vol_risk * 100,
                                'Risk Contribution %': mcr
                            })
    
                    if risk_contributions:
                        risk_df = pd.DataFrame(risk_contributions).sort_values('Risk Contribution %', ascending=False)
    
                        # Normalize to percentage of total risk
                        total_risk = risk_df['Risk Contribution %'].sum()
                        risk_df['% of Portfolio Risk'] = (risk_df['Risk Contribution %'] / total_risk * 100).round(1)
    
                        # Display table
                        make_scrollable_table(risk_df, height=600, hide_index=True, use_container_width=True)
    
                        # Visualization
                        fig_risk_contrib = go.Figure(go.Bar(
                            x=risk_df['% of Portfolio Risk'],
                            y=risk_df['Ticker'],
                            orientation='h',
                            marker_color='#ff6b00',
                            text=[f"{val:.1f}%" for val in risk_df['% of Portfolio Risk']],
                            textposition='outside'
                        ))
    
                        fig_risk_contrib.update_layout(
                            title="Risk Contribution by Position",
                            xaxis_title="% of Total Portfolio Risk",
                            yaxis_title="",
                            height=500,
                            paper_bgcolor='rgba(0, 0, 0, 0)',
                            plot_bgcolor='rgba(10, 25, 41, 0.3)',
                            font=dict(color='#ffffff')
                        )
    
                        st.plotly_chart(fig_risk_contrib, use_container_width=True)
    
                # === SECTOR ALLOCATION ANALYSIS ===
                st.divider()
                st.markdown("### üìä Sector Allocation Analysis")
                st.info("View portfolio sector distribution with enhanced visibility")
    
                # Use full width for better label visibility
                sector_chart = create_professional_sector_allocation_pie(enhanced_df)
                if sector_chart:
                    # Increase height for better label display
                    sector_chart.update_layout(
                        height=600,
                        margin=dict(l=20, r=150, t=40, b=20),  # More margin for labels
                        showlegend=True,
                        legend=dict(
                            yanchor="middle",
                            y=0.5,
                            xanchor="left",
                            x=1.05
                        )
                    )
                    st.plotly_chart(sector_chart, use_container_width=True)
    
            # ============================================================
            # TAB 4: ATTRIBUTION & BENCHMARKING (Enhanced)
            # ============================================================
            with tab4:
                st.subheader("Performance Attribution & Benchmark Comparison")
    
                if benchmark_returns is not None and portfolio_returns is not None and len(portfolio_returns) > 0:
    
                    # Align returns
                    common_dates = portfolio_returns.index.intersection(benchmark_returns.index)
                    port_aligned = portfolio_returns.loc[common_dates]
                    bench_aligned = benchmark_returns.loc[common_dates]
    
                    # Calculate metrics
                    port_total = (1 + port_aligned).prod() - 1
                    bench_total = (1 + bench_aligned).prod() - 1
                    excess_return = port_total - bench_total
    
                    # Display summary
                    col1, col2, col3 = st.columns(3)
    
                    with col1:
                        st.metric("Portfolio Return", f"{port_total*100:.2f}%")
    
                    with col2:
                        st.metric("Benchmark Return (SPY)", f"{bench_total*100:.2f}%")
    
                    with col3:
                        st.metric("Excess Return (Alpha)", f"{excess_return*100:+.2f}%",
                                 delta_color="normal" if excess_return > 0 else "inverse")
    
                    st.divider()
    
                    # === CUMULATIVE RETURN COMPARISON ===
                    st.subheader("üìà Cumulative Performance vs Benchmark")
    
                    port_cumulative = (1 + port_aligned).cumprod() - 1
                    bench_cumulative = (1 + bench_aligned).cumprod() - 1
    
                    fig_cumulative = go.Figure()
    
                    fig_cumulative.add_trace(go.Scatter(
                        x=port_cumulative.index,
                        y=port_cumulative.values * 100,
                        mode='lines',
                        line=dict(color='#00d4ff', width=2),
                        name='Your Portfolio'
                    ))
    
                    fig_cumulative.add_trace(go.Scatter(
                        x=bench_cumulative.index,
                        y=bench_cumulative.values * 100,
                        mode='lines',
                        line=dict(color='#ffaa00', width=2, dash='dash'),
                        name='SPY Benchmark'
                    ))
    
                    fig_cumulative.update_layout(
                        title="Cumulative Returns Comparison",
                        xaxis_title="Date",
                        yaxis_title="Cumulative Return (%)",
                        height=500,
                        paper_bgcolor='rgba(0, 0, 0, 0)',
                        plot_bgcolor='rgba(10, 25, 41, 0.3)',
                        font=dict(color='#ffffff'),
                        hovermode='x unified'
                    )
    
                    st.plotly_chart(fig_cumulative, use_container_width=True)
    
                    st.divider()
    
                    # === TRACKING ERROR & INFORMATION RATIO ===
                    st.subheader("üìä Active Management Metrics")
    
                    tracking_col1, tracking_col2, tracking_col3 = st.columns(3)
    
                    # Tracking Error
                    excess_returns = port_aligned - bench_aligned
                    tracking_error = excess_returns.std() * np.sqrt(252) * 100
    
                    with tracking_col1:
                        st.metric("Tracking Error", f"{tracking_error:.2f}%",
                                 help="Volatility of excess returns vs benchmark")
    
                    # Information Ratio
                    info_ratio = calculate_information_ratio(port_aligned, bench_aligned)
    
                    with tracking_col2:
                        st.metric("Information Ratio", f"{info_ratio:.2f}" if info_ratio else "N/A",
                                 help="Excess return per unit of tracking error")
    
                    # Active Share (simplified - would need holdings-level data for true calculation)
                    with tracking_col3:
                        st.metric("Active Positions", f"{len(enhanced_df)}",
                                 help="Number of holdings in portfolio")
        
        # ========================================================================
        # PORTFOLIO DEEP DIVE - ENHANCED
        # ========================================================================
        elif page == "üî¨ Portfolio Deep Dive":
            st.markdown("## üî¨ PORTFOLIO DEEP DIVE - ENHANCED")
            st.markdown("---")
    
            portfolio_data = load_portfolio_data()
            
            if portfolio_data is None or (isinstance(portfolio_data, pd.DataFrame) and portfolio_data.empty):
                st.warning("‚ö†Ô∏è No portfolio data.")
                st.stop()
            
            df = pd.DataFrame(portfolio_data)
            enhanced_df = create_enhanced_holdings_table(df)
    
            tab1, tab2, tab3, tab4 = st.tabs([
                "üéØ Attribution", "üîÑ Sector Rotation", "üìä Concentration", "üèÜ Brinson Attribution"
            ])
            
            with tab1:
                col1, col2 = st.columns(2)
                
                with col1:
                    heatmap = create_portfolio_heatmap(enhanced_df)
                    if heatmap:
                        st.plotly_chart(heatmap, use_container_width=True)
                
                with col2:
                    waterfall = create_holdings_attribution_waterfall(enhanced_df)
                    if waterfall:
                        st.plotly_chart(waterfall, use_container_width=True)
            
            with tab2:
                rotation = create_sector_rotation_heatmap(enhanced_df, start_date, end_date)
                if rotation:
                    st.plotly_chart(rotation, use_container_width=True)
            
            with tab3:
                col1, col2 = st.columns([1, 2])
                
                with col1:
                    gauge = create_concentration_gauge(enhanced_df)
                    if gauge:
                        st.plotly_chart(gauge, use_container_width=True)
                
                with col2:
                    # ENHANCED: Better concentration visual
                    conc_analysis = create_concentration_analysis(enhanced_df)
                    if conc_analysis:
                        st.plotly_chart(conc_analysis, use_container_width=True)
    
            with tab4:
                st.markdown("### üèÜ Brinson Attribution Analysis")
                st.markdown("Decompose portfolio performance into **Allocation** (sector timing) vs **Selection** (stock picking) skill")
    
                # Validate and map sectors before attribution analysis
                enhanced_df_validated = validate_and_map_sectors(enhanced_df.copy())
    
                # Get benchmark data
                benchmark_weights = SP500_SECTOR_WEIGHTS
                with st.spinner("Fetching benchmark sector returns..."):
                    benchmark_returns = get_benchmark_sector_returns(period='1Y')
    
                # Calculate attribution
                try:
                    attribution_results = calculate_brinson_attribution(
                        enhanced_df_validated,
                        benchmark_weights,
                        benchmark_returns,
                        period='1Y'
                    )
    
                    # Display skill assessment card
                    import streamlit.components.v1 as components
                    components.html(create_skill_assessment_card(attribution_results), height=400)
    
                    # Display waterfall chart
                    st.plotly_chart(create_brinson_attribution_chart(attribution_results),
                                   use_container_width=True)
    
                    # Display detailed sector table
                    st.markdown("#### üìã Sector-by-Sector Attribution")
                    sector_table = create_sector_attribution_table(attribution_results['attribution_df'])
                    make_scrollable_table(
                        sector_table,
                        height=600,
                        hide_index=True,
                        use_container_width=True,
                        column_config=None
                    )
    
                    # Explanation
                    with st.expander("‚ÑπÔ∏è Understanding Brinson Attribution"):
                        st.markdown("""
                        **Brinson Attribution** breaks down your portfolio outperformance into:
    
                        1. **Allocation Effect** - Your skill at sector timing
                           - Measures if you overweighted sectors that outperformed
                           - Example: Overweighting tech before a tech rally = positive allocation
    
                        2. **Selection Effect** - Your skill at stock picking
                           - Measures if your stocks beat their sector average
                           - Example: Picking NVDA in tech when NVDA beats XLK = positive selection
    
                        3. **Interaction Effect** - Combined benefit
                           - Being overweight the right sectors AND picking winners within them
    
                        **Interpretation:**
                        - **High Allocation Score**: You're good at macro/sector calls ‚Üí Use sector ETFs
                        - **High Selection Score**: You're good at stock picking ‚Üí Focus on fundamentals
                        - **Both Low**: Consider passive indexing
    
                        **Benchmark**: S&P 500 sector weights and sector ETF returns (XLK, XLV, XLF, etc.)
                        """)
    
                except Exception as e:
                    st.error(f"Error calculating Brinson Attribution: {str(e)}")
                    st.info("üí° Make sure your portfolio has valid sector classifications and return data.")
    
            # ============================================================
            # QUALITY SCORECARD - COMPREHENSIVE QUALITY ANALYSIS
            # ============================================================
            st.divider()
            st.subheader("üèÜ Portfolio Quality Scorecard")
            st.info("Comprehensive quality analysis for all holdings based on profitability, growth, financial health, and analyst ratings")
    
            # Calculate comprehensive quality metrics for each holding
            quality_data = []
    
            for _, row in enhanced_df.iterrows():
                ticker = row['Ticker']
                info = fetch_stock_info(ticker)
    
                if info:
                    quality_data.append({
                        'Ticker': ticker,
                        'Asset Name': row.get('Asset Name', ticker),
                        'Quality Score': row.get('Quality Score', 5.0),
                        'ROE': f"{info.get('returnOnEquity', 0) * 100:.1f}%" if info.get('returnOnEquity') else 'N/A',
                        'Profit Margin': f"{info.get('profitMargins', 0) * 100:.1f}%" if info.get('profitMargins') else 'N/A',
                        'Revenue Growth': f"{info.get('revenueGrowth', 0) * 100:.1f}%" if info.get('revenueGrowth') else 'N/A',
                        'Debt/Equity': f"{info.get('debtToEquity', 0):.1f}" if info.get('debtToEquity') else 'N/A',
                        'Current Ratio': f"{info.get('currentRatio', 0):.2f}" if info.get('currentRatio') else 'N/A',
                        'Peg Ratio': f"{info.get('pegRatio', 0):.2f}" if info.get('pegRatio') else 'N/A',
                        'Analyst Rating': info.get('recommendationKey', 'N/A').replace('_', ' ').title(),
                        'Target Price': f"${info.get('targetMeanPrice', 0):.2f}" if info.get('targetMeanPrice') else 'N/A',
                        'Upside': f"{((info.get('targetMeanPrice', 0) / row['Current Price']) - 1) * 100:+.1f}%" if info.get('targetMeanPrice') and row['Current Price'] > 0 else 'N/A'
                    })
    
            if quality_data:
                quality_df = pd.DataFrame(quality_data)
    
                # Sort by Quality Score descending
                quality_df = quality_df.sort_values('Quality Score', ascending=False)
    
                # Display quality scorecard table
                make_scrollable_table(
                    quality_df,
                    height=600,
                    hide_index=True,
                    use_container_width=True,
                    column_config=None
                )
    
                # Quality distribution chart
                fig_quality = go.Figure()
    
                colors_quality = [
                    COLORS['success'] if score >= 7 else COLORS['warning'] if score >= 5 else COLORS['danger']
                    for score in quality_df['Quality Score']
                ]
    
                fig_quality.add_trace(go.Bar(
                    x=quality_df['Ticker'],
                    y=quality_df['Quality Score'],
                    marker_color=colors_quality,
                    text=quality_df['Quality Score'].apply(lambda x: f"{x:.1f}"),
                    textposition='outside',
                    hovertemplate='<b>%{x}</b><br>Quality Score: %{y:.1f}/10<extra></extra>'
                ))
    
                fig_quality.update_layout(
                    title="Portfolio Quality Score Distribution",
                    yaxis_title="Quality Score (0-10)",
                    xaxis_title="",
                    height=400,
                    yaxis=dict(range=[0, 11]),
                    showlegend=False
                )
    
                apply_chart_theme(fig_quality)
                st.plotly_chart(fig_quality, use_container_width=True)
    
                # Quality insights
                high_quality = quality_df[quality_df['Quality Score'] >= 7]
                medium_quality = quality_df[(quality_df['Quality Score'] >= 5) & (quality_df['Quality Score'] < 7)]
                low_quality = quality_df[quality_df['Quality Score'] < 5]
    
                col1, col2, col3 = st.columns(3)
    
                with col1:
                    st.markdown(f"#### ‚úÖ High Quality ({len(high_quality)})")
                    if len(high_quality) > 0:
                        st.success(", ".join(high_quality['Ticker'].tolist()))
                    else:
                        st.markdown("*None*")
    
                with col2:
                    st.markdown(f"#### ‚ö†Ô∏è Medium Quality ({len(medium_quality)})")
                    if len(medium_quality) > 0:
                        st.warning(", ".join(medium_quality['Ticker'].tolist()))
                    else:
                        st.markdown("*None*")
    
                with col3:
                    st.markdown(f"#### üî¥ Low Quality ({len(low_quality)})")
                    if len(low_quality) > 0:
                        st.error(", ".join(low_quality['Ticker'].tolist()))
                        st.caption("*Consider reviewing these positions*")
                    else:
                        st.markdown("*None*")
    
                # Overall portfolio quality score
                avg_quality = quality_df['Quality Score'].mean()
                st.markdown(f"### üìä Overall Portfolio Quality: **{avg_quality:.1f}/10**")
    
                if avg_quality >= 7:
                    st.success("‚úÖ Your portfolio consists of high-quality companies with strong fundamentals")
                elif avg_quality >= 5:
                    st.warning("‚ö†Ô∏è Your portfolio has mixed quality - consider upgrading lower-rated holdings")
                else:
                    st.error("üî¥ Portfolio quality is below average - focus on fundamental improvements")
    
            else:
                st.warning("Unable to fetch quality data for holdings")
    
            # ============================================================
            # MPT PORTFOLIO OPTIMIZATION - MODERN PORTFOLIO THEORY
            # ============================================================
            st.divider()
            st.subheader("‚öôÔ∏è Portfolio Optimization (Modern Portfolio Theory)")
            st.info("Optimize portfolio allocation using production-grade MPT algorithms with intelligent risk management")
    
            col1, col2, col3, col4 = st.columns([2, 1, 2, 1])
    
            with col1:
                optimization_objective = st.selectbox(
                    "Optimization Objective",
                    ["Max Sharpe Ratio", "Min Volatility", "Max Return", "Risk Parity"],
                    index=0,
                    help="Select optimization strategy based on your investment goals"
                )
    
            with col2:
                risk_free_rate_input = st.number_input(
                    "Risk-Free Rate (%)",
                    value=RISK_FREE_RATE * 100,
                    min_value=0.0,
                    max_value=10.0,
                    step=0.1
                ) / 100
    
            with col3:
                # üéØ NEW v10.3: Risk Profile Selector
                st.markdown("**Risk Profile**")
                risk_profile_mpt = st.radio(
                    "Investment Style",
                    options=['conservative', 'moderate', 'aggressive'],
                    format_func=lambda x: {
                        'conservative': 'üõ°Ô∏è Conservative',
                        'moderate': '‚öñÔ∏è Moderate',
                        'aggressive': 'üöÄ Aggressive'
                    }[x],
                    index=1,  # Default to Moderate
                    key="risk_profile_mpt",
                    horizontal=True,
                    help="Auto-configures position limits and diversification based on your risk tolerance"
                )
    
            with col4:
                if st.button("üöÄ Run MPT Optimization", type="primary", key="run_mpt_opt"):
                    st.session_state['run_mpt_optimization'] = True
    
            # Map optimization objective to strategy type
            strategy_map = {
                "Max Sharpe Ratio": "max_sharpe",
                "Min Volatility": "min_volatility",
                "Max Return": "max_return",
                "Risk Parity": "risk_parity"
            }
            strategy_type_mpt = strategy_map[optimization_objective]
    
            # Get risk profile configuration
            config_mpt = RiskProfile.get_config(risk_profile_mpt, strategy_type_mpt)
    
            # Display auto-configuration
            st.caption(f"üìä **Auto-configured for {risk_profile_mpt.title()} {optimization_objective}:** Max position {config_mpt['max_position_base']*100:.0f}%, Min {config_mpt['min_diversification']} holdings, Risk budget {config_mpt['risk_budget_per_asset']*100:.0f}%/asset")
    
            # Advanced: Manual Override (collapsed by default)
            with st.expander("üîß Advanced: Manual Position Constraints & Leverage Override"):
                st.warning("‚ö†Ô∏è Advanced users only - Manual overrides bypass risk profile automation")
                use_manual_mpt = st.checkbox("Use manual position constraints", value=False, key="use_manual_mpt")
    
                if use_manual_mpt:
                    col1, col2, col3 = st.columns(3)
                    with col1:
                        max_position = st.slider(
                            "Max Position Size (%)",
                            min_value=1,
                            max_value=50,
                            value=int(config_mpt['max_position_base']*100),
                            step=1,
                            key="max_pos_mpt_manual",
                            help="Maximum weight allowed per security (prevents over-concentration)"
                        ) / 100
    
                    with col2:
                        min_position = st.slider(
                            "Min Position Size (%)",
                            min_value=1,
                            max_value=50,
                            value=2,
                            step=1,
                            key="min_pos_mpt_manual",
                            help="Minimum meaningful position size (smaller positions excluded)"
                        ) / 100
    
                    with col3:
                        target_leverage = st.slider(
                            "Target Leverage (x)",
                            min_value=1.0,
                            max_value=3.0,
                            value=1.0,
                            step=0.1,
                            key="target_leverage_mpt_manual",
                            help="Portfolio leverage: 1.0x = no leverage, 2.0x = 2x leverage, etc. Leverage = sum(abs(weights))"
                        )
    
                    # Validation: Ensure min < max
                    if min_position >= max_position:
                        st.error(f"‚ö†Ô∏è Min position ({min_position*100:.0f}%) must be less than max position ({max_position*100:.0f}%)")
                else:
                    # Use risk profile defaults
                    max_position = config_mpt['max_position_base']
                    min_position = 0.02  # Standard minimum
                    target_leverage = 1.0  # Default: no leverage
    
            if st.session_state.get('run_mpt_optimization', False):
                # Validate constraints before optimization
                if min_position >= max_position:
                    st.error("‚ùå Cannot optimize: Min position must be less than max position")
                elif max_position * len(enhanced_df) < 1.0:
                    st.error(f"‚ùå Cannot optimize: Max position too small. With {len(enhanced_df)} assets and {max_position*100:.0f}% max, portfolio cannot reach 100%")
                else:
                    with st.spinner("‚ö° Running portfolio optimization..."):
                        # Get historical returns for all holdings
                        returns_data = {}
                        for ticker in enhanced_df['Ticker'].unique():
                            hist_data = fetch_historical_data(ticker,
                                                             datetime.now() - timedelta(days=252),
                                                             datetime.now())
                            if hist_data is not None and len(hist_data) > 0:
                                returns_data[ticker] = hist_data['Close'].pct_change().dropna()
    
                        # Create returns dataframe
                        returns_df = pd.DataFrame(returns_data)
                        returns_df = returns_df.dropna()
    
                        if len(returns_df) > 30:
                            # üéØ TWO-STAGE DIVERSIFICATION-FIRST OPTIMIZATION
                            # Stage 1: Find peak performance
                            # Stage 2: Maximize diversification while maintaining acceptable performance
    
                            st.info(f"üîç Running two-stage diversification-first optimization for {strategy_type_mpt}...")
    
                            # Use the two-stage diversification-first optimizer
                            optimal_weights_array = optimize_two_stage_diversification_first(
                                returns_df=returns_df,
                                strategy_type=strategy_type_mpt,
                                risk_profile_config=config_mpt,
                                risk_free_rate=risk_free_rate_input,
                                verbose=False,  # Don't print to console in Streamlit
                                target_leverage=target_leverage  # Pass leverage parameter
                            )
    
                            # Convert to Series
                            optimal_weights = pd.Series(optimal_weights_array, index=returns_df.columns)
    
                            # Get current weights
                            current_weights_dict = {}
                            total_value = enhanced_df['Total Value'].sum()
                            for _, row in enhanced_df.iterrows():
                                current_weights_dict[row['Ticker']] = row['Total Value'] / total_value
    
                            current_weights = pd.Series(current_weights_dict)
    
                            # Create comparison dataframe
                            comparison_data = []
                            for ticker in optimal_weights.index:
                                current_w = current_weights.get(ticker, 0)
                                optimal_w = optimal_weights.get(ticker, 0)
    
                                comparison_data.append({
                                    'Ticker': ticker,
                                    'Current Weight': current_w * 100,
                                    'Optimal Weight': optimal_w * 100,
                                    'Difference': (optimal_w - current_w) * 100,
                                    'Action': 'üü¢ Increase' if optimal_w > current_w else 'üî¥ Decrease' if optimal_w < current_w else '‚ö™ Hold'
                                })
    
                            comparison_df = pd.DataFrame(comparison_data)
                            comparison_df = comparison_df.sort_values('Optimal Weight', ascending=False)
    
                            st.markdown("### üìä Optimization Results")
    
                            # Format for display
                            display_comparison = comparison_df.copy()
                            display_comparison['Current Weight'] = display_comparison['Current Weight'].apply(lambda x: f"{x:.2f}%")
                            display_comparison['Optimal Weight'] = display_comparison['Optimal Weight'].apply(lambda x: f"{x:.2f}%")
                            display_comparison['Difference'] = display_comparison['Difference'].apply(lambda x: f"{x:+.2f}%")
    
                            make_scrollable_table(display_comparison, height=600, hide_index=True, use_container_width=True)
    
                            # Calculate portfolio metrics
                            st.markdown("### üìà Expected Performance")
    
                            # Current portfolio metrics
                            current_return = (returns_df * current_weights).sum(axis=1).mean() * 252
                            current_vol = (returns_df * current_weights).sum(axis=1).std() * np.sqrt(252)
                            current_sharpe = (current_return - risk_free_rate_input) / current_vol if current_vol > 0 else 0
    
                            # Optimal portfolio metrics
                            optimal_return = (returns_df * optimal_weights).sum(axis=1).mean() * 252
                            optimal_vol = (returns_df * optimal_weights).sum(axis=1).std() * np.sqrt(252)
                            optimal_sharpe = (optimal_return - risk_free_rate_input) / optimal_vol if optimal_vol > 0 else 0
    
                            # MPT Optimization toast with performance data
                            return_improvement = (optimal_return - current_return) * 100
                            vol_change = (optimal_vol - current_vol) * 100
                            sharpe_change = optimal_sharpe - current_sharpe
                            show_toast(
                                f"MPT {optimization_objective}: Return {optimal_return*100:.1f}% (+{return_improvement:.1f}%), Sharpe {optimal_sharpe:.2f} (+{sharpe_change:.2f})",
                                toast_type="success",
                                duration=5000
                            )
    
                            # Calculate leverage for both portfolios
                            current_leverage = np.abs(current_weights).sum()
                            optimal_leverage = np.abs(optimal_weights).sum()
    
                            col1, col2 = st.columns(2)
    
                            with col1:
                                st.markdown("#### üìä Current Portfolio")
                                st.metric("Expected Return", f"{current_return * 100:.2f}%")
                                st.metric("Volatility", f"{current_vol * 100:.2f}%")
                                st.metric("Sharpe Ratio", f"{current_sharpe:.2f}")
                                st.metric("Portfolio Leverage", f"{current_leverage:.2f}x",
                                         help="Leverage = sum of absolute weights")
    
                            with col2:
                                st.markdown("#### ‚ú® Optimized Portfolio")
                                st.metric("Expected Return", f"{optimal_return * 100:.2f}%",
                                         delta=f"{(optimal_return - current_return) * 100:+.2f}%")
                                st.metric("Volatility", f"{optimal_vol * 100:.2f}%",
                                         delta=f"{(optimal_vol - current_vol) * 100:+.2f}%",
                                         delta_color="inverse")
                                st.metric("Sharpe Ratio", f"{optimal_sharpe:.2f}",
                                         delta=f"{(optimal_sharpe - current_sharpe):+.2f}")
                                st.metric("Portfolio Leverage", f"{optimal_leverage:.2f}x",
                                         delta=f"{(optimal_leverage - current_leverage):+.2f}x",
                                         help="Leverage = sum of absolute weights")
    
                            # üéØ NEW v10.3: Portfolio Quality Assessment
                            st.markdown("---")
                            st.markdown("### üéØ Portfolio Quality Assessment")
    
                            try:
                                # Calculate realism score
                                realism_mpt = validate_portfolio_realism(
                                    optimal_weights.values,
                                    returns_df,
                                    strategy_type_mpt
                                )
    
                                # Calculate explanations
                                explainer_mpt = OptimizationExplainer()
                                explanations_mpt = explainer_mpt.explain_portfolio_weights(
                                    optimal_weights.values,
                                    returns_df,
                                    strategy_type_mpt,
                                    None
                                )
    
                                # Identify red/yellow flags
                                red_flags_mpt = explainer_mpt.identify_red_flags(
                                    optimal_weights.values,
                                    returns_df,
                                    config_mpt
                                )
    
                                # Display realism score
                                col_a, col_b, col_c = st.columns([1, 2, 2])
    
                                with col_a:
                                    score_color = "üü¢" if realism_mpt['overall'] >= 80 else "üü°" if realism_mpt['overall'] >= 60 else "üî¥"
                                    st.metric("Realism Score", f"{score_color} {realism_mpt['overall']}/100")
    
                                with col_b:
                                    st.markdown(f"**Classification:** {realism_mpt['classification']}")
                                    if realism_mpt['issues']:
                                        st.caption(f"‚ö†Ô∏è Issues: {', '.join(realism_mpt['issues'])}")
    
                                with col_c:
                                    effective_n_mpt = explanations_mpt['diversification']['effective_holdings']
                                    st.metric("Effective Holdings", f"{effective_n_mpt:.1f}")
                                    st.caption(explanations_mpt['diversification']['explanation'])
    
                                # Display alerts
                                if red_flags_mpt['red_flags'] or red_flags_mpt['yellow_flags']:
                                    st.markdown("**‚ö†Ô∏è Alerts:**")
                                    for flag in red_flags_mpt['red_flags']:
                                        st.error(flag)
                                    for flag in red_flags_mpt['yellow_flags']:
                                        st.warning(flag)
                                else:
                                    st.success("‚úÖ No major concerns - portfolio looks healthy!")
    
                                # Portfolio explanation
                                with st.expander("üìä Why These Weights? - Portfolio Explanation"):
                                    st.markdown("##### Top Holdings Analysis")
                                    for holding in explanations_mpt['top_holdings']:
                                        st.markdown(f"**{holding['ticker']}** - {holding['weight']*100:.1f}%")
                                        for reason in holding['reasons']:
                                            st.markdown(f"  ‚Ä¢ {reason}")
                                        st.markdown("")
    
                                    st.markdown("##### Risk Contributors")
                                    st.markdown("Assets contributing most to portfolio risk:")
                                    for contributor in explanations_mpt['risk']['top_risk_contributors']:
                                        risk_pct = contributor['risk_contribution'] * 100 if contributor['risk_contribution'] > 0 else 0
                                        st.markdown(f"  ‚Ä¢ **{contributor['ticker']}**: {risk_pct:.1f}% risk contribution (weight: {contributor['weight']*100:.1f}%)")
    
                            except Exception as e:
                                st.info("üí° Portfolio quality metrics ready")
    
                            st.markdown("---")
    
                            # Weight comparison chart
                            st.markdown("### üìà Weight Comparison")
    
                            fig_weights = go.Figure()
    
                            fig_weights.add_trace(go.Bar(
                                name='Current',
                                x=comparison_df['Ticker'],
                                y=comparison_df['Current Weight'],
                                marker_color=COLORS['electric_blue'],
                                text=comparison_df['Current Weight'].apply(lambda x: f"{x:.1f}%"),
                                textposition='auto'
                            ))
    
                            fig_weights.add_trace(go.Bar(
                                name='Optimal',
                                x=comparison_df['Ticker'],
                                y=comparison_df['Optimal Weight'],
                                marker_color=COLORS['teal'],
                                text=comparison_df['Optimal Weight'].apply(lambda x: f"{x:.1f}%"),
                                textposition='auto'
                            ))
    
                            fig_weights.update_layout(
                                title=f"Current vs Optimal Weights ({optimization_objective})",
                                xaxis_title="",
                                yaxis_title="Weight (%)",
                                barmode='group',
                                height=500,
                                showlegend=True
                            )
    
                            apply_chart_theme(fig_weights)
                            st.plotly_chart(fig_weights, use_container_width=True)
    
                            # Portfolio Quality Validation Metrics
                            st.markdown("#### ‚úÖ Portfolio Quality Checks")
                            st.info("Validate that the optimized portfolio meets practical portfolio management principles")
    
                            col1, col2, col3, col4 = st.columns(4)
    
                            with col1:
                                n_positions = np.sum(optimal_weights > 0)
                                st.metric("Number of Positions", n_positions)
                                if n_positions < 5:
                                    st.warning("‚ö†Ô∏è Low diversification")
                                else:
                                    st.success("‚úÖ Well diversified")
    
                            with col2:
                                max_weight = np.max(optimal_weights)
                                st.metric("Largest Position", f"{max_weight*100:.1f}%")
                                if max_weight > 0.30:
                                    st.warning("‚ö†Ô∏è High concentration")
                                else:
                                    st.success("‚úÖ Balanced")
    
                            with col3:
                                # Herfindahl-Hirschman Index (concentration measure)
                                herfindahl_index = np.sum(optimal_weights**2)
                                st.metric("HHI Index", f"{herfindahl_index:.3f}")
                                st.caption(f"Ideal: {1/len(optimal_weights):.3f}")
                                if herfindahl_index > 0.3:
                                    st.warning("‚ö†Ô∏è Concentrated")
                                else:
                                    st.success("‚úÖ Diversified")
    
                            with col4:
                                # Effective number of positions (inverse of HHI)
                                effective_positions = 1 / herfindahl_index if herfindahl_index > 0 else 0
                                st.metric("Effective N", f"{effective_positions:.1f}")
                                st.caption("Diversification measure")
    
                            # Show positions that were excluded (< min_position)
                            excluded_positions = optimal_weights[optimal_weights == 0]
                            if len(excluded_positions) > 0:
                                with st.expander(f"‚ÑπÔ∏è {len(excluded_positions)} positions excluded (below {min_position*100:.0f}% threshold)"):
                                    st.write(", ".join(excluded_positions.index.tolist()))
                                    st.caption("These securities had weights below the minimum threshold and were excluded for practicality")
    
                            st.success(f"‚úÖ Optimization complete using {optimization_objective} strategy with realistic constraints!")
    
                        else:
                            st.error("Insufficient historical data for optimization (need 30+ days)")
    
            # ============================================================
            # CORRELATION HEATMAP - NEW ADDITION
            # ============================================================
            import numpy as np  # Ensure numpy is available in this scope

            st.divider()
            st.subheader("üï∏Ô∏è Portfolio Correlation Analysis")

            period = st.selectbox(
                "Correlation Period:",
                options=['30d', '90d', '1y'],
                index=1,
                format_func=lambda x: {'30d': '30 Days', '90d': '90 Days', '1y': '1 Year'}[x]
            )
    
            correlation_matrix = calculate_portfolio_correlations(enhanced_df, period=period)
    
            if correlation_matrix is not None and len(correlation_matrix) > 1:
    
                # Diversification score
                avg_corr = correlation_matrix.where(
                    np.triu(np.ones(correlation_matrix.shape), k=1).astype(bool)
                ).stack().mean()
    
                div_score = (1 - avg_corr) * 10
    
                col1, col2 = st.columns(2)
    
                with col1:
                    st.metric("Diversification Score", f"{div_score:.1f}/10")
    
                with col2:
                    st.metric("Average Correlation", f"{avg_corr:.2f}")
    
                # PROFESSIONAL HEATMAP
                fig_heatmap = go.Figure(data=go.Heatmap(
                    z=correlation_matrix.values,
                    x=correlation_matrix.columns,
                    y=correlation_matrix.index,
                    colorscale='RdYlGn',
                    zmid=0,
                    zmin=-1,
                    zmax=1,
                    text=np.round(correlation_matrix.values, 2),
                    texttemplate='%{text}',
                    textfont={"size": 10, "color": "#000000"},
                    colorbar=dict(
                        title="Correlation",
                        titleside="right",
                        tickmode="linear",
                        tick0=-1,
                        dtick=0.5
                    ),
                    hovertemplate='%{y} vs %{x}<br>Correlation: %{z:.2f}<extra></extra>'
                ))
    
                fig_heatmap.update_layout(
                    title=dict(
                        text=f"Correlation Heatmap ({period})",
                        font=dict(size=18, color='#ffffff'),
                        x=0.5,
                        xanchor='center'
                    ),
                    height=600,
                    xaxis=dict(
                        tickangle=-45,
                        tickfont=dict(size=11, color='#ffffff')
                    ),
                    yaxis=dict(
                        tickfont=dict(size=11, color='#ffffff')
                    ),
                    paper_bgcolor='rgba(0, 0, 0, 0)',
                    plot_bgcolor='rgba(10, 25, 41, 0.3)'
                )
    
                st.plotly_chart(fig_heatmap, use_container_width=True)
    
                # Insights
                with st.expander("üí° Correlation Insights"):
                    # High correlations
                    high_corr_pairs = []
                    for i in range(len(correlation_matrix)):
                        for j in range(i+1, len(correlation_matrix)):
                            corr_val = correlation_matrix.iloc[i, j]
                            if corr_val > 0.75:
                                high_corr_pairs.append((
                                    correlation_matrix.index[i],
                                    correlation_matrix.columns[j],
                                    corr_val
                                ))
    
                    if high_corr_pairs:
                        st.warning("**Highly Correlated Pairs (>0.75):**")
                        for t1, t2, corr in sorted(high_corr_pairs, key=lambda x: x[2], reverse=True):
                            st.write(f"‚Ä¢ {t1} ‚Üî {t2}: {corr:.2f}")
                        st.caption("*These holdings move very similarly - limited diversification benefit*")
                    else:
                        st.success("‚úÖ No extreme correlations detected - good diversification")
            else:
                st.warning("Need at least 2 holdings with sufficient price history for correlation analysis")
    
        # ========================================================================
        # MULTI-FACTOR ANALYSIS - ENHANCED
        # ========================================================================
        elif page == "üìä Multi-Factor Analysis":
            st.markdown("## üìä MULTI-FACTOR ANALYSIS - ENHANCED")
            st.markdown("---")
    
            portfolio_data = load_portfolio_data()
            
            if portfolio_data is None or (isinstance(portfolio_data, pd.DataFrame) and portfolio_data.empty):
                st.warning("‚ö†Ô∏è No portfolio data.")
                st.stop()
            
            df = pd.DataFrame(portfolio_data)
            enhanced_df = create_enhanced_holdings_table(df)
            
            with st.spinner("Running analysis..."):
                factor_data = calculate_factor_exposures(enhanced_df, start_date, end_date)
            
            if factor_data:
                st.markdown(f"**Model R¬≤ = {factor_data['r_squared']:.3f}**")
                st.progress(factor_data['r_squared'])
                
                result = create_factor_attribution_table(factor_data, enhanced_df)
                
                tab1, tab2, tab3 = st.tabs([
                    "üìà Factor Momentum", "üéØ Exposure Radar", "üìä Attribution"
                ])
                
                with tab1:
                    momentum = create_factor_momentum_chart(factor_data)
                    if momentum:
                        st.plotly_chart(momentum, use_container_width=True)
                
                with tab2:
                    radar = create_factor_exposure_radar(factor_data)
                    if radar:
                        st.plotly_chart(radar, use_container_width=True)
                
                with tab3:
                    if result is not None:
                        attr_df, factor_summary, sector_summary = result
                        
                        if factor_summary is not None:
                            st.markdown("### Factor Summary")
                            factor_display = factor_summary.copy()
                            factor_display['Total Contribution'] = factor_display['Total Contribution'].apply(
                                lambda x: f"{x:.4f}")
                            make_scrollable_table(factor_display, height=400, hide_index=True, use_container_width=True, column_config=None)
                        
                        if attr_df is not None:
                            st.markdown("### Holdings Attribution")
                            holdings_attr = attr_df.pivot_table(
                                index='Ticker',
                                columns='Factor',
                                values='Contribution',
                                aggfunc='sum'
                            ).round(4)
    
                            make_scrollable_table(holdings_attr, height=600, hide_index=True, use_container_width=True, column_config=None)
                            
                            st.info("""
                            **Positive values**: Holding increases exposure
                            **Negative values**: Holding decreases exposure
                            """)
            else:
                st.error("Unable to calculate factor exposures.")
        
        # ========================================================================
        # VALUATION HOUSE - ENHANCED WITH SMART ASSUMPTIONS
        # ========================================================================
        elif page == "üí∞ Valuation House":
            st.markdown("## üí∞ VALUATION HOUSE - EXCELLENCE EDITION")
            st.markdown("### Professional DCF Valuation Engine with Smart Assumptions")
            
            st.info("üéØ **New Feature:** Toggle between Manual and Smart Assumptions for realistic valuations!")
            
            # Company Search
            st.markdown("---")
            st.markdown("#### üîç Company Search")
            
            col1, col2 = st.columns([3, 1])
            
            with col1:
                ticker_input = st.text_input(
                    "Enter Ticker Symbol",
                    placeholder="e.g., AAPL, MSFT, GOOGL",
                    help="Enter any publicly traded company ticker"
                ).upper()
            
            with col2:
                search_button = st.button("üöÄ Load Company", type="primary", use_container_width=True)
            
            if search_button and ticker_input:
                with st.spinner(f"üìä Fetching data for {ticker_input}..."):
                    company_data = fetch_company_financials(ticker_input)
                    
                    if company_data['success']:
                        st.session_state['valuation_company'] = company_data
                        st.success(f"‚úÖ Loaded {company_data['company']['name']}")
                    else:
                        st.error(f"‚ùå Could not fetch data: {company_data.get('error', 'Unknown error')}")
            
            # Display valuation if company is loaded
            if 'valuation_company' in st.session_state:
                company = st.session_state['valuation_company']['company']
                financials = st.session_state['valuation_company']['financials']
                
                st.markdown("---")
                
                # Company Overview
                st.markdown(f"### üìä {company['name']} ({company['ticker']})")
                
                col1, col2, col3, col4, col5 = st.columns(5)
                col1.metric("Current Price", format_currency(company['current_price']))
                col2.metric("Market Cap", format_large_number(company['market_cap']))
                col3.metric("Sector", company['sector'])
                col4.metric("Beta", f"{company['beta']:.2f}")
                col5.metric("Forward P/E", f"{company.get('forward_pe', 'N/A'):.1f}" if company.get('forward_pe') else "N/A")
                
                st.markdown("---")
    
                # ENHANCED: Comprehensive Valuation Method Selection
                st.markdown("#### üéØ Valuation Method Selection")
    
                valuation_method = st.selectbox(
                    "Choose Valuation Approach",
                    options=[
                        'üéØ Consensus Valuation (Multi-Method Aggregate)',
                        'FCFF DCF (Free Cash Flow to Firm)',
                        'FCFE DCF (Free Cash Flow to Equity)',
                        'Gordon Growth DDM (Dividend Discount Model)',
                        'Multi-Stage DDM (2-Stage Dividend Model)',
                        'Residual Income Model (Economic Profit)',
                        'Relative Valuation (Peer Multiples)',
                        'Sum-of-the-Parts (SOTP)'
                    ],
                    help="Select from 8 institutional-grade valuation methodologies"
                )
    
                # Extract method key for logic
                if 'Consensus' in valuation_method:
                    method_key = 'CONSENSUS'
                elif 'FCFF' in valuation_method:
                    method_key = 'FCFF'
                elif 'FCFE' in valuation_method:
                    method_key = 'FCFE'
                elif 'Gordon' in valuation_method:
                    method_key = 'GORDON_DDM'
                elif 'Multi-Stage' in valuation_method:
                    method_key = 'MULTISTAGE_DDM'
                elif 'Residual' in valuation_method:
                    method_key = 'RESIDUAL_INCOME'
                elif 'Relative' in valuation_method:
                    method_key = 'RELATIVE'
                else:
                    method_key = 'SOTP'
    
                # Show method description
                method_descriptions = {
                    'CONSENSUS': """üéØ **Consensus Valuation:** Intelligent aggregation of 7 valuation methods with automated weighting:
                    - **FCFF DCF (25%)** - Most comprehensive firm valuation using smart assumptions
                    - **FCFE DCF (20%)** - Equity DCF valuation using smart assumptions
                    - **P/E Multiple (15%)** - Earnings-based comparison
                    - **EV/EBITDA (15%)** - Enterprise value perspective
                    - **PEG Ratio (10%)** - Growth-adjusted valuation
                    - **P/B Multiple (10%)** - Book value anchor
                    - **P/S Multiple (5%)** - Revenue-based valuation
    
                    DCF methods use AI-generated smart assumptions based on sector benchmarks and company fundamentals. Invalid or nonsensical results are automatically excluded using statistical outlier detection.""",
                    'FCFF': "üíº **FCFF DCF:** Values the entire firm by discounting free cash flows available to all investors (debt + equity)",
                    'FCFE': "üí∞ **FCFE DCF:** Values equity directly by discounting free cash flows available to equity holders only",
                    'GORDON_DDM': "üìà **Gordon Growth DDM:** Values stocks using perpetual dividend growth (D‚ÇÅ / (r - g)). Best for stable dividend payers",
                    'MULTISTAGE_DDM': "üöÄ **Multi-Stage DDM:** 2-phase model with high growth period transitioning to stable growth. Ideal for growing dividend stocks",
                    'RESIDUAL_INCOME': "üéØ **Residual Income:** Edwards-Bell-Ohlson model valuing excess returns over cost of equity (BV + PV(RI))",
                    'RELATIVE': "üìä **Relative Valuation:** Peer comparison using 6 multiples (P/E, P/B, P/S, PEG, EV/EBITDA, EV/EBIT)",
                    'SOTP': "üè¢ **Sum-of-the-Parts:** Values multi-segment companies by summing independent business unit valuations"
                }
    
                st.info(method_descriptions[method_key])
    
                # Scenario buttons only for DCF methods
                if method_key in ['FCFF', 'FCFE']:
                    st.markdown("---")
                    st.markdown("#### üéØ Quick Scenarios")
                    scenario_col1, scenario_col2, scenario_col3, scenario_col4 = st.columns([1, 1, 1, 2])
    
                    scenario_selected = None
    
                    with scenario_col1:
                        if st.button(VALUATION_SCENARIOS['BEAR']['name'], use_container_width=True, key="bear_btn"):
                            scenario_selected = 'BEAR'
                            st.session_state['selected_scenario'] = 'BEAR'
    
                    with scenario_col2:
                        if st.button(VALUATION_SCENARIOS['BASE']['name'], use_container_width=True, key="base_btn"):
                            scenario_selected = 'BASE'
                            st.session_state['selected_scenario'] = 'BASE'
    
                    with scenario_col3:
                        if st.button(VALUATION_SCENARIOS['BULL']['name'], use_container_width=True, key="bull_btn"):
                            scenario_selected = 'BULL'
                            st.session_state['selected_scenario'] = 'BULL'
    
                    with scenario_col4:
                        if st.button("üîÑ Reset to Manual", use_container_width=True, key="reset_btn"):
                            if 'selected_scenario' in st.session_state:
                                del st.session_state['selected_scenario']
    
                    # Show active scenario
                    if 'selected_scenario' in st.session_state:
                        active_scenario = st.session_state['selected_scenario']
                        st.success(f"‚úÖ **Active Scenario:** {VALUATION_SCENARIOS[active_scenario]['name']} - {VALUATION_SCENARIOS[active_scenario]['description']}")
    
                    # ============================================================
                    # MODEL INPUTS DASHBOARD (ATLAS v11.0)
                    # ============================================================
                    st.markdown("---")
                    st.markdown("#### üéØ DCF Input Mode")
    
                    use_model_inputs_dashboard = st.checkbox(
                        "üìä Use Model Inputs Dashboard (Advanced)",
                        value=False,
                        help="Full transparency: DuPont ROE, SGR, live WACC, editable projections",
                        key="use_model_inputs_dashboard"
                    )
    
                    if use_model_inputs_dashboard and MODEL_INPUTS_DASHBOARD_AVAILABLE:
                        st.info("""
                        **üìä Model Inputs Dashboard Active**
    
                        You now have complete control and transparency:
                        - üîç DuPont ROE breakdown
                        - üìà Sustainable Growth Rate ‚Üí Terminal Growth
                        - üî¥ **LIVE** 10-year Treasury yield ‚Üí WACC
                        - üíé Diluted shares (Treasury Stock Method)
                        - ‚úèÔ∏è Editable projections
                        - üìä Professional charts
                        """)
    
                        # Display the full dashboard
                        dashboard_inputs = display_model_inputs_dashboard(company['ticker'])
    
                        # Store dashboard inputs in session state for DCF calculation
                        # Note: use_model_inputs_dashboard state is already managed by the checkbox widget
                        st.session_state['dashboard_inputs'] = dashboard_inputs
    
                        st.markdown("---")
                        st.markdown("#### ‚úÖ Ready to Run DCF")
                        st.success(f"""
                        **Model Inputs Configured:**
                        - ROE: {dashboard_inputs['roe']*100:.2f}%
                        - Terminal Growth: {dashboard_inputs['terminal_growth']*100:.2f}%
                        - WACC: {dashboard_inputs['wacc']*100:.2f}%
                        - Diluted Shares: {dashboard_inputs['diluted_shares']/1e6:.1f}M
                        """)
    
                    elif use_model_inputs_dashboard and not MODEL_INPUTS_DASHBOARD_AVAILABLE:
                        st.error("‚ùå Model Inputs Dashboard module not available. Using simple mode.")
                        use_model_inputs_dashboard = False
    
                # ============================================================
                # MULTI-STAGE DCF (ATLAS v11.0)
                # ============================================================
                if method_key in ['FCFF', 'FCFE']:
                    st.markdown("---")
                    st.markdown("#### üöÄ Multi-Stage DCF (Advanced)")
    
                    use_multistage_dcf = st.checkbox(
                        "üéØ Enable Multi-Stage DCF Model",
                        value=False,
                        help="Model different growth phases: Hypergrowth ‚Üí Transition ‚Üí Mature",
                        key="use_multistage_dcf"
                    )
    
                    if use_multistage_dcf and MULTISTAGE_DCF_AVAILABLE:
                        st.info("""
                        **üéØ Multi-Stage DCF Active**
    
                        Model realistic growth transitions:
                        - Single-Stage: Mature companies (constant growth)
                        - Two-Stage: Growth companies (high ‚Üí stable)
                        - Three-Stage: Hypergrowth tech (hypergrowth ‚Üí declining ‚Üí mature)
    
                        Choose from pre-configured templates or customize each stage.
                        """)
    
                        # Store historical data for templates
                        historical_data = {
                            'revenue': financials.get('revenue', 0),
                            'ebit': financials.get('ebit', 0),
                            'revenue_growth_3yr': company.get('revenue_growth_3yr', 0.10),
                            'tax_rate': financials.get('tax_rate', 0.21)
                        }
                        st.session_state['financial_data'] = historical_data
    
                        # Display model selection and configuration
                        multistage_config = display_model_selection(historical_data)
    
                        if multistage_config:
                            st.session_state['multistage_config'] = multistage_config
    
                            # Generate projections button
                            st.markdown("---")
                            if st.button("üîÑ Generate Multi-Stage Projections", type="primary"):
                                with st.spinner("Generating stage-based projections..."):
                                    try:
                                        engine = MultiStageProjectionEngine(multistage_config, historical_data)
                                        projections = engine.generate_projections()
    
                                        st.session_state['multistage_projections'] = projections
                                        st.session_state['multistage_engine'] = engine
    
                                        st.success(f"‚úÖ Generated {len(projections)} years of projections across {len(multistage_config.stages)} stages")
    
                                    except Exception as e:
                                        st.error(f"‚ùå Error generating projections: {str(e)}")
    
                            # Display projections and visualizations if available
                            if 'multistage_projections' in st.session_state:
                                projections = st.session_state['multistage_projections']
    
                                # Visualize stage transitions
                                st.markdown("---")
                                visualize_stage_transitions(multistage_config, projections)
    
                                # Run valuation button
                                st.markdown("---")
                                col1, col2 = st.columns(2)
    
                                with col1:
                                    if st.button("üöÄ RUN MULTI-STAGE DCF", type="primary", use_container_width=True):
                                        with st.spinner("Calculating multi-stage DCF valuation..."):
                                            try:
                                                # Get diluted shares (from dashboard or default)
                                                diluted_shares = st.session_state.get('dashboard_inputs', {}).get(
                                                    'diluted_shares',
                                                    company.get('shares_outstanding', 1e9)
                                                )
    
                                                # Calculate net debt
                                                net_debt = financials.get('total_debt', 0) - financials.get('cash', 0)
    
                                                # Run multi-stage DCF
                                                dcf_result = calculate_multistage_dcf(
                                                    projections=projections,
                                                    terminal_growth=multistage_config.terminal_growth_rate,
                                                    wacc=multistage_config.wacc,
                                                    diluted_shares=diluted_shares,
                                                    net_debt=net_debt
                                                )
    
                                                st.session_state['multistage_dcf_result'] = dcf_result
    
                                                # Display results
                                                display_multistage_results(dcf_result, multistage_config)
    
                                            except Exception as e:
                                                st.error(f"‚ùå Error calculating DCF: {str(e)}")
                                                import traceback
                                                st.code(traceback.format_exc())
    
                                with col2:
                                    if st.button("üìä Export Projections", use_container_width=True):
                                        # Export projections to DataFrame
                                        proj_df = pd.DataFrame(projections).T
                                        make_scrollable_table(proj_df, height=600, hide_index=True, use_container_width=True)
    
                                        # Offer download
                                        csv = proj_df.to_csv()
                                        st.download_button(
                                            "üíæ Download CSV",
                                            csv,
                                            f"{ticker_input}_multistage_projections.csv",
                                            "text/csv"
                                        )
    
                    elif use_multistage_dcf and not MULTISTAGE_DCF_AVAILABLE:
                        st.error("‚ùå Multi-Stage DCF module not available.")
    
                st.markdown("---")
    
                # Smart Assumptions Toggle (only for DCF and RI methods - skip if dashboard is active)
                use_smart_assumptions = False
                if method_key in ['FCFF', 'FCFE', 'GORDON_DDM', 'MULTISTAGE_DDM', 'RESIDUAL_INCOME']:
                    st.markdown("#### üß† Assumptions Mode")
                    use_smart_assumptions = st.checkbox(
                        "ü§ñ Use Smart Assumptions (AI-Generated)",
                        help="Generate realistic assumptions based on sector averages, company size, and economic fundamentals"
                    )
    
                    if use_smart_assumptions:
                        st.info("ü§ñ **Smart Mode Active:** Assumptions are generated based on sector benchmarks and economic reality")
                        smart_params = calculate_smart_assumptions(company, financials)
    
                # Assumptions Panel
                st.markdown("---")
                st.markdown("#### üéõÔ∏è Valuation Assumptions")
    
                # =================================================================
                # CONSENSUS VALUATION - MULTI-METHOD AGGREGATE
                # =================================================================
                if method_key == 'CONSENSUS':
                    st.markdown("##### üéØ Consensus Valuation Analysis")
    
                    with st.spinner("Calculating consensus valuation across multiple methods..."):
                        consensus_result = calculate_consensus_valuation(ticker_input, company, financials)
    
                    if consensus_result['consensus_value']:
                        # Display main result
                        st.markdown("---")
                        col1, col2, col3 = st.columns(3)
    
                        with col1:
                            upside_pct = ((consensus_result['consensus_value'] / company['current_price'] - 1) * 100) if company['current_price'] > 0 else 0
                            st.metric(
                                "Consensus Fair Value",
                                f"${consensus_result['consensus_value']:.2f}",
                                delta=f"{upside_pct:+.1f}%" if company['current_price'] > 0 else None
                            )
    
                        with col2:
                            confidence_color = (
                                "üü¢" if consensus_result['confidence_score'] >= 70
                                else "üü°" if consensus_result['confidence_score'] >= 50
                                else "üî¥"
                            )
                            st.metric(
                                "Confidence Score",
                                f"{confidence_color} {consensus_result['confidence_score']:.0f}/100"
                            )
                            st.caption(f"Based on {consensus_result['method_count']} valid methods")
    
                        with col3:
                            st.metric(
                                "Current Price",
                                f"${company['current_price']:.2f}"
                            )
    
                            if upside_pct > 20:
                                st.success("üöÄ Potentially undervalued")
                            elif upside_pct < -20:
                                st.error("‚ö†Ô∏è Potentially overvalued")
                            else:
                                st.info("‚úÖ Fairly valued")
    
                        # Show breakdown of contributing methods
                        st.markdown("---")
                        st.markdown("#### üìä Method Breakdown")
    
                        # Get weights for display (must match weights in calculate_consensus_valuation)
                        METHOD_WEIGHTS = {
                            'FCFF DCF': 0.25,
                            'FCFE DCF': 0.20,
                            'P/E Multiple': 0.15,
                            'EV/EBITDA': 0.15,
                            'PEG Ratio': 0.10,
                            'P/B Multiple': 0.10,
                            'P/S Multiple': 0.05
                        }
    
                        breakdown_data = []
                        for method, value in consensus_result['contributing_methods'].items():
                            weight = METHOD_WEIGHTS.get(method, 0)
                            upside = ((value / company['current_price'] - 1) * 100) if company['current_price'] > 0 else 0
                            breakdown_data.append({
                                'Method': method,
                                'Fair Value': f"${value:.2f}",
                                'Weight': f"{weight*100:.0f}%",
                                'vs Current': f"{upside:+.1f}%",
                                'Status': '‚úÖ Included'
                            })
    
                        breakdown_df = pd.DataFrame(breakdown_data)
                        make_scrollable_table(breakdown_df, height=400, hide_index=True, use_container_width=True)
    
                        # Show excluded methods
                        if consensus_result['excluded_methods']:
                            with st.expander("‚ö†Ô∏è Excluded Methods"):
                                for method, reason in consensus_result['excluded_methods'].items():
                                    st.warning(f"**{method}**: {reason}")
    
                        # Visualization: Range of valuations
                        st.markdown("---")
                        st.markdown("#### üìà Valuation Range")
    
                        values = list(consensus_result['contributing_methods'].values())
                        methods = list(consensus_result['contributing_methods'].keys())
    
                        fig = go.Figure()
    
                        # Bar chart of individual methods
                        fig.add_trace(go.Bar(
                            x=methods,
                            y=values,
                            name='Method Valuations',
                            marker_color=COLORS['electric_blue'],
                            text=[f"${v:.2f}" for v in values],
                            textposition='auto'
                        ))
    
                        # Add current price line
                        fig.add_hline(
                            y=company['current_price'],
                            line_dash="dash",
                            line_color="red",
                            annotation_text=f"Current: ${company['current_price']:.2f}",
                            annotation_position="right"
                        )
    
                        # Add consensus line
                        fig.add_hline(
                            y=consensus_result['consensus_value'],
                            line_dash="solid",
                            line_color="green",
                            line_width=2,
                            annotation_text=f"Consensus: ${consensus_result['consensus_value']:.2f}",
                            annotation_position="left"
                        )
    
                        fig.update_layout(
                            title="Valuation Methods Comparison",
                            xaxis_title="Method",
                            yaxis_title="Fair Value ($)",
                            height=500,
                            showlegend=False
                        )
    
                        apply_chart_theme(fig)
                        st.plotly_chart(fig, use_container_width=True)
    
                    else:
                        st.error("‚ùå Unable to calculate consensus valuation")
                        st.warning("Insufficient valid data from valuation methods")
    
                        if consensus_result['excluded_methods']:
                            st.subheader("Issues Found:")
                            for method, reason in consensus_result['excluded_methods'].items():
                                st.warning(f"**{method}**: {reason}")
    
                # =================================================================
                # DCF METHODS (FCFF / FCFE) - Existing comprehensive inputs
                # =================================================================
                elif method_key in ['FCFF', 'FCFE']:
                    # Check if Model Inputs Dashboard is active
                    dashboard_active = ('dashboard_inputs' in st.session_state and
                                       st.session_state.get('use_model_inputs_dashboard', False))
    
                    if dashboard_active:
                        # =========================================================
                        # DASHBOARD MODE: Use pre-calculated inputs from Model Inputs Dashboard
                        # =========================================================
                        st.success("‚úÖ **Dashboard Mode Active** - Using inputs from Model Inputs Dashboard")
    
                        dashboard_data = st.session_state['dashboard_inputs']
    
                        # Extract dashboard inputs
                        discount_rate = dashboard_data['wacc']  # Pre-calculated WACC
                        terminal_growth = dashboard_data['terminal_growth']  # SGR-guided terminal growth
                        shares = dashboard_data['diluted_shares']  # Diluted shares (Treasury Stock Method)
                        dcf_projections_obj = dashboard_data.get('projections')  # DCFProjections object
    
                        # Display what we're using (read-only summary)
                        col1, col2, col3 = st.columns(3)
                        with col1:
                            st.metric("WACC (Discount Rate)", f"{discount_rate*100:.2f}%",
                                     help="From Model Inputs Dashboard (Live Treasury + CAPM)")
                        with col2:
                            st.metric("Terminal Growth Rate", f"{terminal_growth*100:.2f}%",
                                     help="From SGR Analysis in Dashboard")
                        with col3:
                            st.metric("Diluted Shares", f"{shares/1e6:.1f}M",
                                     help="Treasury Stock Method from Dashboard")
    
                        st.info("üí° To modify these inputs, edit them in the Model Inputs Dashboard above, then re-run valuation.")
    
                    else:
                        # =========================================================
                        # MANUAL MODE: Show traditional input sliders
                        # =========================================================
                        tab1, tab2, tab3 = st.tabs(["üìà Growth & Operations", "üí∞ Cost of Capital", "üéØ Terminal Value"])
    
                        with tab1:
                            st.markdown("##### Growth & Operating Assumptions")
    
                            col1, col2 = st.columns(2)
    
                            with col1:
                                # Determine revenue growth value
                                if use_smart_assumptions:
                                    revenue_growth = smart_params['revenue_growth']
                                    st.metric("Revenue Growth Rate", f"{revenue_growth*100:.1f}%",
                                             delta="AI Generated", delta_color="normal")
                                elif 'selected_scenario' in st.session_state:
                                    # Use scenario value
                                    scenario_key = st.session_state['selected_scenario']
                                    default_value = VALUATION_SCENARIOS[scenario_key]['revenue_growth'] * 100
                                    revenue_growth = st.slider(
                                        "Revenue Growth Rate (%)",
                                        min_value=-10.0,
                                        max_value=30.0,
                                        value=default_value,
                                        step=0.5,
                                        key=f"rev_growth_{scenario_key}"
                                    ) / 100
                                else:
                                    revenue_growth = st.slider(
                                        "Revenue Growth Rate (%)",
                                        min_value=-10.0,
                                        max_value=30.0,
                                        value=5.0,
                                        step=0.5
                                    ) / 100
    
                                if use_smart_assumptions:
                                    ebit_margin = smart_params['ebit_margin']
                                    st.metric("EBIT Margin", f"{ebit_margin*100:.1f}%",
                                             delta="AI Generated", delta_color="normal")
                                else:
                                    ebit_margin = st.slider(
                                        "EBIT Margin (%)",
                                        min_value=0.0,
                                        max_value=50.0,
                                        value=20.0,
                                        step=1.0
                                    ) / 100
    
                                forecast_years = st.slider(
                                    "Forecast Horizon (Years)",
                                    min_value=3,
                                    max_value=15,
                                    value=smart_params['forecast_years'] if use_smart_assumptions else 5,
                                    step=1
                                )
    
                            # Multi-Stage Growth Feature
                            st.markdown("---")
                            st.markdown("##### üöÄ Multi-Stage Growth (Advanced)")
    
                            use_multistage = st.checkbox(
                                "Enable Multi-Stage Revenue Growth",
                                value=False,
                                help="Model different growth phases: High Growth ‚Üí Transition ‚Üí Mature",
                                key="enable_multistage_growth"
                            )
    
                            if use_multistage:
                                st.info("""
                                **Multi-Stage Growth Model**
                                - **Stage 1 (High Growth)**: Initial years with elevated growth
                                - **Stage 2 (Transition)**: Gradual decline to mature growth
                                - **Stage 3 (Mature)**: Stable, long-term growth rate
                                """)
    
                                multistage_col1, multistage_col2 = st.columns(2)
    
                                with multistage_col1:
                                    stage1_years = st.slider(
                                        "Stage 1 Duration (Years)",
                                        min_value=1,
                                        max_value=min(10, forecast_years - 2),
                                        value=min(3, forecast_years - 2),
                                        step=1,
                                        help="Number of years in high-growth phase"
                                    )
    
                                    stage1_growth = st.slider(
                                        "Stage 1 Growth Rate (%)",
                                        min_value=0.0,
                                        max_value=50.0,
                                        value=15.0,
                                        step=1.0,
                                        help="Revenue growth during high-growth phase"
                                    ) / 100
    
                                with multistage_col2:
                                    # Calculate max years for stage 2
                                    max_stage2 = max(2, forecast_years - stage1_years - 1)
                                    default_stage2 = min(2, max_stage2 - 1)
    
                                    stage2_years = st.slider(
                                        "Stage 2 Duration (Years)",
                                        min_value=1,
                                        max_value=max_stage2,
                                        value=max(1, default_stage2),  # Ensure value >= min_value
                                        step=1,
                                        help="Number of years in transition phase"
                                    )
    
                                    stage2_growth = st.slider(
                                        "Stage 2 Growth Rate (%)",
                                        min_value=0.0,
                                        max_value=30.0,
                                        value=8.0,
                                        step=1.0,
                                        help="Revenue growth during transition phase"
                                    ) / 100
    
                                # Stage 3 is automatic - remaining years
                                stage3_years = forecast_years - stage1_years - stage2_years
                                stage3_growth = st.slider(
                                    f"Stage 3 Growth Rate (%) - {stage3_years} years",
                                    min_value=0.0,
                                    max_value=15.0,
                                    value=3.0,
                                    step=0.5,
                                    help="Mature/stable growth rate for remaining years"
                                ) / 100
    
                                # Store multi-stage config in session state
                                st.session_state['multistage_config'] = {
                                    'enabled': True,
                                    'stage1_years': stage1_years,
                                    'stage1_growth': stage1_growth,
                                    'stage2_years': stage2_years,
                                    'stage2_growth': stage2_growth,
                                    'stage3_years': stage3_years,
                                    'stage3_growth': stage3_growth
                                }
    
                                # Display summary
                                st.success(f"""
                                **Growth Profile:**
                                - Years 1-{stage1_years}: {stage1_growth*100:.1f}% growth (High Growth)
                                - Years {stage1_years+1}-{stage1_years+stage2_years}: {stage2_growth*100:.1f}% growth (Transition)
                                - Years {stage1_years+stage2_years+1}-{forecast_years}: {stage3_growth*100:.1f}% growth (Mature)
                                """)
                            else:
                                # Clear multi-stage config if disabled
                                st.session_state['multistage_config'] = {'enabled': False}
    
                            with col2:
                                if use_smart_assumptions:
                                    capex_pct = smart_params['capex_pct']
                                    st.metric("CapEx (% of Revenue)", f"{capex_pct*100:.1f}%",
                                             delta="AI Generated", delta_color="normal")
                                else:
                                    capex_pct = st.slider(
                                        "CapEx (% of Revenue)",
                                        min_value=0.0,
                                        max_value=20.0,
                                        value=5.0,
                                        step=0.5
                                    ) / 100
    
                                if use_smart_assumptions:
                                    depreciation_pct = smart_params['depreciation_pct']
                                    st.metric("Depreciation (% of Revenue)", f"{depreciation_pct*100:.1f}%",
                                             delta="AI Generated", delta_color="normal")
                                else:
                                    depreciation_pct = st.slider(
                                        "Depreciation (% of Revenue)",
                                        min_value=0.0,
                                        max_value=15.0,
                                        value=3.0,
                                        step=0.5
                                    ) / 100
    
                                wc_change = st.number_input(
                                    "Working Capital Change ($M)",
                                    min_value=-1000.0,
                                    max_value=1000.0,
                                    value=float(smart_params['wc_change']) if use_smart_assumptions else 0.0,  # FIX: Ensure float
                                    step=10.0
                                ) * 1e6
    
                        with tab2:
                            st.markdown("##### Cost of Capital Assumptions")
    
                            col1, col2 = st.columns(2)
    
                            with col1:
                                risk_free = st.slider(
                                    "Risk-Free Rate (%)",
                                    min_value=0.0,
                                    max_value=10.0,
                                    value=4.5,
                                    step=0.1
                                ) / 100
    
                                market_risk_premium = st.slider(
                                    "Market Risk Premium (%)",
                                    min_value=3.0,
                                    max_value=10.0,
                                    value=6.0,
                                    step=0.5
                                ) / 100
    
                                beta = st.number_input(
                                    "Beta",
                                    min_value=0.0,
                                    max_value=3.0,
                                    value=float(company['beta']) if company['beta'] else 1.0,
                                    step=0.1
                                )
    
                            with col2:
                                if method_key == 'FCFF':
                                    cost_debt = st.slider(
                                        "Cost of Debt (%)",
                                        min_value=0.0,
                                        max_value=15.0,
                                        value=5.0,
                                        step=0.5
                                    ) / 100
    
                                if use_smart_assumptions:
                                    tax_rate = smart_params['tax_rate']
                                    st.metric("Tax Rate", f"{tax_rate*100:.1f}%",
                                             delta="AI Generated", delta_color="normal")
                                else:
                                    tax_rate = st.slider(
                                        "Tax Rate (%)",
                                        min_value=0.0,
                                        max_value=40.0,
                                        value=float(financials.get('tax_rate', 0.21) * 100),
                                        step=1.0
                                    ) / 100
    
                                if method_key == 'FCFE':
                                    net_borrowing = st.number_input(
                                        "Net Borrowing ($M)",
                                        min_value=-1000.0,
                                        max_value=1000.0,
                                        value=0.0,
                                        step=10.0
                                    ) * 1e6
    
                        with tab3:
                            st.markdown("##### Terminal Value Assumptions")
    
                            col1, col2 = st.columns(2)
    
                            with col1:
                                if use_smart_assumptions:
                                    terminal_growth = smart_params['terminal_growth']
                                    st.metric("Perpetual Growth Rate", f"{terminal_growth*100:.1f}%",
                                             delta="AI Generated", delta_color="normal")
                                else:
                                    terminal_growth = st.slider(
                                        "Perpetual Growth Rate (%)",
                                        min_value=0.0,
                                        max_value=5.0,
                                        value=2.5,
                                        step=0.1
                                    ) / 100
    
                            with col2:
                                st.info(f"""
                                **Terminal Value Method:** Gordon Growth Model
    
                                TV = FCF‚Çô‚Çä‚ÇÅ / (r - g)
                                """)
    
                # =================================================================
                # DIVIDEND DISCOUNT MODELS (GORDON & MULTI-STAGE)
                # =================================================================
                elif method_key == 'GORDON_DDM':
                    st.markdown("##### Gordon Growth DDM Inputs")
    
                    col1, col2 = st.columns(2)
    
                    with col1:
                        # Get current dividend from company data
                        current_dividend_default = company.get('dividendRate', 0) * company['shares_outstanding']
                        if current_dividend_default == 0:
                            # Try to estimate from dividend yield
                            div_yield = company.get('dividendYield', 0)
                            if div_yield > 0:
                                current_dividend_default = company['market_cap'] * div_yield
    
                        current_dividend = st.number_input(
                            "Current Annual Dividend ($)",
                            min_value=0.0,
                            value=float(current_dividend_default),
                            step=0.01,
                            help="Total annual dividend paid by the company"
                        )
    
                        if use_smart_assumptions:
                            cost_of_equity_ddm = smart_params.get('cost_of_equity', 0.10)
                            st.metric("Cost of Equity", f"{cost_of_equity_ddm*100:.1f}%",
                                     delta="AI Generated", delta_color="normal")
                        else:
                            risk_free_ddm = st.slider(
                                "Risk-Free Rate (%)",
                                min_value=0.0,
                                max_value=10.0,
                                value=4.5,
                                step=0.1,
                                key="ddm_risk_free"
                            ) / 100
    
                            market_risk_premium_ddm = st.slider(
                                "Market Risk Premium (%)",
                                min_value=3.0,
                                max_value=10.0,
                                value=6.0,
                                step=0.5,
                                key="ddm_mrp"
                            ) / 100
    
                            beta_ddm = st.number_input(
                                "Beta",
                                min_value=0.0,
                                max_value=3.0,
                                value=float(company['beta']) if company['beta'] else 1.0,
                                step=0.1,
                                key="ddm_beta"
                            )
    
                            cost_of_equity_ddm = calculate_cost_of_equity(risk_free_ddm, beta_ddm, market_risk_premium_ddm)
                            st.info(f"Calculated Cost of Equity: {cost_of_equity_ddm*100:.2f}%")
    
                    with col2:
                        if use_smart_assumptions:
                            growth_rate_ddm = smart_params.get('dividend_growth', 0.03)
                            st.metric("Dividend Growth Rate", f"{growth_rate_ddm*100:.1f}%",
                                     delta="AI Generated", delta_color="normal")
                        else:
                            growth_rate_ddm = st.slider(
                                "Perpetual Dividend Growth Rate (%)",
                                min_value=0.0,
                                max_value=5.0,
                                value=2.5,
                                step=0.1,
                                help="Long-term sustainable dividend growth rate"
                            ) / 100
    
                        st.info(f"""
                        **Gordon Growth Formula:**
    
                        Value = D‚ÇÅ / (r - g)
    
                        Where D‚ÇÅ = D‚ÇÄ √ó (1 + g)
                        """)
    
                # =================================================================
                # MULTI-STAGE DDM
                # =================================================================
                elif method_key == 'MULTISTAGE_DDM':
                    st.markdown("##### Multi-Stage DDM Inputs (2-Stage Model)")
    
                    col1, col2 = st.columns(2)
    
                    with col1:
                        # Get current dividend
                        current_dividend_default = company.get('dividendRate', 0) * company['shares_outstanding']
                        if current_dividend_default == 0:
                            div_yield = company.get('dividendYield', 0)
                            if div_yield > 0:
                                current_dividend_default = company['market_cap'] * div_yield
    
                        current_dividend_ms = st.number_input(
                            "Current Annual Dividend ($)",
                            min_value=0.0,
                            value=float(current_dividend_default),
                            step=0.01,
                            key="ms_dividend"
                        )
    
                        if use_smart_assumptions:
                            cost_of_equity_ms = smart_params.get('cost_of_equity', 0.10)
                            st.metric("Cost of Equity", f"{cost_of_equity_ms*100:.1f}%",
                                     delta="AI Generated", delta_color="normal")
                        else:
                            risk_free_ms = st.slider(
                                "Risk-Free Rate (%)",
                                min_value=0.0,
                                max_value=10.0,
                                value=4.5,
                                step=0.1,
                                key="ms_risk_free"
                            ) / 100
    
                            market_risk_premium_ms = st.slider(
                                "Market Risk Premium (%)",
                                min_value=3.0,
                                max_value=10.0,
                                value=6.0,
                                step=0.5,
                                key="ms_mrp"
                            ) / 100
    
                            beta_ms = st.number_input(
                                "Beta",
                                min_value=0.0,
                                max_value=3.0,
                                value=float(company['beta']) if company['beta'] else 1.0,
                                step=0.1,
                                key="ms_beta"
                            )
    
                            cost_of_equity_ms = calculate_cost_of_equity(risk_free_ms, beta_ms, market_risk_premium_ms)
                            st.info(f"Calculated Cost of Equity: {cost_of_equity_ms*100:.2f}%")
    
                    with col2:
                        if use_smart_assumptions:
                            high_growth_rate = smart_params.get('high_growth_rate', 0.08)
                            high_growth_years = smart_params.get('high_growth_years', 5)
                            stable_growth_rate = smart_params.get('stable_growth_rate', 0.03)
    
                            st.metric("High Growth Rate", f"{high_growth_rate*100:.1f}%", delta="AI Generated")
                            st.metric("High Growth Years", f"{high_growth_years} years", delta="AI Generated")
                            st.metric("Stable Growth Rate", f"{stable_growth_rate*100:.1f}%", delta="AI Generated")
                        else:
                            high_growth_rate = st.slider(
                                "High Growth Rate (%)",
                                min_value=0.0,
                                max_value=20.0,
                                value=8.0,
                                step=0.5,
                                help="Initial high dividend growth rate"
                            ) / 100
    
                            high_growth_years = st.slider(
                                "High Growth Period (Years)",
                                min_value=3,
                                max_value=15,
                                value=5,
                                step=1,
                                help="Number of years of high growth"
                            )
    
                            stable_growth_rate = st.slider(
                                "Stable Growth Rate (%)",
                                min_value=0.0,
                                max_value=5.0,
                                value=2.5,
                                step=0.1,
                                help="Long-term perpetual growth rate"
                            ) / 100
    
                # =================================================================
                # RESIDUAL INCOME MODEL
                # =================================================================
                elif method_key == 'RESIDUAL_INCOME':
                    st.markdown("##### Residual Income Model Inputs")
    
                    col1, col2 = st.columns(2)
    
                    with col1:
                        # Book value of equity
                        book_value_default = financials.get('total_equity', company.get('bookValue', 0) * company['shares_outstanding'])
    
                        book_value_equity = st.number_input(
                            "Book Value of Equity ($)",
                            min_value=0.0,
                            value=float(book_value_default),
                            step=1000000.0,
                            help="Current book value of shareholders' equity"
                        )
    
                        if use_smart_assumptions:
                            roe = smart_params.get('roe', 0.15)
                            st.metric("Return on Equity (ROE)", f"{roe*100:.1f}%",
                                     delta="AI Generated", delta_color="normal")
                        else:
                            roe = st.slider(
                                "Return on Equity - ROE (%)",
                                min_value=0.0,
                                max_value=50.0,
                                value=15.0,
                                step=0.5,
                                help="Expected ROE for future periods"
                            ) / 100
    
                        forecast_years_ri = st.slider(
                            "Forecast Horizon (Years)",
                            min_value=3,
                            max_value=15,
                            value=smart_params.get('forecast_years', 5) if use_smart_assumptions else 5,
                            step=1,
                            key="ri_forecast_years"
                        )
    
                    with col2:
                        if use_smart_assumptions:
                            cost_of_equity_ri = smart_params.get('cost_of_equity', 0.10)
                            st.metric("Cost of Equity", f"{cost_of_equity_ri*100:.1f}%",
                                     delta="AI Generated", delta_color="normal")
                        else:
                            risk_free_ri = st.slider(
                                "Risk-Free Rate (%)",
                                min_value=0.0,
                                max_value=10.0,
                                value=4.5,
                                step=0.1,
                                key="ri_risk_free"
                            ) / 100
    
                            market_risk_premium_ri = st.slider(
                                "Market Risk Premium (%)",
                                min_value=3.0,
                                max_value=10.0,
                                value=6.0,
                                step=0.5,
                                key="ri_mrp"
                            ) / 100
    
                            beta_ri = st.number_input(
                                "Beta",
                                min_value=0.0,
                                max_value=3.0,
                                value=float(company['beta']) if company['beta'] else 1.0,
                                step=0.1,
                                key="ri_beta"
                            )
    
                            cost_of_equity_ri = calculate_cost_of_equity(risk_free_ri, beta_ri, market_risk_premium_ri)
                            st.info(f"Calculated Cost of Equity: {cost_of_equity_ri*100:.2f}%")
    
                        if use_smart_assumptions:
                            growth_rate_ri = smart_params.get('terminal_growth', 0.025)
                            st.metric("Terminal Growth Rate", f"{growth_rate_ri*100:.1f}%",
                                     delta="AI Generated", delta_color="normal")
                        else:
                            growth_rate_ri = st.slider(
                                "Terminal Growth Rate (%)",
                                min_value=0.0,
                                max_value=5.0,
                                value=2.5,
                                step=0.1,
                                key="ri_terminal_growth",
                                help="Long-term growth rate for terminal value"
                            ) / 100
    
                        st.info(f"""
                        **Residual Income Formula:**
    
                        Value = BV + PV(RI)
    
                        RI = (ROE - r) √ó BV
                        """)
    
                # =================================================================
                # RELATIVE VALUATION (PEER MULTIPLES)
                # =================================================================
                elif method_key == 'RELATIVE':
                    st.markdown("##### Relative Valuation - Peer Multiples")
    
                    st.info(f"""
                    This method values the company based on peer comparison using 6 key multiples:
    
                    - **P/E Ratio:** Price to Earnings
                    - **P/B Ratio:** Price to Book Value
                    - **P/S Ratio:** Price to Sales
                    - **EV/EBITDA:** Enterprise Value to EBITDA
                    - **EV/EBIT:** Enterprise Value to EBIT
                    - **PEG Ratio:** P/E to Growth
    
                    Peer companies are automatically selected from the {company['sector']} sector.
                    """)
    
                    # Fetch peers
                    with st.spinner("Fetching peer companies..."):
                        ticker = company['ticker']
                        sector = company['sector']
                        peers = fetch_peer_companies(ticker, sector, max_peers=10)
    
                        if peers:
                            st.success(f"Found {len(peers)} peer companies: {', '.join(peers)}")
                        else:
                            st.warning("No peer companies found. Using default sector averages.")
    
                # =================================================================
                # SUM-OF-THE-PARTS (SOTP)
                # =================================================================
                elif method_key == 'SOTP':
                    st.markdown("##### Sum-of-the-Parts Valuation")
    
                    st.info("""
                    SOTP values multi-segment companies by valuing each business unit independently.
    
                    For each segment, provide:
                    - Revenue
                    - EBITDA Margin
                    - EV/Revenue Multiple (based on comparable companies)
                    """)
    
                    # Number of segments
                    num_segments = st.number_input(
                        "Number of Business Segments",
                        min_value=1,
                        max_value=10,
                        value=2,
                        step=1
                    )
    
                    # Create segment inputs
                    segments = []
                    for i in range(num_segments):
                        with st.expander(f"Segment {i+1}", expanded=(i == 0)):
                            col1, col2, col3 = st.columns(3)
    
                            with col1:
                                segment_name = st.text_input(
                                    "Segment Name",
                                    value=f"Segment {i+1}",
                                    key=f"seg_name_{i}"
                                )
    
                                segment_revenue = st.number_input(
                                    "Revenue ($M)",
                                    min_value=0.0,
                                    value=100.0,
                                    step=10.0,
                                    key=f"seg_rev_{i}"
                                ) * 1e6
    
                            with col2:
                                segment_ebitda_margin = st.slider(
                                    "EBITDA Margin (%)",
                                    min_value=0.0,
                                    max_value=50.0,
                                    value=20.0,
                                    step=1.0,
                                    key=f"seg_ebitda_{i}"
                                ) / 100
    
                            with col3:
                                segment_multiple = st.number_input(
                                    "EV/Revenue Multiple",
                                    min_value=0.0,
                                    max_value=10.0,
                                    value=2.0,
                                    step=0.1,
                                    key=f"seg_mult_{i}",
                                    help="Based on comparable segment peers"
                                )
    
                            segments.append({
                                'name': segment_name,
                                'revenue': segment_revenue,
                                'ebitda_margin': segment_ebitda_margin,
                                'ev_revenue_multiple': segment_multiple
                            })
    
                st.markdown("---")
                
                # Calculate Valuation (All Methods)
                if st.button("üöÄ Calculate Intrinsic Value", type="primary", use_container_width=True):
                    with st.spinner(f"üî¨ Running {method_key} Valuation..."):
    
                        shares = company['shares_outstanding']
    
                        # =================================================================
                        # DCF METHODS (FCFF / FCFE)
                        # =================================================================
                        if method_key in ['FCFF', 'FCFE']:
                            # Check if Dashboard Mode is active
                            dashboard_active = ('dashboard_inputs' in st.session_state and
                                               st.session_state.get('use_model_inputs_dashboard', False))
    
                            if dashboard_active:
                                # =========================================================
                                # DASHBOARD MODE: Use pre-calculated inputs and projections
                                # =========================================================
                                dashboard_data = st.session_state['dashboard_inputs']
    
                                # Extract dashboard values
                                discount_rate = dashboard_data['wacc']
                                terminal_growth = dashboard_data['terminal_growth']
                                shares = dashboard_data['diluted_shares']
                                dcf_proj_obj = dashboard_data.get('projections')
    
                                # Convert DCFProjections object to legacy projection format
                                # for compatibility with calculate_dcf_value()
                                if dcf_proj_obj:
                                    projections = []
                                    for year in range(1, dcf_proj_obj.forecast_years + 1):
                                        year_data = dcf_proj_obj.final_projections[year]
                                        projections.append({
                                            'year': year,
                                            'revenue': year_data['revenue'],
                                            'ebit': year_data.get('ebit', 0),
                                            'nopat': year_data.get('nopat', 0),
                                            'fcff': year_data.get('fcff', 0),
                                            'fcfe': year_data.get('fcfe', 0)
                                        })
                                    final_fcf = projections[-1]['fcff'] if method_key == 'FCFF' else projections[-1]['fcfe']
                                else:
                                    # Fallback if projections object not available
                                    st.error("‚ö†Ô∏è Dashboard projections not available. Using manual calculation.")
                                    dashboard_active = False
    
                            if not dashboard_active:
                                # =========================================================
                                # MANUAL MODE: Use slider inputs and traditional calculation
                                # =========================================================
                                # Calculate cost of equity
                                cost_equity = calculate_cost_of_equity(risk_free, beta, market_risk_premium)
    
                                # Calculate discount rate
                                if method_key == 'FCFF':
                                    total_debt = financials.get('total_debt', 0)
                                    total_equity = company['market_cap']
                                    discount_rate = calculate_wacc(cost_equity, cost_debt, tax_rate, total_debt, total_equity)
                                else:
                                    discount_rate = cost_equity
    
                                # Get base financials
                                base_revenue = financials.get('revenue', 0)
                                base_ebit = financials.get('ebit', 0)
                                base_net_income = financials.get('net_income', 0)
    
                                # ENHANCED: Project cash flows with scaling D&A and CapEx
                                # Get multi-stage config if enabled
                                multistage_config = st.session_state.get('multistage_config', {'enabled': False})
    
                                if method_key == 'FCFF':
                                    projections = project_fcff_enhanced(
                                        base_revenue, base_ebit, revenue_growth, ebit_margin, tax_rate,
                                        depreciation_pct, capex_pct, wc_change, forecast_years, multistage_config
                                    )
                                    final_fcf = projections[-1]['fcff']
                                else:
                                    projections = project_fcfe_enhanced(
                                        base_revenue, base_net_income, revenue_growth, tax_rate,
                                        depreciation_pct, capex_pct, wc_change, net_borrowing, forecast_years, multistage_config
                                    )
                                    final_fcf = projections[-1]['fcfe']
    
                                # Use shares from company data
                                shares = company['shares_outstanding']
    
                            # =================================================================
                            # SBC INTEGRATION: Adjust FCFF for Share-Based Compensation
                            # =================================================================
                            sbc_enabled = False
                            sbc_forecast = None
                            projections_without_sbc = None
    
                            if dashboard_active and SBC_AVAILABLE:
                                # Check if SBC is enabled in dashboard
                                sbc_data = dashboard_data.get('sbc')
                                if sbc_data and sbc_data.get('enabled', False):
                                    sbc_enabled = True
    
                                    # Store original projections for before/after comparison
                                    projections_without_sbc = [p.copy() for p in projections]
    
                                    # Generate SBC forecast using revenue projections
                                    revenue_projections = {p['year']: p['revenue'] for p in projections}
    
                                    config = sbc_data['config']
                                    forecaster = SBCForecaster(config)
                                    sbc_forecast = forecaster.generate_sbc_forecast(revenue_projections)
    
                                    # Integrate SBC into FCFF projections
                                    # Convert projections list to dict format for integration
                                    projections_dict = {p['year']: p for p in projections}
                                    updated_projections_dict = integrate_sbc_with_fcff(
                                        projections_dict,
                                        sbc_forecast,
                                        sbc_already_in_fcff=False  # Dashboard mode calculates from NOPAT
                                    )
    
                                    # Convert back to list format
                                    projections = [updated_projections_dict[year] for year in sorted(updated_projections_dict.keys())]
    
                                    # Update final FCF (now includes SBC)
                                    final_fcf = projections[-1]['fcff'] if method_key == 'FCFF' else projections[-1]['fcfe']
    
                                    st.info(f"‚úÖ SBC integrated into valuation. Avg SBC: {config.starting_sbc_pct_revenue:.1f}% of revenue")
    
                            # Calculate terminal value (both modes)
                            terminal_value = calculate_terminal_value(final_fcf, discount_rate, terminal_growth)
    
                            # Calculate DCF value (both modes)
                            net_debt = financials.get('total_debt', 0) - financials.get('cash', 0)
    
                            dcf_results = calculate_dcf_value(
                                projections, discount_rate, terminal_value, shares,
                                net_debt if method_key == 'FCFF' else 0, method_key
                            )
    
                            dcf_results['net_debt'] = net_debt
    
                            # Store results
                            st.session_state['valuation_results'] = dcf_results
                            st.session_state['dcf_projections'] = projections
                            st.session_state['valuation_method'] = method_key
                            st.session_state['discount_rate'] = discount_rate
                            st.session_state['terminal_growth'] = terminal_growth
                            st.session_state['used_smart_assumptions'] = use_smart_assumptions if not dashboard_active else False
                            st.session_state['used_dashboard_mode'] = dashboard_active
    
                            # Store SBC data for before/after comparison
                            if sbc_enabled:
                                st.session_state['sbc_enabled'] = True
                                st.session_state['sbc_forecast'] = sbc_forecast
                                st.session_state['projections_without_sbc'] = projections_without_sbc
                                st.session_state['sbc_forecaster'] = forecaster
                            else:
                                st.session_state['sbc_enabled'] = False
    
                        # =================================================================
                        # GORDON GROWTH DDM
                        # =================================================================
                        elif method_key == 'GORDON_DDM':
                            gordon_results = calculate_gordon_growth_ddm(
                                current_dividend=current_dividend,
                                cost_of_equity=cost_of_equity_ddm,
                                growth_rate=growth_rate_ddm,
                                shares_outstanding=shares
                            )
    
                            # Store results
                            st.session_state['valuation_results'] = gordon_results
                            st.session_state['valuation_method'] = method_key
                            st.session_state['used_smart_assumptions'] = use_smart_assumptions
    
                        # =================================================================
                        # MULTI-STAGE DDM
                        # =================================================================
                        elif method_key == 'MULTISTAGE_DDM':
                            multistage_results = calculate_multistage_ddm(
                                current_dividend=current_dividend_ms,
                                cost_of_equity=cost_of_equity_ms,
                                high_growth_rate=high_growth_rate,
                                high_growth_years=high_growth_years,
                                stable_growth_rate=stable_growth_rate,
                                shares_outstanding=shares
                            )
    
                            # Store results
                            st.session_state['valuation_results'] = multistage_results
                            st.session_state['valuation_method'] = method_key
                            st.session_state['used_smart_assumptions'] = use_smart_assumptions
    
                        # =================================================================
                        # RESIDUAL INCOME
                        # =================================================================
                        elif method_key == 'RESIDUAL_INCOME':
                            residual_results = calculate_residual_income(
                                book_value_equity=book_value_equity,
                                roe=roe,
                                cost_of_equity=cost_of_equity_ri,
                                growth_rate=growth_rate_ri,
                                forecast_years=forecast_years_ri,
                                shares_outstanding=shares
                            )
    
                            # Store results
                            st.session_state['valuation_results'] = residual_results
                            st.session_state['valuation_method'] = method_key
                            st.session_state['used_smart_assumptions'] = use_smart_assumptions
    
                        # =================================================================
                        # RELATIVE VALUATION
                        # =================================================================
                        elif method_key == 'RELATIVE':
                            # Calculate peer multiples
                            median_multiples = calculate_peer_multiples(peers)
    
                            if median_multiples:
                                # Prepare company financials for relative valuation
                                company_financials_dict = {
                                    'eps': financials.get('eps', 0),
                                    'book_value_per_share': financials.get('book_value_per_share', 0),
                                    'sales_per_share': financials.get('revenue', 0) / shares if shares > 0 else 0,
                                    'ebitda': financials.get('ebitda', 0),
                                    'ebit': financials.get('ebit', 0),
                                    'revenue': financials.get('revenue', 0),
                                    'total_debt': financials.get('total_debt', 0),
                                    'cash': financials.get('cash', 0)
                                }
    
                                relative_results = apply_relative_valuation(
                                    company_financials=company_financials_dict,
                                    median_multiples=median_multiples,
                                    shares_outstanding=shares
                                )
    
                                # Add method and average value
                                relative_results['method'] = 'Relative Valuation'
                                relative_results['intrinsic_value_per_share'] = relative_results.get('average_relative_value', 0)
    
                                # Store results
                                st.session_state['valuation_results'] = relative_results
                                st.session_state['valuation_method'] = method_key
                                st.session_state['used_smart_assumptions'] = False
                            else:
                                st.error("Unable to calculate peer multiples. Please check peer company data.")
                                st.stop()
    
                        # =================================================================
                        # SUM-OF-THE-PARTS (SOTP)
                        # =================================================================
                        elif method_key == 'SOTP':
                            sotp_results = calculate_sotp_valuation(
                                segments=segments,
                                discount_rate=0.10,  # Default WACC for SOTP
                                shares_outstanding=shares
                            )
    
                            # Store results
                            st.session_state['valuation_results'] = sotp_results
                            st.session_state['valuation_method'] = method_key
                            st.session_state['used_smart_assumptions'] = False
    
                        st.success("‚úÖ Valuation Complete!")
    
                # Display Results
                if 'valuation_results' in st.session_state:
                    results = st.session_state['valuation_results']
                    method = st.session_state['valuation_method']
                    projections = st.session_state.get('dcf_projections', None)
    
                    st.markdown("---")
                    st.markdown("### üìä Valuation Results")
    
                    if st.session_state.get('used_smart_assumptions', False):
                        st.success("ü§ñ **These results used AI-Generated Smart Assumptions**")
    
                    # Key metrics
                    intrinsic_value = results['intrinsic_value_per_share']
                    current_price = company['current_price']
                    upside_downside = ((intrinsic_value - current_price) / current_price) * 100
    
                    # DCF Valuation toast with upside/downside
                    if abs(upside_downside) < 1000:  # Valid result
                        if upside_downside > 20:
                            toast_msg = f"DCF Valuation: ${intrinsic_value:.2f} target | {upside_downside:.1f}% upside - Significantly Undervalued"
                            toast_type = "success"
                        elif upside_downside > 0:
                            toast_msg = f"DCF Valuation: ${intrinsic_value:.2f} target | {upside_downside:.1f}% upside - Slightly Undervalued"
                            toast_type = "info"
                        elif upside_downside > -20:
                            toast_msg = f"DCF Valuation: ${intrinsic_value:.2f} target | {abs(upside_downside):.1f}% downside - Slightly Overvalued"
                            toast_type = "warning"
                        else:
                            toast_msg = f"DCF Valuation: ${intrinsic_value:.2f} target | {abs(upside_downside):.1f}% downside - Significantly Overvalued"
                            toast_type = "warning"
                        show_toast(toast_msg, toast_type=toast_type, duration=5000)
                    
                    col1, col2, col3, col4 = st.columns(4)
                    
                    col1.metric(
                        "Intrinsic Value",
                        format_currency(intrinsic_value),
                        delta=format_percentage(upside_downside) if abs(upside_downside) < 1000 else "¬±‚àû"
                    )
                    
                    col2.metric("Current Price", format_currency(current_price))
                    
                    col3.metric(
                        "Upside/Downside",
                        format_percentage(upside_downside) if abs(upside_downside) < 1000 else "¬±‚àû",
                        delta="Undervalued" if upside_downside > 0 else "Overvalued"
                    )
    
                    # v9.7 FIX: Safe access to session_state with defaults
                    discount_rate = st.session_state.get('discount_rate', results.get('discount_rate', 0.10))
                    col4.metric("Discount Rate", ATLASFormatter.format_yield(discount_rate * 100, decimals=1))
                    
                    # Valuation interpretation
                    st.markdown("---")
                    
                    if upside_downside > 20:
                        st.success(f"""
                        ‚úÖ **Significantly Undervalued**
                        
                        The intrinsic value suggests the stock is trading at a {abs(upside_downside):.1f}% discount to fair value.
                        """)
                    elif upside_downside > 0:
                        st.info(f"""
                        üìä **Slightly Undervalued**
                        
                        Modest upside potential of {upside_downside:.1f}%.
                        """)
                    elif upside_downside > -20:
                        st.warning(f"""
                        ‚ö†Ô∏è **Slightly Overvalued**
                        
                        Trading {abs(upside_downside):.1f}% above fair value.
                        """)
                    else:
                        st.error(f"""
                        ‚ùå **Significantly Overvalued**
                        
                        Trading at a {abs(upside_downside):.1f}% premium to fair value.
                        """)
                    
                    st.markdown("---")
    
                    # Visualizations (only for DCF methods)
                    if method in ['FCFF', 'FCFE'] and projections:
                        col1, col2 = st.columns(2)
    
                        with col1:
                            waterfall = create_dcf_waterfall(results, method)
                            st.plotly_chart(waterfall, use_container_width=True)
    
                        with col2:
                            cf_chart = create_cash_flow_chart(projections, method)
                            st.plotly_chart(cf_chart, use_container_width=True)
    
                    # Sensitivity Analysis
                    st.markdown("---")
                    st.markdown("#### üéØ Sensitivity Analysis")
    
                    # v9.7 FIX: Safe access to session_state with defaults
                    terminal_growth = st.session_state.get('terminal_growth', results.get('terminal_growth', 0.025))
                    sensitivity = create_sensitivity_table(
                        intrinsic_value,
                        discount_rate,
                        terminal_growth
                    )
                    st.plotly_chart(sensitivity, use_container_width=True)
    
                    # ============================================================
                    # DCF TRAP DETECTION SYSTEM (ATLAS v11.0)
                    # ============================================================
                    if method in ['FCFF', 'FCFE'] and DCF_TRAP_DETECTION_AVAILABLE:
                        st.markdown("---")
                        st.markdown("### üîç DCF Quality Assessment (NEW)")
    
                        st.info("""
                        **üéØ What is this?** The DCF Trap Detection System analyzes your valuation assumptions to identify common
                        patterns associated with value traps. Philosophy: *"Mathematically sound ‚â† Economically sound"*
    
                        This institutional-grade analysis checks for:
                        ‚Ä¢ Discount Rate Illusion ‚Ä¢ Terminal Value Dependency ‚Ä¢ Revenue Concentration
                        ‚Ä¢ Idiosyncratic Optionality ‚Ä¢ Absence of Critical Factor
                        """)
    
                        # Run trap detection
                        with st.spinner("üîç Running trap detection analysis..."):
                            try:
                                # Prepare DCF inputs for trap detector
                                revenue_projections = [p.get('revenue', 0) for p in projections] if projections else []
    
                                if method == 'FCFF':
                                    fcf_projections = [p.get('fcff', 0) for p in projections] if projections else []
                                else:
                                    fcf_projections = [p.get('fcfe', 0) for p in projections] if projections else []
    
                                dcf_inputs_for_trap_detection = {
                                    'wacc': discount_rate,
                                    'terminal_growth_rate': terminal_growth,
                                    'projection_years': len(projections) if projections else 5,
                                    'revenue_projections': revenue_projections,
                                    'fcf_projections': fcf_projections,
                                    'terminal_value': results.get('pv_terminal', 0),
                                    'enterprise_value': results.get('enterprise_value', 0) if method == 'FCFF' else results.get('equity_value', 0),
                                    'current_price': current_price,
                                    'fair_value': intrinsic_value
                                }
    
                                # Run trap detection
                                trap_summary = analyze_dcf_traps(company['ticker'], dcf_inputs_for_trap_detection)
    
                                # Display warnings
                                display_trap_warnings(trap_summary, company['ticker'])
    
                            except Exception as e:
                                st.error(f"‚ö†Ô∏è Trap detection error: {str(e)}")
                                st.info("Trap detection requires valid DCF inputs. Please ensure all assumptions are properly configured.")
    
                    # =================================================================
                    # SBC BEFORE/AFTER COMPARISON
                    # =================================================================
                    if st.session_state.get('sbc_enabled', False) and SBC_AVAILABLE:
                        st.markdown("---")
                        st.markdown("#### üí∞ SBC Impact on Valuation")
    
                        try:
                            # Get SBC data from session state
                            sbc_forecast = st.session_state.get('sbc_forecast', {})
                            projections_without_sbc = st.session_state.get('projections_without_sbc', [])
                            forecaster = st.session_state.get('sbc_forecaster')
    
                            if sbc_forecast and projections_without_sbc and forecaster:
                                # Calculate valuation WITHOUT SBC for comparison
                                projections_dict_no_sbc = {p['year']: p for p in projections_without_sbc}
                                terminal_value_no_sbc = calculate_terminal_value(
                                    projections_without_sbc[-1]['fcff'],
                                    discount_rate,
                                    terminal_growth
                                )
    
                                dcf_results_no_sbc = calculate_dcf_value(
                                    projections_without_sbc,
                                    discount_rate,
                                    terminal_value_no_sbc,
                                    results.get('diluted_shares', company['shares_outstanding']),
                                    results.get('net_debt', 0),
                                    method
                                )
    
                                # Create comparison analysis
                                comparison = create_sbc_comparison_analysis(
                                    valuation_without_sbc=dcf_results_no_sbc,
                                    valuation_with_sbc=results,
                                    sbc_forecast=sbc_forecast
                                )
    
                                # Display comparison using the UI component
                                display_sbc_valuation_impact(comparison, company['ticker'])
    
                                # Educational message
                                with st.expander("üìö Why This Matters", expanded=False):
                                    st.markdown("""
                                    ### Share-Based Compensation is a Real Cost
    
                                    Many analysts ignore SBC in DCF valuations, treating it as "non-cash."
                                    This is incorrect because:
    
                                    1. **SBC dilutes shareholders** - Every stock grant reduces your ownership %
                                    2. **SBC represents real economic transfer** - If not paid in stock, would be cash
                                    3. **High-SBC companies are systematically overvalued** - Ignoring 10%+ SBC causes 15-20% overvaluation
    
                                    **ATLAS properly treats SBC as a cash cost**, providing more accurate valuations.
    
                                    **The comparison above shows:**
                                    - How much fair value changes when SBC is properly accounted for
                                    - The percentage impact on enterprise value
                                    - Whether ignoring SBC would cause material mispricing
    
                                    **Rule of Thumb:**
                                    - SBC < 3% of revenue: Not material, minor impact
                                    - SBC 3-7%: Material, should be modeled
                                    - SBC > 7%: Highly material, ignoring it causes major overvaluation
                                    """)
    
                        except Exception as e:
                            st.warning(f"‚ö†Ô∏è Could not display SBC comparison: {str(e)}")
    
                    # Detailed Projections Table
                    st.markdown("---")
                    st.markdown("#### üìã Detailed Cash Flow Projections")
    
                    proj_df = pd.DataFrame(projections)
    
                    # Format for display
                    if method == 'FCFF':
                        display_cols = ['year', 'revenue', 'ebit', 'nopat', 'depreciation', 'capex', 'change_wc', 'fcff']
                        col_names = ['Year', 'Revenue', 'EBIT', 'NOPAT', 'D&A', 'CapEx', 'ŒîWC', 'FCFF']
                    else:
                        display_cols = ['year', 'revenue', 'net_income', 'depreciation', 'capex', 'change_wc', 'net_borrowing', 'fcfe']
                        col_names = ['Year', 'Revenue', 'Net Income', 'D&A', 'CapEx', 'ŒîWC', 'Borrowing', 'FCFE']
    
                    # Check if all required columns exist in projections
                    if not proj_df.empty and all(col in proj_df.columns for col in display_cols):
                        proj_display = proj_df[display_cols].copy()
                        proj_display.columns = col_names
                    else:
                        # Fallback: show all available columns
                        proj_display = proj_df.copy()
                        st.warning(f"‚ö†Ô∏è Some projection columns missing. Showing available data.")
                    
                    # Format numbers
                    for col in proj_display.columns:
                        if col != 'Year':
                            proj_display[col] = proj_display[col].apply(format_large_number)
    
                    make_scrollable_table(proj_display, height=600, hide_index=True, use_container_width=True, column_config=None)
                    
                    st.info("üí° **Technical Note:** D&A and CapEx scale with revenue growth (as they should!)")
                    
                    # Export Options
                    st.markdown("---")
                    col1, col2, col3 = st.columns(3)
                    
                    with col1:
                        if st.button("üì• Export to Excel", use_container_width=True):
                            st.info("Excel export feature coming soon!")
                    
                    with col2:
                        if st.button("üìÑ Generate PDF Report", use_container_width=True):
                            st.info("PDF export feature coming soon!")
                    
                    with col3:
                        if st.button("üîÑ Reset Valuation", use_container_width=True):
                            for key in ['dcf_results', 'dcf_projections', 'used_smart_assumptions']:
                                if key in st.session_state:
                                    del st.session_state[key]
                            st.rerun()
            
            else:
                # No company loaded
                st.markdown("---")
                st.markdown("""
                ### üìö How to Use Valuation House - Excellence Edition
                
                **NEW in v9.3: ü§ñ Smart Assumptions Mode**
                - AI-generated assumptions based on sector benchmarks
                - Realistic, economically grounded projections
                - Toggle between manual and smart modes
                
                **Step 1:** Search for any publicly traded company
                **Step 2:** Choose FCFF or FCFE valuation method
                **Step 3:** Enable Smart Assumptions or customize manually
                **Step 4:** Calculate intrinsic value and analyze results
                **Step 5:** Review sensitivity analysis
                
                ---
                
                ### ‚ú® What's New in v9.3 Excellence
                
                ‚úÖ **Smart Assumptions:** AI-powered realistic assumptions
                ‚úÖ **Fixed Scaling:** D&A and CapEx properly scale with revenue
                ‚úÖ **Enhanced Visuals:** Seamless dark mode theming
                ‚úÖ **Better Analysis:** More comprehensive sensitivity testing
                
                *Ready to start? Enter a ticker symbol above!* üöÄ
                """)
    
        # ========================================================================
        # MONTE CARLO ENGINE (v11.0)
        # ========================================================================
        elif page == "üé≤ Monte Carlo Engine":
            st.markdown("### üé≤ Monte Carlo Simulation Engine")
            st.markdown("**Advanced Stochastic Modeling with Geometric Brownian Motion**")
    
            portfolio_data = load_portfolio_data()
    
            # ‚úÖ FIX: Proper DataFrame empty check
            if portfolio_data is None or (isinstance(portfolio_data, pd.DataFrame) and portfolio_data.empty):
                st.warning("‚ö†Ô∏è Please upload portfolio data via Phoenix Parser first")
            else:
                st.success(f"‚úÖ Portfolio loaded: {len(portfolio_data)} positions")
    
                # Configuration
                col1, col2, col3 = st.columns(3)
                with col1:
                    n_scenarios = st.number_input("Number of Scenarios", min_value=1000, max_value=50000, value=10000, step=1000)
                with col2:
                    time_horizon = st.number_input("Time Horizon (days)", min_value=30, max_value=1000, value=252, step=30)
                with col3:
                    confidence_level = st.slider("Confidence Level", min_value=90, max_value=99, value=95, step=1)
    
                if st.button("üöÄ Run Monte Carlo Simulation", type="primary"):
                    with st.spinner("Running Monte Carlo simulation..."):
                        try:
                            # ===== FIX #4: Handle Symbol vs Ticker column name =====
                            # Detect which column name is used
                            ticker_column = 'Symbol' if 'Symbol' in portfolio_data.columns else 'Ticker'
                            print(f"üéØ Detected ticker column: '{ticker_column}'")
    
                            # Get tickers and current prices
                            tickers = portfolio_data[ticker_column].unique().tolist()
                            print(f"üéØ Found {len(tickers)} unique tickers: {tickers[:5]}...")
    
                            # Download historical data
                            hist_data = yf.download(tickers, period='1y', progress=False)['Close']
    
                            if isinstance(hist_data, pd.Series):
                                hist_data = hist_data.to_frame()
    
                            # Calculate returns
                            returns = hist_data.pct_change().dropna()
    
                            # ===== FIX #8: Aligned Weight Calculation for Monte Carlo =====
    
                            # Get unique tickers (this is what the simulation will use)
                            tickers_list = list(returns.columns)
                            print(f"üéØ Running Monte Carlo for {len(tickers_list)} tickers: {tickers_list}")
    
                            # Calculate total portfolio value
                            if 'Total Value' in portfolio_data.columns:
                                total_value = portfolio_data['Total Value'].sum()
                            else:
                                total_value = (portfolio_data['Quantity'] * portfolio_data['Current Price']).sum()
    
                            print(f"üí∞ Total portfolio value: ${total_value:,.2f}")
    
                            # Build aligned weights dictionary
                            weights_dict = {}
    
                            for ticker in tickers_list:
                                ticker_data = portfolio_data[portfolio_data[ticker_column] == ticker]
    
                                if len(ticker_data) > 0:
                                    if 'Total Value' in ticker_data.columns:
                                        ticker_value = ticker_data['Total Value'].sum()
                                    else:
                                        ticker_value = (ticker_data['Quantity'] * ticker_data['Current Price']).sum()
    
                                    weight = ticker_value / total_value
                                    weights_dict[ticker] = weight
                                else:
                                    # Ticker in returns but not in portfolio - assign zero weight
                                    weights_dict[ticker] = 0.0
                                    print(f"‚ö†Ô∏è Warning: {ticker} in historical data but not in portfolio")
    
                            # Create numpy arrays in same order as tickers_list
                            weights = np.array([weights_dict[ticker] for ticker in tickers_list])
                            S0_values = hist_data.iloc[-1].values
    
                            # ===== CRITICAL VALIDATION =====
                            # Ensure perfect alignment
                            assert len(weights) == len(tickers_list), \
                                f"‚ùå Shape mismatch: {len(weights)} weights vs {len(tickers_list)} tickers"
    
                            assert len(S0_values) == len(tickers_list), \
                                f"‚ùå Shape mismatch: {len(S0_values)} prices vs {len(tickers_list)} tickers"
    
                            assert abs(weights.sum() - 1.0) < 0.01, \
                                f"‚ùå Weights don't sum to 1.0: {weights.sum():.4f}"
    
                            # Ensure all weights are non-negative
                            assert (weights >= 0).all(), \
                                "‚ùå Negative weights detected"
    
                            print(f"‚úÖ Weight validation passed:")
                            print(f"   - Array length: {len(weights)}")
                            print(f"   - Sum: {weights.sum():.4f}")
                            print(f"   - Min weight: {weights.min():.4f}")
                            print(f"   - Max weight: {weights.max():.4f}")
    
                            # Initialize StochasticEngine
                            engine = StochasticEngine(tickers=list(returns.columns), returns_data=returns)
    
                            # Run Monte Carlo simulation
                            portfolio_paths, final_returns, metrics = engine.monte_carlo_simulation(
                                weights=weights,
                                S0_values=S0_values,
                                n_scenarios=n_scenarios,
                                T=time_horizon
                            )
    
                            # Display results
                            st.markdown("---")
                            st.markdown("#### üìä Simulation Results")
    
                            # Metrics
                            col1, col2, col3, col4 = st.columns(4)
                            with col1:
                                st.metric("Expected Return", f"{metrics['Expected Return']:.2%}",
                                         delta=f"{metrics['Expected Return']:.2%}")
                            with col2:
                                st.metric("Volatility", f"{metrics['Volatility']:.2%}")
                            with col3:
                                st.metric(f"VaR {confidence_level}%", f"{metrics['VaR 95%']:.2%}",
                                         delta=f"{metrics['VaR 95%']:.2%}", delta_color="inverse")
                            with col4:
                                st.metric(f"CVaR {confidence_level}%", f"{metrics['CVaR 95%']:.2%}",
                                         delta=f"{metrics['CVaR 95%']:.2%}", delta_color="inverse")
    
                            # Portfolio paths visualization
                            st.markdown("#### üìà Portfolio Value Paths")
    
                            fig = go.Figure()
    
                            # Plot sample paths
                            n_paths_to_plot = min(100, n_scenarios)
                            for i in range(n_paths_to_plot):
                                fig.add_trace(go.Scatter(
                                    y=portfolio_paths[i, :],
                                    mode='lines',
                                    line=dict(width=0.5, color='rgba(0, 212, 255, 0.1)'),
                                    showlegend=False,
                                    hoverinfo='skip'
                                ))
    
                            # Add mean path
                            mean_path = portfolio_paths.mean(axis=0)
                            fig.add_trace(go.Scatter(
                                y=mean_path,
                                mode='lines',
                                name='Mean Path',
                                line=dict(width=3, color='#00ff88')
                            ))
    
                            fig.update_layout(
                                title=f"Monte Carlo Simulation: {n_scenarios:,} Scenarios over {time_horizon} Days",
                                xaxis_title="Days",
                                yaxis_title="Portfolio Value",
                                height=500
                            )
                            apply_chart_theme(fig)
                            st.plotly_chart(fig, use_container_width=True)
    
                            # Returns distribution
                            st.markdown("#### üìä Returns Distribution")
    
                            fig2 = go.Figure()
                            fig2.add_trace(go.Histogram(
                                x=final_returns,
                                nbinsx=50,
                                name='Returns Distribution',
                                marker_color='#00d4ff'
                            ))
    
                            # Add VaR line
                            fig2.add_vline(x=metrics['VaR 95%'], line_dash="dash", line_color="red",
                                          annotation_text=f"VaR {confidence_level}%: {metrics['VaR 95%']:.2%}")
    
                            fig2.update_layout(
                                title="Distribution of Portfolio Returns",
                                xaxis_title="Return",
                                yaxis_title="Frequency",
                                height=400
                            )
                            apply_chart_theme(fig2)
                            st.plotly_chart(fig2, use_container_width=True)
    
                            st.success("‚úÖ Monte Carlo simulation completed successfully!")
    
                        except Exception as e:
                            st.error(f"‚ùå Simulation error: {str(e)}")
                            st.info("üí° Ensure your portfolio has valid data and multiple positions")
    
        # ========================================================================
        # QUANT OPTIMIZER (v11.0)
        # ========================================================================
        elif page == "üßÆ Quant Optimizer":
            # ===== FIX #5: Import required modules =====
            import plotly.graph_objects as go
            import plotly.express as px
            import numpy as np
    
            st.markdown("### üßÆ Quantitative Portfolio Optimizer")
            st.markdown("**Advanced Optimization using Multivariable Calculus & Analytical Gradients**")
    
            portfolio_data = load_portfolio_data()
    
            # ‚úÖ FIX: Proper DataFrame empty check
            if portfolio_data is None or (isinstance(portfolio_data, pd.DataFrame) and portfolio_data.empty):
                st.warning("‚ö†Ô∏è Please upload portfolio data via Phoenix Parser first")
            else:
                st.success(f"‚úÖ Portfolio loaded: {len(portfolio_data)} positions")
    
                # Configuration
                col1, col2, col3 = st.columns(3)
                with col1:
                    risk_free_rate = st.number_input("Risk-Free Rate", min_value=0.0, max_value=0.10, value=0.04, step=0.001, format="%.3f")
                with col2:
                    min_weight = st.number_input("Min Weight per Asset", min_value=0.0, max_value=0.20, value=0.01, step=0.01, format="%.2f")
                with col3:
                    max_weight = st.number_input("Max Weight per Asset", min_value=0.20, max_value=1.0, value=0.40, step=0.05, format="%.2f")
    
                if st.button("üöÄ Optimize Portfolio (Max Sharpe Ratio)", type="primary"):
                    with st.spinner("Running optimization with analytical gradients..."):
                        try:
                            # ===== FIX #5: Handle Symbol vs Ticker column name =====
                            ticker_column = 'Symbol' if 'Symbol' in portfolio_data.columns else 'Ticker'
                            print(f"üéØ Detected ticker column: '{ticker_column}'")
    
                            # Get tickers
                            tickers = portfolio_data[ticker_column].unique().tolist()
                            print(f"üéØ Optimizing portfolio with {len(tickers)} tickers")
    
                            # Download historical data
                            hist_data = yf.download(tickers, period='2y', progress=False)['Close']
    
                            if isinstance(hist_data, pd.Series):
                                hist_data = hist_data.to_frame()
    
                            # Calculate returns
                            returns = hist_data.pct_change().dropna()
    
                            # Initialize QuantOptimizer
                            optimizer = QuantOptimizer(returns_data=returns, risk_free_rate=risk_free_rate)
    
                            # Run optimization
                            optimal_weights, optimal_sharpe, result = optimizer.optimize_max_sharpe(
                                min_weight=min_weight,
                                max_weight=max_weight
                            )
    
                            # Calculate optimal portfolio metrics
                            optimal_return, optimal_vol = optimizer.portfolio_metrics(optimal_weights)
    
                            # Display results
                            st.markdown("---")
                            st.markdown("#### üéØ Optimization Results")
    
                            # Key metrics
                            col1, col2, col3, col4 = st.columns(4)
                            with col1:
                                st.metric("Maximum Sharpe Ratio", f"{optimal_sharpe:.3f}")
                            with col2:
                                st.metric("Expected Return", f"{optimal_return:.2%}")
                            with col3:
                                st.metric("Volatility", f"{optimal_vol:.2%}")
                            with col4:
                                convergence = "‚úÖ Success" if result.success else "‚ö†Ô∏è Warning"
                                st.metric("Convergence", convergence)
    
                            # Optimal weights
                            st.markdown("#### üìä Optimal Portfolio Weights")
    
                            weights_df = pd.DataFrame({
                                'Symbol': returns.columns,
                                'Optimal Weight': optimal_weights,
                                'Weight %': [f"{w:.2%}" for w in optimal_weights]
                            }).sort_values('Optimal Weight', ascending=False)
    
                            # Visualization
                            fig = go.Figure()
                            fig.add_trace(go.Bar(
                                x=weights_df['Symbol'],
                                y=weights_df['Optimal Weight'],
                                marker_color='#00d4ff',
                                text=weights_df['Weight %'],
                                textposition='outside'
                            ))
    
                            fig.update_layout(
                                title="Optimal Portfolio Allocation (Maximum Sharpe Ratio)",
                                xaxis_title="Symbol",
                                yaxis_title="Weight",
                                height=400
                            )
                            apply_chart_theme(fig)
                            st.plotly_chart(fig, use_container_width=True)
    
                            # Table
                            make_scrollable_table(weights_df, height=400, hide_index=True, use_container_width=True)
    
                            # Current vs Optimal comparison
                            st.markdown("#### üîÑ Current vs Optimal Allocation")
    
                            total_value = (portfolio_data['Quantity'] * portfolio_data['Current Price']).sum()
                            portfolio_data['Current Weight'] = (portfolio_data['Quantity'] * portfolio_data['Current Price']) / total_value
    
                            comparison_df = pd.DataFrame({
                                'Symbol': returns.columns
                            })
    
                            comparison_df['Optimal Weight'] = optimal_weights
                            comparison_df = comparison_df.merge(
                                portfolio_data[['Symbol', 'Current Weight']],
                                on='Symbol',
                                how='left'
                            )
                            comparison_df['Current Weight'] = comparison_df['Current Weight'].fillna(0)
                            comparison_df['Change'] = comparison_df['Optimal Weight'] - comparison_df['Current Weight']
    
                            make_scrollable_table(
                                comparison_df.style.format({
                                    'Current Weight': '{:.2%}',
                                    'Optimal Weight': '{:.2%}',
                                    'Change': '{:+.2%}'
                                }),
                                height=400,
                                hide_index=True,
                                use_container_width=True
                            )
    
                            st.success("‚úÖ Portfolio optimization completed successfully!")
                            st.info("üí° This optimization uses analytical gradients (‚àÇSharpe/‚àÇw_i) and SLSQP algorithm for maximum precision")
    
                        except Exception as e:
                            st.error(f"‚ùå Optimization error: {str(e)}")
                            st.info("üí° Ensure your portfolio has at least 2 positions with sufficient historical data")
    
        # ========================================================================
        # LEVERAGE TRACKER (v11.0) - NEW FEATURE
        # ========================================================================
        elif page == "üìä Leverage Tracker":
            st.markdown("## üìä LEVERAGE TRACKING & ANALYSIS")
            st.markdown("**Track how leverage has affected your returns over time**")
    
            # FIX #6: Removed duplicate upload - keep uploads centralized in Phoenix Parser
            # Check if leverage tracker exists in session state
            if 'leverage_tracker' not in st.session_state:
                st.warning("‚ö†Ô∏è No performance history loaded")
                st.info("""
                **To use Leverage Tracking:**
    
                1. Go to üî• **Phoenix Parser** (in sidebar navigation)
                2. Scroll to "üìä Leverage Tracking" section
                3. Upload your Investopedia performance-history.xls file
                4. Return to this page to view full analysis
    
                The performance history upload is centralized in Phoenix Parser to keep all data uploads in one place.
                """)
    
                # Show helpful navigation hint
                st.markdown("---")
                st.caption("üí° Tip: Use the sidebar navigation to quickly switch between pages")
    
                return  # Exit early if no tracker
            else:
                # Display leverage analysis
                tracker = st.session_state.leverage_tracker
                stats = tracker.get_current_stats()
    
                # Header metrics
                st.markdown("### üìä Current Statistics")
    
                col1, col2, col3, col4, col5 = st.columns(5)
    
                with col1:
                    st.metric(
                        "Current Leverage",
                        f"{stats['current_leverage']:.2f}x",
                        help="Gross Exposure / Net Equity"
                    )
    
                with col2:
                    st.metric(
                        "Net Equity",
                        f"${stats['current_equity']:,.0f}",
                        help="Your actual capital"
                    )
    
                with col3:
                    st.metric(
                        "Gross Exposure",
                        f"${stats['current_gross_exposure']:,.0f}",
                        help="Total position value"
                    )
    
                with col4:
                    st.metric(
                        "YTD Equity Return",
                        f"{stats['ytd_equity_return']:.1f}%",
                        help="Return on your capital"
                    )
    
                with col5:
                    st.metric(
                        "YTD Gross Return",
                        f"{stats['ytd_gross_return']:.1f}%",
                        help="Portfolio performance"
                    )
    
                # Additional stats row
                col1, col2, col3 = st.columns(3)
    
                with col1:
                    st.metric(
                        "Average Leverage",
                        f"{stats['avg_leverage']:.2f}x",
                        help="Historical average"
                    )
    
                with col2:
                    st.metric(
                        "Max Leverage",
                        f"{stats['max_leverage']:.2f}x",
                        help="Highest leverage used"
                    )
    
                with col3:
                    st.metric(
                        "Min Leverage",
                        f"{stats['min_leverage']:.2f}x",
                        help="Lowest leverage"
                    )
    
                # Dashboard
                st.markdown("---")
                st.markdown("### üìä 6-Chart Leverage Dashboard")
    
                fig = tracker.create_leverage_dashboard()
                st.plotly_chart(fig, use_container_width=True)
    
                # Workings
                st.markdown("---")
                st.markdown("### üßÆ Calculation Workings")
                st.markdown("**See exactly how leverage is calculated**")
    
                workings = tracker.create_workings_display()
                st.markdown(workings)
    
                # Historical data table
                st.markdown("---")
                st.markdown("### üìã Historical Data Table")
    
                display_df = tracker.leverage_history[[
                    'Date', 'Net Equity', 'Gross Exposure', 'Leverage Ratio',
                    'Equity Return (%)', 'Gross Return (%)', 'Leverage Impact (%)'
                ]].copy()
    
                # Format for display
                display_df['Date'] = display_df['Date'].dt.strftime('%Y-%m-%d')
                display_df['Net Equity'] = display_df['Net Equity'].apply(lambda x: f"${x:,.0f}")
                display_df['Gross Exposure'] = display_df['Gross Exposure'].apply(lambda x: f"${x:,.0f}")
                display_df['Leverage Ratio'] = display_df['Leverage Ratio'].apply(lambda x: f"{x:.2f}x")
    
                for col in ['Equity Return (%)', 'Gross Return (%)', 'Leverage Impact (%)']:
                    display_df[col] = display_df[col].apply(lambda x: f"{x:.2f}%" if pd.notna(x) else "")
    
                make_scrollable_table(display_df, height=400, hide_index=True, use_container_width=True)
    
                # Export options
                st.markdown("---")
                st.markdown("### üíæ Export Options")
    
                col1, col2 = st.columns(2)
    
                with col1:
                    if st.button("üì• Download Full Data (CSV)"):
                        csv = tracker.leverage_history.to_csv(index=False)
                        st.download_button(
                            label="Download CSV",
                            data=csv,
                            file_name="leverage_history.csv",
                            mime="text/csv"
                        )
    
                with col2:
                    if st.button("üîÑ Clear Leverage Data"):
                        del st.session_state.leverage_tracker
                        st.success("‚úÖ Leverage data cleared. Upload a new file to continue.")
                        st.experimental_rerun()
    
        # ========================================================================
        # INVESTOPEDIA LIVE (v11.0) - FIXED TWO-STAGE AUTH
        # ========================================================================
        elif page == "üì° Investopedia Live":
            st.markdown("### üì° Investopedia Paper Trading Integration")
            st.markdown("**Live Portfolio Sync with Investopedia Simulator**")
    
            # ===== FIX #6: Check for Selenium availability =====
            try:
                from selenium import webdriver
                SELENIUM_AVAILABLE = True
            except ImportError:
                SELENIUM_AVAILABLE = False
    
            if not SELENIUM_AVAILABLE:
                st.error("‚ùå Selenium Not Installed")
    
                st.markdown("""
                ### üì¶ Selenium Installation Required
    
                Investopedia integration requires Selenium for web automation.
    
                ---
    
                #### üîß For Google Colab:
    
                Run this in a code cell **before** starting the app:
    
                ```python
                # Install Selenium and ChromeDriver
                !pip install selenium
                !apt-get update
                !apt-get install -y chromium-chromedriver
                !cp /usr/lib/chromium-browser/chromedriver /usr/bin
                ```
    
                Then restart your Streamlit app.
    
                ---
    
                #### üíª For Local Deployment:
    
                ```bash
                # Install Selenium
                pip install selenium webdriver-manager
    
                # For Chrome (recommended)
                # Download ChromeDriver from: https://chromedriver.chromium.org/
                # Or use webdriver-manager to auto-download
                ```
    
                ---
    
                #### üìã Requirements:
    
                - ‚úÖ `selenium` package (Python)
                - ‚úÖ Chrome/Chromium browser
                - ‚úÖ ChromeDriver (matching Chrome version)
    
                ---
                """)
    
                # Add status check
                st.markdown("### üîç Package Status Check")
    
                col1, col2 = st.columns(2)
    
                with col1:
                    try:
                        from selenium import webdriver
                        st.success("‚úÖ selenium installed")
                    except ImportError:
                        st.error("‚ùå selenium missing")
                        st.caption("Run: `pip install selenium`")
    
                with col2:
                    try:
                        import subprocess
                        result = subprocess.run(['which', 'chromedriver'], capture_output=True)
                        if result.returncode == 0:
                            st.success("‚úÖ chromedriver found")
                        else:
                            st.error("‚ùå chromedriver missing")
                            st.caption("Install ChromeDriver")
                    except:
                        st.error("‚ùå chromedriver missing")
                        st.caption("Install ChromeDriver")
    
                st.stop()
    
            # Initialize authentication state
            if 'investopedia_auth_state' not in st.session_state:
                st.session_state.investopedia_auth_state = 'initial'  # initial, awaiting_2fa, authenticated
    
            # Authentication section
            st.markdown("#### üîê Authentication")
    
            # STAGE 1: Initial Login (Email + Password)
            if st.session_state.investopedia_auth_state == 'initial':
                st.info("**Step 1 of 2:** Enter your credentials to trigger 2FA email")
    
                col1, col2 = st.columns(2)
                with col1:
                    email = st.text_input("Email", value="davenompozolo@gmail.com", key="inv_email")
                with col2:
                    password = st.text_input("Password", type="password", key="inv_password")
    
                if st.button("üîì Attempt Login", type="primary"):
                    if password:
                        with st.spinner("Attempting login to Investopedia..."):
                            integration = InvestopediaIntegration(email=email)
                            result = integration.attempt_login(password)
    
                            if result['status'] == 'error':
                                st.error(f"‚ùå {result['message']}")
    
                            elif result['status'] == '2fa_required':
                                # Store integration object for Stage 2
                                st.session_state['investopedia_integration'] = integration
                                st.session_state.investopedia_auth_state = 'awaiting_2fa'
                                st.success(result['message'])
                                st.info("‚è≥ **Step 2 of 2:** Check your email and enter the 2FA code below")
                                st.rerun()
    
                            elif result['status'] == 'success':
                                st.session_state['investopedia_integration'] = integration
                                st.session_state.investopedia_auth_state = 'authenticated'
                                st.success(result['message'])
                                st.balloons()
                                st.rerun()
                    else:
                        st.warning("‚ö†Ô∏è Please enter your password")
    
            # STAGE 2: 2FA Code Submission
            elif st.session_state.investopedia_auth_state == 'awaiting_2fa':
                st.success("‚úì Login attempt successful! 2FA code has been sent to your email.")
                st.info("‚è≥ **Step 2 of 2:** Enter the 6-digit code from your email")
    
                twofa_code = st.text_input("2FA Code", placeholder="Enter 6-digit code", max_chars=6, key="inv_2fa")
    
                col1, col2 = st.columns([3, 1])
                with col1:
                    if st.button("‚úÖ Submit 2FA Code", type="primary"):
                        if twofa_code and len(twofa_code) == 6:
                            with st.spinner("Submitting 2FA code..."):
                                integration = st.session_state.get('investopedia_integration')
    
                                if integration:
                                    result = integration.submit_2fa_code(twofa_code)
    
                                    if result['status'] == 'success':
                                        st.session_state.investopedia_auth_state = 'authenticated'
                                        st.success(result['message'])
                                        st.balloons()
                                        st.rerun()
                                    else:
                                        st.error(f"‚ùå {result['message']}")
                                else:
                                    st.error("‚ùå No active login session. Please restart login.")
                                    st.session_state.investopedia_auth_state = 'initial'
                                    st.rerun()
                        else:
                            st.warning("‚ö†Ô∏è Please enter a valid 6-digit code")
    
                with col2:
                    if st.button("üîô Start Over"):
                        # Cleanup and restart
                        if 'investopedia_integration' in st.session_state:
                            integration = st.session_state['investopedia_integration']
                            integration.cleanup()
                        st.session_state.investopedia_auth_state = 'initial'
                        st.rerun()
    
            # STAGE 3: Authenticated - Portfolio Sync
            elif st.session_state.investopedia_auth_state == 'authenticated':
                st.success("‚úÖ **Authenticated with Investopedia!**")
    
                col1, col2 = st.columns([3, 1])
                with col1:
                    st.markdown("You can now sync your portfolio from Investopedia Simulator")
                with col2:
                    if st.button("üîì Logout"):
                        # Cleanup and reset
                        if 'investopedia_integration' in st.session_state:
                            integration = st.session_state['investopedia_integration']
                            integration.cleanup()
                        st.session_state.investopedia_auth_state = 'initial'
                        st.session_state.pop('investopedia_integration', None)
                        st.rerun()
    
                st.markdown("---")
                st.markdown("#### üìä Portfolio Sync")
    
                if st.button("üîÑ Sync Portfolio from Investopedia", type="primary"):
                    with st.spinner("Fetching portfolio data..."):
                        integration = st.session_state.get('investopedia_integration')
    
                        if integration:
                            portfolio_df = integration.scrape_portfolio()
    
                            if portfolio_df is not None and not portfolio_df.empty:
                                st.success(f"‚úÖ Portfolio synced successfully! Found {len(portfolio_df)} positions")
                                make_scrollable_table(portfolio_df, height=600, hide_index=True, use_container_width=True)
    
                                # Save to session state for use in other ATLAS modules
                                st.session_state['portfolio_data'] = portfolio_df
                                st.info("üí° Portfolio saved! You can now use it in other ATLAS features")
    
                                # Reset auth state after successful sync
                                st.session_state.investopedia_auth_state = 'initial'
                                st.session_state.pop('investopedia_integration', None)
                            else:
                                st.warning("‚ö†Ô∏è No portfolio data found or portfolio is empty")
                                # Reset auth state
                                st.session_state.investopedia_auth_state = 'initial'
                                st.session_state.pop('investopedia_integration', None)
                        else:
                            st.error("‚ùå Authentication session lost. Please login again.")
                            st.session_state.investopedia_auth_state = 'initial'
                            st.rerun()
    
            # Info section
            st.markdown("---")
            st.markdown("#### ‚ÑπÔ∏è About Investopedia Integration")
            st.markdown("""
            **Features:**
            - üîê **Two-stage authentication** with proper 2FA flow
            - üìß Email-based 2FA code delivery
            - üìä Live portfolio data scraping
            - üîÑ Real-time sync with Investopedia Simulator
            - üîí Secure Selenium-based browser automation
    
            **How to use:**
            1. **Step 1:** Enter your email and password
            2. **Step 2:** Click "Attempt Login" - this will trigger Investopedia to send you a 2FA code
            3. **Step 3:** Check your email for the 6-digit code
            4. **Step 4:** Enter the code and click "Submit 2FA Code"
            5. **Step 5:** Once authenticated, click "Sync Portfolio" to fetch your positions
            6. Synced data is automatically available in other ATLAS modules
    
            **Fixed Issues:**
            - ‚úÖ No more Status 403 errors
            - ‚úÖ Honest authentication flow (actually logs in to Investopedia)
            - ‚úÖ Proper 2FA handling (email ‚Üí code ‚Üí submit)
            - ‚úÖ Clear step-by-step progress indicators
    
            **Note:** This feature uses Selenium to automate browser interactions with Investopedia.
            Your credentials are only used for authentication and are not stored.
            """)
    
        # ========================================================================
        # ABOUT
        # ========================================================================
        elif page == "‚ÑπÔ∏è About":
            st.markdown("### ‚ÑπÔ∏è ATLAS Terminal v9.7 ULTIMATE EDITION")
            st.success("""
            **ATLAS v9.7 ULTIMATE EDITION** üöÄüíé‚ú®
    
            **üìÖ RELEASE DATE: November 14, 2025**
            **üî• STATUS: Production Ready & Verified**
    
            **üöÄ NEW IN v9.7 (Latest Release):**
            ‚úÖ Enhanced Performance - Optimized data loading and caching
            ‚úÖ Advanced Risk Metrics - VaR, CVaR, Maximum Drawdown
            ‚úÖ Improved Error Handling - Graceful fallbacks for data fetching
            ‚úÖ Better Data Validation - Enhanced portfolio integrity checks
            ‚úÖ Version Display - Clear versioning throughout interface
            ‚úÖ Code Structure - Modular, maintainable, production-ready
            ‚úÖ Extended Market Coverage - Additional asset classes
    
            **PREVIOUS ENHANCEMENTS (v9.3-v9.6):**
            ‚úÖ Enhanced Home Page (Top Contributors/Detractors + Better Layout)
            ‚úÖ Market Watch COMPLETE REVAMP (Crypto, Bonds, Spreads, 100+ Assets)
            ‚úÖ ALL Charts Seamlessly Themed (No More Black Boxes!)
            ‚úÖ Portfolio Deep Dive Enhanced (Better Concentration Analysis)
            ‚úÖ Valuation House: Smart Assumptions Mode (AI-Generated)
            ‚úÖ Valuation House: Fixed D&A/CapEx Scaling with Revenue
            ‚úÖ Fixed Nov 2024 Columns in All Heatmaps
            ‚úÖ Multi-Factor Analysis (Perfect - No Changes Needed!)
    
            **COMPLETE MODULE LIST:**
            1. **Phoenix Parser** - Exceptional data parsing
            2. **Portfolio Home** - Enhanced dashboard with contributors/detractors
            3. **Market Watch** - Comprehensive: Indices, Crypto, Bonds, Spreads, ETFs, Stocks, Commodities
            4. **Risk Analysis** - World-class metrics & visualizations
            5. **Performance Suite** - Comprehensive analytics
            6. **Portfolio Deep Dive** - Enhanced concentration analysis
            7. **Multi-Factor Analysis** - Advanced attribution (kept perfect!)
            8. **Valuation House** - Smart Assumptions + Enhanced DCF
    
            **KEY FEATURES:**
            - ü§ñ Smart Assumptions for DCF valuations
            - üåç Expanded Market Watch (150+ assets)
            - üìä Seamless chart theming throughout
            - üéØ Enhanced Home Page dashboard
            - üíé Fixed D&A/CapEx scaling
            - üîí Production-ready error handling
            - ‚ö° Optimized performance
            - ‚ú® All original features preserved and enhanced
    
            **VERSION HISTORY:**
            - v9.7 (Nov 2025): Performance, risk metrics, error handling
            - v9.6 (Oct 2025): Valuation House integration
            - v9.5 (Sep 2025): Modular methods expansion
            - v9.4 (Sep 2025): Professional grade enhancements
            - v9.3 (Aug 2025): Excellence edition features
    
            Total: **The Ultimate Investment Analysis Platform - PRODUCTION READY!** üöÄüíé
            """)
    
            # SYSTEM NOTIFICATIONS DEMO
            # ============================================================
            st.divider()
            st.subheader("üß™ System Notifications Demo")
            st.caption("Test the toast notification system with different message types")
    
            col1, col2, col3, col4 = st.columns(4)
    
            with col1:
                if st.button("‚úì Success", use_container_width=True, key="demo_success"):
                    show_toast("Portfolio optimization completed successfully!", toast_type="success", duration=3000)
    
            with col2:
                if st.button("‚úï Error", use_container_width=True, key="demo_error"):
                    show_toast("Failed to connect to market data API", toast_type="error", duration=4000)
    
            with col3:
                if st.button("‚ö† Warning", use_container_width=True, key="demo_warning"):
                    show_toast("Portfolio VaR exceeds risk threshold", toast_type="warning", duration=4000)
    
            with col4:
                if st.button("‚Ñπ Info", use_container_width=True, key="demo_info"):
                    show_toast("Market data updated - last refresh: 14:23:45", toast_type="info", duration=3000)
    
            st.markdown("")  # Spacing
    
            # Sequential demo button
            if st.button("üé¨ Play All Notifications", use_container_width=True, key="demo_sequential"):
                show_toast("Starting system check...", toast_type="info", duration=2000)
                import time
                time.sleep(0.3)
                show_toast("‚úì Market data connection established", toast_type="success", duration=2000)
                time.sleep(0.3)
                show_toast("‚ö†Ô∏è High volatility detected in portfolio", toast_type="warning", duration=2000)
            time.sleep(0.3)
            show_toast("System check complete!", toast_type="success", duration=3000)

if __name__ == "__main__":
    main()
