#!/usr/bin/env python3
"""
ATLAS TERMINAL v10.0 INSTITUTIONAL EDITION
Complete Portfolio Analytics + Valuation House - Bloomberg Terminal Quality

üöÄ NEW IN v10.0 (Latest Release - November 16, 2025):
‚úÖ INSTITUTIONAL PERFORMANCE SUITE: 4-tab professional analysis system
   ‚Ä¢ Portfolio Performance: Enhanced metrics with rolling Sharpe, returns distribution
   ‚Ä¢ Individual Securities: Deep-dive analysis for each holding with technical indicators
   ‚Ä¢ Risk Decomposition: Position-level risk contribution analysis
   ‚Ä¢ Attribution & Benchmarking: Alpha generation and tracking error metrics
‚úÖ Professional Sector Allocation Charts: Clean, modern donut and bar visualizations
‚úÖ Portfolio Correlation Heatmap: Understand diversification with correlation matrix
‚úÖ Individual Security Analysis: Candlestick charts, Bollinger Bands, MA50/MA200
‚úÖ Risk Contribution Analysis: Marginal contribution to risk (MCR) for each position
‚úÖ Beta & Correlation Metrics: Market relationship analysis vs SPY
‚úÖ Enhanced Diversification Scoring: Automated correlation insights

üéØ v9.8 FEATURES (November 2025):
‚úÖ Brinson Attribution Analysis: Measure allocation vs selection skill
‚úÖ Portfolio Management Skill Scores: 0-10 ratings for sector timing and stock picking
‚úÖ Benchmark Sector Returns: Real-time sector ETF performance tracking
‚úÖ Table Dropdown Fix: Nuclear CSS override eliminates all UI glitches
‚úÖ Enhanced Data Tables: Clean, professional rendering across all pages

PREVIOUS ENHANCEMENTS (v9.3-v9.7):
‚úÖ Advanced Risk Metrics: VaR, CVaR, and Maximum Drawdown analysis
‚úÖ Home Page: Top Contributors/Detractors + Enhanced Dashboard
‚úÖ Market Watch: COMPLETE REVAMP (Crypto, Bonds, Spreads, Expanded Universe)
‚úÖ Chart Theming: ALL charts blend seamlessly with dark background
‚úÖ Portfolio Deep Dive: Enhanced visuals + Fixed Nov 2024 columns
‚úÖ Valuation House: Analyst-grade fixes (scaling D&A/CapEx, Smart Assumptions, Editable Projections)

RELEASE DATE: November 16, 2025
PRODUCTION STATUS: VERIFIED AND TESTED
VERSION: 10.0
"""

import pickle
import warnings
import re
import time
import io
import json
import random
import base64
from datetime import datetime, timedelta, date
from pathlib import Path
from collections import Counter, defaultdict
import numpy as np
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import streamlit as st

# PHASE 1 REFACTORING: Centralized configuration
from app.config import (
    COLORS, CHART_HEIGHT_COMPACT, CHART_HEIGHT_STANDARD,
    CHART_HEIGHT_LARGE, CHART_HEIGHT_DEEP_DIVE, CHART_THEME,
    CACHE_DIR, PORTFOLIO_CACHE, TRADE_HISTORY_CACHE,
    ACCOUNT_HISTORY_CACHE, RISK_FREE_RATE, MARKET_RETURN
)

# ============================================================================
# PHASE 2A: NAVIGATION SYSTEM (New modular architecture)
# ============================================================================
from navigation import PAGE_REGISTRY, get_page_by_key, route_to_page

# PHASE 1B: VERTICAL SIDEBAR NAVIGATION (Fomo-inspired)
from ui.components import render_sidebar_navigation

# PHASE 2A: ENHANCED COMPONENTS (Fomo-inspired)
from ui.components import (
    # Badges
    badge, render_badge, badge_group,
    # Enhanced Tables
    atlas_table, atlas_table_with_badges,
    # Chart Theme
    create_line_chart, create_performance_chart,
    ATLAS_TEMPLATE, ATLAS_COLORS
)

# ATLAS v12.0: Professional Blue Theme System
try:
    from ui.theme import (
        ATLAS_COLORS as PROFESSIONAL_COLORS,
        CHART_COLORS as PROFESSIONAL_CHART_COLORS,
        CHART_FILLS,
        FONTS,
        SPACING,
        CHART_LAYOUT,
        get_color,
        get_semantic_color,
        format_percentage as fmt_pct,
        format_currency as fmt_curr,
    )
    from ui.charts_professional import (
        apply_atlas_theme as apply_professional_theme,
        create_performance_chart as create_pro_performance_chart,
        create_bar_chart as create_pro_bar_chart,
        create_donut_chart as create_pro_donut_chart,
        create_gauge_chart as create_pro_gauge_chart,
    )
    PROFESSIONAL_THEME_AVAILABLE = True
    print("‚úÖ Professional Blue Theme System loaded")
except ImportError as e:
    PROFESSIONAL_THEME_AVAILABLE = False
    print(f"‚ö†Ô∏è Professional Theme not available: {e}")

# ============================================================================
# BROKER INTEGRATION SYSTEM (Alpaca, Easy Equities, Manual Entry)
# ============================================================================
try:
    from atlas_broker_manager import BrokerManager, ManualPortfolioAdapter
    from atlas_broker_manager import display_manual_portfolio_editor
    BROKER_MANAGER_AVAILABLE = True
    print("‚úÖ Broker Manager loaded (Alpaca, Easy Equities, Manual Entry)")
except ImportError as e:
    BROKER_MANAGER_AVAILABLE = False
    print(f"‚ö†Ô∏è Broker Manager not available: {e}")

# Auto-install streamlit_option_menu if missing
try:
    from streamlit_option_menu import option_menu
except ImportError:
    import subprocess
    import sys
    print("üì¶ Installing streamlit-option-menu...")
    subprocess.check_call([sys.executable, "-m", "pip", "install", "-q", "streamlit-option-menu>=0.3.6"])
    from streamlit_option_menu import option_menu
    print("‚úÖ streamlit-option-menu installed successfully!")

import yfinance as yf
from scipy import stats
from scipy.optimize import minimize
import networkx as nx
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA
from sklearn.linear_model import LinearRegression

# ATLAS v10.0 Advanced Modules
try:
    from valuation.atlas_dcf_engine import DCFValuation
    from risk_analytics.atlas_monte_carlo import MonteCarloSimulation
    from risk_analytics.atlas_risk_metrics import RiskAnalytics
    from portfolio_tools.atlas_phoenix_mode import PhoenixMode
    from analytics.atlas_performance_attribution import PerformanceAttribution
    from ui.atlas_enhanced_components import (
        create_allocation_chart,
        create_performance_chart,
        create_drawdown_chart,
        create_risk_return_scatter
    )
    V10_MODULES_AVAILABLE = True
except ImportError as e:
    V10_MODULES_AVAILABLE = False
    print(f"‚ö†Ô∏è v10.0 modules not available: {e}")

# ATLAS v11.0 SQL & R Integration
try:
    from data import get_db
    SQL_AVAILABLE = True
    print("‚úÖ SQL data layer loaded")
except ImportError as e:
    SQL_AVAILABLE = False
    print(f"‚ö†Ô∏è SQL layer not available: {e}")

# ATLAS v11.0 DCF Trap Detection System
try:
    from analytics.dcf_trap_detector import DCFTrapDetector, analyze_dcf_traps
    DCF_TRAP_DETECTION_AVAILABLE = True
    print("‚úÖ DCF Trap Detection System loaded")
except ImportError as e:
    DCF_TRAP_DETECTION_AVAILABLE = False
    print(f"‚ö†Ô∏è DCF Trap Detection not available: {e}")

# ATLAS v11.0 Model Inputs Dashboard
try:
    from analytics.model_inputs_ui import display_model_inputs_dashboard
    MODEL_INPUTS_DASHBOARD_AVAILABLE = True
    print("‚úÖ Model Inputs Dashboard loaded")
except ImportError as e:
    MODEL_INPUTS_DASHBOARD_AVAILABLE = False
    print(f"‚ö†Ô∏è Model Inputs Dashboard not available: {e}")

# ============================================================================
# INSTITUTIONAL-GRADE DCF ENHANCEMENTS (January 2026)
# ============================================================================
try:
    from atlas_dcf_institutional import (
        DCFAssumptionManager,
        DCFValidator,
        RobustDCFEngine,
        MonteCarloDCF,
        display_validation_warnings,
        display_monte_carlo_results
    )
    INSTITUTIONAL_DCF_AVAILABLE = True
    print("‚úÖ Institutional-Grade DCF Enhancements loaded")
except ImportError as e:
    INSTITUTIONAL_DCF_AVAILABLE = False
    print(f"‚ö†Ô∏è Institutional DCF not available: {e}")

# ATLAS v11.0 SBC Integration
try:
    from analytics.sbc_forecaster import (
        SBCForecaster,
        SBCForecastConfig,
        SBCForecastMethod,
        integrate_sbc_with_fcff,
        create_sbc_comparison_analysis
    )
    from analytics.sbc_ui import display_sbc_valuation_impact
    SBC_AVAILABLE = True
    print("‚úÖ SBC Integration loaded")
except ImportError as e:
    SBC_AVAILABLE = False
    print(f"‚ö†Ô∏è SBC Integration not available: {e}")

# ============================================================================
# PM-GRADE PORTFOLIO OPTIMIZATION (January 2026)
# ============================================================================
try:
    from atlas_pm_optimization import (
        PMGradeOptimizer,
        AsymmetricRiskOptimizer,
        MarketRegimeDetector,
        ForwardLookingReturns,
        display_regime_analysis,
        display_optimization_results
    )
    PM_OPTIMIZATION_AVAILABLE = True
    print("‚úÖ PM-Grade Optimization loaded")
except ImportError as e:
    PM_OPTIMIZATION_AVAILABLE = False
    print(f"‚ö†Ô∏è PM-Grade Optimization not available: {e}")

# ATLAS v11.0 Multi-Stage DCF
try:
    from analytics.multistage_ui import (
        display_model_selection,
        visualize_stage_transitions,
        display_multistage_results
    )
    from analytics.multistage_dcf import (
        MultiStageProjectionEngine,
        calculate_multistage_dcf
    )
    MULTISTAGE_DCF_AVAILABLE = True
    print("‚úÖ Multi-Stage DCF loaded")
except ImportError as e:
    MULTISTAGE_DCF_AVAILABLE = False
    print(f"‚ö†Ô∏è Multi-Stage DCF not available: {e}")

try:
    from r_analytics import get_r
    R_AVAILABLE = True
    print("‚úÖ R analytics layer loaded")
except ImportError as e:
    R_AVAILABLE = False
    print(f"‚ö†Ô∏è R analytics not available: {e}")

# ATLAS REFACTORING - Phase 1 Infrastructure (Week 1)
try:
    from atlas_terminal.core.cache_manager import cached, cache_manager
    from atlas_terminal.core.error_handler import safe_execute, ErrorHandler
    from atlas_terminal.data.fetchers.market_data import market_data
    REFACTORED_MODULES_AVAILABLE = True
    print("‚úÖ ATLAS Refactored Infrastructure loaded (Cache + Error + Data)")
except ImportError as e:
    REFACTORED_MODULES_AVAILABLE = False
    print(f"‚ö†Ô∏è Refactored modules not available: {e}")

warnings.filterwarnings("ignore")

# ============================================================================
# HELPER FUNCTIONS FOR VALIDATION
# ============================================================================
def is_valid_series(series):
    """Safely check if a pandas Series has valid data"""
    return series is not None and isinstance(series, pd.Series) and not series.empty

def is_valid_dataframe(df):
    """Safely check if a pandas DataFrame has valid data"""
    return df is not None and isinstance(df, pd.DataFrame) and not df.empty


def get_current_portfolio_metrics():
    """
    Extract current portfolio metrics from uploaded performance history.
    Returns dict with equity, gross_exposure, leverage, cash, etc.

    Data source: Performance history file Column F (Account Value)
    - Row 2 (most recent) = Current equity exposure

    Returns:
        dict with keys: equity, cash, stock_value, short_value, gross_exposure,
                       leverage, date, ytd_return, avg_leverage
        None if performance history not loaded
    """
    try:
        # Check if leverage tracker exists in session state
        if 'leverage_tracker' in st.session_state and st.session_state.leverage_tracker is not None:
            tracker = st.session_state.leverage_tracker
            stats = tracker.get_current_stats()

            if stats:
                return {
                    'equity': stats.get('current_equity', 0),
                    'gross_exposure': stats.get('current_gross_exposure', 0),
                    'leverage': stats.get('current_leverage', 1.0),
                    'ytd_return': stats.get('ytd_equity_return', 0),
                    'avg_leverage': stats.get('avg_leverage', 1.0),
                    'max_leverage': stats.get('max_leverage', 1.0),
                    'min_leverage': stats.get('min_leverage', 1.0),
                    'source': 'leverage_tracker'
                }

        # Fallback: Check if equity_capital was stored directly
        if 'equity_capital' in st.session_state and st.session_state.equity_capital:
            return {
                'equity': st.session_state.equity_capital,
                'gross_exposure': st.session_state.get('gross_exposure', st.session_state.equity_capital),
                'leverage': st.session_state.get('leverage', 1.0),
                'ytd_return': 0,
                'avg_leverage': 1.0,
                'source': 'session_state'
            }

        return None

    except Exception as e:
        print(f"Error getting portfolio metrics: {e}")
        return None


def get_portfolio_period_return(period='1y'):
    """
    Calculate actual time-weighted portfolio return from performance history.
    This is the ACTUAL return you achieved, not point-in-time holdings return.

    Parameters:
    -----------
    period : str
        Time period ('1y', '6mo', '3mo', '1mo', 'ytd', 'all')

    Returns:
    --------
    dict with: return (as decimal), start_value, end_value, start_date, end_date, days
    None if performance history not loaded
    """
    try:
        # Get leverage tracker from session state
        if 'leverage_tracker' not in st.session_state or st.session_state.leverage_tracker is None:
            print("DEBUG: leverage_tracker not in session_state")
            return None

        tracker = st.session_state.leverage_tracker
        df = tracker.leverage_history

        if df is None:
            print("DEBUG: leverage_history is None")
            return None

        if isinstance(df, pd.DataFrame) and df.empty:
            print("DEBUG: leverage_history is empty DataFrame")
            return None

        # Make a copy to avoid modifying original
        df = df.copy()

        # Get most recent value (end of period)
        end_row = df.iloc[-1]
        end_value = float(end_row['Net Equity'])
        end_date = pd.to_datetime(end_row['Date'])

        # Get earliest value (start of all data)
        earliest_row = df.iloc[0]
        earliest_date = pd.to_datetime(earliest_row['Date'])

        # Determine start date based on period
        period_lower = period.lower()
        if period_lower == 'all':
            # Use all available data
            start_date = earliest_date
        elif period_lower in ['1y', '1yr', '12m']:
            start_date = end_date - pd.DateOffset(years=1)
        elif period_lower in ['6m', '6mo']:
            start_date = end_date - pd.DateOffset(months=6)
        elif period_lower in ['3m', '3mo']:
            start_date = end_date - pd.DateOffset(months=3)
        elif period_lower in ['1m', '1mo']:
            start_date = end_date - pd.DateOffset(months=1)
        elif period_lower == 'ytd':
            start_date = pd.Timestamp(f'{end_date.year}-01-01')
        else:
            # Default to all available data
            start_date = earliest_date

        # If requested start is before earliest data, use earliest
        if start_date < earliest_date:
            start_date = earliest_date

        # Find closest date to start_date in historical data
        df['_date_diff'] = abs(pd.to_datetime(df['Date']) - start_date)
        start_idx = df['_date_diff'].idxmin()
        start_row = df.loc[start_idx]
        start_value = float(start_row['Net Equity'])
        actual_start_date = pd.to_datetime(start_row['Date'])

        # Calculate return
        if start_value > 0:
            portfolio_return = (end_value - start_value) / start_value
        else:
            portfolio_return = 0

        # Calculate ANNUALIZED return (this is what Performance Suite displays)
        days = (end_date - actual_start_date).days
        n_years = days / 365.0 if days > 0 else 1
        annualized_return = (1 + portfolio_return) ** (1/n_years) - 1 if n_years > 0 else portfolio_return
        days = (end_date - actual_start_date).days

        print(f"DEBUG: Portfolio return calculated: {portfolio_return*100:.2f}% over {days} days")
        print(f"DEBUG: Start: ${start_value:,.0f} ({actual_start_date}) ‚Üí End: ${end_value:,.0f} ({end_date})")

        return {
            'return': portfolio_return,  # As decimal (0.4093 = 40.93%)
            'return_pct': portfolio_return * 100,  # As percentage (total return)
            'annualized_return': annualized_return,  # As decimal
            'annualized_return_pct': annualized_return * 100,  # As percentage (annualized)
            'start_value': start_value,
            'end_value': end_value,
            'start_date': actual_start_date,
            'end_date': end_date,
            'days': days
        }

    except Exception as e:
        import traceback
        print(f"ERROR in get_portfolio_period_return: {e}")
        print(traceback.format_exc())
        return None


def get_benchmark_period_return(benchmark_ticker='SPY', period='1y', match_portfolio_dates=True):
    """
    Get benchmark return over same period as portfolio.

    Parameters:
    -----------
    benchmark_ticker : str
        Benchmark ticker (default 'SPY')
    period : str
        Time period
    match_portfolio_dates : bool
        If True, use exact same dates as portfolio performance history

    Returns:
    --------
    dict with: return (as decimal), start_price, end_price, start_date, end_date, ticker
    None if error
    """
    try:
        import yfinance as yf

        # Get portfolio dates to match exactly
        if match_portfolio_dates:
            portfolio_data = get_portfolio_period_return(period)

            if portfolio_data is not None:
                start_date = portfolio_data['start_date']
                end_date = portfolio_data['end_date']

                # ATLAS Refactoring: Check cache first (1 hour TTL for benchmark data)
                if REFACTORED_MODULES_AVAILABLE:
                    cache_key = cache_manager.get_cache_key('benchmark_return', benchmark_ticker, str(start_date), str(end_date))
                    cached_result = cache_manager.get(cache_key, ttl=3600)
                    if cached_result is not None:
                        return cached_result

                # Get benchmark data for exact same dates
                benchmark = yf.Ticker(benchmark_ticker)
                # Add buffer days to ensure we get data
                hist = benchmark.history(start=start_date - pd.Timedelta(days=5),
                                        end=end_date + pd.Timedelta(days=1))

                if hist.empty:
                    return None

                # Find closest dates to portfolio dates
                hist['_date_diff_start'] = abs(hist.index - start_date)
                hist['_date_diff_end'] = abs(hist.index - end_date)

                start_idx = hist['_date_diff_start'].idxmin()
                end_idx = hist['_date_diff_end'].idxmin()

                start_price = hist.loc[start_idx, 'Close']
                end_price = hist.loc[end_idx, 'Close']
                actual_start = start_idx
                actual_end = end_idx

                benchmark_return = (end_price - start_price) / start_price

                result = {
                    'return': benchmark_return,  # As decimal
                    'return_pct': benchmark_return * 100,  # As percentage
                    'start_price': start_price,
                    'end_price': end_price,
                    'start_date': actual_start,
                    'end_date': actual_end,
                    'ticker': benchmark_ticker
                }

                # Cache the result
                if REFACTORED_MODULES_AVAILABLE:
                    cache_manager.set(cache_key, result, persist=True)

                return result

        # Fallback to standard period - also cache this
        if REFACTORED_MODULES_AVAILABLE:
            cache_key = cache_manager.get_cache_key('benchmark_return_period', benchmark_ticker, period)
            cached_result = cache_manager.get(cache_key, ttl=3600)
            if cached_result is not None:
                return cached_result

        benchmark = yf.Ticker(benchmark_ticker)
        hist = benchmark.history(period=period)

        if hist.empty:
            return None

        start_price = hist['Close'].iloc[0]
        end_price = hist['Close'].iloc[-1]
        benchmark_return = (end_price - start_price) / start_price

        result = {
            'return': benchmark_return,
            'return_pct': benchmark_return * 100,
            'start_price': start_price,
            'end_price': end_price,
            'start_date': hist.index[0],
            'end_date': hist.index[-1],
            'ticker': benchmark_ticker
        }

        # Cache the result
        if REFACTORED_MODULES_AVAILABLE:
            cache_manager.set(cache_key, result, persist=True)

        return result

    except Exception as e:
        # ATLAS Refactoring: User-friendly error handling
        if REFACTORED_MODULES_AVAILABLE:
            ErrorHandler.handle_error(
                error=e,
                context=f"fetching benchmark returns for {benchmark_ticker}",
                fallback_value=None,
                show_traceback=False
            )
        return None

# Formatting utilities - imported from utils/formatting.py
from utils.formatting import format_currency, format_percentage, format_large_number, add_arrow_indicator


# ============================================================================
# GICS SECTOR CLASSIFICATION - Extracted to data/sectors.py (Phase 2)
# ============================================================================
from data.sectors import (
    GICS_SECTORS, GICS_SECTOR_MAPPING, STOCK_SECTOR_OVERRIDES, SPY_SECTOR_WEIGHTS
)



def get_gics_sector(ticker):
    """
    Get GICS Level 1 Sector classification for a ticker.
    Matches how SPY and other ETF benchmarks classify holdings.

    Priority:
    1. Check explicit overrides (most accurate)
    2. Check cache (fast, avoids API call)
    3. Fetch from yfinance and map to GICS
    4. Return 'Other' if unknown

    Returns:
        str: GICS Level 1 sector name
    """
    # Priority 1: Check overrides
    ticker_upper = ticker.upper().strip()
    if ticker_upper in STOCK_SECTOR_OVERRIDES:
        return STOCK_SECTOR_OVERRIDES[ticker_upper]

    # Priority 2: Check cache (6 hour TTL for sector data)
    if REFACTORED_MODULES_AVAILABLE:
        cache_key = cache_manager.get_cache_key('gics_sector', ticker_upper)
        cached_sector = cache_manager.get(cache_key, ttl=21600)  # 6 hours
        if cached_sector is not None:
            return cached_sector

    # Priority 3: Fetch from yfinance and standardize
    try:
        stock = yf.Ticker(ticker_upper)
        info = stock.info
        sector = info.get('sector', 'Other')

        # Map to standard GICS
        if sector in GICS_SECTORS:
            result = sector
        elif sector in GICS_SECTOR_MAPPING:
            result = GICS_SECTOR_MAPPING[sector]
        else:
            result = 'Other'

        # Cache the result
        if REFACTORED_MODULES_AVAILABLE:
            cache_manager.set(cache_key, result, persist=True)

        return result

    except Exception as e:
        # ATLAS Refactoring: User-friendly error handling
        if REFACTORED_MODULES_AVAILABLE:
            ErrorHandler.handle_error(
                error=e,
                context=f"classifying sector for {ticker_upper}",
                fallback_value='Other',
                show_traceback=False
            )
        return 'Other'


def get_portfolio_gics_sectors(portfolio_df):
    """
    Apply GICS sector classification to entire portfolio.

    Parameters:
        portfolio_df: DataFrame with 'Ticker' column

    Returns:
        DataFrame with 'GICS_Sector' column added
    """
    df = portfolio_df.copy()

    # Apply GICS classification to each ticker
    df['GICS_Sector'] = df['Ticker'].apply(get_gics_sector)

    return df


def get_spy_sector_weights():
    """
    Get current SPY sector weights.
    Returns dict with GICS Level 1 sectors and their weights (as percentages).
    """
    return SPY_SECTOR_WEIGHTS.copy()


def get_benchmark_sector_returns(benchmark_ticker='SPY', period='1y'):
    """
    Get sector returns from benchmark ETF.
    Uses sector ETFs as proxies for sector performance.

    Parameters:
        benchmark_ticker: Main benchmark (SPY)
        period: Time period for returns

    Returns:
        dict: {sector: return_percentage}
    """
    # ATLAS Refactoring: Check cache first (6 hour TTL for sector returns)
    if REFACTORED_MODULES_AVAILABLE:
        cache_key = cache_manager.get_cache_key('benchmark_sector_returns', benchmark_ticker, period)
        cached_result = cache_manager.get(cache_key, ttl=21600)  # 6 hours
        if cached_result is not None:
            return cached_result

    # Sector ETF proxies
    sector_etfs = {
        'Information Technology': 'XLK',
        'Financials': 'XLF',
        'Health Care': 'XLV',
        'Consumer Discretionary': 'XLY',
        'Communication Services': 'XLC',
        'Industrials': 'XLI',
        'Consumer Staples': 'XLP',
        'Energy': 'XLE',
        'Materials': 'XLB',
        'Real Estate': 'XLRE',
        'Utilities': 'XLU'
    }

    sector_returns = {}

    for sector, etf in sector_etfs.items():
        try:
            # Check individual ETF cache first
            if REFACTORED_MODULES_AVAILABLE:
                etf_cache_key = cache_manager.get_cache_key('sector_etf_return', etf, period)
                cached_etf = cache_manager.get(etf_cache_key, ttl=21600)
                if cached_etf is not None:
                    sector_returns[sector] = cached_etf
                    continue

            data = yf.Ticker(etf).history(period=period)
            if len(data) > 0:
                ret = (data['Close'].iloc[-1] / data['Close'].iloc[0] - 1) * 100
                sector_returns[sector] = ret
                # Cache individual ETF result
                if REFACTORED_MODULES_AVAILABLE:
                    cache_manager.set(etf_cache_key, ret, persist=True)
            else:
                sector_returns[sector] = 0
        except:
            sector_returns[sector] = 0

    # Cache the complete result
    if REFACTORED_MODULES_AVAILABLE:
        cache_manager.set(cache_key, sector_returns, persist=True)

    return sector_returns


def make_scrollable_table(df, height=600, hide_index=True, use_container_width=True, column_config=None):
    """
    Make any dataframe horizontally scrollable with professional styling.

    Args:
        df: DataFrame to display
        height: Table height in pixels (default 600)
        hide_index: Whether to hide the index column (default True)
        use_container_width: Whether to use full container width (default True)
        column_config: Optional column configuration dict

    Returns:
        Streamlit dataframe component with horizontal scrolling enabled
    """
    # Inject CSS for horizontal scrolling
    st.markdown(
        """
        <style>
        /* Enable horizontal scrolling for all dataframes */
        div[data-testid="stDataFrame"] > div {
            overflow-x: auto !important;
            max-width: 100% !important;
        }

        /* Ensure table doesn't collapse */
        div[data-testid="stDataFrame"] table {
            min-width: 100% !important;
        }

        /* Better scrollbar styling */
        div[data-testid="stDataFrame"] > div::-webkit-scrollbar {
            height: 8px;
        }

        div[data-testid="stDataFrame"] > div::-webkit-scrollbar-track {
            background: #0a1929;
        }

        div[data-testid="stDataFrame"] > div::-webkit-scrollbar-thumb {
            background: #00d4ff;
            border-radius: 4px;
        }

        div[data-testid="stDataFrame"] > div::-webkit-scrollbar-thumb:hover {
            background: #00ffcc;
        }
        </style>
        """,
        unsafe_allow_html=True
    )

    # Display the dataframe
    return st.dataframe(
        df,
        use_container_width=use_container_width,
        hide_index=hide_index,
        height=height,
        column_config=column_config
    )

@st.cache_data(ttl=300)
def search_yahoo_finance(query):
    """
    Search Yahoo Finance for any ticker/company with live data lookup.

    Args:
        query: Search query (ticker symbol or company name)

    Returns:
        List of matching securities with metadata, or None if not found
    """
    if not query or len(query) < 1:
        return None

    try:
        # ATLAS Refactoring - Use cached market data fetcher
        # Try direct ticker lookup first
        if REFACTORED_MODULES_AVAILABLE:
            info = market_data.get_company_info(query.upper())
        else:
            # Fallback to old method
            ticker = yf.Ticker(query.upper())
            info = ticker.info

        if info and info.get('symbol'):
            return [{
                'symbol': info.get('symbol', query.upper()),
                'name': info.get('longName', info.get('shortName', query)),
                'type': info.get('quoteType', 'Unknown'),
                'exchange': info.get('exchange', 'N/A'),
                'currency': info.get('currency', 'USD'),
                'market_cap': info.get('marketCap', 0),
                'sector': info.get('sector', 'N/A'),
                'industry': info.get('industry', 'N/A')
            }]
        else:
            return None
    except Exception as e:
        return None

def init_watchlist():
    """Initialize personal watchlist in session state"""
    if 'personal_watchlist' not in st.session_state:
        st.session_state['personal_watchlist'] = []
        # Try loading from file
        try:
            import json
            from pathlib import Path
            watchlist_file = Path('.atlas_watchlist.json')
            if watchlist_file.exists():
                with open(watchlist_file, 'r') as f:
                    st.session_state['personal_watchlist'] = json.load(f)
        except:
            pass

def add_to_watchlist(ticker, name, asset_type='Stock'):
    """
    Add a ticker to personal watchlist.

    Args:
        ticker: Ticker symbol
        name: Asset name
        asset_type: Type of asset (Stock, ETF, Crypto, etc.)

    Returns:
        True if added, False if already exists
    """
    init_watchlist()

    # Check if already in watchlist
    if any(item['ticker'] == ticker for item in st.session_state['personal_watchlist']):
        return False

    # Add to watchlist
    st.session_state['personal_watchlist'].append({
        'ticker': ticker,
        'name': name,
        'type': asset_type,
        'added_date': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
    })

    # Save to file
    save_watchlist()
    return True

def remove_from_watchlist(ticker):
    """Remove a ticker from personal watchlist"""
    init_watchlist()
    st.session_state['personal_watchlist'] = [
        item for item in st.session_state['personal_watchlist']
        if item['ticker'] != ticker
    ]
    save_watchlist()

def save_watchlist():
    """Save watchlist to file"""
    try:
        import json
        with open('.atlas_watchlist.json', 'w') as f:
            json.dump(st.session_state['personal_watchlist'], f, indent=2)
    except:
        pass

def get_watchlist():
    """Get current watchlist"""
    init_watchlist()
    return st.session_state['personal_watchlist']

@st.cache_data(ttl=1800)
def fetch_us_treasury_yields_fred():
    """
    Fetch US Treasury yields from FRED API (Federal Reserve Economic Data).

    Returns:
        tuple: (maturities, yields, data_source) where data_source indicates FRED, Yahoo, or Fallback
    """
    # FRED series IDs for various Treasury maturities
    fred_series = {
        "DGS1MO": 1/12,      # 1-month
        "DGS3MO": 0.25,      # 3-month
        "DGS6MO": 0.5,       # 6-month
        "DGS1": 1,           # 1-year
        "DGS2": 2,           # 2-year
        "DGS3": 3,           # 3-year
        "DGS5": 5,           # 5-year
        "DGS7": 7,           # 7-year
        "DGS10": 10,         # 10-year
        "DGS20": 20,         # 20-year
        "DGS30": 30          # 30-year
    }

    # Try FRED API first
    try:
        import requests

        # Check if FRED API key is available (from secrets or environment)
        try:
            FRED_API_KEY = st.secrets.get("FRED_API_KEY", None)
        except:
            FRED_API_KEY = None

        if FRED_API_KEY and FRED_API_KEY != "YOUR_API_KEY_HERE":
            maturities = []
            yields = []

            for series_id, maturity in fred_series.items():
                try:
                    url = f"https://api.stlouisfed.org/fred/series/observations"
                    params = {
                        "series_id": series_id,
                        "api_key": FRED_API_KEY,
                        "file_type": "json",
                        "sort_order": "desc",
                        "limit": 1
                    }

                    response = requests.get(url, params=params, timeout=5)

                    if response.status_code == 200:
                        data = response.json()
                        if data.get('observations'):
                            latest = data['observations'][0]
                            yield_value = float(latest['value'])
                            maturities.append(maturity)
                            yields.append(yield_value)
                except:
                    continue

            # If we got good FRED data, return it
            if len(yields) >= 5:
                # Sort by maturity
                sorted_data = sorted(zip(maturities, yields))
                maturities, yields = zip(*sorted_data)
                return list(maturities), list(yields), "FRED API"
    except:
        pass

    # Fallback to Yahoo Finance
    treasuries = {
        "^IRX": 0.25,   # 3-month
        "^FVX": 5,      # 5-year
        "^TNX": 10,     # 10-year
        "^TYX": 30      # 30-year
    }

    maturities = []
    yields = []

    for ticker, maturity in treasuries.items():
        try:
            stock = yf.Ticker(ticker)
            hist = stock.history(period="1d")
            if not hist.empty:
                current_yield = hist['Close'].iloc[-1]
                maturities.append(maturity)
                yields.append(current_yield)
        except:
            continue

    # If Yahoo data worked, return it
    if len(yields) >= 3:
        sorted_data = sorted(zip(maturities, yields))
        maturities, yields = zip(*sorted_data)
        return list(maturities), list(yields), "Yahoo Finance"

    # Final fallback to sample data
    maturities = [0.25, 0.5, 1, 2, 3, 5, 7, 10, 20, 30]
    yields = [4.5, 4.4, 4.3, 4.2, 4.1, 4.0, 4.05, 4.1, 4.3, 4.4]
    return maturities, yields, "Fallback Data"

# ============================================================================
# PAGE CONFIG
# ============================================================================
st.set_page_config(
    page_title="ATLAS Terminal v10.0 INSTITUTIONAL",
    page_icon="üöÄ",
    layout="wide",
    initial_sidebar_state="expanded"  # Phase 1B: Show vertical sidebar
)

# ============================================================================
# CSS/JS STYLING - Extracted to ui/atlas_css.py (Phase 1 Refactoring)
# ============================================================================
from ui.atlas_css import init_atlas_css
init_atlas_css()

# ============================================================================
# CHART THEME FUNCTION & COLORSCALES
# ============================================================================

def apply_chart_theme(fig):
    """Apply dark theme with neon cyan accents to any Plotly figure

    IMPORTANT: This function is called on ALL charts to ensure:
    - Dark background (#1a1d29)
    - White text for all labels
    - Subtle grid lines
    - Proper contrast on dark pages
    """
    fig.update_layout(
        paper_bgcolor='#1a1d29',
        plot_bgcolor='#1a1d29',
        font=dict(color='#FFFFFF', family='Inter, sans-serif'),
        title=dict(font=dict(color='#FFFFFF')),
        xaxis=dict(
            gridcolor='rgba(255, 255, 255, 0.1)',
            linecolor='rgba(255, 255, 255, 0.2)',
            zerolinecolor='rgba(255, 255, 255, 0.1)',
            tickfont=dict(color='#FFFFFF'),
            title=dict(font=dict(color='#FFFFFF')),
        ),
        yaxis=dict(
            gridcolor='rgba(255, 255, 255, 0.1)',
            linecolor='rgba(255, 255, 255, 0.2)',
            zerolinecolor='rgba(255, 255, 255, 0.1)',
            tickfont=dict(color='#FFFFFF'),
            title=dict(font=dict(color='#FFFFFF')),
        ),
        hoverlabel=dict(
            bgcolor='#1a1d29',
            font=dict(color='#FFFFFF'),
            bordercolor='#00BCD4',
        ),
        legend=dict(
            font=dict(color='#FFFFFF'),
            bgcolor='rgba(26, 29, 41, 0.8)',
            bordercolor='rgba(0, 188, 212, 0.3)',
        ),
    )
    return fig

COLORSCALES = {
    "viridis": px.colors.sequential.Viridis,
    "plasma": px.colors.sequential.Plasma,
    "turbo": px.colors.sequential.Turbo,
    "rdylgn": px.colors.diverging.RdYlGn,
    "spectral": px.colors.diverging.Spectral,
}


# ============================================================================
# CONSTANTS & CONFIG - Now imported from app.config
# ============================================================================

# ============================================================================
# MARKET DATA DICTIONARIES - Extracted to data/instruments.py (Phase 2)
# ============================================================================
from data.instruments import (
    GLOBAL_INDICES, CRYPTOCURRENCIES, FX_PAIRS, BOND_YIELDS,
    CREDIT_SPREADS, COMMODITIES, POPULAR_STOCKS, POPULAR_ETFS,
    FACTOR_DEFINITIONS, ETF_SECTORS
)


# ============================================================================
# HELPER FUNCTIONS - format_currency, format_percentage, format_large_number,
# add_arrow_indicator now imported from utils/formatting.py
# ============================================================================

def show_toast(message, toast_type="info", duration=3000):
    """Display a professional toast notification"""
    toast_styles = {
        "success": {"bg": "rgba(0, 255, 136, 0.95)", "border": "#00ff88", "icon": "‚úì"},
        "error": {"bg": "rgba(255, 0, 68, 0.95)", "border": "#ff0044", "icon": "‚úï"},
        "warning": {"bg": "rgba(255, 170, 0, 0.95)", "border": "#ffaa00", "icon": "‚ö†"},
        "info": {"bg": "rgba(0, 212, 255, 0.95)", "border": "#00d4ff", "icon": "‚Ñπ"}
    }
    style = toast_styles.get(toast_type, toast_styles["info"])
    toast_id = f"toast_{int(time.time() * 1000)}_{random.randint(1000, 9999)}"

    toast_html = f"""
    <style>
        .atlas-toast-container {{ position: fixed; top: 80px; right: 20px; z-index: 999999; }}
        .atlas-toast {{ min-width: 300px; max-width: 500px; margin-bottom: 12px; padding: 16px 20px;
                       background: {style['bg']}; border: 2px solid {style['border']}; border-radius: 12px;
                       color: #000; font-family: 'Inter', sans-serif; font-size: 14px; font-weight: 600;
                       animation: slideIn 0.4s ease-out, fadeOut 0.3s ease-in {duration-300}ms forwards; }}
        .atlas-toast-content {{ display: flex; align-items: center; gap: 12px; }}
        .atlas-toast-icon {{ font-size: 20px; }}
        @keyframes slideIn {{ from {{ transform: translateX(400px); opacity: 0; }}
                             to {{ transform: translateX(0); opacity: 1; }} }}
        @keyframes fadeOut {{ to {{ opacity: 0; transform: translateX(100px); }} }}
    </style>
    <div id="{toast_id}" class="atlas-toast">
        <div class="atlas-toast-content">
            <div class="atlas-toast-icon">{style['icon']}</div>
            <div>{message}</div>
        </div>
    </div>
    <script>
        (function() {{
            let container = document.querySelector('.atlas-toast-container');
            if (!container) {{
                container = document.createElement('div');
                container.className = 'atlas-toast-container';
                document.body.appendChild(container);
            }}
            const toast = document.getElementById('{toast_id}');
            if (toast) {{
                container.appendChild(toast);
                setTimeout(() => toast.remove(), {duration});
            }}
        }})();
    </script>
    """
    st.markdown(toast_html, unsafe_allow_html=True)


def display_trap_warnings(trap_summary: dict, ticker: str):
    """
    Display DCF trap detection warnings in user-friendly format

    Args:
        trap_summary: Summary dictionary from DCFTrapDetector.get_summary()
        ticker: Stock ticker symbol
    """
    if not trap_summary or trap_summary.get('total_warnings', 0) == 0:
        # No warnings - display success message
        st.success("""
        ‚úÖ **No Value Trap Patterns Detected**

        The DCF valuation appears sound with no significant red flags. Assumptions look reasonable given the company's risk profile.
        """)
        return

    # Display warnings section
    st.markdown("---")
    st.markdown("### üö® DCF Trap Detection Analysis")

    # Overall summary
    max_severity = trap_summary.get('max_severity', 'LOW')
    overall_confidence = trap_summary.get('overall_confidence', 0)
    total_warnings = trap_summary.get('total_warnings', 0)

    # Severity color coding
    severity_colors = {
        'CRITICAL': 'üî¥',
        'HIGH': 'üü†',
        'MEDIUM': 'üü°',
        'LOW': 'üü¢'
    }

    severity_icon = severity_colors.get(max_severity, 'üü¢')

    # Display summary card
    col1, col2, col3 = st.columns(3)

    with col1:
        st.metric(
            "Overall Risk Level",
            f"{severity_icon} {max_severity}",
            delta=f"{total_warnings} warning(s)"
        )

    with col2:
        st.metric(
            "Detection Confidence",
            f"{overall_confidence*100:.0f}%"
        )

    with col3:
        severity_counts = trap_summary.get('severity_counts', {})
        critical_high = severity_counts.get('CRITICAL', 0) + severity_counts.get('HIGH', 0)
        status = "‚ö†Ô∏è Review Required" if critical_high > 0 else "‚úÖ Monitor"
        st.metric("Action Required", status)

    # Overall recommendation
    recommendation = trap_summary.get('recommendation', '')

    if max_severity == 'CRITICAL':
        st.error(f"""
        **üö® CRITICAL ISSUES DETECTED**

        {recommendation}
        """)
    elif max_severity == 'HIGH':
        st.warning(f"""
        **‚ö†Ô∏è HIGH RISK PATTERNS DETECTED**

        {recommendation}
        """)
    elif max_severity == 'MEDIUM':
        st.warning(f"""
        **‚ö†Ô∏è MODERATE RISK DETECTED**

        {recommendation}
        """)
    else:
        st.info(f"""
        **‚ÑπÔ∏è MINOR CONCERNS DETECTED**

        {recommendation}
        """)

    # Display individual warnings
    st.markdown("#### üìã Detailed Warning Breakdown")

    warnings_list = trap_summary.get('warnings', [])

    for idx, warning in enumerate(warnings_list, 1):
        trap_type = warning.get('trap_type', 'UNKNOWN')
        severity = warning.get('severity', 'LOW')
        confidence = warning.get('confidence', 0)
        title = warning.get('title', 'Warning')
        description = warning.get('description', '')
        recommendation = warning.get('recommendation', '')
        metrics = warning.get('metrics', {})

        # Icon based on severity
        severity_icon = severity_colors.get(severity, 'üü¢')

        # Create expander for each warning
        with st.expander(f"{severity_icon} **{title}** (Confidence: {confidence*100:.0f}%)", expanded=(severity in ['CRITICAL', 'HIGH'])):
            st.markdown(f"**Severity:** {severity_icon} {severity}")
            st.markdown(f"**Confidence:** {confidence*100:.0f}%")

            st.markdown("---")
            st.markdown("**Description:**")
            st.markdown(description)

            # Display relevant metrics
            if metrics:
                st.markdown("---")
                st.markdown("**Key Metrics:**")

                # Format metrics nicely
                metrics_cols = st.columns(min(3, len(metrics)))

                metric_items = list(metrics.items())
                for i, (key, value) in enumerate(metric_items[:6]):  # Show max 6 metrics
                    col_idx = i % 3

                    # Format value based on type
                    if isinstance(value, float):
                        if 'percent' in key.lower() or 'growth' in key.lower() or 'margin' in key.lower():
                            formatted_value = f"{value*100:.1f}%"
                        elif value > 1000:
                            formatted_value = f"${value:,.0f}"
                        else:
                            formatted_value = f"{value:.2f}"
                    elif isinstance(value, dict) or isinstance(value, list):
                        formatted_value = str(value)[:50] + "..." if len(str(value)) > 50 else str(value)
                    else:
                        formatted_value = str(value)

                    # Format key (make it readable)
                    readable_key = key.replace('_', ' ').title()

                    with metrics_cols[col_idx]:
                        st.metric(readable_key, formatted_value)

            st.markdown("---")
            st.markdown("**Recommendation:**")
            st.info(recommendation)

    # Add actionable next steps
    st.markdown("---")
    st.markdown("#### üéØ Recommended Actions")

    if max_severity in ['CRITICAL', 'HIGH']:
        st.markdown("""
        1. **Re-examine DCF assumptions** - Focus on flagged parameters
        2. **Run sensitivity analysis** - Test impact of adjusting problematic assumptions
        3. **Consider alternative valuation** - Use relative valuation or sum-of-parts
        4. **Seek additional validation** - Review with peers or use external benchmarks
        5. **Apply discount to valuation** - Haircut DCF result by 15-30% for safety margin
        """)
    elif max_severity == 'MEDIUM':
        st.markdown("""
        1. **Review flagged assumptions** - Verify they reflect economic reality
        2. **Run stress tests** - Model downside scenarios
        3. **Cross-check with peers** - Compare assumptions to industry benchmarks
        4. **Monitor catalysts** - Track whether assumed improvements materialize
        """)
    else:
        st.markdown("""
        1. **Monitor flagged metrics** - Keep eye on mentioned concerns
        2. **Validate with sensitivity analysis** - Test robustness of valuation
        3. **Proceed with normal diligence** - Valuation appears reasonable
        """)


# ============================================================================
# PROFESSIONAL ENHANCEMENTS - ATLAS v9.4 EXCELLENCE EDITION
# ============================================================================

# Enhanced Formatting Standards with Strict Rules
class ATLASFormatter:
    """
    Centralized professional formatting with strict standards:
    - Prices: $ with 2 decimals
    - Yields/Returns: % with 2 decimals
    - Ratios: 1 decimal, no units
    - Missing data: "‚Äì"
    - Color rules: Green positive, Red negative, Grey zero
    """

    @staticmethod
    def format_price(value, decimals=2):
        """Prices: Always $ with exactly 2 decimals"""
        if pd.isna(value) or value is None:
            return "‚Äì"
        return f"${value:,.{decimals}f}"

    @staticmethod
    def format_yield(value, decimals=2):
        """Yields/Returns: Always % with exactly 2 decimals"""
        if pd.isna(value) or value is None:
            return "‚Äì"
        return f"{value:.{decimals}f}%"

    @staticmethod
    def format_ratio(value, decimals=1):
        """Ratios: 1 decimal place, no units"""
        if pd.isna(value) or value is None:
            return "‚Äì"
        return f"{value:.{decimals}f}"

    @staticmethod
    def get_color(value):
        """Color rules: Green positive, Red negative, Grey zero"""
        if pd.isna(value) or value is None:
            return COLORS['text_muted']
        if value > 0:
            return COLORS['success']
        elif value < 0:
            return COLORS['danger']
        return COLORS['text_muted']

    @staticmethod
    def format_timestamp(dt=None):
        """Data freshness indicator with precise timestamp"""
        if dt is None:
            dt = datetime.now()
        return dt.strftime("%Y-%m-%d %H:%M:%S")

    @staticmethod
    def get_freshness_badge(minutes_ago):
        """Visual freshness indicator based on age"""
        if minutes_ago < 5:
            return f"üü¢ Live ({minutes_ago}m ago)"
        elif minutes_ago < 30:
            return f"üü° Recent ({minutes_ago}m ago)"
        else:
            return f"üî¥ Stale ({minutes_ago}m ago)"

# Valuation Scenario System
VALUATION_SCENARIOS = {
    'BEAR': {
        'name': 'üêª Bear Case',
        'revenue_growth': -0.05,
        'terminal_growth': 0.015,
        'risk_premium': 0.08,
        'capex_pct': 0.07,
        'description': 'Conservative: Negative growth, higher risk premium, elevated capex'
    },
    'BASE': {
        'name': 'üìä Base Case',
        'revenue_growth': 0.05,
        'terminal_growth': 0.025,
        'risk_premium': 0.06,
        'capex_pct': 0.05,
        'description': 'Realistic: Moderate growth assumptions, normal operating conditions'
    },
    'BULL': {
        'name': 'üöÄ Bull Case',
        'revenue_growth': 0.15,
        'terminal_growth': 0.035,
        'risk_premium': 0.05,
        'capex_pct': 0.04,
        'description': 'Optimistic: High growth, lower risk premium, efficient capex'
    }
}

def create_risk_snapshot(df, portfolio_returns):
    """
    Professional Risk Snapshot Dashboard Widget
    Displays: Portfolio Beta, Volatility, Max Drawdown, Top 3 Exposures
    """
    # Calculate aggregate portfolio beta
    weighted_beta = (df['Beta'].fillna(1.0) * df['Weight %'] / 100).sum()

    # Calculate annualized volatility
    vol = portfolio_returns.std() * np.sqrt(252) * 100 if is_valid_series(portfolio_returns) else 0

    # Calculate max drawdown
    if is_valid_series(portfolio_returns) and len(portfolio_returns) > 0:
        cumulative = (1 + portfolio_returns).cumprod()
        running_max = cumulative.expanding().max()
        drawdown = ((cumulative - running_max) / running_max * 100).min()
    else:
        drawdown = 0

    # Top 3 exposures by weight
    top_3 = df.nlargest(3, 'Weight %')[['Ticker', 'Weight %']]

    # Create compact, professional HTML widget
    snapshot_html = f"""
    <div style='background: linear-gradient(135deg, {COLORS['card_background']} 0%, {COLORS['card_background_alt']} 100%);
                border: 2px solid {COLORS['neon_blue']}; border-radius: 12px; padding: 20px; margin: 10px 0;
                box-shadow: 0 0 30px {COLORS['shadow']};'>
        <h3 style='color: {COLORS['neon_blue']}; margin: 0 0 15px 0; font-size: 18px;'>‚ö° Risk Snapshot</h3>
        <div style='display: grid; grid-template-columns: repeat(4, 1fr); gap: 15px;'>
            <div>
                <div style='color: {COLORS['text_muted']}; font-size: 11px; text-transform: uppercase;'>Portfolio Beta</div>
                <div style='color: {COLORS['text_primary']}; font-size: 24px; font-weight: 600;'>{ATLASFormatter.format_ratio(weighted_beta)}</div>
            </div>
            <div>
                <div style='color: {COLORS['text_muted']}; font-size: 11px; text-transform: uppercase;'>Volatility (Ann.)</div>
                <div style='color: {COLORS['warning']}; font-size: 24px; font-weight: 600;'>{ATLASFormatter.format_yield(vol)}</div>
            </div>
            <div>
                <div style='color: {COLORS['text_muted']}; font-size: 11px; text-transform: uppercase;'>Max Drawdown</div>
                <div style='color: {COLORS['danger']}; font-size: 24px; font-weight: 600;'>{ATLASFormatter.format_yield(drawdown)}</div>
            </div>
            <div>
                <div style='color: {COLORS['text_muted']}; font-size: 11px; text-transform: uppercase;'>Top Exposures</div>
                <div style='color: {COLORS['text_primary']}; font-size: 13px; line-height: 1.6; margin-top: 5px;'>
                    {'<br>'.join([f"‚Ä¢ {row['Ticker']} ({row['Weight %']:.1f}%)" for _, row in top_3.iterrows()])}
                </div>
            </div>
        </div>
    </div>
    """
    return snapshot_html

def calculate_signal_health(metrics):
    """
    Calculate overall portfolio health score with traffic light system
    Returns: (status, percentage, label)
    GREEN: 80%+, YELLOW: 50-79%, RED: <50%
    """
    score = 0
    max_score = 5

    # Check 1: Positive returns
    if metrics.get('Total Return', 0) > 0:
        score += 1

    # Check 2: Sharpe > 1.0 (good risk-adjusted returns)
    if metrics.get('Sharpe Ratio', 0) > 1.0:
        score += 1

    # Check 3: Drawdown > -20% (manageable losses)
    if metrics.get('Max Drawdown', -100) > -20:
        score += 1

    # Check 4: Win rate > 55% (more winning days)
    if metrics.get('Win Rate', 0) > 55:
        score += 1

    # Check 5: Volatility < 25% (controlled risk)
    if metrics.get('Annualized Volatility', 100) < 25:
        score += 1

    percentage = (score / max_score) * 100

    if percentage >= 80:
        status = 'GREEN'
        emoji = 'üü¢'
        label = 'HEALTHY'
    elif percentage >= 50:
        status = 'YELLOW'
        emoji = 'üü°'
        label = 'CAUTION'
    else:
        status = 'RED'
        emoji = 'üî¥'
        label = 'AT RISK'

    return status, percentage, f"{emoji} {label}"

def create_signal_health_badge(metrics):
    """Create visual health indicator badge for portfolio"""
    status, percentage, label = calculate_signal_health(metrics)

    color_map = {
        'GREEN': COLORS['success'],
        'YELLOW': COLORS['warning'],
        'RED': COLORS['danger']
    }

    badge_html = f"""
    <div style='display: inline-block; background: {color_map[status]}; color: #ffffff; padding: 10px 20px; border-radius: 20px; font-weight: 700; font-size: 15px; margin: 10px 0; box-shadow: 0 4px 12px rgba(0,0,0,0.3);'>
        {label} ({percentage:.0f}%)
    </div>
    """
    return badge_html

def create_pnl_attribution_sector(df):
    """v9.7 ENHANCED: P&L Attribution by Sector - Now showing % contribution"""
    # Calculate sector P&L in dollars
    sector_pnl_dollars = df.groupby('Sector')['Total Gain/Loss $'].sum()

    # v9.7 FIX: Convert to percentage contribution of total portfolio P&L
    total_pnl = sector_pnl_dollars.sum()
    if total_pnl != 0:
        sector_pnl_pct = (sector_pnl_dollars / abs(total_pnl)) * 100
    else:
        sector_pnl_pct = sector_pnl_dollars * 0  # All zeros if no P&L

    sector_pnl_pct = sector_pnl_pct.sort_values(ascending=False)

    fig = go.Figure(go.Waterfall(
        name="Sector P&L %",
        orientation="v",
        x=sector_pnl_pct.index,
        y=sector_pnl_pct.values,
        connector={"line": {"color": COLORS['neon_blue'], "width": 2}},
        decreasing={"marker": {"color": COLORS['danger']}},
        increasing={"marker": {"color": COLORS['success']}},
        textposition="outside",
        text=[f"{v:+.1f}%" for v in sector_pnl_pct.values],
        textfont=dict(size=12, color=COLORS['text_primary'])
    ))

    fig.update_layout(
        title="üíº P&L Attribution by Sector (%)",
        yaxis_title="P&L Contribution (%)",
        xaxis_title="",
        height=CHART_HEIGHT_STANDARD,  # P1-4: Standardized height
        showlegend=False
    )

    apply_chart_theme(fig)
    return fig

def create_pnl_attribution_position(df, top_n=10):
    """v9.7 ENHANCED: P&L Attribution by Position - Now showing % returns"""
    # v9.7 FIX: Use Total Gain/Loss % instead of dollars
    top_contributors = df.nlargest(top_n // 2, 'Total Gain/Loss %')
    top_detractors = df.nsmallest(top_n // 2, 'Total Gain/Loss %')
    combined = pd.concat([top_contributors, top_detractors]).sort_values('Total Gain/Loss %')

    colors = [COLORS['success'] if x > 0 else COLORS['danger'] for x in combined['Total Gain/Loss %']]

    # Create labels with ticker and percentage
    labels = [f"{ticker}" for ticker in combined['Ticker']]

    fig = go.Figure(go.Bar(
        x=combined['Total Gain/Loss %'],
        y=labels,
        orientation='h',
        marker=dict(
            color=colors,
            line=dict(color=COLORS['border'], width=2),
            opacity=0.9
        ),
        text=[f"{v:+.1f}%" for v in combined['Total Gain/Loss %']],
        textposition='outside',
        textfont=dict(size=11, color=COLORS['text_primary']),
        hovertemplate='<b>%{y}</b><br>Return: %{x:.2f}%<extra></extra>'
    ))

    fig.update_layout(
        title=f"üéØ Top {top_n} P&L Contributors & Detractors (%)",
        xaxis_title="Return (%)",
        yaxis_title="",
        height=CHART_HEIGHT_STANDARD,  # P1-4: Standardized height
        showlegend=False,
        xaxis=dict(zeroline=True, zerolinewidth=2, zerolinecolor=COLORS['text_muted'])
    )

    apply_chart_theme(fig)
    return fig

def create_sparkline(ticker, days=30):
    """Generate mini sparkline chart for ticker (last 30 days)"""
    # ATLAS Refactoring - Use cached market data fetcher
    try:
        if REFACTORED_MODULES_AVAILABLE:
            # Map days to period string
            period_map = {30: "1mo", 90: "3mo", 7: "5d", 5: "5d"}
            period = period_map.get(days, f"{days}d")
            hist = market_data.get_stock_history(ticker, period=period, interval="1d")
        else:
            # Fallback to old method
            stock = yf.Ticker(ticker)
            hist = stock.history(period=f"{days}d")

        if hist.empty:
            return None

        # Convert timezone-aware index to timezone-naive
        if hist.index.tz is not None:
            hist.index = hist.index.tz_localize(None)

        prices = hist['Close'].values

        # Determine color based on overall trend
        color = COLORS['success'] if prices[-1] > prices[0] else COLORS['danger']

        fig = go.Figure()
        fig.add_trace(go.Scatter(
            y=prices,
            mode='lines',
            line=dict(color=color, width=1.5),
            fill='tozeroy',
            fillcolor=f"rgba{tuple(list(int(color.lstrip('#')[i:i+2], 16) for i in (0, 2, 4)) + [0.2])}",
            showlegend=False
        ))

        fig.update_layout(
            height=60,
            width=150,
            margin=dict(l=0, r=0, t=0, b=0),
            xaxis=dict(visible=False),
            yaxis=dict(visible=False),
            paper_bgcolor='rgba(0,0,0,0)',
            plot_bgcolor='rgba(0,0,0,0)',
            hovermode=False
        )

        return fig
    except:
        return None

def calculate_forward_rates(maturities, spot_rates):
    """Calculate forward rates from spot rates"""
    forward_rates = []
    forward_maturities = []

    for i in range(len(maturities) - 1):
        t1 = maturities[i]
        t2 = maturities[i + 1]
        s1 = spot_rates[i] / 100  # Convert to decimal
        s2 = spot_rates[i + 1] / 100

        # Forward rate formula: f(t1,t2) = [(1 + s2)^t2 / (1 + s1)^t1]^(1/(t2-t1)) - 1
        forward_rate = (((1 + s2) ** t2) / ((1 + s1) ** t1)) ** (1 / (t2 - t1)) - 1
        forward_rates.append(forward_rate * 100)  # Convert back to percentage
        forward_maturities.append(f"{int(t1)}Y-{int(t2)}Y")

    return forward_maturities, forward_rates

def create_yield_curve():
    """
    Professional US Treasury Yield Curve visualization with multi-source data.

    Data sources (in priority order):
    1. FRED API (Federal Reserve) - Most accurate and comprehensive
    2. Yahoo Finance - Backup source
    3. Fallback data - If all sources fail
    """
    # Fetch yields from multi-source function
    maturities, yields_data, data_source = fetch_us_treasury_yields_fred()

    if not yields_data:
        return None

    # Create labels for display
    label_map = {
        1/12: "1M", 0.25: "3M", 0.5: "6M",
        1: "1Y", 2: "2Y", 3: "3Y", 5: "5Y",
        7: "7Y", 10: "10Y", 20: "20Y", 30: "30Y"
    }
    labels = [label_map.get(m, f"{m:.1f}Y") for m in maturities]

    # Sort by maturity
    sorted_data = sorted(zip(maturities, yields_data, labels))
    maturities, yields_data, labels = zip(*sorted_data)

    # Calculate forward rates
    forward_labels, forward_rates = calculate_forward_rates(list(maturities), list(yields_data))

    # Create positions for forward rates (plot at midpoint between maturities)
    forward_x = []
    for i in range(len(maturities) - 1):
        forward_x.append((maturities[i] + maturities[i+1]) / 2)

    fig = go.Figure()

    # Spot yield curve
    fig.add_trace(go.Scatter(
        x=maturities,
        y=yields_data,
        mode='lines+markers',
        line=dict(color=COLORS['neon_blue'], width=3),
        marker=dict(size=12, color=COLORS['electric_blue'], line=dict(color=COLORS['border'], width=2)),
        text=[f"{l}: {y:.2f}%" for l, y in zip(labels, yields_data)],
        hovertemplate='<b>Spot %{text}</b><extra></extra>',
        name='Spot Yield Curve'
    ))

    # Forward rate curve overlaid
    if forward_rates:
        fig.add_trace(go.Scatter(
            x=forward_x,
            y=forward_rates,
            mode='lines+markers',
            line=dict(color=COLORS['success'], width=2, dash='dash'),
            marker=dict(size=8, color=COLORS['success'], symbol='diamond'),
            text=[f"{label}: {rate:.2f}%" for label, rate in zip(forward_labels, forward_rates)],
            hovertemplate='<b>Forward %{text}</b><extra></extra>',
            name='Implied Forward Rates'
        ))

    # Add data source indicator to title
    source_icon = {
        "FRED API": "üèõÔ∏è",
        "Yahoo Finance": "üìä",
        "Fallback Data": "‚ö†Ô∏è"
    }.get(data_source, "üìà")

    fig.update_layout(
        title=f"{source_icon} US Treasury Yield Curve with Forward Rates<br><sub>Data Source: {data_source}</sub>",
        xaxis_title="Maturity (Years)",
        yaxis_title="Yield (%)",
        height=500,
        showlegend=True,
        legend=dict(
            orientation="h",
            yanchor="bottom",
            y=1.02,
            xanchor="right",
            x=1
        )
    )

    apply_chart_theme(fig)
    return fig, list(maturities), list(yields_data), data_source

@st.cache_data(ttl=3600)  # Cache for 1 hour
def fetch_uk_gilt_yields():
    """Fetch live UK Gilt yields from Yahoo Finance"""
    # UK Government Bond Yield tickers (Yahoo Finance format)
    uk_bond_tickers = {
        "^FTGB03M": {"maturity": 0.25, "name": "3M"},   # 3-month
        "^FTGB06M": {"maturity": 0.5, "name": "6M"},    # 6-month
        "^FTGB01Y": {"maturity": 1, "name": "1Y"},      # 1-year
        "^FTGB02Y": {"maturity": 2, "name": "2Y"},      # 2-year
        "^FTGB03Y": {"maturity": 3, "name": "3Y"},      # 3-year
        "^FTGB05Y": {"maturity": 5, "name": "5Y"},      # 5-year
        "^FTGB07Y": {"maturity": 7, "name": "7Y"},      # 7-year
        "^FTGB10Y": {"maturity": 10, "name": "10Y"},    # 10-year
        "^FTGB15Y": {"maturity": 15, "name": "15Y"},    # 15-year
        "^FTGB20Y": {"maturity": 20, "name": "20Y"},    # 20-year
        "^FTGB30Y": {"maturity": 30, "name": "30Y"}     # 30-year
    }

    yields_data = []
    maturities = []

    for ticker, info in uk_bond_tickers.items():
        try:
            bond = yf.Ticker(ticker)
            hist = bond.history(period="5d")  # Get last 5 days in case today's data isn't available
            if not hist.empty:
                current_yield = hist['Close'].iloc[-1]
                yields_data.append(current_yield)
                maturities.append(info['maturity'])
        except:
            continue

    # If we got live data, use it
    if len(yields_data) >= 4:
        # Sort by maturity
        sorted_data = sorted(zip(maturities, yields_data))
        maturities, yields_data = zip(*sorted_data)
        return list(maturities), list(yields_data)

    # Fallback to sample data if live fetch fails
    maturities = [0.25, 0.5, 1, 2, 3, 5, 7, 10, 15, 20, 30]
    yields = [4.8, 4.6, 4.5, 4.2, 4.1, 4.0, 4.05, 4.1, 4.3, 4.4, 4.5]
    return maturities, yields

@st.cache_data(ttl=3600)  # Cache for 1 hour
def fetch_german_bund_yields():
    """Fetch live German Bund yields from Yahoo Finance"""
    # German Government Bond Yield tickers
    de_bond_tickers = {
        "^DEBM03M": {"maturity": 0.25, "name": "3M"},
        "^DEBM06M": {"maturity": 0.5, "name": "6M"},
        "^DEBM01Y": {"maturity": 1, "name": "1Y"},
        "^DEBM02Y": {"maturity": 2, "name": "2Y"},
        "^DEBM03Y": {"maturity": 3, "name": "3Y"},
        "^DEBM05Y": {"maturity": 5, "name": "5Y"},
        "^DEBM07Y": {"maturity": 7, "name": "7Y"},
        "^DEBM10Y": {"maturity": 10, "name": "10Y"},
        "^DEBM15Y": {"maturity": 15, "name": "15Y"},
        "^DEBM20Y": {"maturity": 20, "name": "20Y"},
        "^DEBM30Y": {"maturity": 30, "name": "30Y"}
    }

    yields_data = []
    maturities = []

    for ticker, info in de_bond_tickers.items():
        try:
            bond = yf.Ticker(ticker)
            hist = bond.history(period="5d")
            if not hist.empty:
                current_yield = hist['Close'].iloc[-1]
                yields_data.append(current_yield)
                maturities.append(info['maturity'])
        except:
            continue

    # If we got live data, use it
    if len(yields_data) >= 4:
        sorted_data = sorted(zip(maturities, yields_data))
        maturities, yields_data = zip(*sorted_data)
        return list(maturities), list(yields_data)

    # Fallback to sample data
    maturities = [0.25, 0.5, 1, 2, 3, 5, 7, 10, 15, 20, 30]
    yields = [3.2, 3.0, 2.9, 2.8, 2.7, 2.5, 2.55, 2.6, 2.75, 2.85, 2.9]
    return maturities, yields

@st.cache_data(ttl=3600)  # Cache for 1 hour
def fetch_sa_government_bond_yields():
    """Fetch live South African Government Bond yields"""
    # Try South African bond tickers (JSE)
    sa_bond_tickers = {
        "R2030.JO": {"maturity": 6, "name": "R2030"},   # R186 - 2030 maturity
        "R2032.JO": {"maturity": 8, "name": "R2032"},   # R2032
        "R2035.JO": {"maturity": 11, "name": "R2035"},  # R2035
        "R2040.JO": {"maturity": 16, "name": "R2040"},  # R2040
        "R2048.JO": {"maturity": 24, "name": "R2048"}   # R2048
    }

    yields_data = []
    maturities = []

    for ticker, info in sa_bond_tickers.items():
        try:
            bond = yf.Ticker(ticker)
            hist = bond.history(period="5d")
            if not hist.empty and 'Close' in hist.columns:
                # For bonds, we need to convert price to yield (approximate)
                # This is a simplified calculation
                price = hist['Close'].iloc[-1]
                # Rough yield approximation: higher price = lower yield
                # This is simplified - real calculation would need coupon rate
                continue  # Skip for now
        except:
            continue

    # Use sample data for SA bonds (JSE bond data is tricky to fetch directly)
    maturities = [0.25, 0.5, 1, 2, 3, 5, 7, 10, 15, 20, 30]
    yields = [8.5, 9.0, 9.5, 10.0, 10.3, 10.8, 11.0, 11.2, 11.4, 11.5, 11.6]
    return maturities, yields

def create_yield_curve_with_forwards(maturities, yields, title, color='#FF6B6B'):
    """Create yield curve with overlaid forward rates for any country"""
    # Calculate forward rates
    forward_labels, forward_rates = calculate_forward_rates(maturities, yields)

    # Create positions for forward rates (plot at midpoint between maturities)
    forward_x = []
    for i in range(len(maturities) - 1):
        forward_x.append((maturities[i] + maturities[i+1]) / 2)

    fig = go.Figure()

    # Spot yield curve
    labels = [f"{int(m)}Y" if m >= 1 else f"{int(m*12)}M" for m in maturities]
    fig.add_trace(go.Scatter(
        x=maturities,
        y=yields,
        mode='lines+markers',
        line=dict(color=color, width=3),
        marker=dict(size=12, line=dict(color=COLORS['border'], width=2)),
        text=[f"{l}: {y:.2f}%" for l, y in zip(labels, yields)],
        hovertemplate='<b>Spot %{text}</b><extra></extra>',
        name='Spot Yield Curve'
    ))

    # Forward rate curve overlaid
    if forward_rates:
        fig.add_trace(go.Scatter(
            x=forward_x,
            y=forward_rates,
            mode='lines+markers',
            line=dict(color=COLORS['success'], width=2, dash='dash'),
            marker=dict(size=8, color=COLORS['success'], symbol='diamond'),
            text=[f"{label}: {rate:.2f}%" for label, rate in zip(forward_labels, forward_rates)],
            hovertemplate='<b>Forward %{text}</b><extra></extra>',
            name='Implied Forward Rates'
        ))

    fig.update_layout(
        title=f"üìà {title}",
        xaxis_title="Maturity (Years)",
        yaxis_title="Yield (%)",
        height=500,
        showlegend=True,
        legend=dict(
            orientation="h",
            yanchor="bottom",
            y=1.02,
            xanchor="right",
            x=1
        )
    )

    apply_chart_theme(fig)
    return fig

def get_data_freshness(cache_time=None):
    """Calculate and format data age for freshness indicators"""
    if cache_time is None:
        return ATLASFormatter.format_timestamp(), 0

    now = datetime.now()
    age_seconds = (now - cache_time).total_seconds()
    age_minutes = int(age_seconds / 60)

    timestamp = ATLASFormatter.format_timestamp(cache_time)
    badge = ATLASFormatter.get_freshness_badge(age_minutes)

    return timestamp, age_minutes, badge

# ============================================================================
# DATA FUNCTIONS
# ============================================================================

def save_portfolio_data(data):
    """
    Save portfolio data to BOTH database and pickle cache
    Database is primary storage, pickle is backup
    """
    # Save to pickle (backwards compatibility)
    with open(PORTFOLIO_CACHE, "wb") as f:
        pickle.dump(data, f)

    # PHASE 4: Auto-save to database
    if SQL_AVAILABLE:
        try:
            db = get_db()
            # Convert list of dicts to DataFrame
            df = pd.DataFrame(data)

            # Ensure required columns exist
            if 'Ticker' in df.columns and 'Shares' in df.columns:
                # Prepare DataFrame for database
                portfolio_df = df.copy()

                # Rename columns to match database schema
                column_mapping = {
                    'Ticker': 'ticker',
                    'Shares': 'quantity',
                    'Avg Price': 'avg_cost',  # From account imports
                    'Avg Cost': 'avg_cost',   # From trade imports (Phoenix Parser)
                    'Current Price': 'current_price'
                }

                # Only rename columns that exist
                portfolio_df = portfolio_df.rename(columns={
                    k: v for k, v in column_mapping.items() if k in portfolio_df.columns
                })

                # Ensure required columns
                required_cols = ['ticker', 'quantity', 'avg_cost']
                if all(col in portfolio_df.columns for col in required_cols):
                    # Select only relevant columns
                    save_cols = [col for col in ['ticker', 'quantity', 'avg_cost', 'current_price']
                                 if col in portfolio_df.columns]
                    portfolio_df = portfolio_df[save_cols]

                    # Save to database
                    db.save_portfolio(portfolio_df)
                    print(f"‚úÖ Portfolio saved to database ({len(portfolio_df)} positions)")
                else:
                    missing = [col for col in required_cols if col not in portfolio_df.columns]
                    print(f"‚ö†Ô∏è Cannot save to database: missing columns {missing}")
                    print(f"   Available columns: {list(portfolio_df.columns)}")
        except Exception as e:
            print(f"‚ö†Ô∏è Database save failed (pickle still saved): {e}")
            import traceback
            print(traceback.format_exc())

def load_portfolio_data():
    """
    Load portfolio data from DATABASE FIRST, fallback to pickle
    This implements Phase 4: SQL-first loading
    """
    # PHASE 4: Try database first
    if SQL_AVAILABLE:
        try:
            db = get_db()
            df = db.get_portfolio()

            if len(df) > 0:
                # Convert database format back to app format
                column_mapping = {
                    'ticker': 'Ticker',
                    'quantity': 'Shares',
                    'avg_cost': 'Avg Cost',  # Standard column name in app
                    'current_price': 'Current Price'
                }

                df = df.rename(columns={
                    k: v for k, v in column_mapping.items() if k in df.columns
                })

                print(f"‚úÖ Loaded {len(df)} positions from database")
                return df  # ‚úÖ FIX: Return DataFrame instead of list
        except Exception as e:
            print(f"‚ö†Ô∏è Database load failed, falling back to pickle: {e}")

    # Fallback to pickle
    if PORTFOLIO_CACHE.exists():
        with open(PORTFOLIO_CACHE, "rb") as f:
            data = pickle.load(f)
            print(f"‚úÖ Loaded {len(data)} positions from pickle cache")
            # ‚úÖ FIX: Convert to DataFrame if it's a list
            if isinstance(data, list):
                return pd.DataFrame(data)
            return data

    return pd.DataFrame()  # ‚úÖ FIX: Return empty DataFrame instead of empty list


def get_portfolio_from_broker_or_legacy():
    """
    NEW: Unified portfolio data loader - checks broker adapter first, then falls back to legacy load

    This function enables the new multi-broker system (Alpaca, Easy Equities, Manual Entry)
    while maintaining backward compatibility with existing Phoenix Parser workflow.

    Priority:
    1. Check if broker adapter is active (Alpaca/EE/Manual) ‚Üí use adapter.get_positions()
    2. Check if fresh data in session_state['portfolio_df'] ‚Üí use that
    3. Fall back to load_portfolio_data() (SQL/pickle)

    Returns:
    --------
    pd.DataFrame : Portfolio positions in ATLAS format
    """
    # Priority 1: Check for active broker adapter
    if BROKER_MANAGER_AVAILABLE and 'active_broker' in st.session_state and st.session_state.active_broker:
        try:
            # Get the adapter based on broker type
            broker_key = st.session_state.active_broker

            if broker_key == 'manual' and 'manual_configured' in st.session_state:
                adapter = ManualPortfolioAdapter()
                positions = adapter.get_positions()
                if not positions.empty:
                    print(f"‚úÖ Loaded {len(positions)} positions from Manual Entry")
                    return positions

            elif broker_key == 'alpaca' and 'alpaca_adapter' in st.session_state:
                adapter = st.session_state.alpaca_adapter
                positions = adapter.get_positions()
                if not positions.empty:
                    print(f"‚úÖ Loaded {len(positions)} positions from Alpaca Markets")
                    # Convert Alpaca format to ATLAS format
                    atlas_format = positions.rename(columns={
                        'ticker': 'Ticker',
                        'quantity': 'Shares',
                        'avg_cost': 'Avg Cost',
                        'current_price': 'Current Price',
                        'market_value': 'Market Value',
                        'cost_basis': 'Cost Basis',
                        'unrealized_pl': 'Unrealized P&L',
                        'unrealized_plpc': 'Unrealized P&L %',
                        'weight': 'Weight %'
                    })
                    return atlas_format

            elif broker_key == 'easy_equities' and 'ee_adapter' in st.session_state:
                adapter = st.session_state.ee_adapter
                positions = adapter.get_positions()
                if not positions.empty:
                    print(f"‚úÖ Loaded {len(positions)} positions from Easy Equities")
                    return positions

        except Exception as e:
            print(f"‚ö†Ô∏è Broker data load failed: {e}, falling back to legacy")

    # Priority 2: Check session_state for fresh Phoenix Parser data
    if 'portfolio_df' in st.session_state and st.session_state['portfolio_df'] is not None:
        if len(st.session_state['portfolio_df']) > 0:
            print(f"‚úÖ Using fresh data from session_state ({len(st.session_state['portfolio_df'])} positions)")
            return st.session_state['portfolio_df']

    # Priority 3: Fall back to legacy load (SQL ‚Üí pickle)
    print("üìÇ Loading from legacy system (SQL/pickle)")
    return load_portfolio_data()


def save_trade_history(df):
    """
    Save trade history to BOTH database and pickle cache
    """
    # Save to pickle (backwards compatibility)
    with open(TRADE_HISTORY_CACHE, "wb") as f:
        pickle.dump(df, f)

    # Check if SQL is available
    if not SQL_AVAILABLE:
        print("‚ö†Ô∏è SQL not available - trades saved to pickle only")
        import streamlit as st
        st.warning("‚ö†Ô∏è Trades saved to local file only (database not available)")
        return

    if df is None or len(df) == 0:
        print("‚ö†Ô∏è No trades to save")
        return

    try:
        db = get_db()
        trades_df = df.copy()

        # IMPROVED COLUMN MAPPING - Add all variations including "Trade Type"
        column_mapping = {}

        # Date column - ALL POSSIBLE NAMES
        date_cols = [
            'Date', 'date', 'DATE',
            'Trade Date', 'Execution Date', 'Exec Date',
            'Transaction Date', 'Settlement Date'
        ]
        for col in date_cols:
            if col in trades_df.columns:
                column_mapping[col] = 'date'
                break

        # Ticker/Symbol column - ALL POSSIBLE NAMES
        ticker_cols = [
            'Ticker', 'ticker', 'TICKER',
            'Symbol', 'symbol', 'SYMBOL',
            'Underlying', 'Security', 'Instrument'
        ]
        for col in ticker_cols:
            if col in trades_df.columns:
                column_mapping[col] = 'ticker'
                break

        # Action column - ALL POSSIBLE NAMES (INCLUDING "Trade Type") ‚≠ê CRITICAL FIX
        action_cols = [
            'Action', 'action', 'ACTION',
            'Trade Type', 'TradeType', 'TRADE TYPE',  # ‚Üê FIX: Added these!
            'Type', 'type', 'TYPE',
            'Side', 'side', 'SIDE',
            'Buy/Sell', 'BUY/SELL',
            'Transaction Type', 'Trade Action'
        ]
        for col in action_cols:
            if col in trades_df.columns:
                column_mapping[col] = 'action'
                break

        # Quantity column - ALL POSSIBLE NAMES
        qty_cols = [
            'Quantity', 'quantity', 'QUANTITY',
            'Qty', 'qty', 'QTY',
            'Shares', 'shares', 'SHARES',
            'Amount', 'amount', 'AMOUNT',
            'Volume', 'volume', 'VOLUME',
            'Size', 'size', 'SIZE'
        ]
        for col in qty_cols:
            if col in trades_df.columns:
                column_mapping[col] = 'quantity'
                break

        # Price column - ALL POSSIBLE NAMES
        price_cols = [
            'Price', 'price', 'PRICE',
            'Exec Price', 'Execution Price', 'Fill Price',
            'Trade Price', 'Avg Price', 'Average Price'
        ]
        for col in price_cols:
            if col in trades_df.columns:
                column_mapping[col] = 'price'
                break

        # Apply mapping
        print(f"üìã Column mapping found: {column_mapping}")
        trades_df = trades_df.rename(columns=column_mapping)

        # Check if we have all required columns
        required = ['date', 'ticker', 'action', 'quantity', 'price']
        missing = [col for col in required if col not in trades_df.columns]

        if missing:
            error_msg = f"‚ö†Ô∏è Cannot save to database - missing columns: {missing}"
            print(error_msg)
            print(f"üìã Available columns after mapping: {list(trades_df.columns)}")
            import streamlit as st
            st.error(f"‚ùå {error_msg}")
            st.info(f"""
            **Columns in uploaded file:**
            {', '.join(df.columns)}

            **Missing after mapping:**
            {', '.join(missing)}

            Trades saved to local file, but not database.
            """)
            return

        # Select only required columns
        trades_df = trades_df[required]

        # Clean and validate data
        # Convert date to string if it's datetime
        if pd.api.types.is_datetime64_any_dtype(trades_df['date']):
            trades_df['date'] = trades_df['date'].dt.strftime('%Y-%m-%d')

        # Ensure numeric types
        trades_df['quantity'] = pd.to_numeric(trades_df['quantity'], errors='coerce')
        trades_df['price'] = pd.to_numeric(trades_df['price'], errors='coerce')

        # Remove rows with NaN values
        trades_df = trades_df.dropna()

        if len(trades_df) == 0:
            print("‚ö†Ô∏è No valid trades after cleaning")
            return

        # CRITICAL FIX: Normalize action values to 'BUY' or 'SELL'
        # Database has CHECK constraint: action IN ('BUY', 'SELL')
        # Investopedia uses values like "Stock: Buy at Market Open"
        def normalize_action(action_str):
            """Extract BUY or SELL from action string"""
            action_lower = str(action_str).lower()
            if 'buy' in action_lower:
                return 'BUY'
            elif 'sell' in action_lower or 'short' in action_lower:
                return 'SELL'
            else:
                # Default fallback - should not happen with proper mapping
                print(f"‚ö†Ô∏è Unknown action format: {action_str}, defaulting to BUY")
                return 'BUY'

        trades_df['action'] = trades_df['action'].apply(normalize_action)
        print(f"üìã Normalized actions - sample: {trades_df['action'].head().tolist()}")

        # Save to database
        db.bulk_insert('trades', trades_df, if_exists='append')
        print(f"‚úÖ Saved {len(trades_df)} trades to database")
        import streamlit as st
        st.success(f"‚úÖ Saved {len(trades_df)} trades to database permanently!")

    except Exception as e:
        error_msg = f"‚ö†Ô∏è Database save failed: {e}"
        print(error_msg)
        import streamlit as st
        st.error(error_msg)
        import traceback
        st.code(traceback.format_exc())
        st.info("Trades are saved to local pickle file as backup")


def load_trade_history():
    if TRADE_HISTORY_CACHE.exists():
        with open(TRADE_HISTORY_CACHE, "rb") as f:
            return pickle.load(f)
    return None

def save_account_history(df):
    with open(ACCOUNT_HISTORY_CACHE, "wb") as f:
        pickle.dump(df, f)

def load_account_history():
    if ACCOUNT_HISTORY_CACHE.exists():
        with open(ACCOUNT_HISTORY_CACHE, "rb") as f:
            return pickle.load(f)
    return None

# v9.7 NEW FEATURE: Data Validation & Integrity Checks
def validate_portfolio_data(portfolio_data):
    """
    NEW IN v9.7: Comprehensive data validation and integrity checking
    Returns validation metrics and quality scores
    """
    if portfolio_data is None or (isinstance(portfolio_data, pd.DataFrame) and portfolio_data.empty):
        return {
            'is_valid': False,
            'total_holdings': 0,
            'data_quality_score': 0,
            'issues': ['No portfolio data available'],
            'warnings': [],
            'null_counts': {},
            'total_rows': 0,
            'complete_rows': 0
        }

    df = pd.DataFrame(portfolio_data)
    issues = []
    warnings = []

    # Check required columns - use flexible column names
    required_columns = ['Ticker']
    optional_columns = ['Quantity', 'Current Price', 'Shares', 'Price', 'Last Price']

    missing_columns = [col for col in required_columns if col not in df.columns]
    if missing_columns:
        issues.append(f"Missing required columns: {', '.join(missing_columns)}")

    # Check for null values only on existing columns
    existing_check_cols = [col for col in required_columns if col in df.columns]
    null_counts = {}

    if existing_check_cols:
        null_counts = df[existing_check_cols].isnull().sum().to_dict()
        for col, count in null_counts.items():
            if count > 0:
                warnings.append(f"{col}: {count} missing values")

    # Check for negative quantities (flexible column names)
    qty_col = None
    for col in ['Quantity', 'Shares', 'Qty']:
        if col in df.columns:
            qty_col = col
            break

    if qty_col:
        negative_qty = (df[qty_col] < 0).sum()
        if negative_qty > 0:
            warnings.append(f"{negative_qty} holdings with negative quantities (short positions)")

    # Check for zero/negative prices (flexible column names)
    price_col = None
    for col in ['Current Price', 'Price', 'Last Price', 'Close']:
        if col in df.columns:
            price_col = col
            break

    if price_col:
        invalid_prices = (df[price_col] <= 0).sum()
        if invalid_prices > 0:
            issues.append(f"{invalid_prices} holdings with invalid prices (‚â§0)")

    # Check for duplicate tickers
    if 'Ticker' in df.columns:
        duplicates = df['Ticker'].duplicated().sum()
        if duplicates > 0:
            warnings.append(f"{duplicates} duplicate ticker entries")

    # Calculate data quality score (0-100)
    quality_score = 100
    quality_score -= len(issues) * 15  # Severe penalty for issues
    quality_score -= len(warnings) * 5  # Moderate penalty for warnings
    quality_score = max(0, min(100, quality_score))

    # Calculate complete rows
    complete_rows = len(df)
    if existing_check_cols:
        complete_rows = len(df.dropna(subset=existing_check_cols))

    return {
        'is_valid': len(issues) == 0,
        'total_holdings': len(df),
        'data_quality_score': quality_score,
        'issues': issues,
        'warnings': warnings,
        'null_counts': null_counts,
        'total_rows': len(df),
        'complete_rows': complete_rows
    }

def get_leverage_info():
    account_df = load_account_history()
    if account_df is not None:
        latest_cash = account_df.get('Cash Balance', account_df.get('Cash', pd.Series([0]))).iloc[-1]
        
        if isinstance(latest_cash, str):
            latest_cash = latest_cash.replace('$', '').replace(',', '')
            if '(' in latest_cash and ')' in latest_cash:
                latest_cash = '-' + latest_cash.replace('(', '').replace(')', '')
            try:
                latest_cash = float(latest_cash)
            except:
                latest_cash = 0
        
        latest_margin = 0
        
        if 'Margin Used' in account_df.columns:
            latest_margin = account_df['Margin Used'].iloc[-1]
            if isinstance(latest_margin, str):
                latest_margin = latest_margin.replace('$', '').replace(',', '')
                if '(' in latest_margin and ')' in latest_margin:
                    latest_margin = '-' + latest_margin.replace('(', '').replace(')', '')
                try:
                    latest_margin = float(latest_margin)
                except:
                    latest_margin = 0
        
        if latest_cash < 0:
            latest_margin = abs(latest_cash)
            
        total_value = 0
        if 'Total Value' in account_df.columns:
            total_value = account_df['Total Value'].iloc[-1]
            if isinstance(total_value, str):
                total_value = total_value.replace('$', '').replace(',', '')
                if '(' in total_value and ')' in total_value:
                    total_value = '-' + total_value.replace('(', '').replace(')', '')
                try:
                    total_value = float(total_value)
                except:
                    total_value = abs(latest_cash) + latest_margin
        else:
            total_value = abs(latest_cash) + latest_margin

        # FIX #4: Correct leverage formula - Gross Exposure / Net Equity
        # (aligned with Leverage Tracker page calculation)
        net_equity = total_value - latest_margin if total_value > latest_margin else total_value
        leverage_ratio = (total_value / net_equity) if net_equity > 0 else 1.0

        return {
            'margin_used': latest_margin,
            'cash_balance': latest_cash,
            'leverage_ratio': leverage_ratio,
            'total_value': total_value,
            'net_equity': net_equity  # Added for clarity
        }
    return None

@st.cache_data(ttl=300)
def fetch_market_data(ticker):
    # ATLAS Refactoring - Use cached market data fetcher
    try:
        # Import ticker conversion utility
        from modules import convert_ee_ticker_to_yahoo

        # Convert Easy Equities ticker to Yahoo Finance format
        yahoo_ticker = convert_ee_ticker_to_yahoo(ticker)

        if REFACTORED_MODULES_AVAILABLE:
            info = market_data.get_company_info(yahoo_ticker)
            hist = market_data.get_stock_history(yahoo_ticker, period="5d", interval="1d")
        else:
            # Fallback to old method
            stock = yf.Ticker(yahoo_ticker)
            info = stock.info
            hist = stock.history(period="5d")

        if hist.empty:
            return None

        # Convert timezone-aware index to timezone-naive
        if hist.index.tz is not None:
            hist.index = hist.index.tz_localize(None)

        current_price = hist['Close'].iloc[-1]
        prev_close = hist['Close'].iloc[-2] if len(hist) > 1 else current_price
        daily_change = current_price - prev_close
        daily_change_pct = (daily_change / prev_close * 100) if prev_close else 0

        five_day_return = ((current_price / hist['Close'].iloc[0]) - 1) * 100 if len(hist) >= 5 else 0

        company_name = info.get('longName', info.get('shortName', ticker))

        return {
            "price": current_price,
            "daily_change": daily_change,
            "daily_change_pct": daily_change_pct,
            "five_day_return": five_day_return,
            "volume": info.get('volume', 0),
            "avg_volume": info.get('averageVolume', 0),
            "sector": info.get('sector', 'Unknown'),
            "beta": info.get('beta', None),
            "market_cap": info.get('marketCap', 0),
            "company_name": company_name,
            "52_week_high": info.get('fiftyTwoWeekHigh', None),
            "52_week_low": info.get('fiftyTwoWeekLow', None)
        }
    except Exception as e:
        # ATLAS Refactoring: User-friendly error handling
        if REFACTORED_MODULES_AVAILABLE:
            ErrorHandler.handle_error(
                error=e,
                context=f"fetching market data for {ticker}",
                fallback_value=None,
                show_traceback=False
            )
        return None

def is_option_ticker(ticker):
    """
    Detect if ticker is an option symbol
    Options typically have format: TICKER[DATE][TYPE][STRIKE]
    Examples: AU2520F50, META2405D482.5, AAPL240119C150
    """
    import re

    # Skip if too short
    if len(ticker) <= 6:
        return False

    # Specific known options to exclude
    known_options = ['AU2520F50', 'META2405D482.5']
    if ticker.upper() in known_options:
        return True

    # General option pattern detection
    # Pattern: Letters + 4-digit year (20XX, 24XX, etc) + optional letter + decimals
    # Examples: META2405D482.5 = META + 2405 + D + 482.5
    #           AU2520F50 = AU + 2520 + F + 50
    option_pattern = r'^[A-Z]+\d{4}[A-Z]\d+\.?\d*$'
    if re.match(option_pattern, ticker.upper()):
        return True

    # Standard options format (older logic)
    has_year = any(str(y) in ticker for y in range(2020, 2030))
    has_strike = any(c.isdigit() for c in ticker[6:])
    has_type = ticker[-1] in ['C', 'P'] or 'C' in ticker[6:] or 'P' in ticker[6:]
    return has_year and has_strike and has_type

def classify_ticker_sector(ticker, default_sector):
    if pd.notna(default_sector) and default_sector != "Unknown":
        return default_sector
    
    if ticker in ETF_SECTORS:
        return ETF_SECTORS[ticker]
    
    return "Other"

@st.cache_data(ttl=600)
def fetch_historical_data(ticker, start_date, end_date):
    try:
        # Import ticker conversion utility
        from modules import convert_ee_ticker_to_yahoo

        # Convert Easy Equities ticker to Yahoo Finance format
        yahoo_ticker = convert_ee_ticker_to_yahoo(ticker)

        stock = yf.Ticker(yahoo_ticker)
        hist = stock.history(start=start_date, end=end_date)
        if not hist.empty:
            # Convert timezone-aware index to timezone-naive to prevent comparison errors
            if hist.index.tz is not None:
                hist.index = hist.index.tz_localize(None)
            return hist
    except:
        pass
    return None

@st.cache_data(ttl=3600)
def fetch_stock_info(ticker):
    """Fetch stock information from yfinance"""
    # ATLAS Refactoring - Use cached market data fetcher
    try:
        # Import ticker conversion utility
        from modules import convert_ee_ticker_to_yahoo

        # Convert Easy Equities ticker to Yahoo Finance format
        yahoo_ticker = convert_ee_ticker_to_yahoo(ticker)

        if REFACTORED_MODULES_AVAILABLE:
            return market_data.get_company_info(yahoo_ticker)
        else:
            # Fallback to old method
            stock = yf.Ticker(yahoo_ticker)
            info = stock.info
            return info
    except Exception as e:
        # ATLAS Refactoring: User-friendly error handling
        if REFACTORED_MODULES_AVAILABLE:
            ErrorHandler.handle_error(
                error=e,
                context=f"fetching stock information for {ticker}",
                fallback_value=None,
                show_traceback=False
            )
        return None

@st.cache_data(ttl=3600)
def fetch_analyst_data(ticker):
    # ATLAS Refactoring - Use cached market data fetcher
    try:
        if REFACTORED_MODULES_AVAILABLE:
            info = market_data.get_company_info(ticker)
        else:
            # Fallback to old method
            stock = yf.Ticker(ticker)
            info = stock.info

        rating = info.get('recommendationKey', 'none')
        if rating == 'none' or rating is None:
            rating = "No Coverage"

        return {
            'rating': rating.upper() if rating != "No Coverage" else rating,
            'target_price': info.get('targetMeanPrice'),
            'num_analysts': info.get('numberOfAnalystOpinions', 0),
            'success': True
        }
    except Exception as e:
        # ATLAS Refactoring: User-friendly error handling
        if REFACTORED_MODULES_AVAILABLE:
            ErrorHandler.handle_error(
                error=e,
                context=f"fetching analyst data for {ticker}",
                fallback_value={'success': False, 'rating': 'No Coverage', 'target_price': None},
                show_traceback=False
            )
        return {'success': False, 'rating': 'No Coverage', 'target_price': None}

# ============================================================================
# VALUATION HOUSE - ENHANCED WITH SMART ASSUMPTIONS
# ============================================================================

@st.cache_data(ttl=3600)
def _safe_lookup(df, col, field_names):
    """Lookup a value from a DataFrame trying multiple field name variants."""
    if isinstance(field_names, str):
        field_names = [field_names]
    for name in field_names:
        if name in df.index:
            val = df.loc[name, col]
            if pd.notna(val):
                return float(val)
    return 0

def fetch_company_financials(ticker):
    """Fetch comprehensive financial data for valuation.

    Uses yfinance with robust field name fallbacks to handle variations
    across different companies and sectors (pharma, biotech, etc.).
    Falls back to direct yfinance if refactored module returns empty data.
    """
    try:
        # Try refactored module first, then direct yfinance as fallback
        info = {}
        income_stmt = pd.DataFrame()
        balance_sheet = pd.DataFrame()
        cash_flow = pd.DataFrame()

        if REFACTORED_MODULES_AVAILABLE:
            info = market_data.get_company_info(ticker)
            income_stmt = market_data.get_financials(ticker, statement_type="income")
            balance_sheet = market_data.get_financials(ticker, statement_type="balance")
            cash_flow = market_data.get_financials(ticker, statement_type="cashflow")

        # Direct yfinance fallback if refactored module returned empty data
        if not info or income_stmt.empty:
            stock = yf.Ticker(ticker)
            if not info:
                info = stock.info or {}
            if income_stmt.empty:
                income_stmt = stock.income_stmt if hasattr(stock, 'income_stmt') and stock.income_stmt is not None else stock.financials
            if balance_sheet.empty:
                balance_sheet = stock.balance_sheet
            if cash_flow.empty:
                cash_flow = stock.cashflow if hasattr(stock, 'cashflow') else stock.cash_flow

        # Ensure DataFrames are valid
        if income_stmt is None:
            income_stmt = pd.DataFrame()
        if balance_sheet is None:
            balance_sheet = pd.DataFrame()
        if cash_flow is None:
            cash_flow = pd.DataFrame()

        # Basic company info - try multiple key names for price
        current_price = info.get('currentPrice') or info.get('regularMarketPrice') or info.get('previousClose', 0)
        shares = info.get('sharesOutstanding') or info.get('impliedSharesOutstanding', 0)

        company_data = {
            'ticker': ticker,
            'name': info.get('longName') or info.get('shortName', ticker),
            'sector': info.get('sector', 'Unknown'),
            'industry': info.get('industry', 'Unknown'),
            'current_price': current_price,
            'market_cap': info.get('marketCap', 0),
            'shares_outstanding': shares,
            'beta': info.get('beta', 1.0),
            'forward_pe': info.get('forwardPE'),
            'trailing_pe': info.get('trailingPE'),
        }

        # Parse financials with robust field name fallbacks
        financials = {}

        if isinstance(income_stmt, pd.DataFrame) and not income_stmt.empty:
            latest_col = income_stmt.columns[0]

            # Revenue: try multiple field names (varies by company/sector)
            financials['revenue'] = _safe_lookup(income_stmt, latest_col, [
                'Total Revenue', 'Revenue', 'Operating Revenue',
                'Total Revenue And Other Operating Revenues'
            ])
            # EBIT: try multiple field names
            financials['ebit'] = _safe_lookup(income_stmt, latest_col, [
                'EBIT', 'Operating Income', 'Operating Income Loss',
                'Normalized EBITDA', 'Total Operating Income As Reported'
            ])
            # Net Income
            financials['net_income'] = _safe_lookup(income_stmt, latest_col, [
                'Net Income', 'Net Income Common Stockholders',
                'Net Income From Continuing Operations',
                'Net Income Common Stockholders Net Income'
            ])
            # Tax
            financials['tax_expense'] = _safe_lookup(income_stmt, latest_col, [
                'Tax Provision', 'Income Tax Expense', 'Tax Rate For Calcs',
                'Current Income Tax Expense', 'Tax Effect Of Unusual Items'
            ])

            # Calculate tax rate
            if financials['ebit'] != 0 and financials['tax_expense'] != 0:
                financials['tax_rate'] = abs(financials['tax_expense'] / financials['ebit'])
                financials['tax_rate'] = min(financials['tax_rate'], 0.40)  # Cap at 40%
            else:
                financials['tax_rate'] = 0.21  # Default US corporate tax rate

        if isinstance(balance_sheet, pd.DataFrame) and not balance_sheet.empty:
            latest_col = balance_sheet.columns[0]

            financials['total_debt'] = _safe_lookup(balance_sheet, latest_col, [
                'Total Debt', 'Long Term Debt', 'Long Term Debt And Capital Lease Obligation',
                'Total Non Current Liabilities Net Minority Interest',
                'Current Debt And Capital Lease Obligation', 'Net Debt'
            ])
            financials['cash'] = _safe_lookup(balance_sheet, latest_col, [
                'Cash And Cash Equivalents', 'Cash Cash Equivalents And Short Term Investments',
                'Cash Financial', 'Cash And Short Term Investments',
                'Cash Equivalents', 'Cash'
            ])
            financials['total_equity'] = _safe_lookup(balance_sheet, latest_col, [
                'Total Equity Gross Minority Interest', 'Stockholders Equity',
                'Total Stockholders Equity', 'Common Stock Equity',
                'Total Capitalization', 'Tangible Book Value'
            ])

        if isinstance(cash_flow, pd.DataFrame) and not cash_flow.empty:
            latest_col = cash_flow.columns[0]

            capex_val = _safe_lookup(cash_flow, latest_col, [
                'Capital Expenditure', 'Capital Expenditures',
                'Purchase Of Property Plant And Equipment',
                'Net PPE Purchase And Sale'
            ])
            financials['capex'] = abs(capex_val) if capex_val else 0

            financials['depreciation'] = _safe_lookup(cash_flow, latest_col, [
                'Depreciation And Amortization', 'Depreciation',
                'Depreciation Amortization Depletion',
                'Depreciation And Amortization In Income Statement'
            ])
            financials['operating_cf'] = _safe_lookup(cash_flow, latest_col, [
                'Operating Cash Flow', 'Cash Flow From Continuing Operating Activities',
                'Total Cash From Operating Activities',
                'Net Cash Provided By Operating Activities'
            ])

        # Calculate working capital change (simplified)
        financials['change_wc'] = 0  # User can adjust

        # Check if we got enough data for a meaningful valuation
        has_revenue = financials.get('revenue', 0) != 0
        has_price = company_data['current_price'] != 0

        if not has_revenue and not has_price:
            return {
                'success': False,
                'error': f"No financial data available for {ticker}. The ticker may be invalid or data is not available on Yahoo Finance."
            }

        return {
            'company': company_data,
            'financials': financials,
            'success': True
        }

    except Exception as e:
        # ATLAS Refactoring: User-friendly error handling
        if REFACTORED_MODULES_AVAILABLE:
            ErrorHandler.handle_error(
                error=e,
                context=f"fetching financial statements for {ticker}",
                fallback_value={'success': False, 'error': str(e)},
                show_traceback=False
            )
        return {
            'success': False,
            'error': str(e)
        }

def calculate_smart_assumptions(company_data, financials):
    """
    NEW: Calculate realistic, economically grounded assumptions
    based on company fundamentals, sector averages, and economic reality
    """
    sector = company_data.get('sector', 'Unknown')
    revenue = financials.get('revenue', 0)
    ebit = financials.get('ebit', 0)
    
    # Smart revenue growth (based on sector and size)
    sector_growth_rates = {
        'Technology': 0.08,
        'Healthcare': 0.06,
        'Financial Services': 0.05,
        'Consumer Cyclical': 0.04,
        'Consumer Defensive': 0.03,
        'Energy': 0.03,
        'Industrials': 0.04,
        'Basic Materials': 0.03,
        'Real Estate': 0.03,
        'Utilities': 0.02,
        'Communication Services': 0.05,
        'Unknown': 0.04
    }
    
    base_growth = sector_growth_rates.get(sector, 0.04)
    
    # Adjust for company size (larger = slower growth)
    market_cap = company_data.get('market_cap', 0)
    if market_cap > 500e9:  # Mega cap
        size_adjustment = -0.02
    elif market_cap > 100e9:  # Large cap
        size_adjustment = -0.01
    elif market_cap > 10e9:  # Mid cap
        size_adjustment = 0
    else:  # Small cap
        size_adjustment = 0.01
    
    smart_revenue_growth = base_growth + size_adjustment
    
    # Smart EBIT margin (sector averages)
    sector_ebit_margins = {
        'Technology': 0.25,
        'Healthcare': 0.20,
        'Financial Services': 0.30,
        'Consumer Cyclical': 0.10,
        'Consumer Defensive': 0.08,
        'Energy': 0.15,
        'Industrials': 0.12,
        'Basic Materials': 0.15,
        'Real Estate': 0.40,
        'Utilities': 0.20,
        'Communication Services': 0.18,
        'Unknown': 0.15
    }
    
    smart_ebit_margin = sector_ebit_margins.get(sector, 0.15)
    
    # Smart CapEx (as % of revenue, sector-based)
    sector_capex_rates = {
        'Technology': 0.03,
        'Healthcare': 0.04,
        'Financial Services': 0.02,
        'Consumer Cyclical': 0.05,
        'Consumer Defensive': 0.04,
        'Energy': 0.12,
        'Industrials': 0.06,
        'Basic Materials': 0.10,
        'Real Estate': 0.08,
        'Utilities': 0.15,
        'Communication Services': 0.07,
        'Unknown': 0.05
    }
    
    smart_capex_pct = sector_capex_rates.get(sector, 0.05)
    
    # Smart Depreciation (typically 60-80% of CapEx for mature companies)
    smart_depreciation_pct = smart_capex_pct * 0.7
    
    # Smart Terminal Growth (conservative)
    smart_terminal_growth = 0.025  # Long-term GDP growth
    
    # Smart Tax Rate (based on geography and sector)
    smart_tax_rate = 0.21  # US corporate rate
    
    return {
        'revenue_growth': smart_revenue_growth,
        'ebit_margin': smart_ebit_margin,
        'capex_pct': smart_capex_pct,
        'depreciation_pct': smart_depreciation_pct,
        'terminal_growth': smart_terminal_growth,
        'tax_rate': smart_tax_rate,
        'wc_change': 0,  # Assume neutral
        'forecast_years': 5
    }

def calculate_wacc(cost_equity, cost_debt, tax_rate, debt, equity):
    """Calculate Weighted Average Cost of Capital"""
    total_value = debt + equity
    if total_value == 0:
        return cost_equity
    
    weight_equity = equity / total_value
    weight_debt = debt / total_value
    
    wacc = (cost_equity * weight_equity) + (cost_debt * (1 - tax_rate) * weight_debt)
    return wacc

def calculate_cost_of_equity(risk_free_rate, beta, market_risk_premium):
    """Calculate Cost of Equity using CAPM"""
    return risk_free_rate + (beta * market_risk_premium)

def calculate_terminal_value(final_fcf, discount_rate, terminal_growth):
    """Calculate Terminal Value using Gordon Growth Model"""
    if discount_rate <= terminal_growth:
        return 0
    return final_fcf * (1 + terminal_growth) / (discount_rate - terminal_growth)

def project_fcff_enhanced(base_revenue, base_ebit, revenue_growth, ebit_margin, tax_rate,
                         depreciation_pct, capex_pct, change_wc, forecast_years, multistage_config=None):
    """
    ENHANCED: Project FCFF with D&A and CapEx scaling with revenue
    Supports multi-stage growth modeling
    """
    projections = []

    current_revenue = base_revenue

    for year in range(1, forecast_years + 1):
        # Determine growth rate for this year (multi-stage or single-stage)
        # Handle both dict and object types for multistage_config
        if multistage_config:
            if isinstance(multistage_config, dict):
                enabled = multistage_config.get('enabled', False)
                stage1_years = multistage_config.get('stage1_years', 0)
                stage2_years = multistage_config.get('stage2_years', 0)
                stage1_growth = multistage_config.get('stage1_growth', revenue_growth)
                stage2_growth = multistage_config.get('stage2_growth', revenue_growth)
                stage3_growth = multistage_config.get('stage3_growth', revenue_growth)
            else:
                enabled = getattr(multistage_config, 'enabled', False)
                stage1_years = getattr(multistage_config, 'stage1_years', 0)
                stage2_years = getattr(multistage_config, 'stage2_years', 0)
                stage1_growth = getattr(multistage_config, 'stage1_growth', revenue_growth)
                stage2_growth = getattr(multistage_config, 'stage2_growth', revenue_growth)
                stage3_growth = getattr(multistage_config, 'stage3_growth', revenue_growth)

            if enabled:
                if year <= stage1_years:
                    current_growth = stage1_growth
                elif year <= stage1_years + stage2_years:
                    current_growth = stage2_growth
                else:
                    current_growth = stage3_growth
            else:
                current_growth = revenue_growth
        else:
            current_growth = revenue_growth

        # Grow revenue
        current_revenue = current_revenue * (1 + current_growth)

        # Calculate EBIT based on margin
        current_ebit = current_revenue * ebit_margin
        
        # Calculate NOPAT
        nopat = current_ebit * (1 - tax_rate)
        
        # FIXED: Scale D&A and CapEx with revenue
        depreciation = current_revenue * depreciation_pct
        capex = current_revenue * capex_pct
        
        # Calculate FCFF
        fcff = nopat + depreciation - capex - change_wc
        
        projections.append({
            'year': year,
            'revenue': current_revenue,
            'ebit': current_ebit,
            'nopat': nopat,
            'depreciation': depreciation,
            'capex': capex,
            'change_wc': change_wc,
            'fcff': fcff
        })
    
    return projections

def project_fcfe_enhanced(base_revenue, base_net_income, revenue_growth, tax_rate,
                         depreciation_pct, capex_pct, change_wc, net_borrowing, forecast_years, multistage_config=None):
    """
    ENHANCED: Project FCFE with D&A and CapEx scaling with revenue
    Supports multi-stage growth modeling
    """
    projections = []

    current_revenue = base_revenue
    current_ni = base_net_income

    # Calculate initial NI margin
    ni_margin = current_ni / current_revenue if current_revenue > 0 else 0

    for year in range(1, forecast_years + 1):
        # Determine growth rate for this year (multi-stage or single-stage)
        # Handle both dict and object types for multistage_config
        if multistage_config:
            if isinstance(multistage_config, dict):
                enabled = multistage_config.get('enabled', False)
                stage1_years = multistage_config.get('stage1_years', 0)
                stage2_years = multistage_config.get('stage2_years', 0)
                stage1_growth = multistage_config.get('stage1_growth', revenue_growth)
                stage2_growth = multistage_config.get('stage2_growth', revenue_growth)
                stage3_growth = multistage_config.get('stage3_growth', revenue_growth)
            else:
                enabled = getattr(multistage_config, 'enabled', False)
                stage1_years = getattr(multistage_config, 'stage1_years', 0)
                stage2_years = getattr(multistage_config, 'stage2_years', 0)
                stage1_growth = getattr(multistage_config, 'stage1_growth', revenue_growth)
                stage2_growth = getattr(multistage_config, 'stage2_growth', revenue_growth)
                stage3_growth = getattr(multistage_config, 'stage3_growth', revenue_growth)

            if enabled:
                if year <= stage1_years:
                    current_growth = stage1_growth
                elif year <= stage1_years + stage2_years:
                    current_growth = stage2_growth
                else:
                    current_growth = stage3_growth
            else:
                current_growth = revenue_growth
        else:
            current_growth = revenue_growth

        # Grow revenue
        current_revenue = current_revenue * (1 + current_growth)

        # Grow net income
        current_ni = current_revenue * ni_margin
        
        # FIXED: Scale D&A and CapEx with revenue
        depreciation = current_revenue * depreciation_pct
        capex = current_revenue * capex_pct
        
        # Calculate FCFE
        fcfe = current_ni + depreciation - capex - change_wc + net_borrowing
        
        projections.append({
            'year': year,
            'revenue': current_revenue,
            'net_income': current_ni,
            'depreciation': depreciation,
            'capex': capex,
            'change_wc': change_wc,
            'net_borrowing': net_borrowing,
            'fcfe': fcfe
        })
    
    return projections

def calculate_dcf_value(projections, discount_rate, terminal_value, shares_outstanding, 
                       net_debt=0, method='FCFF'):
    """Calculate DCF valuation"""
    # Discount projected cash flows
    pv_cash_flows = []
    total_pv = 0
    
    for proj in projections:
        year = proj['year']
        cf = proj['fcff'] if method == 'FCFF' else proj['fcfe']
        pv = cf / ((1 + discount_rate) ** year)
        pv_cash_flows.append(pv)
        total_pv += pv
    
    # Discount terminal value
    pv_terminal = terminal_value / ((1 + discount_rate) ** len(projections))
    
    # Calculate enterprise/equity value
    enterprise_value = total_pv + pv_terminal
    
    if method == 'FCFF':
        # For FCFF, subtract net debt to get equity value
        equity_value = enterprise_value - net_debt
    else:
        # For FCFE, enterprise value IS equity value
        equity_value = enterprise_value
    
    # Calculate per share value
    intrinsic_value_per_share = equity_value / shares_outstanding if shares_outstanding > 0 else 0
    
    return {
        'pv_cash_flows': pv_cash_flows,
        'total_pv_cash_flows': total_pv,
        'terminal_value': terminal_value,
        'pv_terminal': pv_terminal,
        'enterprise_value': enterprise_value,
        'equity_value': equity_value,
        'intrinsic_value_per_share': intrinsic_value_per_share
    }

# ============================================================================
# VALUATION HOUSE RENOVATION - NEW MODULAR METHODS
# Following Damodaran / McKinsey Standards
# ============================================================================

# Industry-Standard Constraints
VALUATION_CONSTRAINTS = {
    'max_terminal_growth': 0.04,  # 4% (long-term GDP growth)
    'max_payout_ratio': 1.0,      # 100%
    'min_roe': 0.0,               # 0%
    'max_roe': 0.50,              # 50% (sanity check)
    'max_pe_multiple': 100,       # Outlier filter
    'min_pe_multiple': 3,         # Outlier filter
}

def apply_damodaran_constraints(value, constraint_type):
    """Apply industry-standard Damodaran constraints"""
    if constraint_type == 'terminal_growth':
        return min(value, VALUATION_CONSTRAINTS['max_terminal_growth'])
    elif constraint_type == 'payout_ratio':
        return min(max(value, 0), VALUATION_CONSTRAINTS['max_payout_ratio'])
    elif constraint_type == 'roe':
        return min(max(value, VALUATION_CONSTRAINTS['min_roe']), VALUATION_CONSTRAINTS['max_roe'])
    return value

# ============================================================================
# DIVIDEND DISCOUNT MODELS (DDM)
# ============================================================================

def calculate_gordon_growth_ddm(current_dividend, cost_of_equity, growth_rate, shares_outstanding):
    """
    Gordon Growth Model (Constant Growth DDM)
    Value = D1 / (r - g)
    Where D1 = D0 * (1 + g)
    """
    # Apply constraint: growth < cost of equity
    if growth_rate >= cost_of_equity:
        growth_rate = cost_of_equity * 0.9  # Safety margin

    # Constrain terminal growth
    growth_rate = apply_damodaran_constraints(growth_rate, 'terminal_growth')

    # Calculate next year's dividend
    d1 = current_dividend * (1 + growth_rate)

    # Gordon Growth formula
    equity_value = d1 / (cost_of_equity - growth_rate)
    intrinsic_value_per_share = equity_value / shares_outstanding if shares_outstanding > 0 else 0

    return {
        'method': 'Gordon Growth DDM',
        'current_dividend': current_dividend,
        'd1': d1,
        'cost_of_equity': cost_of_equity,
        'growth_rate': growth_rate,
        'equity_value': equity_value,
        'intrinsic_value_per_share': intrinsic_value_per_share,
        'shares_outstanding': shares_outstanding
    }

def calculate_multistage_ddm(current_dividend, cost_of_equity, high_growth_rate,
                             high_growth_years, stable_growth_rate, shares_outstanding):
    """
    Multi-Stage DDM (H-Model or 2-Stage)
    Phase 1: High growth period
    Phase 2: Transition to stable growth
    """
    # Apply constraints
    stable_growth_rate = apply_damodaran_constraints(stable_growth_rate, 'terminal_growth')

    if stable_growth_rate >= cost_of_equity:
        stable_growth_rate = cost_of_equity * 0.9

    pv_dividends = 0
    current_div = current_dividend

    # Phase 1: High growth dividends
    for year in range(1, high_growth_years + 1):
        current_div = current_div * (1 + high_growth_rate)
        pv = current_div / ((1 + cost_of_equity) ** year)
        pv_dividends += pv

    # Terminal value using Gordon Growth
    terminal_dividend = current_div * (1 + stable_growth_rate)
    terminal_value = terminal_dividend / (cost_of_equity - stable_growth_rate)
    pv_terminal = terminal_value / ((1 + cost_of_equity) ** high_growth_years)

    equity_value = pv_dividends + pv_terminal
    intrinsic_value_per_share = equity_value / shares_outstanding if shares_outstanding > 0 else 0

    return {
        'method': 'Multi-Stage DDM',
        'pv_high_growth_dividends': pv_dividends,
        'terminal_value': terminal_value,
        'pv_terminal': pv_terminal,
        'equity_value': equity_value,
        'intrinsic_value_per_share': intrinsic_value_per_share,
        'high_growth_years': high_growth_years,
        'stable_growth_rate': stable_growth_rate,
        'shares_outstanding': shares_outstanding
    }

# ============================================================================
# RESIDUAL INCOME (ECONOMIC PROFIT) MODEL
# ============================================================================

def calculate_residual_income(book_value_equity, roe, cost_of_equity, growth_rate,
                              forecast_years, shares_outstanding):
    """
    Residual Income Model (Edwards-Bell-Ohlson)
    Value = Book Value + PV(Residual Income)
    RI = (ROE - Cost of Equity) √ó Book Value
    """
    # Apply ROE constraints
    roe = apply_damodaran_constraints(roe, 'roe')
    growth_rate = apply_damodaran_constraints(growth_rate, 'terminal_growth')

    pv_residual_income = 0
    current_bv = book_value_equity

    for year in range(1, forecast_years + 1):
        # Calculate residual income
        residual_income = (roe - cost_of_equity) * current_bv

        # Discount to present value
        pv_ri = residual_income / ((1 + cost_of_equity) ** year)
        pv_residual_income += pv_ri

        # Grow book value
        current_bv = current_bv * (1 + roe)

    # Terminal value of residual income
    terminal_ri = (roe - cost_of_equity) * current_bv
    terminal_value = terminal_ri / (cost_of_equity - growth_rate) if (cost_of_equity - growth_rate) > 0 else 0
    pv_terminal = terminal_value / ((1 + cost_of_equity) ** forecast_years)

    equity_value = book_value_equity + pv_residual_income + pv_terminal
    intrinsic_value_per_share = equity_value / shares_outstanding if shares_outstanding > 0 else 0

    return {
        'method': 'Residual Income',
        'book_value_equity': book_value_equity,
        'roe': roe,
        'cost_of_equity': cost_of_equity,
        'pv_residual_income': pv_residual_income,
        'pv_terminal': pv_terminal,
        'equity_value': equity_value,
        'intrinsic_value_per_share': intrinsic_value_per_share,
        'shares_outstanding': shares_outstanding
    }

# ============================================================================
# RELATIVE VALUATION - PEER MULTIPLES
# ============================================================================

def fetch_peer_companies(ticker, sector, max_peers=10):
    """
    Fetch comparable companies for relative valuation
    Uses sector peers with similar market cap
    """
    # Sector peer mapping (simplified - can be enhanced)
    sector_peers = {
        'Technology': ['AAPL', 'MSFT', 'GOOGL', 'META', 'NVDA', 'ORCL', 'CRM', 'ADBE', 'INTC', 'AMD'],
        'Financial Services': ['JPM', 'BAC', 'WFC', 'C', 'GS', 'MS', 'BLK', 'V', 'MA'],
        'Healthcare': ['JNJ', 'UNH', 'PFE', 'ABBV', 'TMO', 'LLY', 'MRK', 'ABT'],
        'Consumer Cyclical': ['AMZN', 'TSLA', 'NKE', 'MCD', 'SBUX', 'HD', 'LOW'],
        'Consumer Defensive': ['WMT', 'PG', 'KO', 'PEP', 'COST', 'CL', 'GIS'],
        'Energy': ['XOM', 'CVX', 'COP', 'SLB', 'EOG', 'PXD'],
        'Industrials': ['BA', 'CAT', 'GE', 'UPS', 'HON', 'LMT', 'RTX'],
        'Communication Services': ['GOOGL', 'META', 'DIS', 'NFLX', 'CMCSA', 'T', 'VZ'],
    }

    peers = sector_peers.get(sector, [])
    # Remove the target ticker from peers
    peers = [p for p in peers if p != ticker]

    return peers[:max_peers]

def calculate_peer_multiples(peers):
    """
    Calculate median multiples from peer companies
    Returns: P/E, EV/EBITDA, EV/EBIT, P/B, EV/Sales, PEG
    """
    multiples_data = []

    for peer in peers:
        try:
            stock = yf.Ticker(peer)
            info = stock.info

            pe = info.get('trailingPE')
            pb = info.get('priceToBook')
            ps = info.get('priceToSalesTrailing12Months')
            peg = info.get('pegRatio')

            # Calculate EV multiples
            market_cap = info.get('marketCap', 0)
            total_debt = info.get('totalDebt', 0)
            cash = info.get('totalCash', 0)
            ev = market_cap + total_debt - cash

            ebitda = info.get('ebitda')
            ebit = info.get('ebit')
            revenue = info.get('totalRevenue')

            ev_ebitda = ev / ebitda if ebitda and ebitda > 0 else None
            ev_ebit = ev / ebit if ebit and ebit > 0 else None
            ev_sales = ev / revenue if revenue and revenue > 0 else None

            # Apply outlier filters
            if pe and VALUATION_CONSTRAINTS['min_pe_multiple'] <= pe <= VALUATION_CONSTRAINTS['max_pe_multiple']:
                multiples_data.append({
                    'ticker': peer,
                    'pe': pe,
                    'pb': pb,
                    'ps': ps,
                    'peg': peg,
                    'ev_ebitda': ev_ebitda,
                    'ev_ebit': ev_ebit,
                    'ev_sales': ev_sales
                })
        except:
            continue

    if not multiples_data:
        return None

    # Calculate median multiples
    df = pd.DataFrame(multiples_data)

    median_multiples = {
        'pe': df['pe'].median(),
        'pb': df['pb'].median(),
        'ps': df['ps'].median(),
        'peg': df['peg'].median(),
        'ev_ebitda': df['ev_ebitda'].median(),
        'ev_ebit': df['ev_ebit'].median(),
        'ev_sales': df['ev_sales'].median(),
        'num_peers': len(multiples_data),
        'peer_data': multiples_data
    }

    return median_multiples

def apply_relative_valuation(company_financials, median_multiples, shares_outstanding):
    """
    Apply peer multiples to company financials
    Returns valuation for each multiple
    """
    results = {}

    # Extract company metrics
    eps = company_financials.get('eps', 0)
    book_value_per_share = company_financials.get('book_value_per_share', 0)
    sales_per_share = company_financials.get('sales_per_share', 0)
    ebitda = company_financials.get('ebitda', 0)
    ebit = company_financials.get('ebit', 0)
    revenue = company_financials.get('revenue', 0)
    total_debt = company_financials.get('total_debt', 0)
    cash = company_financials.get('cash', 0)

    # P/E Valuation
    if median_multiples['pe'] and eps:
        results['pe_value'] = eps * median_multiples['pe']

    # P/B Valuation
    if median_multiples['pb'] and book_value_per_share:
        results['pb_value'] = book_value_per_share * median_multiples['pb']

    # P/S Valuation
    if median_multiples['ps'] and sales_per_share:
        results['ps_value'] = sales_per_share * median_multiples['ps']

    # EV/EBITDA Valuation
    if median_multiples['ev_ebitda'] and ebitda and ebitda > 0:
        ev = ebitda * median_multiples['ev_ebitda']
        equity_value = ev - total_debt + cash
        results['ev_ebitda_value'] = equity_value / shares_outstanding if shares_outstanding > 0 else 0

    # EV/EBIT Valuation
    if median_multiples['ev_ebit'] and ebit and ebit > 0:
        ev = ebit * median_multiples['ev_ebit']
        equity_value = ev - total_debt + cash
        results['ev_ebit_value'] = equity_value / shares_outstanding if shares_outstanding > 0 else 0

    # EV/Sales Valuation
    if median_multiples['ev_sales'] and revenue and revenue > 0:
        ev = revenue * median_multiples['ev_sales']
        equity_value = ev - total_debt + cash
        results['ev_sales_value'] = equity_value / shares_outstanding if shares_outstanding > 0 else 0

    # Calculate average relative valuation
    valid_values = [v for v in results.values() if v is not None and v > 0]
    results['average_relative_value'] = np.median(valid_values) if valid_values else 0
    results['median_multiples'] = median_multiples

    return results

# ============================================================================
# SUM-OF-THE-PARTS (SOTP) VALUATION
# ============================================================================

def calculate_sotp_valuation(segments, discount_rate, shares_outstanding):
    """
    Sum-of-the-Parts valuation for multi-segment companies
    segments = [{'name': 'Segment A', 'revenue': X, 'ebitda_margin': Y, 'multiple': Z}, ...]
    """
    total_value = 0
    segment_values = []

    for segment in segments:
        name = segment.get('name', 'Unnamed')
        revenue = segment.get('revenue', 0)
        ebitda_margin = segment.get('ebitda_margin', 0)
        ev_revenue_multiple = segment.get('ev_revenue_multiple', 0)

        # Calculate segment EBITDA
        ebitda = revenue * ebitda_margin

        # Value segment using EV/Revenue multiple
        segment_ev = revenue * ev_revenue_multiple

        segment_values.append({
            'name': name,
            'revenue': revenue,
            'ebitda': ebitda,
            'ev': segment_ev
        })

        total_value += segment_ev

    # Convert to equity value (simplified - assumes segments share same debt structure)
    intrinsic_value_per_share = total_value / shares_outstanding if shares_outstanding > 0 else 0

    return {
        'method': 'Sum-of-the-Parts',
        'segment_values': segment_values,
        'total_enterprise_value': total_value,
        'intrinsic_value_per_share': intrinsic_value_per_share,
        'shares_outstanding': shares_outstanding
    }

# ============================================================================
# CONSOLIDATED VALUATION SUMMARY
# ============================================================================

def create_valuation_summary_table(valuations_dict, current_price):
    """
    Create consolidated summary table from all valuation methods
    valuations_dict = {'FCFF': result, 'FCFE': result, 'DDM': result, ...}
    """
    summary_data = []

    for method, result in valuations_dict.items():
        if result and 'intrinsic_value_per_share' in result:
            intrinsic_value = result['intrinsic_value_per_share']

            if intrinsic_value > 0:
                upside = ((intrinsic_value - current_price) / current_price) * 100

                summary_data.append({
                    'Method': method,
                    'Intrinsic Value': intrinsic_value,
                    'Current Price': current_price,
                    'Upside/Downside (%)': upside,
                    'Rating': 'BUY' if upside > 20 else ('HOLD' if upside > -10 else 'SELL')
                })

    if not summary_data:
        return None

    df = pd.DataFrame(summary_data)

    # Add summary statistics
    avg_intrinsic = df['Intrinsic Value'].mean()
    median_intrinsic = df['Intrinsic Value'].median()
    avg_upside = df['Upside/Downside (%)'].mean()

    # Consensus rating
    buy_count = len(df[df['Rating'] == 'BUY'])
    hold_count = len(df[df['Rating'] == 'HOLD'])
    sell_count = len(df[df['Rating'] == 'SELL'])

    if buy_count > max(hold_count, sell_count):
        consensus = 'BUY'
    elif sell_count > max(buy_count, hold_count):
        consensus = 'SELL'
    else:
        consensus = 'HOLD'

    summary_stats = {
        'average_intrinsic_value': avg_intrinsic,
        'median_intrinsic_value': median_intrinsic,
        'average_upside': avg_upside,
        'consensus_rating': consensus,
        'num_methods': len(df),
        'buy_count': buy_count,
        'hold_count': hold_count,
        'sell_count': sell_count
    }

    return df, summary_stats

# ============================================================================
# CONSENSUS VALUATION - MULTI-METHOD AGGREGATION
# ============================================================================

def get_industry_average_pe(ticker):
    """Get industry average P/E ratio for comparison"""
    # ATLAS Refactoring - Use cached market data fetcher
    try:
        if REFACTORED_MODULES_AVAILABLE:
            info = market_data.get_company_info(ticker)
        else:
            # Fallback to old method
            stock = yf.Ticker(ticker)
            info = stock.info
        industry = info.get('industry', '')

        # Industry average P/E ratios (approximate benchmarks)
        industry_pe_map = {
            'Software': 30.0,
            'Technology': 25.0,
            'Semiconductors': 22.0,
            'Biotechnology': 20.0,
            'Healthcare': 18.0,
            'Financial Services': 12.0,
            'Banks': 10.0,
            'Insurance': 11.0,
            'Retail': 15.0,
            'Consumer Cyclical': 16.0,
            'Consumer Defensive': 18.0,
            'Energy': 12.0,
            'Utilities': 16.0,
            'Real Estate': 20.0,
            'Industrials': 17.0,
            'Materials': 14.0,
            'Communication Services': 19.0
        }

        # Try to match industry
        for key, pe in industry_pe_map.items():
            if key.lower() in industry.lower():
                return pe

        # Default market average
        return 18.0

    except:
        return 18.0

def get_industry_average_pb(ticker):
    """Get industry average P/B ratio"""
    # ATLAS Refactoring - Use cached market data fetcher
    try:
        if REFACTORED_MODULES_AVAILABLE:
            info = market_data.get_company_info(ticker)
        else:
            # Fallback to old method
            stock = yf.Ticker(ticker)
            info = stock.info
        industry = info.get('industry', '')

        # Industry average P/B ratios
        industry_pb_map = {
            'Software': 8.0,
            'Technology': 6.0,
            'Biotechnology': 4.0,
            'Healthcare': 3.5,
            'Financial Services': 1.5,
            'Banks': 1.2,
            'Insurance': 1.3,
            'Retail': 3.0,
            'Consumer Cyclical': 2.5,
            'Consumer Defensive': 3.0,
            'Energy': 1.5,
            'Utilities': 1.8,
            'Real Estate': 2.0,
            'Industrials': 2.8,
            'Materials': 2.0
        }

        for key, pb in industry_pb_map.items():
            if key.lower() in industry.lower():
                return pb

        return 3.0

    except:
        return 3.0

def get_industry_average_ev_ebitda(ticker):
    """Get industry average EV/EBITDA multiple"""
    # ATLAS Refactoring - Use cached market data fetcher
    try:
        if REFACTORED_MODULES_AVAILABLE:
            info = market_data.get_company_info(ticker)
        else:
            # Fallback to old method
            stock = yf.Ticker(ticker)
            info = stock.info
        industry = info.get('industry', '')

        # Industry average EV/EBITDA multiples
        industry_ev_ebitda_map = {
            'Software': 20.0,
            'Technology': 16.0,
            'Biotechnology': 15.0,
            'Healthcare': 14.0,
            'Financial Services': 10.0,
            'Banks': 8.0,
            'Retail': 10.0,
            'Consumer Cyclical': 11.0,
            'Consumer Defensive': 12.0,
            'Energy': 8.0,
            'Utilities': 10.0,
            'Real Estate': 15.0,
            'Industrials': 11.0,
            'Materials': 9.0
        }

        for key, ev_ebitda in industry_ev_ebitda_map.items():
            if key.lower() in industry.lower():
                return ev_ebitda

        return 12.0

    except:
        return 12.0

def calculate_consensus_valuation(ticker, company_data, financials):
    """
    Calculate consensus valuation from multiple methods with intelligent weighting
    Includes DCF (FCFF & FCFE) using smart assumptions

    Returns:
    --------
    dict with:
        - consensus_value: weighted average valuation
        - confidence_score: 0-100 based on method agreement
        - contributing_methods: dict of methods and values used
        - excluded_methods: dict of methods excluded and why
    """

    # Define method weights (sum to 1.0) - DCF gets highest weight as most comprehensive
    METHOD_WEIGHTS = {
        'FCFF DCF': 0.25,        # Most comprehensive - firm valuation
        'FCFE DCF': 0.20,        # Equity valuation
        'P/E Multiple': 0.15,    # Reduced from 0.25
        'EV/EBITDA': 0.15,       # Reduced from 0.25
        'PEG Ratio': 0.10,       # Reduced from 0.20
        'P/B Multiple': 0.10,    # Reduced from 0.15
        'P/S Multiple': 0.05     # Reduced from 0.15
    }

    valuations = {}
    excluded_methods = {}

    current_price = company_data.get('current_price', 0)
    shares_outstanding = company_data.get('shares_outstanding', 0)

    # Get smart assumptions for DCF methods
    smart_params = calculate_smart_assumptions(company_data, financials)

    # =================================================================
    # DCF METHODS - FCFF and FCFE with Smart Assumptions
    # =================================================================

    # 0A. FCFF DCF Valuation
    try:
        revenue = financials.get('revenue', 0)
        ebit = financials.get('ebit', 0)
        total_debt = financials.get('total_debt', 0)
        cash = financials.get('cash', 0)
        total_equity = financials.get('total_equity', 0)
        beta = company_data.get('beta', 1.0)

        if revenue > 0 and ebit > 0 and shares_outstanding > 0:
            # Calculate discount rate (WACC)
            risk_free_rate = 0.04  # 4% risk-free rate
            market_risk_premium = 0.06  # 6% market risk premium
            cost_of_equity = calculate_cost_of_equity(risk_free_rate, beta, market_risk_premium)
            cost_of_debt = 0.05  # Assume 5% cost of debt

            net_debt = total_debt - cash
            wacc = calculate_wacc(cost_of_equity, cost_of_debt, smart_params['tax_rate'],
                                 total_debt, total_equity)

            # Project FCFF
            projections = project_fcff_enhanced(
                base_revenue=revenue,
                base_ebit=ebit,
                revenue_growth=smart_params['revenue_growth'],
                ebit_margin=smart_params['ebit_margin'],
                tax_rate=smart_params['tax_rate'],
                depreciation_pct=smart_params['depreciation_pct'],
                capex_pct=smart_params['capex_pct'],
                change_wc=smart_params['wc_change'],
                forecast_years=smart_params['forecast_years']
            )

            if projections and len(projections) > 0:
                final_fcf = projections[-1]['fcff']

                # Calculate terminal value
                terminal_value = calculate_terminal_value(
                    final_fcf, wacc, smart_params['terminal_growth']
                )

                # Calculate DCF value
                dcf_result = calculate_dcf_value(
                    projections=projections,
                    discount_rate=wacc,
                    terminal_value=terminal_value,
                    shares_outstanding=shares_outstanding,
                    net_debt=net_debt,
                    method='FCFF'
                )

                intrinsic_value = dcf_result['intrinsic_value_per_share']

                if intrinsic_value > 0 and intrinsic_value < current_price * 10:  # Sanity check
                    valuations['FCFF DCF'] = intrinsic_value
                else:
                    excluded_methods['FCFF DCF'] = f"Unrealistic DCF value: ${intrinsic_value:.2f}"
            else:
                excluded_methods['FCFF DCF'] = "Failed to generate projections"
        else:
            excluded_methods['FCFF DCF'] = "Missing revenue, EBIT, or shares data"
    except Exception as e:
        excluded_methods['FCFF DCF'] = f"Calculation error: {str(e)}"

    # 0B. FCFE DCF Valuation
    try:
        revenue = financials.get('revenue', 0)
        net_income = financials.get('net_income', 0)
        beta = company_data.get('beta', 1.0)

        if revenue > 0 and net_income > 0 and shares_outstanding > 0:
            # Calculate discount rate (cost of equity)
            risk_free_rate = 0.04
            market_risk_premium = 0.06
            cost_of_equity = calculate_cost_of_equity(risk_free_rate, beta, market_risk_premium)

            # Project FCFE
            projections = project_fcfe_enhanced(
                base_revenue=revenue,
                base_net_income=net_income,
                revenue_growth=smart_params['revenue_growth'],
                tax_rate=smart_params['tax_rate'],
                depreciation_pct=smart_params['depreciation_pct'],
                capex_pct=smart_params['capex_pct'],
                change_wc=smart_params['wc_change'],
                net_borrowing=0,  # Assume neutral
                forecast_years=smart_params['forecast_years']
            )

            if projections and len(projections) > 0:
                final_fcf = projections[-1]['fcfe']

                # Calculate terminal value
                terminal_value = calculate_terminal_value(
                    final_fcf, cost_of_equity, smart_params['terminal_growth']
                )

                # Calculate DCF value
                dcf_result = calculate_dcf_value(
                    projections=projections,
                    discount_rate=cost_of_equity,
                    terminal_value=terminal_value,
                    shares_outstanding=shares_outstanding,
                    net_debt=0,  # Already in equity value
                    method='FCFE'
                )

                intrinsic_value = dcf_result['intrinsic_value_per_share']

                if intrinsic_value > 0 and intrinsic_value < current_price * 10:  # Sanity check
                    valuations['FCFE DCF'] = intrinsic_value
                else:
                    excluded_methods['FCFE DCF'] = f"Unrealistic DCF value: ${intrinsic_value:.2f}"
            else:
                excluded_methods['FCFE DCF'] = "Failed to generate projections"
        else:
            excluded_methods['FCFE DCF'] = "Missing revenue, net income, or shares data"
    except Exception as e:
        excluded_methods['FCFE DCF'] = f"Calculation error: {str(e)}"

    # =================================================================
    # MULTIPLES-BASED VALUATION METHODS
    # =================================================================

    # 1. P/E Multiple Valuation
    try:
        # Get EPS
        net_income = financials.get('net_income', 0)
        if shares_outstanding > 0 and net_income > 0:
            eps = net_income / shares_outstanding
            industry_pe = get_industry_average_pe(ticker)

            if eps > 0 and industry_pe > 0:
                pe_value = eps * industry_pe

                # Sanity check
                if current_price > 0:
                    implied_pe = pe_value / eps
                    if 0 < implied_pe < 100:  # Reasonable P/E range
                        valuations['P/E Multiple'] = pe_value
                    else:
                        excluded_methods['P/E Multiple'] = f"Unrealistic P/E ratio: {implied_pe:.1f}"
                else:
                    valuations['P/E Multiple'] = pe_value
            else:
                excluded_methods['P/E Multiple'] = "Negative or missing EPS data"
        else:
            excluded_methods['P/E Multiple'] = "Negative earnings or missing shares data"
    except Exception as e:
        excluded_methods['P/E Multiple'] = f"Calculation error: {str(e)}"

    # 2. P/B Multiple Valuation
    try:
        total_equity = financials.get('total_equity', 0)
        if shares_outstanding > 0 and total_equity > 0:
            book_value_per_share = total_equity / shares_outstanding
            industry_pb = get_industry_average_pb(ticker)

            if book_value_per_share > 0 and industry_pb > 0:
                pb_value = book_value_per_share * industry_pb

                # Sanity check
                if pb_value > 0 and pb_value < book_value_per_share * 15:
                    valuations['P/B Multiple'] = pb_value
                else:
                    excluded_methods['P/B Multiple'] = "Unrealistic P/B multiple"
            else:
                excluded_methods['P/B Multiple'] = "Negative or missing book value"
        else:
            excluded_methods['P/B Multiple'] = "Missing equity or shares data"
    except Exception as e:
        excluded_methods['P/B Multiple'] = f"Calculation error: {str(e)}"

    # 3. EV/EBITDA Valuation
    try:
        ebit = financials.get('ebit', 0)
        depreciation = financials.get('depreciation', 0)
        ebitda = ebit + depreciation

        total_debt = financials.get('total_debt', 0)
        cash = financials.get('cash', 0)
        net_debt = total_debt - cash

        industry_ev_ebitda = get_industry_average_ev_ebitda(ticker)

        if ebitda > 0 and industry_ev_ebitda > 0 and shares_outstanding > 0:
            enterprise_value = ebitda * industry_ev_ebitda
            equity_value = enterprise_value - net_debt
            ev_ebitda_value = equity_value / shares_outstanding

            if ev_ebitda_value > 0:
                valuations['EV/EBITDA'] = ev_ebitda_value
            else:
                excluded_methods['EV/EBITDA'] = "Negative equity value (high debt)"
        else:
            excluded_methods['EV/EBITDA'] = "Missing EBITDA or shares data"
    except Exception as e:
        excluded_methods['EV/EBITDA'] = f"Calculation error: {str(e)}"

    # 4. PEG Ratio Valuation (with comprehensive fallbacks)
    try:
        stock = yf.Ticker(ticker)
        info = stock.info
        peg_value = None
        growth_rate = None
        eps_value = None

        # Get available data points
        peg_ratio = info.get('pegRatio')
        forward_eps = info.get('forwardEps')
        trailing_eps = info.get('trailingEps')
        earnings_growth = info.get('earningsGrowth')  # Forward earnings growth
        earnings_quarterly_growth = info.get('earningsQuarterlyGrowth')
        revenue_growth = info.get('revenueGrowth')
        current_pe = info.get('trailingPE')
        forward_pe = info.get('forwardPE')

        # FALLBACK 1: Use forward EPS and earnings growth (primary method)
        if forward_eps and forward_eps > 0 and earnings_growth and earnings_growth > 0:
            growth_rate = earnings_growth
            eps_value = forward_eps
        # FALLBACK 2: Use trailing EPS and earnings growth
        elif trailing_eps and trailing_eps > 0 and earnings_growth and earnings_growth > 0:
            growth_rate = earnings_growth
            eps_value = trailing_eps
        # FALLBACK 3: Use forward EPS and quarterly growth as proxy
        elif forward_eps and forward_eps > 0 and earnings_quarterly_growth and earnings_quarterly_growth > 0:
            growth_rate = earnings_quarterly_growth
            eps_value = forward_eps
        # FALLBACK 4: Use trailing EPS and revenue growth as proxy (conservative)
        elif trailing_eps and trailing_eps > 0 and revenue_growth and revenue_growth > 0:
            # Use 70% of revenue growth as earnings growth proxy (conservative)
            growth_rate = revenue_growth * 0.7
            eps_value = trailing_eps
        # FALLBACK 5: Back-calculate from existing PEG ratio and P/E
        elif peg_ratio and peg_ratio > 0 and (forward_pe or current_pe):
            pe_value = forward_pe if forward_pe and forward_pe > 0 else current_pe
            if pe_value and pe_value > 0:
                # PEG = P/E / Growth, so Growth = P/E / PEG
                growth_rate = pe_value / peg_ratio / 100  # Convert to decimal
                eps_value = forward_eps if forward_eps and forward_eps > 0 else trailing_eps

        # Calculate PEG-based valuation if we have both growth rate and EPS
        if growth_rate and growth_rate > 0 and eps_value and eps_value > 0:
            # Fair PEG ratio is typically around 1.0
            fair_peg = 1.0
            fair_pe = (growth_rate * 100) * fair_peg  # Convert growth to percentage
            peg_value = eps_value * fair_pe

            # Sanity checks
            if not (0 < fair_pe < 50):  # Reasonable P/E range
                excluded_methods['PEG Ratio'] = f"Unrealistic implied P/E: {fair_pe:.1f}"
            elif not (0 < peg_value < current_price * 5):  # Not more than 5x current price
                excluded_methods['PEG Ratio'] = f"Unrealistic PEG value: ${peg_value:.2f}"
            else:
                valuations['PEG Ratio'] = peg_value
        else:
            excluded_methods['PEG Ratio'] = "Missing EPS or growth data (all fallbacks exhausted)"
    except Exception as e:
        excluded_methods['PEG Ratio'] = f"Calculation error: {str(e)}"

    # 5. P/S (Price-to-Sales) Multiple
    try:
        revenue = financials.get('revenue', 0)
        if shares_outstanding > 0 and revenue > 0:
            sales_per_share = revenue / shares_outstanding

            # Get sector-appropriate P/S ratio
            stock = yf.Ticker(ticker)
            sector = stock.info.get('sector', '')

            sector_ps_map = {
                'Technology': 6.0,
                'Healthcare': 4.0,
                'Financial': 2.5,
                'Consumer Cyclical': 1.5,
                'Consumer Defensive': 1.8,
                'Energy': 1.2,
                'Industrials': 1.5,
                'Utilities': 2.0,
                'Real Estate': 5.0
            }

            ps_multiple = 2.0  # Default
            for key, ps in sector_ps_map.items():
                if key.lower() in sector.lower():
                    ps_multiple = ps
                    break

            ps_value = sales_per_share * ps_multiple

            if ps_value > 0:
                valuations['P/S Multiple'] = ps_value
            else:
                excluded_methods['P/S Multiple'] = "Negative valuation"
        else:
            excluded_methods['P/S Multiple'] = "Missing revenue or shares data"
    except Exception as e:
        excluded_methods['P/S Multiple'] = f"Calculation error: {str(e)}"

    # Filter outliers using IQR method if we have at least 3 methods
    if len(valuations) >= 3:
        values = list(valuations.values())
        q1 = np.percentile(values, 25)
        q3 = np.percentile(values, 75)
        iqr = q3 - q1
        lower_bound = q1 - 1.5 * iqr
        upper_bound = q3 + 1.5 * iqr

        # Remove outliers
        for method, value in list(valuations.items()):
            if value < lower_bound or value > upper_bound:
                excluded_methods[method] = f"Statistical outlier (value: ${value:.2f}, bounds: ${lower_bound:.2f}-${upper_bound:.2f})"
                del valuations[method]

    # Calculate weighted consensus
    if valuations:
        # Normalize weights for available methods
        total_weight = sum(METHOD_WEIGHTS.get(m, 0.1) for m in valuations.keys())

        if total_weight > 0:
            consensus_value = sum(
                valuations[method] * (METHOD_WEIGHTS.get(method, 0.1) / total_weight)
                for method in valuations.keys()
            )

            # Calculate confidence score (0-100)
            # Based on: 1) number of methods, 2) convergence of values
            method_count_score = (len(valuations) / len(METHOD_WEIGHTS)) * 50

            # Convergence score: how tightly clustered are the valuations?
            if len(valuations) > 1:
                cv = np.std(list(valuations.values())) / np.mean(list(valuations.values()))
                convergence_score = max(0, (1 - cv) * 50)
            else:
                convergence_score = 25

            confidence_score = min(100, method_count_score + convergence_score)

            return {
                'consensus_value': consensus_value,
                'confidence_score': confidence_score,
                'contributing_methods': valuations,
                'excluded_methods': excluded_methods,
                'method_count': len(valuations)
            }

    # If no valid valuations
    return {
        'consensus_value': None,
        'confidence_score': 0,
        'contributing_methods': {},
        'excluded_methods': excluded_methods,
        'method_count': 0
    }

# ============================================================================
# PHOENIX PARSER
# ============================================================================

def parse_trade_history_file(uploaded_file):
    try:
        df = pd.read_html(uploaded_file)[0]
        required_cols = ['Date', 'Symbol', 'Trade Type', 'Quantity', 'Price']
        if not all(col in df.columns for col in required_cols):
            return None
        df['Price'] = df['Price'].astype(str).str.replace('$', '').str.replace(',', '').astype(float)
        df['Date'] = pd.to_datetime(df['Date'])
        df = df.sort_values('Date')
        return df
    except:
        return None

def parse_account_history_file(uploaded_file):
    try:
        df = pd.read_html(uploaded_file)[0]
        df['Date'] = pd.to_datetime(df['Date'])
        df = df.sort_values('Date')
        return df
    except:
        return None

def calculate_portfolio_from_trades(trade_df):
    holdings = {}
    for _, row in trade_df.iterrows():
        symbol = row['Symbol']
        trade_type = row['Trade Type']
        quantity = row['Quantity']
        price = row['Price']
        
        if is_option_ticker(symbol):
            continue
        
        if symbol not in holdings:
            holdings[symbol] = {'total_shares': 0, 'total_cost': 0, 'trades': []}
        
        is_buy = 'Buy' in trade_type
        
        if is_buy:
            holdings[symbol]['total_shares'] += quantity
            holdings[symbol]['total_cost'] += (quantity * price)
            holdings[symbol]['trades'].append({'type': 'BUY', 'quantity': quantity, 'price': price})
        else:
            remaining_to_sell = quantity
            for trade in holdings[symbol]['trades']:
                if trade['type'] == 'BUY' and remaining_to_sell > 0:
                    if trade['quantity'] <= remaining_to_sell:
                        holdings[symbol]['total_cost'] -= (trade['quantity'] * trade['price'])
                        holdings[symbol]['total_shares'] -= trade['quantity']
                        remaining_to_sell -= trade['quantity']
                        trade['quantity'] = 0
                    else:
                        holdings[symbol]['total_cost'] -= (remaining_to_sell * trade['price'])
                        holdings[symbol]['total_shares'] -= remaining_to_sell
                        trade['quantity'] -= remaining_to_sell
                        remaining_to_sell = 0
    
    portfolio_data = []
    for symbol, data in holdings.items():
        if data['total_shares'] > 0:
            avg_cost = data['total_cost'] / data['total_shares']
            portfolio_data.append({
                'Ticker': symbol,
                'Shares': data['total_shares'],
                'Avg Cost': avg_cost
            })
    
    if portfolio_data is None or (isinstance(portfolio_data, pd.DataFrame) and portfolio_data.empty):
        return pd.DataFrame(columns=['Ticker', 'Shares', 'Avg Cost'])
    return pd.DataFrame(portfolio_data).sort_values('Ticker')

# ============================================================================
# PORTFOLIO CALCULATIONS
# ============================================================================

@st.cache_data(ttl=600)
def calculate_portfolio_returns(df, start_date, end_date, equity=None):
    """
    Calculate portfolio returns correctly accounting for leverage

    CRITICAL FIX: Returns calculated on EQUITY basis, not gross exposure.
    With leverage, pct_change() on gross exposure understates returns.

    Args:
        df: Portfolio dataframe with positions
        start_date: Start date for historical data
        end_date: End date for historical data
        equity: User's equity capital (default: from session state)

    Returns:
        Returns series calculated on equity basis (leverage amplified)
    """
    try:
        valid_positions = []
        for _, row in df.iterrows():
            if not is_option_ticker(row['Ticker']):
                valid_positions.append(row)

        if not valid_positions:
            return None

        valid_df = pd.DataFrame(valid_positions)
        all_data = {}

        for _, row in valid_df.iterrows():
            ticker = row['Ticker']
            data = fetch_historical_data(ticker, start_date, end_date)
            if data is not None and len(data) > 0:
                all_data[ticker] = data

        if not all_data:
            return None

        common_dates = None
        for ticker, data in all_data.items():
            dates = set(data.index)
            common_dates = dates if common_dates is None else common_dates.intersection(dates)

        common_dates = sorted(list(common_dates))
        if len(common_dates) < 2:
            return None

        # Calculate daily portfolio gross values
        portfolio_values = []
        for date in common_dates:
            daily_value = 0
            for _, row in valid_df.iterrows():
                ticker = row['Ticker']
                if ticker in all_data:
                    try:
                        price = all_data[ticker].loc[date, 'Close']
                        daily_value += price * row['Shares']
                    except KeyError:
                        continue
            portfolio_values.append(daily_value)

        portfolio_series = pd.Series(portfolio_values, index=common_dates)

        # CRITICAL FIX: Calculate returns on EQUITY basis, not gross exposure
        # Get equity from performance history or session state if not provided
        if equity is None:
            # Try to get from performance history first
            metrics = get_current_portfolio_metrics()
            if metrics and metrics.get('equity', 0) > 0:
                equity = metrics['equity']
            else:
                # Fallback to session state, then initial portfolio value
                equity = st.session_state.get('equity_capital', portfolio_values[0])

        # Calculate dollar changes in portfolio value
        portfolio_changes = portfolio_series.diff()

        # Returns = dollar change / equity (not / previous gross value)
        # This correctly amplifies returns with leverage
        returns = portfolio_changes / equity

        # Drop first NaN value
        returns = returns.dropna()

        return returns
    except:
        return None

# ============================================================================
# BRINSON ATTRIBUTION ANALYSIS - NEW IN v9.7
# ============================================================================

# S&P 500 Sector Weights (Benchmark)
SP500_SECTOR_WEIGHTS = {
    'Technology': 28.5,
    'Healthcare': 13.2,
    'Financial Services': 12.8,
    'Consumer Cyclical': 10.5,
    'Communication Services': 8.7,
    'Industrials': 8.3,
    'Consumer Defensive': 6.8,
    'Energy': 4.2,
    'Real Estate': 2.5,
    'Basic Materials': 2.3,
    'Utilities': 2.2
}

@st.cache_data(ttl=3600)
def get_benchmark_sector_returns(period='1Y'):
    """
    Fetch sector ETF returns as proxy for benchmark sector performance
    """
    sector_etfs = {
        'Technology': 'XLK',
        'Healthcare': 'XLV',
        'Financial Services': 'XLF',
        'Consumer Cyclical': 'XLY',
        'Communication Services': 'XLC',
        'Industrials': 'XLI',
        'Consumer Defensive': 'XLP',
        'Energy': 'XLE',
        'Real Estate': 'XLRE',
        'Basic Materials': 'XLB',
        'Utilities': 'XLU'
    }

    benchmark_returns = {}

    # Calculate date range based on period
    end_date = datetime.now()
    if period == '1Y':
        start_date = end_date - timedelta(days=365)
    elif period == 'YTD':
        start_date = datetime(end_date.year, 1, 1)
    elif period == '3M':
        start_date = end_date - timedelta(days=90)
    else:
        start_date = end_date - timedelta(days=365)

    for sector, etf in sector_etfs.items():
        try:
            data = fetch_historical_data(etf, start_date=start_date, end_date=end_date)
            if data is not None and len(data) > 0:
                total_return = ((data['Close'].iloc[-1] / data['Close'].iloc[0]) - 1) * 100
                benchmark_returns[sector] = total_return
            else:
                benchmark_returns[sector] = 0.0
        except:
            benchmark_returns[sector] = 0.0

    return benchmark_returns

def calculate_skill_score(effect_value):
    """
    Convert attribution effect to skill score (0-10 scale)

    Positive effects = higher scores
    Scale: -5% to +5% maps to 0-10
    """
    # Normalize to 0-10 scale
    if effect_value >= 5:
        return 10.0
    elif effect_value <= -5:
        return 0.0
    else:
        return 5.0 + (effect_value / 5.0) * 5.0


def calculate_brinson_attribution_gics(portfolio_df, period='1y'):
    """
    Calculate Brinson attribution using correct GICS sector classification.
    This version matches S&P 500 / SPY benchmark classification for accurate results.

    Parameters:
    -----------
    portfolio_df : pd.DataFrame
        Portfolio holdings with columns: Ticker, Weight % (or Total Value), Total Gain/Loss %
    period : str
        Time period for returns ('1y', '6mo', '3mo', '1mo', 'ytd')

    Returns:
    --------
    dict with:
        - attribution_df: DataFrame with sector-level attribution
        - stock_attribution_df: DataFrame with stock-level attribution
        - total_allocation_effect, total_selection_effect, total_interaction_effect
        - total_attribution
        - allocation_skill_score, selection_skill_score
        - validation: dict with reconciliation info
    """
    df = portfolio_df.copy()

    # Step 1: Apply GICS sector classification
    df['GICS_Sector'] = df['Ticker'].apply(get_gics_sector)

    # Step 2: Calculate portfolio weights if not provided
    if 'Weight %' not in df.columns:
        if 'Total Value' in df.columns:
            total_value = df['Total Value'].sum()
            df['Weight %'] = (df['Total Value'] / total_value) * 100
        else:
            # Equal weight
            df['Weight %'] = 100 / len(df)

    # Step 3: Get benchmark weights and returns
    benchmark_weights = get_spy_sector_weights()
    benchmark_returns = get_benchmark_sector_returns(period=period)

    # Step 4: Get benchmark total return (SPY)
    try:
        spy_data = yf.Ticker('SPY').history(period=period)
        benchmark_total_return = (spy_data['Close'].iloc[-1] / spy_data['Close'].iloc[0] - 1) * 100
    except:
        benchmark_total_return = sum(benchmark_weights[s] / 100 * benchmark_returns.get(s, 0)
                                     for s in benchmark_weights.keys())

    # Step 5: Aggregate portfolio by GICS sector
    # Use value-weighted returns within each sector
    portfolio_sectors = df.groupby('GICS_Sector').agg({
        'Weight %': 'sum',
        'Total Gain/Loss %': lambda x: np.average(x, weights=df.loc[x.index, 'Weight %'])
    }).reset_index()

    portfolio_sectors.columns = ['Sector', 'Portfolio Weight', 'Portfolio Return']
    portfolio_sectors['Portfolio Weight'] = portfolio_sectors['Portfolio Weight'] / 100

    # Step 6: Calculate attribution for each sector
    results = []

    for _, row in portfolio_sectors.iterrows():
        sector = row['Sector']

        # Portfolio weight and return
        wp = row['Portfolio Weight']
        rp = row['Portfolio Return'] / 100

        # Benchmark weight and return
        wb = benchmark_weights.get(sector, 0) / 100
        rb = benchmark_returns.get(sector, 0) / 100

        # Benchmark total return
        rb_total = benchmark_total_return / 100

        # Brinson-Fachler Attribution:
        # Allocation Effect = (wp - wb) √ó (rb - rb_total)
        # Selection Effect = wp √ó (rp - rb)  # Using portfolio weight (Brinson-Fachler)
        # Interaction Effect = (wp - wb) √ó (rp - rb)

        allocation_effect = (wp - wb) * (rb - rb_total) * 100
        selection_effect = wp * (rp - rb) * 100
        interaction_effect = (wp - wb) * (rp - rb) * 100

        results.append({
            'Sector': sector,
            'Portfolio Weight': wp * 100,
            'Benchmark Weight': wb * 100,
            'Weight Diff': (wp - wb) * 100,
            'Portfolio Return': rp * 100,
            'Benchmark Return': rb * 100,
            'Return Diff': (rp - rb) * 100,
            'Allocation Effect': allocation_effect,
            'Selection Effect': selection_effect,
            'Interaction Effect': interaction_effect,
            'Total Effect': allocation_effect + selection_effect + interaction_effect
        })

    # Include sectors where portfolio has 0% but benchmark has weight
    portfolio_sector_list = portfolio_sectors['Sector'].tolist()
    for sector, wb in benchmark_weights.items():
        if sector not in portfolio_sector_list and wb > 0:
            wb_pct = wb / 100
            rb = benchmark_returns.get(sector, 0) / 100
            rb_total = benchmark_total_return / 100

            # Portfolio has 0% in this sector
            allocation_effect = (0 - wb_pct) * (rb - rb_total) * 100
            selection_effect = 0  # No selection effect when no holdings
            interaction_effect = 0

            results.append({
                'Sector': sector,
                'Portfolio Weight': 0,
                'Benchmark Weight': wb,
                'Weight Diff': -wb,
                'Portfolio Return': 0,
                'Benchmark Return': rb * 100,
                'Return Diff': -rb * 100,
                'Allocation Effect': allocation_effect,
                'Selection Effect': selection_effect,
                'Interaction Effect': interaction_effect,
                'Total Effect': allocation_effect
            })

    attribution_df = pd.DataFrame(results)
    attribution_df = attribution_df.sort_values('Total Effect', ascending=False)

    # Step 7: Calculate totals
    total_allocation = attribution_df['Allocation Effect'].sum()
    total_selection = attribution_df['Selection Effect'].sum()
    total_interaction = attribution_df['Interaction Effect'].sum()
    total_attribution = total_allocation + total_selection + total_interaction

    # Step 8: Calculate stock-level attribution
    stock_results = []
    portfolio_total_return = (df['Weight %'] * df['Total Gain/Loss %']).sum() / 100

    # SPY weights for major holdings (approximate, as of recent data)
    SPY_WEIGHTS = {
        'AAPL': 7.0, 'MSFT': 6.5, 'NVDA': 5.5, 'GOOGL': 3.5, 'GOOG': 3.5,
        'AMZN': 3.5, 'META': 2.5, 'TSLA': 2.0, 'BRK.B': 1.7, 'LLY': 1.5,
        'V': 1.2, 'JPM': 1.15, 'UNH': 1.1, 'XOM': 1.05, 'MA': 1.0,
        'JNJ': 0.95, 'PG': 0.9, 'AVGO': 0.9, 'HD': 0.85, 'CVX': 0.8,
        'MRK': 0.75, 'ABBV': 0.75, 'COST': 0.7, 'PEP': 0.7, 'KO': 0.65,
        'BAC': 0.65, 'NFLX': 0.6, 'CRM': 0.6, 'AMD': 0.55, 'WMT': 0.55,
        'ADBE': 0.5, 'TMO': 0.5, 'DIS': 0.5, 'ACN': 0.45, 'CSCO': 0.45,
        'ABT': 0.45, 'VZ': 0.4, 'T': 0.4, 'ORCL': 0.4, 'INTC': 0.4,
        'WFC': 0.4, 'C': 0.35, 'QCOM': 0.35, 'UPS': 0.35, 'PM': 0.35,
        'MS': 0.3, 'GS': 0.3, 'AXP': 0.3, 'BA': 0.3, 'CAT': 0.3,
        'IBM': 0.3, 'NOW': 0.3, 'BKR': 0.25, 'NVT': 0.2,
    }

    for _, row in df.iterrows():
        ticker = row['Ticker']
        weight = row['Weight %'] / 100
        stock_return = row['Total Gain/Loss %'] / 100
        sector = row['GICS_Sector']

        # Get SPY index weight (0 if not in index)
        index_weight = SPY_WEIGHTS.get(ticker, 0.0)

        # Benchmark return for this sector
        sector_benchmark_return = benchmark_returns.get(sector, 0) / 100

        # Contribution to portfolio return
        contribution = weight * stock_return * 100

        # Active contribution (vs if held at benchmark sector return)
        active_contribution = weight * (stock_return - sector_benchmark_return) * 100

        stock_results.append({
            'Ticker': ticker,
            'GICS_Sector': sector,
            'Weight %': weight * 100,
            'Index Weight %': index_weight,  # SPY weight
            'Return %': stock_return * 100,
            'Sector Benchmark Return %': sector_benchmark_return * 100,
            'Return vs Sector': (stock_return - sector_benchmark_return) * 100,
            'Contribution %': contribution,
            'Active Contribution %': active_contribution
        })

    stock_attribution_df = pd.DataFrame(stock_results)
    stock_attribution_df = stock_attribution_df.sort_values('Active Contribution %', ascending=False)

    # Step 9: Validation - LINK TO PERFORMANCE SUITE
    # PRIORITY: Use Performance Suite's annualized return if available (session state)
    # This ensures Attribution shows the EXACT SAME value as Performance Suite

    # CHECK SESSION STATE FIRST - This is the linked value from Performance Suite
    performance_suite_return = st.session_state.get('portfolio_annualized_return')

    if performance_suite_return is not None:
        # USE PERFORMANCE SUITE VALUE - This is the correct linked value
        actual_portfolio_return = performance_suite_return
        actual_benchmark_return_val = benchmark_total_return  # Use benchmark from holdings
        actual_alpha = actual_portfolio_return - actual_benchmark_return_val
        attribution_sum = total_allocation + total_selection + total_interaction
        reconciliation_diff = abs(actual_alpha - attribution_sum)

        validation = {
            'portfolio_return': actual_portfolio_return,  # FROM PERFORMANCE SUITE
            'benchmark_return': actual_benchmark_return_val,
            'actual_alpha': actual_alpha,
            'attribution_sum': attribution_sum,
            'reconciliation_diff': reconciliation_diff,
            'is_reconciled': reconciliation_diff < 5.0,
            'source': 'performance_suite',  # Indicates linked to Performance Suite
        }
    else:
        # Fallback to point-in-time holdings return (if Performance Suite not visited yet)
        actual_alpha = portfolio_total_return - benchmark_total_return
        attribution_sum = total_allocation + total_selection + total_interaction
        reconciliation_diff = abs(actual_alpha - attribution_sum)

        validation = {
            'portfolio_return': portfolio_total_return,
            'benchmark_return': benchmark_total_return,
            'actual_alpha': actual_alpha,
            'attribution_sum': attribution_sum,
            'reconciliation_diff': reconciliation_diff,
            'is_reconciled': reconciliation_diff < 1.0,
            'source': 'point_in_time',
            'warning': 'Visit Performance Suite first to see accurate returns.'
        }

    return {
        'attribution_df': attribution_df,
        'stock_attribution_df': stock_attribution_df,
        'total_allocation_effect': total_allocation,
        'total_selection_effect': total_selection,
        'total_interaction_effect': total_interaction,
        'total_attribution': total_attribution,
        'allocation_skill_score': calculate_skill_score(total_allocation),
        'selection_skill_score': calculate_skill_score(total_selection),
        'validation': validation,
        'benchmark_weights': benchmark_weights,
        'benchmark_returns': benchmark_returns
    }


def display_stock_attribution_table(stock_df):
    """
    Display stock-level attribution in glassmorphism styled cards.

    Parameters:
        stock_df: DataFrame from calculate_brinson_attribution_gics
    """
    # Top Contributors - Show Top 10
    top_contributors = stock_df.head(10)
    bottom_contributors = stock_df.tail(10).iloc[::-1]  # Reverse to show worst first

    top_html = """
<div style="background: rgba(26, 35, 50, 0.7); backdrop-filter: blur(10px); border: 1px solid rgba(0, 212, 255, 0.2); border-radius: 12px; padding: 20px; margin: 10px 0;">
<h4 style="color: #00d4ff; margin: 0 0 15px 0; font-family: 'Inter', sans-serif; text-transform: uppercase; letter-spacing: 0.1em;">üèÜ Top Alpha Contributors</h4>
<table style="width: 100%; border-collapse: collapse; font-family: 'Inter', sans-serif;">
<tr style="border-bottom: 1px solid rgba(0, 212, 255, 0.2);">
<th style="text-align: left; padding: 8px; color: #8890a0; font-size: 0.75rem; text-transform: uppercase;">Ticker</th>
<th style="text-align: left; padding: 8px; color: #8890a0; font-size: 0.75rem; text-transform: uppercase;">Sector</th>
<th style="text-align: right; padding: 8px; color: #8890a0; font-size: 0.75rem; text-transform: uppercase;">Weight</th>
<th style="text-align: right; padding: 8px; color: #8890a0; font-size: 0.75rem; text-transform: uppercase;">Index Wt</th>
<th style="text-align: right; padding: 8px; color: #8890a0; font-size: 0.75rem; text-transform: uppercase;">Return</th>
<th style="text-align: right; padding: 8px; color: #8890a0; font-size: 0.75rem; text-transform: uppercase;">vs Sector</th>
<th style="text-align: right; padding: 8px; color: #8890a0; font-size: 0.75rem; text-transform: uppercase;">Alpha Contrib</th>
</tr>
"""
    for _, row in top_contributors.iterrows():
        color = '#00ff9d' if row['Active Contribution %'] > 0 else '#ff006b'
        index_wt = row.get('Index Weight %', 0)
        top_html += f"""
<tr style="border-bottom: 1px solid rgba(255,255,255,0.05);">
<td style="padding: 10px; color: #00d4ff; font-weight: 600;">{row['Ticker']}</td>
<td style="padding: 10px; color: #c0c8d0; font-size: 0.85rem;">{row['GICS_Sector']}</td>
<td style="padding: 10px; color: #c0c8d0; text-align: right;">{row['Weight %']:.1f}%</td>
<td style="padding: 10px; color: #8890a0; text-align: right;">{index_wt:.1f}%</td>
<td style="padding: 10px; color: {'#00ff9d' if row['Return %'] > 0 else '#ff006b'}; text-align: right; font-family: 'JetBrains Mono', monospace;">{row['Return %']:+.1f}%</td>
<td style="padding: 10px; color: {'#00ff9d' if row['Return vs Sector'] > 0 else '#ff006b'}; text-align: right; font-family: 'JetBrains Mono', monospace;">{row['Return vs Sector']:+.1f}%</td>
<td style="padding: 10px; color: {color}; text-align: right; font-weight: 700; font-family: 'JetBrains Mono', monospace;">{row['Active Contribution %']:+.2f}%</td>
</tr>
"""
    top_html += "</table></div>"

    # Bottom Contributors
    bottom_html = """
<div style="background: rgba(26, 35, 50, 0.7); backdrop-filter: blur(10px); border: 1px solid rgba(255, 0, 107, 0.2); border-radius: 12px; padding: 20px; margin: 10px 0;">
<h4 style="color: #ff006b; margin: 0 0 15px 0; font-family: 'Inter', sans-serif; text-transform: uppercase; letter-spacing: 0.1em;">üìâ Top Alpha Detractors</h4>
<table style="width: 100%; border-collapse: collapse; font-family: 'Inter', sans-serif;">
<tr style="border-bottom: 1px solid rgba(255, 0, 107, 0.2);">
<th style="text-align: left; padding: 8px; color: #8890a0; font-size: 0.75rem; text-transform: uppercase;">Ticker</th>
<th style="text-align: left; padding: 8px; color: #8890a0; font-size: 0.75rem; text-transform: uppercase;">Sector</th>
<th style="text-align: right; padding: 8px; color: #8890a0; font-size: 0.75rem; text-transform: uppercase;">Weight</th>
<th style="text-align: right; padding: 8px; color: #8890a0; font-size: 0.75rem; text-transform: uppercase;">Index Wt</th>
<th style="text-align: right; padding: 8px; color: #8890a0; font-size: 0.75rem; text-transform: uppercase;">Return</th>
<th style="text-align: right; padding: 8px; color: #8890a0; font-size: 0.75rem; text-transform: uppercase;">vs Sector</th>
<th style="text-align: right; padding: 8px; color: #8890a0; font-size: 0.75rem; text-transform: uppercase;">Alpha Contrib</th>
</tr>
"""
    for _, row in bottom_contributors.iterrows():
        color = '#00ff9d' if row['Active Contribution %'] > 0 else '#ff006b'
        index_wt = row.get('Index Weight %', 0)
        bottom_html += f"""
<tr style="border-bottom: 1px solid rgba(255,255,255,0.05);">
<td style="padding: 10px; color: #ff006b; font-weight: 600;">{row['Ticker']}</td>
<td style="padding: 10px; color: #c0c8d0; font-size: 0.85rem;">{row['GICS_Sector']}</td>
<td style="padding: 10px; color: #c0c8d0; text-align: right;">{row['Weight %']:.1f}%</td>
<td style="padding: 10px; color: #8890a0; text-align: right;">{index_wt:.1f}%</td>
<td style="padding: 10px; color: {'#00ff9d' if row['Return %'] > 0 else '#ff006b'}; text-align: right; font-family: 'JetBrains Mono', monospace;">{row['Return %']:+.1f}%</td>
<td style="padding: 10px; color: {'#00ff9d' if row['Return vs Sector'] > 0 else '#ff006b'}; text-align: right; font-family: 'JetBrains Mono', monospace;">{row['Return vs Sector']:+.1f}%</td>
<td style="padding: 10px; color: {color}; text-align: right; font-weight: 700; font-family: 'JetBrains Mono', monospace;">{row['Active Contribution %']:+.2f}%</td>
</tr>
"""
    bottom_html += "</table></div>"

    return top_html, bottom_html


def display_attribution_validation(validation):
    """
    Display attribution validation/reconciliation info.
    Now shows data source (performance history vs point-in-time) and additional context.
    """
    is_valid = validation['is_reconciled']
    source = validation.get('source', 'unknown')

    # Color coding based on data source quality
    if source == 'performance_suite':
        # LINKED TO PERFORMANCE SUITE - Best quality
        status_color = '#00ff9d' if is_valid else '#ffd93d'
        status_icon = '‚úì' if is_valid else '‚ö†'
        source_badge = '<span style="background: #00ff9d; color: #0a0f1a; padding: 2px 8px; border-radius: 4px; font-size: 0.65rem; margin-left: 10px;">LINKED TO PERFORMANCE SUITE</span>'
    elif source == 'performance_history':
        status_color = '#00ff9d' if is_valid else '#ffd93d'
        status_icon = '‚úì' if is_valid else '‚ö†'
        source_badge = '<span style="background: #00d4ff; color: #0a0f1a; padding: 2px 8px; border-radius: 4px; font-size: 0.65rem; margin-left: 10px;">FROM PERFORMANCE HISTORY</span>'
    else:
        status_color = '#ffd93d'
        status_icon = '‚ö†'
        source_badge = '<span style="background: #ffd93d; color: #0a0f1a; padding: 2px 8px; border-radius: 4px; font-size: 0.65rem; margin-left: 10px;">POINT-IN-TIME (Visit Performance Suite first)</span>'

    # Build additional info based on source
    additional_info = ""
    if source == 'performance_history' and validation.get('days'):
        days = validation.get('days', 0)
        portfolio_start = validation.get('portfolio_start', 0)
        portfolio_end = validation.get('portfolio_end', 0)
        additional_info = f"""
<div style="margin-top: 10px; padding: 8px; background: rgba(0, 212, 255, 0.05); border-radius: 4px; font-size: 0.75rem; color: #8890a0;">
<strong style="color: #00d4ff;">Period:</strong> {days} days |
<strong style="color: #00d4ff;">Portfolio:</strong> ${portfolio_start:,.0f} ‚Üí ${portfolio_end:,.0f}
</div>
"""

    warning_html = ""
    if validation.get('warning'):
        warning_html = f"""
<div style="margin-top: 10px; padding: 10px; background: rgba(255, 217, 61, 0.1); border-left: 3px solid #ffd93d; border-radius: 4px;">
<span style="color: #ffd93d;">‚ö†Ô∏è {validation['warning']}</span>
</div>
"""

    html = f"""
<div style="background: rgba(26, 35, 50, 0.7); backdrop-filter: blur(10px); border: 1px solid rgba(0, 212, 255, 0.2); border-radius: 12px; padding: 20px; margin: 20px 0;">
<h4 style="color: #00d4ff; margin: 0 0 15px 0; font-family: 'Inter', sans-serif; text-transform: uppercase; letter-spacing: 0.1em;">üìä Attribution Reconciliation{source_badge}</h4>
<div style="display: grid; grid-template-columns: repeat(4, 1fr); gap: 15px;">
<div style="background: rgba(10, 15, 26, 0.6); border-radius: 8px; padding: 12px; text-align: center;">
<div style="color: #8890a0; font-size: 0.7rem; text-transform: uppercase; margin-bottom: 5px;">Portfolio Return (Ann.)</div>
<div style="color: {'#00ff9d' if validation['portfolio_return'] > 0 else '#ff006b'}; font-size: 1.5rem; font-weight: 700; font-family: 'JetBrains Mono', monospace;">{validation['portfolio_return']:+.2f}%</div>
</div>
<div style="background: rgba(10, 15, 26, 0.6); border-radius: 8px; padding: 12px; text-align: center;">
<div style="color: #8890a0; font-size: 0.7rem; text-transform: uppercase; margin-bottom: 5px;">Benchmark Return (SPY)</div>
<div style="color: {'#00ff9d' if validation['benchmark_return'] > 0 else '#ff006b'}; font-size: 1.5rem; font-weight: 700; font-family: 'JetBrains Mono', monospace;">{validation['benchmark_return']:+.2f}%</div>
</div>
<div style="background: rgba(10, 15, 26, 0.6); border-radius: 8px; padding: 12px; text-align: center;">
<div style="color: #8890a0; font-size: 0.7rem; text-transform: uppercase; margin-bottom: 5px;">Actual Alpha</div>
<div style="color: {'#00ff9d' if validation['actual_alpha'] > 0 else '#ff006b'}; font-size: 1.8rem; font-weight: 700; font-family: 'JetBrains Mono', monospace;">{validation['actual_alpha']:+.2f}%</div>
</div>
<div style="background: rgba(10, 15, 26, 0.6); border-radius: 8px; padding: 12px; text-align: center;">
<div style="color: #8890a0; font-size: 0.7rem; text-transform: uppercase; margin-bottom: 5px;">Attribution Sum</div>
<div style="color: {'#00ff9d' if validation['attribution_sum'] > 0 else '#ff006b'}; font-size: 1.5rem; font-weight: 700; font-family: 'JetBrains Mono', monospace;">{validation['attribution_sum']:+.2f}%</div>
</div>
</div>
<div style="margin-top: 15px; padding: 10px; background: linear-gradient(90deg, rgba({status_color[1:]}, 0.1) 0%, transparent 100%); border-left: 3px solid {status_color}; border-radius: 4px;">
<span style="color: {status_color}; font-weight: 600;">{status_icon} {'Attribution Reconciled' if is_valid else 'Reconciliation Difference (trades/timing)'}</span>
<span style="color: #8890a0; margin-left: 10px;">Difference: {validation['reconciliation_diff']:.2f}%</span>
</div>
{additional_info}
{warning_html}
</div>
"""
    return html


def calculate_brinson_attribution(portfolio_df, benchmark_weights, benchmark_returns, period='YTD'):
    """
    Calculate Brinson attribution: Allocation, Selection, and Interaction effects

    Parameters:
    -----------
    portfolio_df : pd.DataFrame
        Portfolio holdings with columns: Ticker, Sector, Weight %, Total Gain/Loss %
    benchmark_weights : dict
        Benchmark sector weights {sector: weight}
    benchmark_returns : dict
        Benchmark sector returns {sector: return}
    period : str
        Time period for analysis (YTD, 1Y, etc.)

    Returns:
    --------
    dict with attribution_df, total_allocation_effect, total_selection_effect,
    total_interaction_effect, total_attribution, allocation_skill_score, selection_skill_score
    """

    # Group portfolio by sector
    portfolio_sectors = portfolio_df.groupby('Sector').agg({
        'Weight %': 'sum',
        'Total Gain/Loss %': 'mean'  # Average return in sector
    }).reset_index()

    portfolio_sectors.columns = ['Sector', 'Portfolio Weight', 'Portfolio Return']
    portfolio_sectors['Portfolio Weight'] = portfolio_sectors['Portfolio Weight'] / 100

    results = []

    # Calculate benchmark total return (weighted average)
    rb_total = sum([benchmark_weights.get(s, 0) / 100 * benchmark_returns.get(s, 0) / 100
                   for s in benchmark_weights.keys()])

    for sector in portfolio_sectors['Sector']:
        # Get weights
        wp = portfolio_sectors[portfolio_sectors['Sector'] == sector]['Portfolio Weight'].iloc[0]
        wb = benchmark_weights.get(sector, 0) / 100

        # Get returns
        rp = portfolio_sectors[portfolio_sectors['Sector'] == sector]['Portfolio Return'].iloc[0] / 100
        rb = benchmark_returns.get(sector, 0) / 100

        # Brinson Attribution Formula:
        # Allocation Effect = (wp - wb) √ó (rb - rb_total)
        # Selection Effect = wb √ó (rp - rb)
        # Interaction Effect = (wp - wb) √ó (rp - rb)

        allocation_effect = (wp - wb) * (rb - rb_total) * 100
        selection_effect = wb * (rp - rb) * 100
        interaction_effect = (wp - wb) * (rp - rb) * 100

        results.append({
            'Sector': sector,
            'Portfolio Weight': wp * 100,
            'Benchmark Weight': wb * 100,
            'Weight Diff': (wp - wb) * 100,
            'Portfolio Return': rp * 100,
            'Benchmark Return': rb * 100,
            'Return Diff': (rp - rb) * 100,
            'Allocation Effect': allocation_effect,
            'Selection Effect': selection_effect,
            'Interaction Effect': interaction_effect,
            'Total Effect': allocation_effect + selection_effect + interaction_effect
        })

    attribution_df = pd.DataFrame(results)

    # Calculate totals
    total_allocation = attribution_df['Allocation Effect'].sum()
    total_selection = attribution_df['Selection Effect'].sum()
    total_interaction = attribution_df['Interaction Effect'].sum()
    total_attribution = total_allocation + total_selection + total_interaction

    return {
        'attribution_df': attribution_df,
        'total_allocation_effect': total_allocation,
        'total_selection_effect': total_selection,
        'total_interaction_effect': total_interaction,
        'total_attribution': total_attribution,
        'allocation_skill_score': calculate_skill_score(total_allocation),
        'selection_skill_score': calculate_skill_score(total_selection)
    }

def create_brinson_attribution_chart(attribution_results, use_professional_theme=True):
    """
    Create waterfall chart showing allocation, selection, and interaction effects
    Professional Blue theme with clean styling
    """

    # Aggregate by effect type
    total_allocation = attribution_results['total_allocation_effect']
    total_selection = attribution_results['total_selection_effect']
    total_interaction = attribution_results['total_interaction_effect']
    total = attribution_results['total_attribution']

    # Theme colors
    if use_professional_theme and PROFESSIONAL_THEME_AVAILABLE:
        connector_color = 'rgba(255, 255, 255, 0.5)'
        success_color = '#00E676'
        danger_color = '#FF1744'
        total_color = '#00BCD4'
        title_color = '#FFFFFF'
        text_color = '#FFFFFF'
        paper_bg = '#1a1d29'
        grid_color = 'rgba(255, 255, 255, 0.1)'
    else:
        connector_color = COLORS['neon_blue']
        success_color = COLORS['success']
        danger_color = COLORS['danger']
        total_color = COLORS['electric_blue']
        title_color = '#ffffff'
        text_color = '#ffffff'
        paper_bg = 'rgba(0, 0, 0, 0)'
        grid_color = 'rgba(99, 102, 241, 0.1)'

    fig = go.Figure(go.Waterfall(
        name="Attribution",
        orientation="v",
        x=['Allocation<br>Effect', 'Selection<br>Effect', 'Interaction<br>Effect', 'Total<br>Attribution'],
        y=[total_allocation, total_selection, total_interaction, total],
        measure=['relative', 'relative', 'relative', 'total'],
        text=[f"{total_allocation:+.2f}%", f"{total_selection:+.2f}%",
              f"{total_interaction:+.2f}%", f"{total:.2f}%"],
        textposition="outside",
        textfont=dict(size=12, family='JetBrains Mono', color=text_color),
        connector={"line": {"color": connector_color, "width": 2}},
        decreasing={"marker": {"color": danger_color}},
        increasing={"marker": {"color": success_color}},
        totals={"marker": {"color": total_color}}
    ))

    fig.update_layout(
        title=dict(text="üìä Brinson Attribution: Portfolio Outperformance Breakdown",
                   font=dict(size=16, color=title_color, family='Inter'), x=0.02, xanchor='left'),
        yaxis=dict(title="Effect (%)", showgrid=True, gridcolor=grid_color,
                   tickfont=dict(size=10, color=text_color)),
        xaxis=dict(tickfont=dict(size=10, color=text_color)),
        height=450,
        showlegend=False,
        paper_bgcolor=paper_bg,
        plot_bgcolor=paper_bg,
        font=dict(family='Inter', color=text_color),
        margin=dict(l=60, r=30, t=60, b=50)
    )

    if not use_professional_theme:
        apply_chart_theme(fig)
    return fig

def create_skill_assessment_card(attribution_results):
    """
    Create visual skill assessment comparing allocation vs selection
    Uses glassmorphism styling to match ATLAS dashboard theme
    """

    allocation_score = attribution_results['allocation_skill_score']
    selection_score = attribution_results['selection_skill_score']

    allocation_effect = attribution_results['total_allocation_effect']
    selection_effect = attribution_results['total_selection_effect']

    # Determine primary skill
    if allocation_score > selection_score + 2:
        primary_skill = "Sector Timing (Allocation)"
        recommendation = "Focus on sector rotation strategies. Consider using sector ETFs."
    elif selection_score > allocation_score + 2:
        primary_skill = "Stock Picking (Selection)"
        recommendation = "Focus on fundamental analysis. Your stock picks add value."
    else:
        primary_skill = "Balanced"
        recommendation = "Continue current strategy - both skills are comparable."

    # Status emojis and colors
    alloc_color = '#00ff9d' if allocation_effect > 0 else '#ff006b'
    select_color = '#00ff9d' if selection_effect > 0 else '#ff006b'
    alloc_status = '‚úì Strong sector rotation' if allocation_effect > 1 else '‚óã Neutral sector timing' if allocation_effect > -1 else '‚úó Poor sector allocation'
    select_status = '‚úì Strong stock picks' if selection_effect > 1 else '‚óã Neutral stock selection' if selection_effect > -1 else '‚úó Stocks underperform sector'

    html = f"""
    <style>
        @import url('https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700;800&family=JetBrains+Mono:wght@400;500;600;700&display=swap');
    </style>
    <div style="
        background: rgba(26, 35, 50, 0.7);
        backdrop-filter: blur(10px);
        -webkit-backdrop-filter: blur(10px);
        border: 1px solid rgba(0, 212, 255, 0.2);
        border-radius: 12px;
        padding: 24px;
        margin: 20px 0;
        font-family: 'Inter', -apple-system, BlinkMacSystemFont, sans-serif;
    ">
        <h3 style="
            font-family: 'Inter', sans-serif;
            font-size: 1.2rem;
            font-weight: 700;
            color: #00d4ff;
            text-transform: uppercase;
            letter-spacing: 0.1em;
            margin: 0 0 20px 0;
            text-shadow: 0 0 10px rgba(0, 212, 255, 0.3);
        ">
            üéØ Portfolio Management Skill Assessment
        </h3>

        <div style="display: grid; grid-template-columns: 1fr 1fr; gap: 20px;">

            <!-- Allocation Skill -->
            <div style="
                background: rgba(10, 15, 26, 0.6);
                border: 1px solid rgba(0, 212, 255, 0.15);
                border-radius: 8px;
                padding: 16px;
            ">
                <div style="
                    font-family: 'Inter', sans-serif;
                    font-size: 0.75rem;
                    font-weight: 600;
                    color: #8890a0;
                    text-transform: uppercase;
                    letter-spacing: 0.1em;
                    margin-bottom: 8px;
                ">ALLOCATION SKILL (Sector Timing)</div>

                <div style="
                    font-family: 'JetBrains Mono', monospace;
                    font-size: 2.5rem;
                    font-weight: 700;
                    color: {alloc_color};
                    text-shadow: 0 0 15px {alloc_color}40;
                    margin: 8px 0;
                ">{allocation_score:.1f}/10</div>

                <div style="
                    font-family: 'Inter', sans-serif;
                    font-size: 0.9rem;
                    color: #c0c8d0;
                    margin-top: 8px;
                ">Effect: {allocation_effect:+.2f}%</div>

                <div style="
                    font-family: 'Inter', sans-serif;
                    font-size: 0.75rem;
                    color: {alloc_color};
                    margin-top: 8px;
                ">{alloc_status}</div>
            </div>

            <!-- Selection Skill -->
            <div style="
                background: rgba(10, 15, 26, 0.6);
                border: 1px solid rgba(0, 212, 255, 0.15);
                border-radius: 8px;
                padding: 16px;
            ">
                <div style="
                    font-family: 'Inter', sans-serif;
                    font-size: 0.75rem;
                    font-weight: 600;
                    color: #8890a0;
                    text-transform: uppercase;
                    letter-spacing: 0.1em;
                    margin-bottom: 8px;
                ">SELECTION SKILL (Stock Picking)</div>

                <div style="
                    font-family: 'JetBrains Mono', monospace;
                    font-size: 2.5rem;
                    font-weight: 700;
                    color: {select_color};
                    text-shadow: 0 0 15px {select_color}40;
                    margin: 8px 0;
                ">{selection_score:.1f}/10</div>

                <div style="
                    font-family: 'Inter', sans-serif;
                    font-size: 0.9rem;
                    color: #c0c8d0;
                    margin-top: 8px;
                ">Effect: {selection_effect:+.2f}%</div>

                <div style="
                    font-family: 'Inter', sans-serif;
                    font-size: 0.75rem;
                    color: {select_color};
                    margin-top: 8px;
                ">{select_status}</div>
            </div>
        </div>

        <!-- Recommendation -->
        <div style="
            background: linear-gradient(90deg, rgba(0, 212, 255, 0.1) 0%, transparent 100%);
            border-left: 3px solid #00d4ff;
            padding: 12px 16px;
            margin-top: 20px;
            border-radius: 4px;
        ">
            <div style="
                font-family: 'Inter', sans-serif;
                font-size: 0.75rem;
                font-weight: 700;
                color: #00d4ff;
                text-transform: uppercase;
                letter-spacing: 0.1em;
                margin-bottom: 4px;
            ">üí° Primary Strength: {primary_skill}</div>
            <div style="
                font-family: 'Inter', sans-serif;
                font-size: 0.85rem;
                color: #c0c8d0;
            ">{recommendation}</div>
        </div>
    </div>
    """

    return html

def validate_and_map_sectors(df):
    """
    Ensure all securities are properly classified into standard sectors
    Map any non-standard sectors to standard GICS sectors
    """
    STANDARD_SECTORS = [
        'Technology', 'Healthcare', 'Financial Services', 'Consumer Cyclical',
        'Communication Services', 'Industrials', 'Consumer Defensive',
        'Energy', 'Real Estate', 'Basic Materials', 'Utilities'
    ]

    SECTOR_MAPPING = {
        'Information Technology': 'Technology',
        'Health Care': 'Healthcare',
        'Financials': 'Financial Services',
        'Consumer Discretionary': 'Consumer Cyclical',
        'Communication': 'Communication Services',
        'Consumer Staples': 'Consumer Defensive',
        'Materials': 'Basic Materials',
        'Technology ': 'Technology',  # Trim whitespace
        'Financial': 'Financial Services',
    }

    # Apply mapping
    df['Sector'] = df['Sector'].replace(SECTOR_MAPPING)

    # Check for unmapped sectors
    unmapped = df[~df['Sector'].isin(STANDARD_SECTORS)]['Sector'].unique()
    if len(unmapped) > 0:
        st.warning(f"‚ö†Ô∏è Unmapped sectors found: {', '.join(unmapped)}. These will be grouped as 'Other'.")
        df.loc[~df['Sector'].isin(STANDARD_SECTORS), 'Sector'] = 'Other'

    return df

def validate_brinson_calculations(attribution_df, portfolio_weights, benchmark_weights,
                                  portfolio_returns, benchmark_returns):
    """
    Validate Brinson attribution calculations with detailed checks
    Returns validation results dict
    """
    validation_output = []

    validation_output.append("=" * 60)
    validation_output.append("BRINSON ATTRIBUTION VALIDATION")
    validation_output.append("=" * 60)

    # Check 1: Weights sum to 100%
    port_weight_sum = sum(portfolio_weights.values())
    bench_weight_sum = sum(benchmark_weights.values())

    validation_output.append("\n1. WEIGHT VALIDATION:")
    validation_output.append(f"   Portfolio weights sum: {port_weight_sum:.2f}%")
    validation_output.append(f"   Benchmark weights sum: {bench_weight_sum:.2f}%")

    weight_check_passed = True
    if abs(port_weight_sum - 100) > 0.1:
        validation_output.append("   ‚ö†Ô∏è WARNING: Portfolio weights don't sum to 100%")
        weight_check_passed = False
    if abs(bench_weight_sum - 100) > 0.1:
        validation_output.append("   ‚ö†Ô∏è WARNING: Benchmark weights don't sum to 100%")
        weight_check_passed = False

    # Check 2: Attribution effects sum correctly
    total_allocation = attribution_df['Allocation Effect'].sum()
    total_selection = attribution_df['Selection Effect'].sum()
    total_interaction = attribution_df['Interaction Effect'].sum()
    total_attribution = total_allocation + total_selection + total_interaction

    validation_output.append(f"\n2. ATTRIBUTION DECOMPOSITION:")
    validation_output.append(f"   Allocation Effect: {total_allocation:+.2f}%")
    validation_output.append(f"   Selection Effect: {total_selection:+.2f}%")
    validation_output.append(f"   Interaction Effect: {total_interaction:+.2f}%")
    validation_output.append(f"   Total Attribution: {total_attribution:+.2f}%")

    # Check 3: Compare to actual excess return
    portfolio_return = sum(portfolio_weights.get(s, 0) * portfolio_returns.get(s, 0) / 100
                          for s in portfolio_weights.keys())
    benchmark_return = sum(benchmark_weights.get(s, 0) * benchmark_returns.get(s, 0) / 100
                          for s in benchmark_weights.keys())
    actual_excess = portfolio_return - benchmark_return

    validation_output.append(f"\n3. EXCESS RETURN VALIDATION:")
    validation_output.append(f"   Portfolio Return: {portfolio_return * 100:.2f}%")
    validation_output.append(f"   Benchmark Return: {benchmark_return * 100:.2f}%")
    validation_output.append(f"   Actual Excess Return: {actual_excess * 100:.2f}%")
    validation_output.append(f"   Attribution Total: {total_attribution:.2f}%")
    validation_output.append(f"   Difference: {abs(actual_excess * 100 - total_attribution):.4f}%")

    attribution_matches = abs(actual_excess * 100 - total_attribution) < 0.5
    if not attribution_matches:
        validation_output.append("   ‚ö†Ô∏è WARNING: Attribution doesn't match excess return")

    # Check 4: Sector-level sanity checks
    validation_output.append(f"\n4. SECTOR-LEVEL CHECKS:")
    for _, row in attribution_df.iterrows():
        sector = row['Sector']
        alloc = row['Allocation Effect']
        selection = row['Selection Effect']
        validation_output.append(f"   {sector}:")
        validation_output.append(f"      Allocation: {alloc:+.2f}% | Selection: {selection:+.2f}%")

    validation_output.append("\n" + "=" * 60)

    # Print to console for debugging
    for line in validation_output:
        print(line)

    return {
        'weight_check_passed': weight_check_passed,
        'attribution_matches': attribution_matches,
        'total_attribution': total_attribution,
        'actual_excess': actual_excess * 100,
        'validation_output': '\n'.join(validation_output)
    }

def create_sector_attribution_table(attribution_df):
    """
    Create detailed sector-by-sector attribution table
    """

    # Format for display
    display_df = attribution_df[[
        'Sector', 'Weight Diff', 'Return Diff',
        'Allocation Effect', 'Selection Effect', 'Total Effect'
    ]].copy()

    # Sort by total effect
    display_df = display_df.sort_values('Total Effect', ascending=False)

    # Format percentages
    for col in ['Weight Diff', 'Return Diff', 'Allocation Effect', 'Selection Effect', 'Total Effect']:
        display_df[col] = display_df[col].apply(lambda x: f"{x:+.2f}%")

    return display_df

@st.cache_data(ttl=600)
def calculate_benchmark_returns(benchmark_ticker, start_date, end_date):
    try:
        data = fetch_historical_data(benchmark_ticker, start_date, end_date)
        if data is None or data.empty:
            return None
        returns = data['Close'].pct_change().dropna()
        return returns
    except:
        return None

# ============================================================================
# ENHANCED HOLDINGS TABLE
# ============================================================================

def create_enhanced_holdings_table(df):
    from modules import format_ticker_for_display

    enhanced_df = df.copy()

    # Check if this is an Easy Equities portfolio
    # CRITICAL FIX: Check BOTH attrs AND EE-specific columns
    # attrs are lost when data is saved/loaded via pickle/database
    # So we also check for EE-specific columns that only exist in EE portfolios
    is_ee_portfolio = (
        enhanced_df.attrs.get('source') == 'easy_equities' or  # Fresh from sync
        'Market_Value' in enhanced_df.columns  # Loaded from storage (attrs lost but columns preserved)
    )

    # Normalize column names for Easy Equities compatibility
    # Easy Equities uses different column names than manual uploads
    column_mapping = {
        'Cost_Basis': 'Avg Cost',        # Easy Equities ‚Üí ATLAS
        'Market_Value': 'Total Value',   # Easy Equities ‚Üí ATLAS (if needed)
        'Purchase_Value': 'Total Cost',  # Easy Equities ‚Üí ATLAS
        'Current_Price': 'Current Price', # Ensure consistent naming
    }

    for ee_col, atlas_col in column_mapping.items():
        if ee_col in enhanced_df.columns and atlas_col not in enhanced_df.columns:
            enhanced_df[atlas_col] = enhanced_df[ee_col]

    # Add display ticker column (Phase 1 Fix)
    enhanced_df['Display Ticker'] = enhanced_df['Ticker'].apply(format_ticker_for_display)

    # Enrich with Yahoo Finance data for ALL portfolios (both manual and EE)
    # We need Beta, Daily Change, Sector, etc. even for EE portfolios
    for idx, row in enhanced_df.iterrows():
        ticker = row['Ticker']

        # Convert EE ticker format to Yahoo Finance format for API calls
        # EQU.ZA.BTI ‚Üí BTI.JO (for JSE stocks)
        yahoo_ticker = ticker
        if ticker.startswith('EQU.ZA.'):
            # Extract base ticker and add .JO for JSE
            base_ticker = ticker.replace('EQU.ZA.', '')
            yahoo_ticker = f"{base_ticker}.JO"
        elif ticker.startswith('EC10.EC.'):
            # EasyCrypto tickers - skip Yahoo Finance (crypto)
            yahoo_ticker = None

        if yahoo_ticker:
            market_data = fetch_market_data(yahoo_ticker)

            if market_data:
                # Only set Asset Name if not already set (EE provides 'Name')
                if 'Asset Name' not in enhanced_df.columns or pd.isna(enhanced_df.at[idx, 'Asset Name']):
                    enhanced_df.at[idx, 'Asset Name'] = market_data['company_name']

                # Set market data (Beta, Daily Change, etc.)
                enhanced_df.at[idx, 'Daily Change'] = market_data['daily_change']
                enhanced_df.at[idx, 'Daily Change %'] = market_data['daily_change_pct']
                enhanced_df.at[idx, '5D Return %'] = market_data['five_day_return']
                enhanced_df.at[idx, 'Beta'] = market_data.get('beta', 1.0)
                enhanced_df.at[idx, 'Volume'] = market_data.get('volume', 0)
                base_sector = market_data.get('sector', 'Unknown')
                enhanced_df.at[idx, 'Sector'] = classify_ticker_sector(yahoo_ticker, base_sector)

                # For EE portfolios, DON'T overwrite Current Price
                # EE's price is accurate for their platform, Yahoo might differ
                if not is_ee_portfolio:
                    enhanced_df.at[idx, 'Current Price'] = market_data['price']
            else:
                # Yahoo Finance fetch failed - set defaults
                enhanced_df.at[idx, 'Asset Name'] = enhanced_df.at[idx, 'Asset Name'] if 'Asset Name' in enhanced_df.columns else ticker
                enhanced_df.at[idx, 'Sector'] = 'Other'
                enhanced_df.at[idx, 'Beta'] = 1.0
                enhanced_df.at[idx, 'Daily Change'] = 0.0
                enhanced_df.at[idx, 'Daily Change %'] = 0.0
                enhanced_df.at[idx, '5D Return %'] = 0.0
                enhanced_df.at[idx, 'Volume'] = 0

        # Fetch analyst data for all portfolios
        analyst_data = fetch_analyst_data(yahoo_ticker if yahoo_ticker else ticker)
        if analyst_data['success']:
            enhanced_df.at[idx, 'Analyst Rating'] = analyst_data['rating']
            enhanced_df.at[idx, 'Price Target'] = analyst_data['target_price']
        else:
            enhanced_df.at[idx, 'Analyst Rating'] = 'No Coverage'
            enhanced_df.at[idx, 'Price Target'] = None

        # Calculate Quality Score for all portfolios
        info = fetch_stock_info(yahoo_ticker if yahoo_ticker else ticker)
        if info:
            enhanced_df.at[idx, 'Quality Score'] = calculate_quality_score(ticker, info)
        else:
            enhanced_df.at[idx, 'Quality Score'] = 5.0

    enhanced_df['Sector'] = enhanced_df['Sector'].fillna('Other')

    # CRITICAL SPLIT: Different calculation logic for manual vs EE portfolios
    if not is_ee_portfolio:
        # MANUAL UPLOADS: Calculate totals from shares √ó prices
        enhanced_df['Shares'] = enhanced_df['Shares'].round(0).astype(int)
        enhanced_df['Total Cost'] = enhanced_df['Shares'] * enhanced_df['Avg Cost']
        enhanced_df['Total Value'] = enhanced_df['Shares'] * enhanced_df['Current Price']
        enhanced_df['Total Gain/Loss $'] = enhanced_df['Total Value'] - enhanced_df['Total Cost']
        enhanced_df['Total Gain/Loss %'] = ((enhanced_df['Current Price'] - enhanced_df['Avg Cost']) / enhanced_df['Avg Cost']) * 100
        enhanced_df['Daily P&L $'] = enhanced_df['Shares'] * enhanced_df['Daily Change']
    else:
        # EASY EQUITIES: Use EE's totals directly - DON'T RECALCULATE!
        # EE already provides correct Total Value, Total Cost, Unrealized_PnL

        # Map EE columns to ATLAS display columns (already done in column_mapping above)
        if 'Unrealized_PnL' in enhanced_df.columns:
            enhanced_df['Total Gain/Loss $'] = enhanced_df['Unrealized_PnL']

        if 'Unrealized_PnL_Pct' in enhanced_df.columns:
            enhanced_df['Total Gain/Loss %'] = enhanced_df['Unrealized_PnL_Pct']

        # For Daily P&L, calculate from Yahoo Finance Daily Change if available
        if 'Daily Change' in enhanced_df.columns and 'Shares' in enhanced_df.columns:
            enhanced_df['Daily P&L $'] = enhanced_df['Shares'] * enhanced_df['Daily Change']
        else:
            enhanced_df['Daily P&L $'] = 0.0

        # Set Asset Name from EE's 'Name' column if available
        if 'Name' in enhanced_df.columns and 'Asset Name' not in enhanced_df.columns:
            enhanced_df['Asset Name'] = enhanced_df['Name']

    # CRITICAL FIX: Add DUAL weight columns (equity-based AND gross-based)
    gross_exposure = enhanced_df['Total Value'].sum()

    # Get equity from performance history or session state
    metrics = get_current_portfolio_metrics()
    if metrics and metrics.get('equity', 0) > 0:
        equity = metrics['equity']
    else:
        equity = st.session_state.get('equity_capital', gross_exposure)  # Fallback to gross if no equity set

    # Weight % of Equity - can exceed 100% with leverage!
    enhanced_df['Weight % of Equity'] = (enhanced_df['Total Value'] / equity * 100) if equity > 0 else 0

    # Weight % of Gross Exposure - always sums to 100%
    enhanced_df['Weight % of Gross'] = (enhanced_df['Total Value'] / gross_exposure * 100) if gross_exposure > 0 else 0

    # Keep legacy 'Weight %' for backwards compatibility (use gross-based)
    enhanced_df['Weight %'] = enhanced_df['Weight % of Gross']

    return enhanced_df

def calculate_quality_score(ticker, info):
    """
    Calculate comprehensive quality score (0-10)
    Based on: Profitability, Growth, Financial Health, Valuation
    """
    score = 5.0  # Start at neutral

    try:
        # Profitability metrics
        roe = info.get('returnOnEquity', 0)
        if roe and roe > 0.15:
            score += 1
        elif roe and roe > 0.10:
            score += 0.5

        # Growth metrics
        revenue_growth = info.get('revenueGrowth', 0)
        if revenue_growth and revenue_growth > 0.15:
            score += 1
        elif revenue_growth and revenue_growth > 0.05:
            score += 0.5

        # Financial health
        debt_to_equity = info.get('debtToEquity', 0)
        if debt_to_equity and debt_to_equity < 50:
            score += 1
        elif debt_to_equity and debt_to_equity < 100:
            score += 0.5

        # Profitability
        profit_margin = info.get('profitMargins', 0)
        if profit_margin and profit_margin > 0.20:
            score += 1
        elif profit_margin and profit_margin > 0.10:
            score += 0.5

        # Current ratio (liquidity)
        current_ratio = info.get('currentRatio', 0)
        if current_ratio and current_ratio > 2:
            score += 0.5
        elif current_ratio and current_ratio > 1:
            score += 0.25

        # Analyst recommendations
        recommendation = info.get('recommendationKey', '')
        if recommendation in ['strong_buy', 'buy']:
            score += 0.5

        # Cap at 10
        score = min(10.0, score)

    except Exception as e:
        score = 5.0

    return round(score, 1)

def style_holdings_dataframe(df):
    display_df = df[[
        'Ticker', 'Asset Name', 'Shares', 'Avg Cost', 'Current Price',
        'Daily Change %', '5D Return %', 'Weight %', 'Daily P&L $', 
        'Total Gain/Loss $', 'Total Gain/Loss %', 'Beta', 'Analyst Rating'
    ]].copy()
    
    pct_cols = ['Daily Change %', '5D Return %', 'Weight %', 'Total Gain/Loss %']
    for col in pct_cols:
        display_df[col] = display_df[col].apply(lambda x: format_percentage(x))
    
    currency_cols = ['Avg Cost', 'Current Price', 'Daily P&L $', 'Total Gain/Loss $']
    for col in currency_cols:
        display_df[col] = display_df[col].apply(format_currency)
    
    display_df['Daily Change %'] = display_df['Daily Change %'].apply(add_arrow_indicator)
    display_df['Total Gain/Loss %'] = display_df['Total Gain/Loss %'].apply(add_arrow_indicator)

    return display_df

def style_holdings_dataframe_with_optimization(df):
    """Style holdings dataframe with optimization columns"""
    display_df = df[[
        'Ticker', 'Asset Name', 'Shares', 'Current Price',
        'Weight %', 'Optimal Weight %', 'Weight Diff %',
        'Shares to Trade', 'Action', 'Total Gain/Loss %'
    ]].copy()

    # Format percentages
    pct_cols = ['Weight %', 'Optimal Weight %', 'Weight Diff %', 'Total Gain/Loss %']
    for col in pct_cols:
        if col in display_df.columns:
            display_df[col] = display_df[col].apply(lambda x: format_percentage(x) if pd.notna(x) else '')

    # Format currency
    display_df['Current Price'] = display_df['Current Price'].apply(format_currency)

    # Format shares to trade with sign
    display_df['Shares to Trade'] = display_df['Shares to Trade'].apply(
        lambda x: f"+{int(x):,}" if x > 0 else f"{int(x):,}" if x < 0 else "0" if pd.notna(x) else ''
    )

    # Add indicators to action column
    def style_action(val):
        if val == 'BUY':
            return 'üü¢ BUY'
        elif val == 'SELL':
            return 'üî¥ SELL'
        elif val == 'HOLD':
            return '‚ö™ HOLD'
        return val

    if 'Action' in display_df.columns:
        display_df['Action'] = display_df['Action'].apply(style_action)

    return display_df

# ============================================================================
# RISK METRICS
# ============================================================================

def calculate_sharpe_ratio(returns, risk_free_rate=RISK_FREE_RATE):
    if not is_valid_series(returns) or len(returns) < 2:
        return None
    total_return = (1 + returns).prod() - 1
    n_years = len(returns) / 252
    annualized_return = (1 + total_return) ** (1/n_years) - 1 if n_years > 0 else 0
    annualized_vol = returns.std() * np.sqrt(252)
    sharpe = (annualized_return - risk_free_rate) / annualized_vol if annualized_vol > 0 else 0
    return sharpe

def calculate_sortino_ratio(returns, risk_free_rate=RISK_FREE_RATE):
    if not is_valid_series(returns) or len(returns) < 2:
        return None
    total_return = (1 + returns).prod() - 1
    n_years = len(returns) / 252
    annualized_return = (1 + total_return) ** (1/n_years) - 1 if n_years > 0 else 0
    downside_returns = returns[returns < 0]
    if len(downside_returns) < 2:
        return None
    downside_std = downside_returns.std() * np.sqrt(252)
    sortino = (annualized_return - risk_free_rate) / downside_std if downside_std > 0 else 0
    return sortino

def calculate_information_ratio(portfolio_returns, benchmark_returns):
    if not is_valid_series(portfolio_returns) or not is_valid_series(benchmark_returns):
        return None
    if len(portfolio_returns) < 2 or len(benchmark_returns) < 2:
        return None
    common_dates = portfolio_returns.index.intersection(benchmark_returns.index)
    portfolio_returns = portfolio_returns.loc[common_dates]
    benchmark_returns = benchmark_returns.loc[common_dates]
    excess_returns = portfolio_returns - benchmark_returns
    if len(excess_returns) < 2:
        return None
    total_excess = (1 + excess_returns).prod() - 1
    n_years = len(excess_returns) / 252
    annualized_excess = (1 + total_excess) ** (1/n_years) - 1 if n_years > 0 else 0
    tracking_error = excess_returns.std() * np.sqrt(252)
    info_ratio = annualized_excess / tracking_error if tracking_error > 0 else 0
    return info_ratio

# v9.7 ENHANCEMENT: Added caching for performance optimization
@st.cache_data(ttl=300)
def calculate_var(returns, confidence=0.95, equity=None):
    """
    Calculate Value at Risk with caching for improved performance

    CRITICAL FIX: Returns VaR as percentage. If equity provided, also returns dollar VaR.
    VaR dollar amount is calculated on EQUITY, not gross exposure.

    Args:
        returns: Return series (should be on equity basis from calculate_portfolio_returns)
        confidence: Confidence level (e.g., 0.95 = 95%)
        equity: Optional equity capital to calculate dollar VaR

    Returns:
        VaR percentage (or None if error)
    """
    if not is_valid_series(returns) or len(returns) < 2:
        return None
    try:
        var = np.percentile(returns, (1 - confidence) * 100)
        # Note: returns are already on equity basis (from fixed calculate_portfolio_returns)
        # so var percentile correctly represents risk to equity
        return var * 100
    except Exception as e:
        return None

@st.cache_data(ttl=300)
def calculate_cvar(returns, confidence=0.95, equity=None):
    """
    Calculate Conditional VaR (Expected Shortfall) with caching

    CRITICAL FIX: Returns CVaR as percentage. If equity provided, also returns dollar CVaR.
    CVaR dollar amount is calculated on EQUITY, not gross exposure.

    Args:
        returns: Return series (should be on equity basis from calculate_portfolio_returns)
        confidence: Confidence level (e.g., 0.95 = 95%)
        equity: Optional equity capital to calculate dollar CVaR

    Returns:
        CVaR percentage (or None if error)
    """
    if not is_valid_series(returns) or len(returns) < 2:
        return None
    try:
        var = np.percentile(returns, (1 - confidence) * 100)
        cvar = returns[returns <= var].mean()
        # Note: returns are already on equity basis (from fixed calculate_portfolio_returns)
        # so cvar correctly represents expected tail loss to equity
        return cvar * 100
    except Exception as e:
        return None

def calculate_historical_stress_test(enhanced_df):
    """
    Calculate portfolio performance during historical stress periods vs S&P 500.

    Returns performance data for visualization of portfolio resilience during major market events.

    Historical Stress Periods:
    - 2008 Financial Crisis: Sep 2008 - Mar 2009
    - 2011 Euro Crisis: Jul 2011 - Oct 2011
    - 2015-16 China Slowdown: Aug 2015 - Feb 2016
    - Dec 2018 Selloff: Oct 2018 - Dec 2018
    - COVID-19 Crash: Feb 2020 - Mar 2020

    Returns:
        dict: Contains period data, cumulative returns, and stress metrics
    """

    # Define historical stress periods
    stress_periods = {
        '2008 Financial Crisis': {'start': '2008-09-01', 'end': '2009-03-31', 'color': '#FF4136'},
        '2011 Euro Crisis': {'start': '2011-07-01', 'end': '2011-10-31', 'color': '#FF851B'},
        '2015-16 China Slowdown': {'start': '2015-08-01', 'end': '2016-02-29', 'color': '#FFDC00'},
        'Dec 2018 Selloff': {'start': '2018-10-01', 'end': '2018-12-31', 'color': '#39CCCC'},
        'COVID-19 Crash': {'start': '2020-02-01', 'end': '2020-03-31', 'color': '#B10DC9'}
    }

    results = {}

    # Get portfolio tickers and weights
    tickers = enhanced_df['Ticker'].tolist()
    weights = (enhanced_df['Weight %'] / 100).tolist()

    for period_name, period_info in stress_periods.items():
        try:
            # Fetch S&P 500 data for this period
            spy_data = fetch_historical_data('^GSPC', period_info['start'], period_info['end'])

            if spy_data is None or spy_data.empty:
                continue

            # Fetch portfolio holdings data for this period
            portfolio_returns = []
            valid_weights = []

            for ticker, weight in zip(tickers, weights):
                ticker_data = fetch_historical_data(ticker, period_info['start'], period_info['end'])
                if ticker_data is not None and not ticker_data.empty and len(ticker_data) > 0:
                    # Calculate cumulative return for this ticker
                    ticker_returns = ticker_data['Close'].pct_change().fillna(0)
                    portfolio_returns.append(ticker_returns)
                    valid_weights.append(weight)

            if not portfolio_returns:
                continue

            # Normalize weights
            valid_weights = np.array(valid_weights)
            valid_weights = valid_weights / valid_weights.sum()

            # Calculate weighted portfolio returns
            returns_df = pd.DataFrame(portfolio_returns).T
            portfolio_daily_returns = (returns_df * valid_weights).sum(axis=1)

            # Calculate cumulative returns
            portfolio_cumulative = (1 + portfolio_daily_returns).cumprod()
            spy_cumulative = (1 + spy_data['Close'].pct_change().fillna(0)).cumprod()

            # Align indices
            common_index = portfolio_cumulative.index.intersection(spy_cumulative.index)
            if len(common_index) == 0:
                continue

            portfolio_cumulative = portfolio_cumulative.loc[common_index]
            spy_cumulative = spy_cumulative.loc[common_index]

            # Normalize to start at 100
            portfolio_cumulative = (portfolio_cumulative / portfolio_cumulative.iloc[0]) * 100
            spy_cumulative = (spy_cumulative / spy_cumulative.iloc[0]) * 100

            # Calculate stress metrics
            total_return_portfolio = ((portfolio_cumulative.iloc[-1] / 100) - 1) * 100
            total_return_spy = ((spy_cumulative.iloc[-1] / 100) - 1) * 100

            max_drawdown_portfolio = ((portfolio_cumulative / portfolio_cumulative.cummax()) - 1).min() * 100
            max_drawdown_spy = ((spy_cumulative / spy_cumulative.cummax()) - 1).min() * 100

            volatility_portfolio = portfolio_daily_returns.std() * np.sqrt(252) * 100
            volatility_spy = spy_data['Close'].pct_change().std() * np.sqrt(252) * 100

            results[period_name] = {
                'dates': common_index,
                'portfolio_cumulative': portfolio_cumulative,
                'spy_cumulative': spy_cumulative,
                'metrics': {
                    'portfolio_return': total_return_portfolio,
                    'spy_return': total_return_spy,
                    'portfolio_drawdown': max_drawdown_portfolio,
                    'spy_drawdown': max_drawdown_spy,
                    'portfolio_volatility': volatility_portfolio,
                    'spy_volatility': volatility_spy,
                    'outperformance': total_return_portfolio - total_return_spy
                },
                'color': period_info['color']
            }

        except Exception as e:
            # Skip periods where data is unavailable
            continue

    return results

def calculate_var_cvar_portfolio_optimization(enhanced_df, confidence_level=0.95, lookback_days=252, max_position=0.25, min_position=0.02, target_leverage=1.0, risk_profile_config=None):
    """
    Calculate optimal portfolio weights to minimize CVaR (Conditional Value at Risk)

    This function implements portfolio optimization from Quantitative Risk Management
    to find weights that minimize tail risk while maintaining diversification.

    FIXED v11.0: Added leverage constraint support. Leverage = sum of absolute weights.
    PHASE 3: Added gradual rebalancing with turnover and position change limits.

    Args:
        enhanced_df: Enhanced holdings dataframe with current positions
        confidence_level: Confidence level for VaR/CVaR calculation (default 95%)
        lookback_days: Days of historical data to use (default 252 = 1 year)
        max_position: Maximum position size per security (default 25%)
        min_position: Minimum meaningful position size (default 2%)
        target_leverage: Target portfolio leverage (default 1.0 = no leverage)
        risk_profile_config: Optional dict from RiskProfile.get_config() for gradual rebalancing

    Returns:
        tuple: (rebalancing_df, optimization_metrics)
    """
    from scipy.optimize import minimize

    # Get current portfolio composition
    tickers = enhanced_df['Ticker'].tolist()
    current_values = enhanced_df['Total Value'].values
    total_portfolio_value = current_values.sum()

    # CRITICAL FIX: Calculate weights relative to EQUITY, not gross exposure
    # Get equity from performance history or session state
    metrics = get_current_portfolio_metrics()
    if metrics and metrics.get('equity', 0) > 0:
        equity = metrics['equity']
    else:
        equity = st.session_state.get('equity_capital', total_portfolio_value)
    current_weights = current_values / equity  # Can sum > 1.0 with leverage!

    # Fetch historical returns for all tickers
    end_date = datetime.now()
    start_date = end_date - timedelta(days=lookback_days)

    # Build returns matrix
    returns_dict = {}
    for ticker in tickers:
        hist_data = fetch_historical_data(ticker, start_date, end_date)
        if hist_data is not None and len(hist_data) > 1:
            returns = hist_data['Close'].pct_change().dropna()
            returns_dict[ticker] = returns

    # Align all returns to common dates
    returns_df = pd.DataFrame(returns_dict)
    returns_df = returns_df.dropna()

    if len(returns_df) < 30:
        st.warning("Insufficient historical data for optimization (need 30+ days)")
        return None, None

    # CRITICAL FIX: Only keep tickers that have valid data
    valid_tickers = returns_df.columns.tolist()
    returns_matrix = returns_df.values
    n_assets = len(valid_tickers)

    # Update enhanced_df to only include valid tickers
    enhanced_df = enhanced_df[enhanced_df['Ticker'].isin(valid_tickers)].copy()
    tickers = valid_tickers
    current_values = enhanced_df['Total Value'].values
    total_portfolio_value = current_values.sum()

    # CRITICAL FIX: Use equity for current weights (already set above)
    current_weights = current_values / equity  # Can sum > 1.0 with leverage!

    # Define CVaR calculation with production-grade regularization
    def calculate_portfolio_cvar(weights, returns, alpha):
        """
        Calculate CVaR (Expected Shortfall) for given weights

        FIXED v10.3: Removed aggressive penalties causing equal-weight portfolios.
        Now uses gentle regularization scaled appropriately.
        """
        portfolio_returns = returns @ weights
        var_threshold = np.percentile(portfolio_returns, (1-alpha) * 100)
        cvar = portfolio_returns[portfolio_returns <= var_threshold].mean()

        # GENTLE regularization - tiny penalty to avoid extreme concentration
        # CVaR is typically -0.05 to -0.20, so penalty should be ~0.0001 to 0.001
        hhi = np.sum(weights ** 2)
        gentle_regularization = 0.0005 * (hhi - 1/n_assets)

        return -cvar + gentle_regularization

    # Optimization objective
    def objective(weights):
        return calculate_portfolio_cvar(weights, returns_matrix, confidence_level)

    # PHASE 3: Use gradual rebalancing constraints if risk_profile_config provided
    if risk_profile_config is not None:
        # Use realistic constraints with turnover and position change limits
        constraints = build_realistic_constraints(current_weights, risk_profile_config, target_leverage)
        bounds = build_position_bounds(current_weights, risk_profile_config, n_assets)

        # Use current weights as starting point (closer to feasible solution)
        initial_weights = current_weights.copy()
        # Ensure initial weights are within bounds
        for i, (lb, ub) in enumerate(bounds):
            initial_weights[i] = np.clip(initial_weights[i], lb, ub)
        # Re-normalize to target leverage
        if initial_weights.sum() > 0:
            initial_weights = initial_weights * (target_leverage / initial_weights.sum())
    else:
        # Legacy mode: simple constraints without turnover limits
        def leverage_constraint(w, target_lev):
            """Leverage = sum of absolute weights"""
            return np.abs(w).sum() - target_lev

        constraints = [
            {'type': 'eq', 'fun': leverage_constraint, 'args': (target_leverage,)}
        ]

        # Use user-specified bounds
        bounds = tuple((0.0, max_position) for _ in range(n_assets))

        # Initial guess (scaled by leverage)
        initial_weights = np.ones(n_assets) * (target_leverage / n_assets)

    # Run optimization
    result = minimize(
        objective,
        initial_weights,
        method='SLSQP',
        bounds=bounds,
        constraints=constraints,
        options={'maxiter': 1000, 'ftol': 1e-9}
    )

    if not result.success:
        st.warning(f"Optimization converged with warning: {result.message}")

    optimal_weights = result.x

    # PHASE 3: Apply minimum trade threshold to avoid uneconomical trades
    if risk_profile_config is not None:
        min_trade_threshold = risk_profile_config.get('min_trade_threshold', 0.01)
        optimal_weights = apply_trade_threshold(optimal_weights, current_weights, min_trade_threshold)

    # Calculate current and optimal risk metrics
    current_portfolio_returns = returns_matrix @ current_weights
    optimal_portfolio_returns = returns_matrix @ optimal_weights

    current_var = np.percentile(current_portfolio_returns, (1-confidence_level) * 100)
    optimal_var = np.percentile(optimal_portfolio_returns, (1-confidence_level) * 100)

    current_cvar = current_portfolio_returns[current_portfolio_returns <= current_var].mean()
    optimal_cvar = optimal_portfolio_returns[optimal_portfolio_returns <= optimal_var].mean()

    # Calculate Sharpe ratios
    current_sharpe = (current_portfolio_returns.mean() / current_portfolio_returns.std()) * np.sqrt(252)
    optimal_sharpe = (optimal_portfolio_returns.mean() / optimal_portfolio_returns.std()) * np.sqrt(252)

    # Build rebalancing dataframe
    rebalancing_data = []
    for i, ticker in enumerate(tickers):
        current_value = enhanced_df[enhanced_df['Ticker'] == ticker]['Total Value'].values[0]
        current_shares = enhanced_df[enhanced_df['Ticker'] == ticker]['Shares'].values[0]
        current_price = enhanced_df[enhanced_df['Ticker'] == ticker]['Current Price'].values[0]

        optimal_value = optimal_weights[i] * total_portfolio_value
        optimal_shares = optimal_value / current_price
        shares_to_trade = optimal_shares - current_shares
        trade_value = shares_to_trade * current_price

        rebalancing_data.append({
            'Ticker': ticker,
            'Asset Name': enhanced_df[enhanced_df['Ticker'] == ticker]['Asset Name'].values[0],
            'Current Weight %': (current_value / total_portfolio_value) * 100,
            'Optimal Weight %': optimal_weights[i] * 100,
            'Weight Diff %': (optimal_weights[i] * 100) - (current_value / total_portfolio_value * 100),
            'Current Shares': int(current_shares),
            'Target Shares': int(optimal_shares),
            'Shares to Trade': int(shares_to_trade),
            'Current Price': current_price,
            'Trade Value': trade_value,
            'Action': 'BUY' if shares_to_trade > 5 else 'SELL' if shares_to_trade < -5 else 'HOLD',
            'Priority': abs(trade_value)  # Sort by impact
        })

    rebalancing_df = pd.DataFrame(rebalancing_data)
    rebalancing_df = rebalancing_df.sort_values('Priority', ascending=False)

    # Calculate actual turnover
    actual_turnover = np.sum(np.abs(optimal_weights - current_weights)) / 2

    # Calculate optimization metrics
    optimization_metrics = {
        'current_var': current_var * 100,
        'optimal_var': optimal_var * 100,
        'var_reduction_pct': abs((optimal_var - current_var) / abs(current_var)) * 100 if current_var != 0 else 0,
        'current_cvar': current_cvar * 100,
        'optimal_cvar': optimal_cvar * 100,
        'cvar_reduction_pct': abs((optimal_cvar - current_cvar) / abs(current_cvar)) * 100 if current_cvar != 0 else 0,
        'current_sharpe': current_sharpe,
        'optimal_sharpe': optimal_sharpe,
        'sharpe_improvement': optimal_sharpe - current_sharpe,
        'total_trades': len(rebalancing_df[rebalancing_df['Action'] != 'HOLD']),
        'rebalancing_cost': abs(rebalancing_df['Trade Value'].sum()),
        'buy_trades': len(rebalancing_df[rebalancing_df['Action'] == 'BUY']),
        'sell_trades': len(rebalancing_df[rebalancing_df['Action'] == 'SELL']),
        # PHASE 3: Gradual rebalancing metrics
        'actual_turnover_pct': actual_turnover * 100,
        'max_position_change': np.max(np.abs(optimal_weights - current_weights)) * 100,
        'gradual_rebalancing': risk_profile_config is not None,
        'rebalance_style': risk_profile_config.get('rebalance_frequency', 'one-time') if risk_profile_config else 'one-time'
    }

    return rebalancing_df, optimization_metrics

# ============================================================================
# PRODUCTION-GRADE PORTFOLIO OPTIMIZATION SYSTEM v10.3
# ============================================================================
# PM/Developer Hybrid Approach - Built for Trust & Transparency
#
# Key Components:
# 1. RiskProfile - Translate user intent to optimization parameters
# 2. RobustPortfolioOptimizer - Handle estimation uncertainty
# 3. OptimizationExplainer - Generate transparent insights
# 4. Production workflow - Complete end-to-end optimization
# ============================================================================

class RiskProfile:
    """
    Translate user risk tolerance into optimization parameters

    Instead of asking users to set 47 parameters, provide 3 clear risk profiles:
    - Conservative: Capital preservation, steady returns
    - Moderate: Balance growth and risk
    - Aggressive: Maximize returns, accept volatility
    """

    PROFILES = {
        'conservative': {
            'name': 'Conservative',
            'description': 'Maximum diversification with capital preservation',
            'philosophy': 'Prioritize diversification - accept 5-10% lower performance for 2-3x more holdings',

            # MUCH STRICTER POSITION LIMITS (Diversification-First)
            'max_position_base': 0.06,         # Max 6% in any single asset (was 15%)
            'typical_position_target': 0.04,   # Aim for 4% positions
            'max_sector_concentration': 0.25,  # Tight sector limits

            # FORCE BROAD DIVERSIFICATION
            'min_diversification': 18,         # Force at least 18 holdings (was 10)
            'target_holdings': 25,             # Aim for 25+ holdings
            'min_position_to_count': 0.02,     # Only count positions >2%

            # VERY TIGHT CONCENTRATION LIMITS
            'max_top_3_concentration': 0.15,   # Top 3 can't exceed 15%
            'max_top_5_concentration': 0.25,   # Top 5 can't exceed 25%
            'max_top_10_concentration': 0.50,  # Top 10 can't exceed 50%

            # RISK DISTRIBUTION
            'max_drawdown_tolerance': 0.15,    # 15% max drawdown
            'turnover_sensitivity': 'low',     # Avoid frequent trading
            'risk_budget_per_asset': 0.08,     # No asset >8% of portfolio risk (was 12%)
            'target_effective_n': 20,          # Target 20 "effective" holdings

            # DIVERSIFICATION PRIORITY
            'acceptable_sharpe_ratio': 0.90,   # Accept 90% of max Sharpe for diversification
            'diversification_priority': 'maximum',

            # PHASE 3: GRADUAL REBALANCING CONSTRAINTS
            'max_turnover_per_rebalance': 0.15,   # Max 15% portfolio turnover per rebalance
            'max_position_change': 0.03,          # Max 3% change per position per rebalance
            'min_trade_threshold': 0.005,         # Don't trade if change < 0.5%
            'rebalance_frequency': 'quarterly',   # Suggested rebalance frequency
        },

        'moderate': {
            'name': 'Moderate',
            'description': 'Strong diversification with balanced growth',
            'philosophy': 'Balance performance and diversification - accept 3-5% lower performance for better diversification',

            # MODERATE POSITION LIMITS (Still Diversified)
            'max_position_base': 0.10,         # Max 10% in any single asset (was 20%)
            'typical_position_target': 0.06,   # Aim for 6% positions
            'max_sector_concentration': 0.35,

            # GOOD DIVERSIFICATION
            'min_diversification': 12,         # Force at least 12 holdings (was 8)
            'target_holdings': 18,             # Aim for 18+ holdings
            'min_position_to_count': 0.025,

            # REASONABLE CONCENTRATION LIMITS
            'max_top_3_concentration': 0.25,   # Top 3 can't exceed 25%
            'max_top_5_concentration': 0.40,   # Top 5 can't exceed 40%
            'max_top_10_concentration': 0.70,  # Top 10 can't exceed 70%

            # RISK DISTRIBUTION
            'max_drawdown_tolerance': 0.25,
            'turnover_sensitivity': 'medium',
            'risk_budget_per_asset': 0.12,     # No asset >12% of portfolio risk
            'target_effective_n': 12,          # Target 12 "effective" holdings

            # DIVERSIFICATION PRIORITY
            'acceptable_sharpe_ratio': 0.95,   # Accept 95% of max Sharpe
            'diversification_priority': 'high',

            # PHASE 3: GRADUAL REBALANCING CONSTRAINTS
            'max_turnover_per_rebalance': 0.25,   # Max 25% portfolio turnover per rebalance
            'max_position_change': 0.05,          # Max 5% change per position per rebalance
            'min_trade_threshold': 0.01,          # Don't trade if change < 1%
            'rebalance_frequency': 'monthly',     # Suggested rebalance frequency
        },

        'aggressive': {
            'name': 'Aggressive',
            'description': 'Growth-focused but still properly diversified',
            'philosophy': 'Allow concentration where justified, but maintain meaningful diversification',

            # STILL REASONABLE LIMITS
            'max_position_base': 0.15,         # Max 15% in any single asset (was 25%)
            'typical_position_target': 0.08,   # Aim for 8% positions
            'max_sector_concentration': 0.50,

            # MEANINGFUL DIVERSIFICATION
            'min_diversification': 10,         # Force at least 10 holdings (was 6)
            'target_holdings': 15,             # Aim for 15+ holdings
            'min_position_to_count': 0.03,

            # LOOSER BUT STILL BOUNDED
            'max_top_3_concentration': 0.35,   # Top 3 can't exceed 35%
            'max_top_5_concentration': 0.55,   # Top 5 can't exceed 55%
            'max_top_10_concentration': 0.85,  # Top 10 can't exceed 85%

            # RISK DISTRIBUTION
            'max_drawdown_tolerance': 0.35,
            'turnover_sensitivity': 'high',
            'risk_budget_per_asset': 0.15,     # No asset >15% of portfolio risk
            'target_effective_n': 10,          # Target 10 "effective" holdings

            # DIVERSIFICATION PRIORITY
            'acceptable_sharpe_ratio': 0.98,   # Accept 98% of max Sharpe
            'diversification_priority': 'moderate',

            # PHASE 3: GRADUAL REBALANCING CONSTRAINTS
            'max_turnover_per_rebalance': 0.40,   # Max 40% portfolio turnover per rebalance
            'max_position_change': 0.08,          # Max 8% change per position per rebalance
            'min_trade_threshold': 0.015,         # Don't trade if change < 1.5%
            'rebalance_frequency': 'weekly',      # Suggested rebalance frequency
        }
    }

    @classmethod
    def get_config(cls, risk_tolerance, strategy_type):
        """
        Get optimization config based on user risk profile + strategy

        This is the KEY translation layer - from user intent to math parameters

        DIVERSIFICATION-FIRST PHILOSOPHY:
        We no longer adjust limits by strategy. Instead, we maintain strict
        diversification requirements and let the two-stage optimization find
        the most diversified solution on the efficient frontier.
        """
        base_config = cls.PROFILES[risk_tolerance].copy()

        # All strategies now use the same diversification-first constraints
        # The two-stage optimizer will find the most diversified solution
        # that achieves acceptable performance for the chosen strategy

        return base_config


def calculate_risk_adjusted_limits(returns_df, max_position_base, risk_budget_per_asset):
    """
    Calculate risk-adjusted position limits for each asset

    Idea: Higher volatility assets should have lower maximum position sizes
    to prevent them from dominating portfolio risk

    Args:
        returns_df: Historical returns dataframe
        max_position_base: Base maximum position size
        risk_budget_per_asset: Maximum risk contribution per asset

    Returns:
        List of (min, max) tuples for each asset
    """
    # Calculate annualized volatilities
    vols = returns_df.std() * np.sqrt(252)
    avg_vol = vols.mean()

    position_limits = []
    for vol in vols:
        # Adjust max position based on relative volatility
        # High vol ‚Üí lower max position
        vol_adjustment = avg_vol / vol if vol > 0 else 1.0
        adjusted_max = min(max_position_base * vol_adjustment, max_position_base * 1.5)
        adjusted_max = min(adjusted_max, 0.50)  # Hard cap at 50%

        position_limits.append((0, adjusted_max))

    return position_limits


# ============================================================================
# PHASE 3: GRADUAL REBALANCING CONSTRAINT BUILDERS
# ============================================================================
# These functions create realistic constraints that prevent "all or nothing"
# recommendations and produce gradual, professional rebalancing suggestions.
# ============================================================================

def build_realistic_constraints(current_weights, risk_profile_config, target_leverage=1.0):
    """
    Build optimization constraints that enforce gradual portfolio changes.

    Key Constraints:
    1. Turnover Limit: Total portfolio change cannot exceed max_turnover_per_rebalance
    2. Leverage: Sum of absolute weights must equal target leverage

    Args:
        current_weights: numpy array of current portfolio weights
        risk_profile_config: dict from RiskProfile.get_config()
        target_leverage: Target portfolio leverage (default 1.0)

    Returns:
        list: scipy.optimize constraint dicts
    """
    max_turnover = risk_profile_config.get('max_turnover_per_rebalance', 0.25)

    constraints = []

    # 1. Leverage constraint: sum of absolute weights = target
    def leverage_constraint(w):
        return np.abs(w).sum() - target_leverage
    constraints.append({'type': 'eq', 'fun': leverage_constraint})

    # 2. Turnover constraint: total change limited
    # Turnover = sum of |new_weight - old_weight| / 2 (divide by 2 because buying = selling)
    def turnover_constraint(w):
        turnover = np.sum(np.abs(w - current_weights)) / 2
        return max_turnover - turnover  # Must be >= 0
    constraints.append({'type': 'ineq', 'fun': turnover_constraint})

    return constraints


def build_position_bounds(current_weights, risk_profile_config, n_assets):
    """
    Build position bounds that respect maximum change per position.

    Instead of allowing 0% to 25% for every position, this function creates
    bounds like: current_weight ¬± max_position_change, capped at [0, max_position].

    This prevents the optimizer from making drastic changes to any single position.

    Args:
        current_weights: numpy array of current portfolio weights
        risk_profile_config: dict from RiskProfile.get_config()
        n_assets: number of assets in portfolio

    Returns:
        tuple: bounds for scipy.optimize (list of (min, max) tuples)
    """
    max_position = risk_profile_config.get('max_position_base', 0.25)
    max_change = risk_profile_config.get('max_position_change', 0.05)
    min_trade = risk_profile_config.get('min_trade_threshold', 0.01)

    bounds = []
    for i in range(n_assets):
        curr_w = current_weights[i] if i < len(current_weights) else 0

        # Calculate allowed range: current ¬± max_change
        lower = max(0.0, curr_w - max_change)
        upper = min(max_position, curr_w + max_change)

        # If current weight is below min_trade threshold, allow going to 0
        if curr_w < min_trade:
            lower = 0.0

        bounds.append((lower, upper))

    return tuple(bounds)


def apply_trade_threshold(optimal_weights, current_weights, min_trade_threshold):
    """
    Apply minimum trade threshold to avoid tiny, uneconomical trades.

    If the weight change is smaller than min_trade_threshold, keep current weight.
    This prevents generating trades for $50 changes that cost $10 in commissions.

    Args:
        optimal_weights: numpy array of optimized weights
        current_weights: numpy array of current weights
        min_trade_threshold: minimum change to trigger a trade

    Returns:
        numpy array: adjusted optimal weights with small changes zeroed out
    """
    adjusted = optimal_weights.copy()

    for i in range(len(optimal_weights)):
        weight_change = abs(optimal_weights[i] - current_weights[i])
        if weight_change < min_trade_threshold:
            adjusted[i] = current_weights[i]

    # Re-normalize to ensure weights sum to target
    total = adjusted.sum()
    if total > 0:
        adjusted = adjusted * (optimal_weights.sum() / total)

    return adjusted


# ============================================================================
# PHASE 3 DAY 3: EXPERT WISDOM RULES
# ============================================================================
# Professional portfolio management heuristics that supplement mathematical
# optimization with real-world constraints and best practices.
# ============================================================================

EXPERT_WISDOM_RULES = {
    'single_stock_concentration': {
        'name': 'Single Stock Concentration',
        'description': 'No single stock should exceed 25% of portfolio',
        'threshold': 0.25,
        'severity': 'high',
        'recommendation': 'Consider reducing position to improve diversification'
    },
    'top_3_concentration': {
        'name': 'Top 3 Concentration',
        'description': 'Top 3 holdings should not exceed 50% of portfolio',
        'threshold': 0.50,
        'severity': 'medium',
        'recommendation': 'Portfolio may be too concentrated in a few names'
    },
    'sector_concentration': {
        'name': 'Sector Concentration',
        'description': 'Single sector should not exceed 35% of portfolio',
        'threshold': 0.35,
        'severity': 'medium',
        'recommendation': 'Consider diversifying across more sectors'
    },
    'minimum_diversification': {
        'name': 'Minimum Diversification',
        'description': 'Portfolio should have at least 10 meaningful positions',
        'threshold': 10,
        'severity': 'medium',
        'recommendation': 'Add more positions to improve diversification'
    },
    'tiny_position_warning': {
        'name': 'Tiny Positions',
        'description': 'Positions below 1% may not be worth the tracking effort',
        'threshold': 0.01,
        'severity': 'low',
        'recommendation': 'Consider eliminating or building up tiny positions'
    },
    'high_volatility_exposure': {
        'name': 'High Volatility Exposure',
        'description': 'High-volatility stocks (>40% annualized) should have reduced weight',
        'threshold': 0.40,
        'severity': 'medium',
        'recommendation': 'Consider reducing exposure to highly volatile names'
    },
    'correlation_cluster': {
        'name': 'Correlation Cluster',
        'description': 'Avoid having too many highly correlated positions',
        'threshold': 0.80,
        'severity': 'medium',
        'recommendation': 'Positions are highly correlated - diversification benefit is limited'
    }
}


def check_expert_wisdom(optimal_weights, tickers, returns_df, risk_profile_config=None):
    """
    Check portfolio against expert wisdom rules and return violations/warnings.

    Args:
        optimal_weights: numpy array of optimized weights
        tickers: list of ticker symbols
        returns_df: DataFrame of historical returns
        risk_profile_config: optional risk profile configuration

    Returns:
        dict: Contains 'violations' (list of rule violations) and 'score' (wisdom score 0-100)
    """
    violations = []
    n_assets = len(optimal_weights)

    # Rule 1: Single stock concentration
    max_weight = np.max(optimal_weights)
    if max_weight > EXPERT_WISDOM_RULES['single_stock_concentration']['threshold']:
        max_ticker = tickers[np.argmax(optimal_weights)]
        violations.append({
            'rule': 'single_stock_concentration',
            'severity': 'high',
            'message': f"‚ö†Ô∏è **{max_ticker}** has {max_weight*100:.1f}% weight - exceeds 25% single stock limit",
            'ticker': max_ticker,
            'value': max_weight
        })

    # Rule 2: Top 3 concentration
    sorted_weights = np.sort(optimal_weights)[::-1]
    top_3_weight = sorted_weights[:3].sum()
    if top_3_weight > EXPERT_WISDOM_RULES['top_3_concentration']['threshold']:
        top_3_idx = np.argsort(optimal_weights)[::-1][:3]
        top_3_tickers = [tickers[i] for i in top_3_idx]
        violations.append({
            'rule': 'top_3_concentration',
            'severity': 'medium',
            'message': f"‚ö†Ô∏è Top 3 holdings ({', '.join(top_3_tickers)}) = {top_3_weight*100:.1f}% - exceeds 50% limit",
            'tickers': top_3_tickers,
            'value': top_3_weight
        })

    # Rule 3: Minimum diversification (count meaningful positions)
    meaningful_positions = np.sum(optimal_weights >= 0.02)  # 2% threshold
    min_required = risk_profile_config.get('min_diversification', 10) if risk_profile_config else 10
    if meaningful_positions < min_required:
        violations.append({
            'rule': 'minimum_diversification',
            'severity': 'medium',
            'message': f"‚ö†Ô∏è Only {meaningful_positions} meaningful positions (>2%) - target is {min_required}+",
            'value': meaningful_positions
        })

    # Rule 4: Tiny positions warning
    tiny_positions = []
    for i, w in enumerate(optimal_weights):
        if 0 < w < EXPERT_WISDOM_RULES['tiny_position_warning']['threshold']:
            tiny_positions.append(tickers[i])
    if len(tiny_positions) > 3:
        violations.append({
            'rule': 'tiny_position_warning',
            'severity': 'low',
            'message': f"üí° {len(tiny_positions)} positions below 1% - consider consolidating: {', '.join(tiny_positions[:5])}{'...' if len(tiny_positions) > 5 else ''}",
            'tickers': tiny_positions,
            'value': len(tiny_positions)
        })

    # Rule 5: High volatility exposure
    if returns_df is not None and len(returns_df) > 0:
        vols = returns_df.std() * np.sqrt(252)
        high_vol_tickers = []
        for i, ticker in enumerate(tickers):
            if ticker in vols.index:
                if vols[ticker] > EXPERT_WISDOM_RULES['high_volatility_exposure']['threshold']:
                    if optimal_weights[i] > 0.10:  # Only warn if >10% position
                        high_vol_tickers.append((ticker, vols[ticker], optimal_weights[i]))

        if high_vol_tickers:
            for ticker, vol, weight in high_vol_tickers:
                violations.append({
                    'rule': 'high_volatility_exposure',
                    'severity': 'medium',
                    'message': f"‚ö†Ô∏è **{ticker}** has {vol*100:.0f}% volatility with {weight*100:.1f}% weight - consider reducing",
                    'ticker': ticker,
                    'value': {'volatility': vol, 'weight': weight}
                })

    # Calculate wisdom score (0-100)
    high_violations = sum(1 for v in violations if v['severity'] == 'high')
    medium_violations = sum(1 for v in violations if v['severity'] == 'medium')
    low_violations = sum(1 for v in violations if v['severity'] == 'low')

    # Scoring: start at 100, deduct for violations
    score = 100
    score -= high_violations * 20
    score -= medium_violations * 10
    score -= low_violations * 5
    score = max(0, min(100, score))

    return {
        'violations': violations,
        'score': score,
        'high_count': high_violations,
        'medium_count': medium_violations,
        'low_count': low_violations
    }


def get_wisdom_grade(score):
    """Convert wisdom score to letter grade with description."""
    if score >= 90:
        return 'A', 'Excellent', 'üü¢'
    elif score >= 80:
        return 'B', 'Good', 'üü¢'
    elif score >= 70:
        return 'C', 'Acceptable', 'üü°'
    elif score >= 60:
        return 'D', 'Needs Improvement', 'üü†'
    else:
        return 'F', 'Poor', 'üî¥'


def calculate_max_risk_contrib(weights, returns_df):
    """Calculate maximum risk contribution from any single asset"""
    cov_matrix = returns_df.cov() * 252
    port_vol = np.sqrt(weights @ cov_matrix @ weights)

    if port_vol == 0:
        return 0

    # Marginal contribution to risk
    marginal_contrib = (cov_matrix @ weights) / port_vol

    # Total risk contribution
    risk_contrib = weights * marginal_contrib

    # Return max contribution as fraction of total risk
    return np.max(np.abs(risk_contrib)) / np.sum(np.abs(risk_contrib)) if np.sum(np.abs(risk_contrib)) > 0 else 0


class RobustPortfolioOptimizer:
    """
    Optimization that acknowledges we don't know future returns/correlations

    Approach: Generate multiple scenarios, find portfolio that performs well
    across ALL scenarios (not just average)
    """

    def __init__(self, returns_df, confidence_level=0.95):
        self.returns_df = returns_df
        self.confidence_level = confidence_level

    def estimate_returns_with_uncertainty(self):
        """
        Instead of point estimates, get confidence intervals

        Uses bootstrapping to estimate uncertainty in mean returns
        """
        n_bootstrap = 500  # Reduced for performance
        n_samples = len(self.returns_df)

        bootstrap_means = []
        for _ in range(n_bootstrap):
            # Resample with replacement
            sample = self.returns_df.sample(n=n_samples, replace=True)
            bootstrap_means.append(sample.mean())

        bootstrap_means = pd.DataFrame(bootstrap_means)

        return {
            'mean': self.returns_df.mean(),
            'lower_bound': bootstrap_means.quantile((1 - self.confidence_level) / 2),
            'upper_bound': bootstrap_means.quantile((1 + self.confidence_level) / 2),
            'std_error': bootstrap_means.std()
        }

    def estimate_covariance_with_shrinkage(self):
        """
        Sample covariance is noisy - shrink toward diagonal

        Ledoit-Wolf shrinkage: blend sample cov with simple structure
        """
        sample_cov = self.returns_df.cov() * 252

        # Target: diagonal matrix (assume zero correlations)
        target = np.diag(np.diag(sample_cov))

        # Optimal shrinkage intensity (simplified Ledoit-Wolf formula)
        n_samples = len(self.returns_df)
        shrinkage = min(0.5, (n_samples - 2) / (n_samples * (n_samples + 2)))

        # Shrunk covariance
        shrunk_cov = shrinkage * target + (1 - shrinkage) * sample_cov

        return shrunk_cov, shrinkage

    def generate_scenarios(self):
        """
        Generate multiple plausible future scenarios

        Scenarios:
        1. Base case (historical means)
        2. Pessimistic (lower bound returns)
        3. Optimistic (upper bound returns)
        4. High correlation (crisis scenario)
        5. Low correlation (diversification works)
        """
        returns_with_ci = self.estimate_returns_with_uncertainty()
        base_cov, _ = self.estimate_covariance_with_shrinkage()

        scenarios = {
            'base': {
                'returns': returns_with_ci['mean'],
                'cov_matrix': base_cov,
                'probability': 0.40,
                'description': 'Historical averages'
            },

            'pessimistic': {
                'returns': returns_with_ci['lower_bound'],
                'cov_matrix': base_cov * 1.5,  # Higher volatility in downturns
                'probability': 0.20,
                'description': 'Below-average returns, higher volatility'
            },

            'optimistic': {
                'returns': returns_with_ci['upper_bound'],
                'cov_matrix': base_cov * 0.8,
                'probability': 0.20,
                'description': 'Above-average returns, lower volatility'
            },

            'crisis': {
                'returns': returns_with_ci['lower_bound'] * 1.5,
                'cov_matrix': self._increase_correlations(base_cov, target_corr=0.8),
                'probability': 0.10,
                'description': 'Market stress - high correlations'
            },

            'goldilocks': {
                'returns': returns_with_ci['mean'] * 1.2,
                'cov_matrix': self._decrease_correlations(base_cov, target_corr=0.3),
                'probability': 0.10,
                'description': 'Low correlation, steady growth'
            }
        }

        return scenarios

    def _increase_correlations(self, cov_matrix, target_corr=0.8):
        """Simulate crisis scenario with high correlations"""
        corr_matrix = cov_matrix / np.outer(np.sqrt(np.diag(cov_matrix)),
                                            np.sqrt(np.diag(cov_matrix)))

        # Push correlations toward target
        crisis_corr = 0.7 * corr_matrix + 0.3 * target_corr * np.ones_like(corr_matrix)
        np.fill_diagonal(crisis_corr, 1.0)

        # Convert back to covariance
        stds = np.sqrt(np.diag(cov_matrix))
        crisis_cov = np.outer(stds, stds) * crisis_corr

        return crisis_cov

    def _decrease_correlations(self, cov_matrix, target_corr=0.3):
        """Simulate goldilocks scenario with low correlations"""
        corr_matrix = cov_matrix / np.outer(np.sqrt(np.diag(cov_matrix)),
                                            np.sqrt(np.diag(cov_matrix)))

        # Push correlations toward target
        good_corr = 0.5 * corr_matrix + 0.5 * target_corr * np.ones_like(corr_matrix)
        np.fill_diagonal(good_corr, 1.0)

        stds = np.sqrt(np.diag(cov_matrix))
        good_cov = np.outer(stds, stds) * good_corr

        return good_cov


class OptimizationExplainer:
    """
    Translate optimization results into human-readable insights

    Users need to understand:
    1. WHY these weights were chosen
    2. WHAT tradeoffs were made
    3. HOW sensitive is this to assumptions
    """

    def explain_portfolio_weights(self, weights, returns_df, strategy_type, scenarios=None, risk_profile_config=None, peak_performance=None):
        """
        Generate PM-level natural language explanation of optimization results

        PM-LEVEL TRANSPARENCY:
        - WHY each position was chosen (with quantitative support)
        - WHAT tradeoffs were made (explicit cost-benefit)
        - HOW confident we are (uncertainty ranges)
        - WHICH constraints were binding (and why)
        """
        explanations = {}
        tickers = returns_df.columns
        cov_matrix = returns_df.cov() * 252

        # ============================================================
        # 1. EXECUTIVE SUMMARY
        # ============================================================
        effective_n = 1 / np.sum(weights ** 2)
        max_position = np.max(weights)
        top_3_conc = np.sum(np.sort(weights)[-3:])

        port_return = np.sum(returns_df.mean() * weights) * 252
        port_vol = np.sqrt(weights @ cov_matrix @ weights)
        sharpe = (port_return - 0.02) / port_vol if port_vol > 0 else 0

        try:
            max_dd = calculate_portfolio_max_drawdown(weights, returns_df)
        except:
            max_dd = 0

        explanations['executive_summary'] = {
            'title': f'{strategy_type.upper().replace("_", " ")} OPTIMIZATION',
            'metrics': {
                'Expected Return': f"{port_return:.1%}",
                'Expected Volatility': f"{port_vol:.1%}",
                'Sharpe Ratio': f"{sharpe:.2f}",
                'Max Drawdown': f"{max_dd:.1%}",
                'Effective Holdings': f"{effective_n:.1f}",
                'Largest Position': f"{max_position:.1%}",
                'Top 3 Concentration': f"{top_3_conc:.1%}"
            }
        }

        # ============================================================
        # 2. TOP HOLDINGS WITH DETAILED REASONING
        # ============================================================
        top_holdings = []
        top_5_idx = np.argsort(weights)[-5:][::-1]
        for idx in top_5_idx:
            ticker = tickers[idx]
            weight = weights[idx]

            # Enhanced reasoning with quantitative support
            reasons = self._explain_single_holding_enhanced(
                ticker, weight, returns_df, cov_matrix, strategy_type
            )

            top_holdings.append({
                'ticker': ticker,
                'weight': weight,
                'weight_pct': f"{weight:.1%}",
                'reasons': reasons
            })

        explanations['top_holdings'] = top_holdings

        # ============================================================
        # 3. TRADEOFF ANALYSIS (Critical for PM trust)
        # ============================================================
        tradeoffs = []

        if risk_profile_config and peak_performance:
            # Calculate what was sacrificed for diversification
            current_performance = sharpe
            performance_cost = (1 - current_performance/peak_performance) * 100 if peak_performance > 0 else 0

            tradeoffs.append(
                f"Accepted {performance_cost:.1f}% lower Sharpe ratio to achieve "
                f"{effective_n:.0f} effective holdings (vs concentrated peak)"
            )

            if 'max_drawdown_tolerance' in risk_profile_config:
                dd_limit = risk_profile_config['max_drawdown_tolerance']
                dd_margin = dd_limit - max_dd
                tradeoffs.append(
                    f"Maximum drawdown: {max_dd:.1%} (within {dd_limit:.1%} limit, "
                    f"{dd_margin:.1%} margin of safety)"
                )

        explanations['tradeoffs'] = tradeoffs

        # ============================================================
        # 4. CONSTRAINT ANALYSIS (Which constraints were binding?)
        # ============================================================
        binding_constraints = []

        if risk_profile_config:
            # Check position limits
            if max_position > risk_profile_config.get('max_position_base', 1) * 0.95:
                binding_constraints.append(
                    f"Position limit binding: Largest position at {max_position:.1%} "
                    f"(limit: {risk_profile_config['max_position_base']:.1%})"
                )

            # Check concentration limits
            if top_3_conc > risk_profile_config.get('max_top_3_concentration', 1) * 0.95:
                binding_constraints.append(
                    f"Top-3 concentration binding: {top_3_conc:.1%} "
                    f"(limit: {risk_profile_config['max_top_3_concentration']:.1%})"
                )

            # Check drawdown constraint
            if 'max_drawdown_tolerance' in risk_profile_config:
                dd_limit = risk_profile_config['max_drawdown_tolerance']
                if max_dd > dd_limit * 0.90:
                    binding_constraints.append(
                        f"Drawdown constraint active: {max_dd:.1%} "
                        f"(limit: {dd_limit:.1%})"
                    )

        explanations['binding_constraints'] = binding_constraints if binding_constraints else [
            "No constraints binding - optimizer found unconstrained optimum"
        ]

        # ============================================================
        # 5. RISK BREAKDOWN (Where is risk coming from?)
        # ============================================================
        risk_contribs = self._calculate_risk_contributions(weights, cov_matrix)
        top_risk_idx = np.argsort(risk_contribs)[-5:][::-1]

        explanations['risk_breakdown'] = [
            {
                'ticker': tickers[i],
                'weight': f"{weights[i]:.1%}",
                'risk_contribution': f"{risk_contribs[i]:.1%}",
                'risk_to_weight_ratio': f"{(risk_contribs[i]/weights[i]):.2f}x" if weights[i] > 0 else "N/A"
            }
            for i in top_risk_idx
        ]

        # ============================================================
        # 6. UNCERTAINTY & ASSUMPTIONS
        # ============================================================
        explanations['assumptions'] = [
            f"Historical returns based on {len(returns_df)} trading days",
            "Assumes returns are normally distributed (actual returns may have fat tails)",
            "Past performance does not guarantee future results",
            "Correlations and volatilities may change during market stress"
        ]

        return explanations

    def _explain_single_holding_enhanced(self, ticker, weight, returns_df, cov_matrix, strategy_type):
        """
        PM-LEVEL EXPLANATION: WHY was this specific holding chosen?
        Provide quantitative support for every reason
        """
        returns = returns_df[ticker]
        ann_return = returns.mean() * 252
        ann_vol = returns.std() * np.sqrt(252)
        sharpe = ann_return / ann_vol if ann_vol > 0 else 0

        # Correlation with rest of portfolio
        correlations = returns_df.corr()[ticker].drop(ticker)
        avg_corr = correlations.mean()
        max_corr = correlations.max()

        # Risk contribution
        risk_contribs = self._calculate_risk_contributions(np.ones(len(returns_df.columns))/len(returns_df.columns), cov_matrix)

        reasons = []

        # Quantitative reasons based on strategy
        if strategy_type == 'max_sharpe':
            reasons.append(f"Return: {ann_return:.1%}/year, Vol: {ann_vol:.1%}, Sharpe: {sharpe:.2f}")
            if avg_corr < 0.6:
                reasons.append(f"Good diversifier (avg corr: {avg_corr:.2f}, max: {max_corr:.2f})")
            elif avg_corr >= 0.6:
                reasons.append(f"Higher correlation to portfolio (avg: {avg_corr:.2f}) justified by strong Sharpe")

        elif strategy_type == 'min_volatility':
            reasons.append(f"Low volatility: {ann_vol:.1%}/year")
            reasons.append(f"Avg correlation: {avg_corr:.2f} provides portfolio diversification")

        elif strategy_type == 'max_return':
            reasons.append(f"Strong historical return: {ann_return:.1%}/year")
            if ann_vol > 0.30:
                reasons.append(f"High volatility ({ann_vol:.1%}) tolerated for return potential")

        # Weight-based reasoning
        if weight > 0.10:
            reasons.append(f"Large {weight:.1%} allocation reflects strong contribution to objective")
        elif weight < 0.05:
            reasons.append(f"Modest {weight:.1%} allocation for diversification/risk balance")

        return reasons

    def _explain_single_holding(self, ticker, weight, returns_df, strategy_type):
        """WHY was this specific holding chosen?"""
        returns = returns_df[ticker]
        ann_return = returns.mean() * 252
        ann_vol = returns.std() * np.sqrt(252)
        sharpe = ann_return / ann_vol if ann_vol > 0 else 0

        avg_corr = returns_df.corr()[ticker].drop(ticker).mean()

        reasons = []

        if strategy_type == 'max_sharpe':
            if sharpe > 1.0:
                reasons.append(f"Strong risk-adjusted returns (Sharpe: {sharpe:.2f})")
            if avg_corr < 0.5:
                reasons.append(f"Low correlation with other holdings ({avg_corr:.2f})")

        elif strategy_type == 'min_volatility':
            if ann_vol < 0.20:
                reasons.append(f"Low volatility ({ann_vol:.1%} annual)")
            if avg_corr < 0.6:
                reasons.append(f"Provides diversification (avg corr: {avg_corr:.2f})")

        elif strategy_type == 'max_return':
            if ann_return > 0.15:
                reasons.append(f"High historical return ({ann_return:.1%} annual)")

        if weight > 0.15:
            reasons.append(f"Large allocation reflects strong fundamentals")

        if len(reasons) == 0:
            reasons.append("Contributes to overall portfolio optimization")

        return reasons

    def _calculate_risk_contributions(self, weights, cov_matrix):
        """Calculate risk contribution of each asset"""
        port_vol = np.sqrt(weights @ cov_matrix @ weights)

        if port_vol == 0:
            return np.zeros(len(weights))

        # Marginal contribution to risk
        marginal_contrib = (cov_matrix @ weights) / port_vol

        # Total risk contribution
        risk_contrib = weights * marginal_contrib

        return risk_contrib

    def generate_sensitivity_analysis(self, weights, returns_df, scenarios):
        """How sensitive is this portfolio to different scenarios?"""
        sensitivity = {}

        for scenario_name, scenario in scenarios.items():
            port_return = weights @ scenario['returns'] * 252
            port_vol = np.sqrt(weights @ scenario['cov_matrix'] @ weights)
            sharpe = port_return / port_vol if port_vol > 0 else 0

            sensitivity[scenario_name] = {
                'description': scenario['description'],
                'expected_return': port_return * 100,
                'volatility': port_vol * 100,
                'sharpe_ratio': sharpe,
                'probability': scenario['probability']
            }

        return sensitivity

    def identify_red_flags(self, weights, returns_df, config):
        """Automated sanity checks - warn user if something looks off"""
        red_flags = []
        yellow_flags = []

        # 1. Over-concentration
        max_weight = np.max(weights)
        if max_weight > 0.30:
            red_flags.append(f"‚ö†Ô∏è Single position at {max_weight:.1%} - consider reducing")
        elif max_weight > 0.25:
            yellow_flags.append(f"‚ö° Largest position at {max_weight:.1%} - monitor closely")

        # 2. Insufficient diversification
        effective_n = 1 / np.sum(weights ** 2)
        if effective_n < 5:
            red_flags.append(f"‚ö†Ô∏è Very concentrated ({effective_n:.1f} effective holdings)")
        elif effective_n < 7:
            yellow_flags.append(f"‚ö° Moderate concentration ({effective_n:.1f} effective holdings)")

        # 3. Check for extreme allocations
        tiny_positions = np.sum((weights > 0) & (weights < 0.02))
        if tiny_positions > 3:
            yellow_flags.append(f"‚ö° {tiny_positions} very small positions (<2%) - consider consolidating")

        return {'red_flags': red_flags, 'yellow_flags': yellow_flags}


def validate_portfolio_realism(weights, returns_df, strategy_type):
    """
    Score portfolio on realism scale 0-100

    Checks:
    - Diversification level
    - Position sizes
    - Risk concentration
    """
    score = 100
    issues = []

    # 1. Diversification check
    effective_n = 1 / np.sum(weights ** 2)
    if effective_n < 5:
        score -= 30
        issues.append("Very low diversification")
    elif effective_n < 7:
        score -= 15
        issues.append("Low diversification")

    # 2. Position size check
    max_weight = np.max(weights)
    if max_weight > 0.40:
        score -= 25
        issues.append("Excessive single position")
    elif max_weight > 0.30:
        score -= 10
        issues.append("Large single position")

    # 3. Number of tiny positions
    tiny = np.sum((weights > 0) & (weights < 0.02))
    if tiny > 5:
        score -= 15
        issues.append("Too many tiny positions")

    # 4. Equal weight check (bad sign)
    weights_nonzero = weights[weights > 0.01]
    if len(weights_nonzero) > 0:
        cv = np.std(weights_nonzero) / np.mean(weights_nonzero)
        if cv < 0.15:  # Very similar weights
            score -= 20
            issues.append("Near equal weighting detected")

    score = max(0, score)

    # Classification
    if score >= 80:
        classification = "Excellent - Realistic and well-diversified"
    elif score >= 60:
        classification = "Good - Some minor concerns"
    elif score >= 40:
        classification = "Fair - Notable issues present"
    else:
        classification = "Poor - Significant problems"

    return {
        'overall': score,
        'classification': classification,
        'issues': issues
    }


# ============================================================================
# TWO-STAGE DIVERSIFICATION-FIRST OPTIMIZATION SYSTEM
# ============================================================================
# Key Insight: Hundreds of portfolios on efficient frontier perform similarly.
# Choose the MOST DIVERSIFIED one, not the most concentrated.
# ============================================================================

def calculate_performance_metric(weights, returns_df, strategy_type, risk_free_rate=0.02):
    """Calculate the relevant performance metric for the strategy"""
    cov_matrix = returns_df.cov() * 252

    if strategy_type == 'max_sharpe':
        port_return = np.sum(returns_df.mean() * weights) * 252
        port_vol = np.sqrt(weights @ cov_matrix @ weights)
        return (port_return - risk_free_rate) / port_vol if port_vol > 0 else 0

    elif strategy_type == 'min_volatility':
        return -np.sqrt(weights @ cov_matrix @ weights)  # Negative for constraint

    elif strategy_type == 'cvar_minimization':
        portfolio_returns = returns_df.values @ weights
        var_threshold = np.percentile(portfolio_returns, 5)
        cvar = portfolio_returns[portfolio_returns <= var_threshold].mean()
        return -cvar  # Negative because we minimize CVaR

    elif strategy_type == 'max_return':
        mean_returns = returns_df.mean() * 252
        return np.sum(mean_returns * weights)

    elif strategy_type == 'risk_parity':
        # For risk parity, use negative of risk parity error as "performance"
        port_vol = np.sqrt(weights @ cov_matrix @ weights)
        if port_vol < 1e-10:
            return 0
        marginal_contrib = (cov_matrix @ weights) / port_vol
        risk_contrib = weights * marginal_contrib
        target_risk = port_vol / len(weights)
        risk_parity_error = np.sum((risk_contrib - target_risk) ** 2)
        return -risk_parity_error

    return 0


def calculate_portfolio_max_drawdown(weights, returns_df):
    """
    Calculate maximum drawdown for a portfolio with given weights

    Args:
        weights: Portfolio weights
        returns_df: Historical returns dataframe

    Returns:
        Maximum drawdown as a positive decimal (e.g., 0.20 for 20% drawdown)
    """
    try:
        # Calculate portfolio returns
        portfolio_returns = returns_df.values @ weights

        # Calculate cumulative returns
        cumulative = (1 + portfolio_returns).cumprod()

        # Calculate running maximum
        running_max = np.maximum.accumulate(cumulative)

        # Calculate drawdown at each point
        drawdown = (cumulative - running_max) / running_max

        # Return maximum drawdown as positive value
        max_dd = abs(np.min(drawdown))

        return max_dd
    except:
        return 0.0

def calculate_max_risk_contrib_pct(weights, returns_df):
    """Calculate maximum risk contribution from any single asset as percentage"""
    cov_matrix = returns_df.cov() * 252
    port_vol = np.sqrt(weights @ cov_matrix @ weights)

    if port_vol < 1e-10:
        return 0

    marginal_contrib = (cov_matrix @ weights) / port_vol
    risk_contribs = weights * marginal_contrib / port_vol
    return np.max(np.abs(risk_contribs))


def optimize_two_stage_diversification_first(
    returns_df,
    strategy_type,
    risk_profile_config,
    risk_free_rate=0.02,
    verbose=True,
    target_leverage=1.0
):
    """
    TWO-STAGE DIVERSIFICATION-FIRST OPTIMIZATION

    STAGE 1: Find peak performance (the "optimal" concentrated solution)
    STAGE 2: Maximize diversification while maintaining acceptable performance

    This finds the MOST DIVERSIFIED portfolio on the efficient frontier,
    not the most concentrated one.

    FIXED v11.0: Added leverage support

    Args:
        returns_df: Historical returns
        strategy_type: 'max_sharpe', 'min_volatility', etc.
        risk_profile_config: Configuration from RiskProfile
        risk_free_rate: Risk-free rate for Sharpe calculation
        verbose: Print optimization details
        target_leverage: Target portfolio leverage (default 1.0 = no leverage)

    Returns:
        Optimized weights (most diversified solution on efficient frontier)
    """
    from scipy.optimize import minimize

    n_assets = len(returns_df.columns)
    cov_matrix = returns_df.cov() * 252

    # ========================================
    # STAGE 1: FIND PEAK PERFORMANCE
    # ========================================

    if verbose:
        print(f"\n{'='*60}")
        print(f"STAGE 1: Finding peak performance...")
        print(f"{'='*60}")

    # Use relaxed constraints to find true optimum
    peak_weights = optimize_for_peak_performance(
        returns_df, strategy_type, risk_free_rate, max_position=0.30, target_leverage=target_leverage
    )

    peak_performance = calculate_performance_metric(
        peak_weights, returns_df, strategy_type, risk_free_rate
    )

    peak_effective_n = 1 / np.sum(peak_weights ** 2)
    peak_max_position = np.max(peak_weights)

    if verbose:
        print(f"Peak performance: {peak_performance:.4f}")
        print(f"Effective holdings: {peak_effective_n:.1f}")
        print(f"Max position: {peak_max_position:.1%}")

    # ========================================
    # STAGE 2: MAXIMIZE DIVERSIFICATION
    # ========================================

    if verbose:
        print(f"\n{'='*60}")
        print(f"STAGE 2: Maximizing diversification...")
        print(f"{'='*60}")

    # Set acceptable performance threshold
    min_acceptable_performance = peak_performance * risk_profile_config['acceptable_sharpe_ratio']

    if verbose:
        print(f"Min acceptable performance: {min_acceptable_performance:.4f}")
        print(f"(={risk_profile_config['acceptable_sharpe_ratio']:.0%} of peak)")

    def diversification_objective(weights):
        """
        Objective: MINIMIZE concentration (MAXIMIZE diversification)
        Using Herfindahl-Hirschman Index (HHI)
        Lower HHI = more diversified
        """
        hhi = np.sum(weights ** 2)

        # Penalize too few meaningful positions
        meaningful_positions = np.sum(weights >= risk_profile_config['min_position_to_count'])
        if meaningful_positions < risk_profile_config['target_holdings']:
            sparsity_penalty = (risk_profile_config['target_holdings'] - meaningful_positions) * 0.01
        else:
            sparsity_penalty = 0

        return hhi + sparsity_penalty

    # FIXED v11.0: Leverage constraint
    def leverage_constraint_stage2(w, target_lev):
        """Leverage = sum of absolute weights"""
        return np.abs(w).sum() - target_lev

    # Build constraints
    constraints = [
        {'type': 'eq', 'fun': leverage_constraint_stage2, 'args': (target_leverage,)},

        # CRITICAL: Performance must stay above threshold
        {'type': 'ineq',
         'fun': lambda w: calculate_performance_metric(w, returns_df, strategy_type, risk_free_rate) - min_acceptable_performance},

        # Minimum meaningful holdings
        {'type': 'ineq',
         'fun': lambda w: np.sum(w >= risk_profile_config['min_position_to_count']) - risk_profile_config['min_diversification']},

        # Top 3 concentration limit (adjusted for leverage)
        {'type': 'ineq',
         'fun': lambda w: risk_profile_config['max_top_3_concentration'] * target_leverage - np.sum(np.sort(w)[-3:])},

        # Top 5 concentration limit (adjusted for leverage)
        {'type': 'ineq',
         'fun': lambda w: risk_profile_config['max_top_5_concentration'] * target_leverage - np.sum(np.sort(w)[-5:])},

        # Risk contribution limit
        {'type': 'ineq',
         'fun': lambda w: risk_profile_config['risk_budget_per_asset'] - calculate_max_risk_contrib_pct(w, returns_df)},
    ]

    # DRAWDOWN AWARENESS: Add max drawdown constraint for conservative (and moderate) profiles
    if 'max_drawdown_tolerance' in risk_profile_config:
        max_dd_allowed = risk_profile_config['max_drawdown_tolerance']
        if verbose:
            print(f"Adding drawdown constraint: Max {max_dd_allowed:.1%} drawdown")

        constraints.append({
            'type': 'ineq',
            'fun': lambda w: max_dd_allowed - calculate_portfolio_max_drawdown(w, returns_df)
        })

    # Volatility-adjusted position limits
    volatilities = returns_df.std() * np.sqrt(252)
    median_vol = volatilities.median()
    vol_scalars = np.clip(median_vol / volatilities, 0.5, 1.5)

    position_limits = risk_profile_config['max_position_base'] * vol_scalars
    position_limits = np.clip(position_limits, 0.01, risk_profile_config['max_position_base'])

    bounds = [(0, limit) for limit in position_limits]

    # Initial guess: Equal weight scaled by leverage (most diversified starting point)
    initial_guess = np.ones(n_assets) * (target_leverage / n_assets)

    # Optimize for DIVERSIFICATION subject to performance constraint
    result = minimize(
        diversification_objective,
        initial_guess,
        method='SLSQP',
        bounds=bounds,
        constraints=constraints,
        options={'maxiter': 2000, 'ftol': 1e-10}
    )

    if not result.success:
        if verbose:
            print(f"Warning: {result.message}")
            print("Falling back to peak performance portfolio...")
        return peak_weights

    diversified_weights = result.x

    # Clean up tiny positions
    min_position = risk_profile_config.get('min_position_to_count', 0.02) / 2
    diversified_weights[diversified_weights < min_position] = 0

    # Renormalize to target leverage
    current_leverage = np.abs(diversified_weights).sum()
    if current_leverage > 0:
        diversified_weights = diversified_weights * (target_leverage / current_leverage)
    else:
        diversified_weights = peak_weights

    # ========================================
    # STAGE 3: VALIDATE & COMPARE
    # ========================================

    final_performance = calculate_performance_metric(
        diversified_weights, returns_df, strategy_type, risk_free_rate
    )
    performance_ratio = final_performance / peak_performance

    final_effective_n = 1 / np.sum(diversified_weights ** 2)
    final_max_position = np.max(diversified_weights)
    final_top_3 = np.sum(np.sort(diversified_weights)[-3:])

    # Calculate drawdowns for both portfolios
    peak_drawdown = calculate_portfolio_max_drawdown(peak_weights, returns_df)
    final_drawdown = calculate_portfolio_max_drawdown(diversified_weights, returns_df)

    if verbose:
        print(f"\n{'='*60}")
        print(f"DIVERSIFICATION OPTIMIZATION RESULTS")
        print(f"{'='*60}")
        print(f"\nPeak Performance Portfolio:")
        print(f"  Performance: {peak_performance:.4f}")
        print(f"  Effective Holdings: {peak_effective_n:.1f}")
        print(f"  Largest Position: {peak_max_position:.1%}")
        print(f"  Top 3 Total: {np.sum(np.sort(peak_weights)[-3:]):.1%}")
        print(f"  Max Drawdown: {peak_drawdown:.1%}")

        print(f"\nDiversified Portfolio:")
        print(f"  Performance: {final_performance:.4f} ({performance_ratio:.1%} of peak)")
        print(f"  Effective Holdings: {final_effective_n:.1f} ({final_effective_n/peak_effective_n:.1f}x more)")
        print(f"  Largest Position: {final_max_position:.1%}")
        print(f"  Top 3 Total: {final_top_3:.1%}")
        print(f"  Max Drawdown: {final_drawdown:.1%}")

        # Show drawdown constraint status if applicable
        if 'max_drawdown_tolerance' in risk_profile_config:
            max_dd_allowed = risk_profile_config['max_drawdown_tolerance']
            dd_margin = max_dd_allowed - final_drawdown
            print(f"  Drawdown Margin: {dd_margin:.1%} (limit: {max_dd_allowed:.1%})")

        print(f"\nTRADEOFF:")
        print(f"  Diversification Increase: {final_effective_n/peak_effective_n:.1f}x")
        print(f"  Performance Cost: {(1-performance_ratio)*100:.1f}%")
        print(f"  Drawdown Improvement: {(peak_drawdown-final_drawdown):.1%}")
        print(f"{'='*60}\n")

    return diversified_weights


def optimize_for_peak_performance(returns_df, strategy_type, risk_free_rate, max_position=0.30, target_leverage=1.0):
    """
    Find peak performance with minimal constraints

    This is STAGE 1 - find the best possible performance

    FIXED v11.0: Added leverage support
    """
    from scipy.optimize import minimize

    n_assets = len(returns_df.columns)

    # Use the original optimization functions with relaxed constraints
    if strategy_type == 'max_sharpe':
        weights = optimize_max_sharpe(returns_df, risk_free_rate, max_position, 0.01, target_leverage)
    elif strategy_type == 'min_volatility':
        weights = optimize_min_volatility(returns_df, max_position, 0.01, target_leverage)
    elif strategy_type == 'max_return':
        weights = optimize_max_return(returns_df, max_position, 0.01, target_leverage)
    elif strategy_type == 'risk_parity':
        weights = optimize_risk_parity(returns_df, max_position, 0.01, target_leverage)
    else:
        # Default: equal weight scaled by leverage
        weights = pd.Series(np.ones(n_assets) * (target_leverage / n_assets), index=returns_df.columns)

    return weights.values if isinstance(weights, pd.Series) else weights


# ============================================================================
# ORIGINAL OPTIMIZATION FUNCTIONS (Used for Stage 1 Peak Finding)
# ============================================================================

def optimize_max_sharpe(returns_df, risk_free_rate, max_position=0.25, min_position=0.02, target_leverage=1.0):
    """
    Optimize for maximum Sharpe ratio with production-grade constraints

    FIXED v10.3: Removed aggressive penalties that were causing equal-weight portfolios.
    Now uses proper constraints and gentle regularization.

    FIXED v11.0: Added leverage constraint support. Leverage = sum of absolute weights.

    NOTE: This function is now primarily used for STAGE 1 (peak finding).
    For diversification-first optimization, use optimize_two_stage_diversification_first()

    Args:
        target_leverage: Target portfolio leverage (default 1.0 = no leverage)
                        1.0x = sum(abs(weights)) = 1.0 (long only, fully invested)
                        2.0x = sum(abs(weights)) = 2.0 (2x leverage)
    """
    from scipy.optimize import minimize

    n_assets = len(returns_df.columns)

    def neg_sharpe(weights):
        port_return = np.sum(returns_df.mean() * weights) * 252
        port_vol = np.sqrt(np.dot(weights.T, np.dot(returns_df.cov() * 252, weights)))
        sharpe = (port_return - risk_free_rate) / port_vol if port_vol > 0 else 0

        # GENTLE regularization - tiny penalty to avoid extreme concentration
        # Scaled to be ~1% of typical Sharpe ratio magnitude
        hhi = np.sum(weights ** 2)
        gentle_regularization = 0.01 * (hhi - 1/n_assets)

        return -sharpe + gentle_regularization

    # FIXED v11.0: Leverage constraint using absolute sum of weights
    def leverage_constraint(w, target_lev):
        """Leverage = sum of absolute weights"""
        return np.abs(w).sum() - target_lev

    constraints = [
        {'type': 'eq', 'fun': leverage_constraint, 'args': (target_leverage,)}
    ]
    bounds = tuple((0, max_position) for _ in range(n_assets))
    initial_guess = np.array([target_leverage/n_assets] * n_assets)  # Scale initial guess by leverage

    result = minimize(neg_sharpe, initial_guess, method='SLSQP', bounds=bounds, constraints=constraints,
                     options={'maxiter': 1000, 'ftol': 1e-9})

    # Post-processing: Remove tiny positions
    optimized_weights = result.x.copy()
    optimized_weights[optimized_weights < min_position] = 0

    # Renormalize to target leverage
    current_leverage = np.abs(optimized_weights).sum()
    if current_leverage > 0:
        optimized_weights = optimized_weights * (target_leverage / current_leverage)
    else:
        optimized_weights = np.array([target_leverage/n_assets] * n_assets)

    return pd.Series(optimized_weights, index=returns_df.columns)

def optimize_min_volatility(returns_df, max_position=0.25, min_position=0.02, target_leverage=1.0):
    """
    Optimize for minimum volatility with production-grade constraints

    FIXED v10.3: Removed aggressive penalties that were causing equal-weight portfolios.
    Now uses proper constraints and gentle regularization.

    FIXED v11.0: Added leverage constraint support. Leverage = sum of absolute weights.

    Args:
        target_leverage: Target portfolio leverage (default 1.0 = no leverage)
    """
    from scipy.optimize import minimize

    n_assets = len(returns_df.columns)

    def portfolio_vol(weights):
        vol = np.sqrt(np.dot(weights.T, np.dot(returns_df.cov() * 252, weights)))

        # GENTLE regularization - tiny penalty to avoid extreme concentration
        # Scaled to be ~0.5% of typical volatility magnitude
        hhi = np.sum(weights ** 2)
        gentle_regularization = 0.001 * (hhi - 1/n_assets)

        return vol + gentle_regularization

    # FIXED v11.0: Leverage constraint using absolute sum of weights
    def leverage_constraint(w, target_lev):
        """Leverage = sum of absolute weights"""
        return np.abs(w).sum() - target_lev

    constraints = [
        {'type': 'eq', 'fun': leverage_constraint, 'args': (target_leverage,)}
    ]
    bounds = tuple((0, max_position) for _ in range(n_assets))
    initial_guess = np.array([target_leverage/n_assets] * n_assets)

    result = minimize(portfolio_vol, initial_guess, method='SLSQP', bounds=bounds, constraints=constraints,
                     options={'maxiter': 1000, 'ftol': 1e-9})

    # Post-processing: Remove tiny positions
    optimized_weights = result.x.copy()
    optimized_weights[optimized_weights < min_position] = 0

    # Renormalize to target leverage
    current_leverage = np.abs(optimized_weights).sum()
    if current_leverage > 0:
        optimized_weights = optimized_weights * (target_leverage / current_leverage)
    else:
        optimized_weights = np.array([target_leverage/n_assets] * n_assets)

    return pd.Series(optimized_weights, index=returns_df.columns)

def optimize_max_return(returns_df, max_position=0.25, min_position=0.02, target_leverage=1.0):
    """
    Optimize for maximum return with production-grade constraints

    FIXED v10.3: Removed aggressive penalties that were causing equal-weight portfolios.
    Now uses proper constraints and gentle regularization.

    FIXED v11.0: Added leverage constraint support. Leverage = sum of absolute weights.

    Args:
        target_leverage: Target portfolio leverage (default 1.0 = no leverage)
    """
    from scipy.optimize import minimize

    n_assets = len(returns_df.columns)
    mean_returns = returns_df.mean() * 252

    def neg_return(weights):
        portfolio_return = np.sum(mean_returns * weights)

        # GENTLE regularization - tiny penalty to avoid extreme concentration
        # Scaled to be ~1% of typical return magnitude
        hhi = np.sum(weights ** 2)
        gentle_regularization = 0.005 * (hhi - 1/n_assets)

        return -portfolio_return + gentle_regularization

    # FIXED v11.0: Leverage constraint using absolute sum of weights
    def leverage_constraint(w, target_lev):
        """Leverage = sum of absolute weights"""
        return np.abs(w).sum() - target_lev

    constraints = [
        {'type': 'eq', 'fun': leverage_constraint, 'args': (target_leverage,)}
    ]
    bounds = tuple((0, max_position) for _ in range(n_assets))
    initial_guess = np.array([target_leverage/n_assets] * n_assets)

    result = minimize(neg_return, initial_guess, method='SLSQP', bounds=bounds, constraints=constraints,
                     options={'maxiter': 1000, 'ftol': 1e-9})

    # Post-processing: Remove tiny positions
    optimized_weights = result.x.copy()
    optimized_weights[optimized_weights < min_position] = 0

    # Renormalize to target leverage
    current_leverage = np.abs(optimized_weights).sum()
    if current_leverage > 0:
        optimized_weights = optimized_weights * (target_leverage / current_leverage)
    else:
        optimized_weights = np.array([target_leverage/n_assets] * n_assets)

    return pd.Series(optimized_weights, index=returns_df.columns)

def optimize_risk_parity(returns_df, max_position=0.25, min_position=0.02, target_leverage=1.0):
    """
    Risk parity optimization with production-grade constraints

    FIXED v10.3: Removed aggressive penalties that were causing equal-weight portfolios.
    Now uses pure risk parity objective with proper constraints.

    FIXED v11.0: Added leverage constraint support. Leverage = sum of absolute weights.

    Args:
        target_leverage: Target portfolio leverage (default 1.0 = no leverage)
    """
    from scipy.optimize import minimize

    n_assets = len(returns_df.columns)
    cov_matrix = returns_df.cov() * 252

    def risk_parity_objective(weights):
        port_vol = np.sqrt(np.dot(weights.T, np.dot(cov_matrix, weights)))
        if port_vol == 0:
            return 1e10
        marginal_contrib = np.dot(cov_matrix, weights) / port_vol
        risk_contrib = weights * marginal_contrib
        target_risk = port_vol / n_assets
        risk_parity_error = np.sum((risk_contrib - target_risk) ** 2)

        return risk_parity_error

    # FIXED v11.0: Leverage constraint using absolute sum of weights
    def leverage_constraint(w, target_lev):
        """Leverage = sum of absolute weights"""
        return np.abs(w).sum() - target_lev

    constraints = [
        {'type': 'eq', 'fun': leverage_constraint, 'args': (target_leverage,)}
    ]
    bounds = tuple((0, max_position) for _ in range(n_assets))
    initial_guess = np.array([target_leverage/n_assets] * n_assets)

    result = minimize(risk_parity_objective, initial_guess, method='SLSQP', bounds=bounds, constraints=constraints,
                     options={'maxiter': 1000, 'ftol': 1e-9})

    # Post-processing: Remove tiny positions
    optimized_weights = result.x.copy()
    optimized_weights[optimized_weights < min_position] = 0

    # Renormalize to target leverage
    current_leverage = np.abs(optimized_weights).sum()
    if current_leverage > 0:
        optimized_weights = optimized_weights * (target_leverage / current_leverage)
    else:
        optimized_weights = np.array([target_leverage/n_assets] * n_assets)

    return pd.Series(optimized_weights, index=returns_df.columns)

@st.cache_data(ttl=300)
def calculate_max_drawdown(returns):
    """Calculate Maximum Drawdown with caching for improved performance"""
    if not is_valid_series(returns) or len(returns) < 2:
        return None
    try:
        cumulative = (1 + returns).cumprod()
        running_max = cumulative.expanding().max()
        drawdown = (cumulative - running_max) / running_max
        return drawdown.min() * 100
    except Exception as e:
        return None

def calculate_calmar_ratio(returns, risk_free_rate=RISK_FREE_RATE):
    if not is_valid_series(returns) or len(returns) < 2:
        return None
    total_return = (1 + returns).prod() - 1
    n_years = len(returns) / 252
    annualized_return = (1 + total_return) ** (1/n_years) - 1 if n_years > 0 else 0
    max_dd = abs(calculate_max_drawdown(returns))
    if max_dd == 0:
        return 0
    return (annualized_return - risk_free_rate) / (max_dd / 100)

def calculate_portfolio_correlations(df, period='90d'):
    """
    Calculate correlation matrix for portfolio holdings
    period: '30d', '90d', '1y'
    """
    # Parse period
    period_map = {
        '30d': 30,
        '90d': 90,
        '1y': 365
    }
    days = period_map.get(period, 90)

    # Fetch data for all tickers
    end_date = datetime.now()
    start_date = end_date - timedelta(days=days + 30)  # Extra buffer for data

    tickers = df['Ticker'].unique().tolist()

    # Collect returns for all tickers
    returns_dict = {}

    for ticker in tickers:
        try:
            hist_data = fetch_historical_data(ticker, start_date, end_date)
            if hist_data is not None and len(hist_data) > 20:
                ticker_returns = hist_data['Close'].pct_change().dropna()
                if len(ticker_returns) > 0:
                    returns_dict[ticker] = ticker_returns
        except:
            continue

    # Create DataFrame from returns
    if len(returns_dict) < 2:
        return None

    returns_df = pd.DataFrame(returns_dict)

    # Calculate correlation matrix
    correlation_matrix = returns_df.corr()

    return correlation_matrix

# ============================================================================
# CONTINUING IN PART 2...
# ============================================================================
# Part 2 will contain all visualizations and page implementations
# Save this file and paste Part 2 below it!


# ============================================================================
# WORLD-CLASS VISUALIZATIONS - ENHANCED WITH SEAMLESS THEMING
# ============================================================================

def create_top_contributors_chart(df, top_n=5, use_professional_theme=True):
    """Top contributors in PERCENTAGE terms - Professional Blue theme"""
    top_contributors = df.nlargest(top_n, 'Total Gain/Loss %')[['Ticker', 'Asset Name', 'Total Gain/Loss $', 'Total Gain/Loss %']]

    # Theme colors
    if use_professional_theme and PROFESSIONAL_THEME_AVAILABLE:
        bar_color = '#00E676'
        border_color = 'rgba(67, 160, 71, 0.3)'
        title_color = '#FFFFFF'
        text_color = '#FFFFFF'
        paper_bg = '#1a1d29'
        grid_color = 'rgba(255, 255, 255, 0.1)'
    else:
        bar_color = COLORS['success']
        border_color = COLORS['border']
        title_color = '#ffffff'
        text_color = '#ffffff'
        paper_bg = 'rgba(0, 0, 0, 0)'
        grid_color = 'rgba(99, 102, 241, 0.1)'

    fig = go.Figure()

    fig.add_trace(go.Bar(
        x=top_contributors['Total Gain/Loss %'],
        y=top_contributors['Ticker'],
        orientation='h',
        marker=dict(
            color=bar_color,
            line=dict(color=border_color, width=1)
        ),
        text=[f"{x:+.1f}%" for x in top_contributors['Total Gain/Loss %']],
        textposition='outside',
        textfont=dict(size=11, family='JetBrains Mono', color=text_color),
        hovertemplate='<b>%{y}</b><br>Return: %{x:.2f}%<extra></extra>',
        width=0.6
    ))

    fig.update_layout(
        title=dict(text="üéØ Top 5 Contributors", font=dict(size=16, color=title_color, family='Inter'), x=0.02, xanchor='left'),
        xaxis=dict(title="Total Return (%)", showgrid=True, gridcolor=grid_color,
                   tickfont=dict(size=10, color=text_color, family='JetBrains Mono')),
        yaxis=dict(tickfont=dict(size=11, color=text_color)),
        height=350,
        showlegend=False,
        paper_bgcolor=paper_bg,
        plot_bgcolor=paper_bg,
        font=dict(family='Inter', color=text_color),
        margin=dict(l=80, r=60, t=60, b=50)
    )

    if not use_professional_theme:
        apply_chart_theme(fig)
    return fig

def create_top_detractors_chart(df, top_n=5, use_professional_theme=True):
    """Top detractors in PERCENTAGE terms - Professional Blue theme"""
    top_detractors = df.nsmallest(top_n, 'Total Gain/Loss %')[['Ticker', 'Asset Name', 'Total Gain/Loss $', 'Total Gain/Loss %']]

    # Theme colors
    if use_professional_theme and PROFESSIONAL_THEME_AVAILABLE:
        bar_color = '#FF1744'
        border_color = 'rgba(229, 57, 53, 0.3)'
        title_color = '#FFFFFF'
        text_color = '#FFFFFF'
        paper_bg = '#1a1d29'
        grid_color = 'rgba(255, 255, 255, 0.1)'
    else:
        bar_color = COLORS['danger']
        border_color = COLORS['border']
        title_color = '#ffffff'
        text_color = '#ffffff'
        paper_bg = 'rgba(0, 0, 0, 0)'
        grid_color = 'rgba(99, 102, 241, 0.1)'

    fig = go.Figure()

    fig.add_trace(go.Bar(
        x=top_detractors['Total Gain/Loss %'],
        y=top_detractors['Ticker'],
        orientation='h',
        marker=dict(
            color=bar_color,
            line=dict(color=border_color, width=1)
        ),
        text=[f"{x:.1f}%" for x in top_detractors['Total Gain/Loss %']],
        textposition='outside',
        textfont=dict(size=11, family='JetBrains Mono', color=text_color),
        hovertemplate='<b>%{y}</b><br>Loss: %{x:.2f}%<extra></extra>',
        width=0.6
    ))

    fig.update_layout(
        title=dict(text="‚ö†Ô∏è Top 5 Detractors", font=dict(size=16, color=title_color, family='Inter'), x=0.02, xanchor='left'),
        xaxis=dict(title="Total Return (%)", showgrid=True, gridcolor=grid_color,
                   tickfont=dict(size=10, color=text_color, family='JetBrains Mono')),
        yaxis=dict(tickfont=dict(size=11, color=text_color)),
        height=350,
        showlegend=False,
        paper_bgcolor=paper_bg,
        plot_bgcolor=paper_bg,
        font=dict(family='Inter', color=text_color),
        margin=dict(l=80, r=60, t=60, b=50)
    )

    if not use_professional_theme:
        apply_chart_theme(fig)
    return fig

def create_sector_allocation_donut(df):
    """v9.7 ENHANCED: Sector allocation with better spacing and ETF classification"""
    # v9.7 FIX: Rename "Other" to "ETFs"
    df_copy = df.copy()
    df_copy['Sector'] = df_copy['Sector'].replace('Other', 'ETFs')

    sector_allocation = df_copy.groupby('Sector')['Total Value'].sum().reset_index()
    sector_allocation = sector_allocation.sort_values('Total Value', ascending=False)

    # Enhanced color palette for better distinction
    colors = ['#00d4ff', '#00ff88', '#ff6b00', '#b794f6', '#ff00ff',
              '#00ffcc', '#ffaa00', '#0080ff', '#ff0044', '#cyan']

    fig = go.Figure(data=[go.Pie(
        labels=sector_allocation['Sector'],
        values=sector_allocation['Total Value'],
        hole=0.55,  # v9.7: Larger hole for better spacing
        marker=dict(
            colors=colors,
            line=dict(color=COLORS['card_background'], width=3)
        ),
        textposition='inside',
        textinfo='percent',
        textfont=dict(size=14, color='white', family='Inter'),
        insidetextorientation='radial',
        hovertemplate='<b>%{label}</b><br>Value: $%{value:,.0f}<br>Share: %{percent}<extra></extra>',
        pull=[0.05 if i == 0 else 0 for i in range(len(sector_allocation))]  # Pull out largest sector
    )])

    fig.update_layout(
        title=dict(
            text="üìä Sector Allocation",
            font=dict(size=18, color=COLORS['neon_blue']),
            x=0.5,
            xanchor='center'
        ),
        height=CHART_HEIGHT_STANDARD,  # P1-4: Standardized height
        showlegend=True,
        legend=dict(
            orientation="v",
            yanchor="top",
            y=1,
            xanchor="left",
            x=1.05,
            font=dict(size=12, color=COLORS['text_primary']),
            bgcolor='rgba(10, 25, 41, 0.6)',
            bordercolor=COLORS['border'],
            borderwidth=1
        ),
        margin=dict(l=40, r=180, t=80, b=40),  # v9.7: More right margin for legend
        annotations=[dict(
            text='Portfolio<br>Sectors',
            x=0.5, y=0.5,
            font_size=16,
            font_color=COLORS['neon_blue'],
            showarrow=False
        )]
    )

    apply_chart_theme(fig)
    return fig

def create_professional_sector_allocation_pie(df, use_professional_theme=True):
    """
    PROFESSIONAL sector allocation pie chart - Institutional grade
    - Clean, modern design (Professional Blue or Dark theme)
    - Proper label positioning
    - Subtle gradients
    - No clutter
    """
    sector_allocation = df.groupby('Sector')['Total Value'].sum()
    total_value = sector_allocation.sum()
    sector_pct = (sector_allocation / total_value * 100).round(1)

    # Sort by value
    sector_pct = sector_pct.sort_values(ascending=False)

    # Use dark theme if available
    if use_professional_theme and PROFESSIONAL_THEME_AVAILABLE:
        # Dark theme with neon colors
        colors = PROFESSIONAL_CHART_COLORS[:len(sector_pct)]
        text_color = '#FFFFFF'
        border_color = '#1a1d29'
        paper_bg = '#1a1d29'
        plot_bg = '#1a1d29'
        legend_font_color = '#FFFFFF'
        title_color = '#FFFFFF'
    else:
        # Fallback to dark neon theme
        colors = [
            '#00d4ff', '#0080ff', '#00ffcc', '#00ff88', '#ffaa00',
            '#ff6b00', '#b794f6', '#ff00ff', '#00d4ff', '#0080ff', '#00ffcc'
        ][:len(sector_pct)]
        text_color = '#ffffff'
        border_color = '#000000'
        paper_bg = 'rgba(0, 0, 0, 0)'
        plot_bg = 'rgba(10, 25, 41, 0.3)'
        legend_font_color = '#ffffff'
        title_color = '#ffffff'

    fig = go.Figure(data=[go.Pie(
        labels=sector_pct.index,
        values=sector_pct.values,
        hole=0.4,  # Donut style - more modern
        marker=dict(
            colors=colors,
            line=dict(color=border_color, width=2)  # Clean borders
        ),
        textposition='outside' if use_professional_theme else 'auto',
        textinfo='label+percent',
        textfont=dict(
            size=12,
            color=text_color,
            family='Inter, sans-serif'
        ),
        hovertemplate=(
            '<b>%{label}</b><br>' +
            'Allocation: %{percent}<br>' +
            'Value: $%{value:,.0f}<br>' +
            '<extra></extra>'
        ),
        sort=False  # Keep our sorted order
    )])

    fig.update_layout(
        title=dict(
            text='Sector Allocation',
            font=dict(size=16, color=title_color, family='Inter'),
            x=0.02,
            xanchor='left'
        ),
        showlegend=True,
        legend=dict(
            orientation="v",
            yanchor="middle",
            y=0.5,
            xanchor="right",
            x=1.15,
            bgcolor='rgba(255,255,255,0)' if use_professional_theme else 'rgba(0,0,0,0)',
            font=dict(size=11, color=legend_font_color)
        ),
        paper_bgcolor=paper_bg,
        plot_bgcolor=plot_bg,
        height=450,
        margin=dict(l=20, r=150, t=60, b=20)
    )

    return fig

def create_professional_sector_allocation_bar(df):
    """
    PROFESSIONAL sector allocation bar chart
    - Horizontal bars sorted by value
    - Clean labels
    - Professional color coding
    """
    sector_allocation = df.groupby('Sector')['Total Value'].sum()
    total_value = sector_allocation.sum()
    sector_pct = (sector_allocation / total_value * 100).round(1)

    # Sort by value
    sector_data = pd.DataFrame({
        'Sector': sector_pct.index,
        'Percentage': sector_pct.values,
        'Value': sector_allocation.values
    }).sort_values('Value', ascending=True)  # Ascending for horizontal bars

    # Color by size (gradient from small to large)
    colors_gradient = ['#ff3366' if p < 5 else '#ffaa00' if p < 10 else '#00ff88'
                       for p in sector_data['Percentage']]

    fig = go.Figure(go.Bar(
        x=sector_data['Value'],
        y=sector_data['Sector'],
        orientation='h',
        marker=dict(
            color=colors_gradient,
            line=dict(color='#000000', width=1)
        ),
        text=[f"${v:,.0f} ({p:.1f}%)" for v, p in zip(sector_data['Value'], sector_data['Percentage'])],
        textposition='outside',
        textfont=dict(size=11, color='#ffffff'),
        hovertemplate=(
            '<b>%{y}</b><br>' +
            'Value: $%{x:,.0f}<br>' +
            'Percentage: %{customdata:.1f}%<br>' +
            '<extra></extra>'
        ),
        customdata=sector_data['Percentage']
    ))

    fig.update_layout(
        title=dict(
            text='Sector Allocation - Ranked by Value',
            font=dict(size=20, color='#ffffff', family='Inter'),
            x=0.5,
            xanchor='center'
        ),
        xaxis=dict(
            title='Total Value ($)',
            gridcolor='#1a3a52',
            showgrid=True,
            zeroline=False,
            tickformat='$,.0f',
            tickfont=dict(size=11, color='#b0c4de')
        ),
        yaxis=dict(
            title='',
            tickfont=dict(size=12, color='#ffffff')
        ),
        paper_bgcolor='rgba(0, 0, 0, 0)',
        plot_bgcolor='rgba(10, 25, 41, 0.3)',
        height=500,
        margin=dict(l=150, r=100, t=80, b=60),
        showlegend=False
    )

    return fig

def create_rolling_metrics_chart(returns, window=60, use_professional_theme=True):
    """Rolling metrics visualization - Professional Blue theme"""
    if not is_valid_series(returns) or len(returns) < window:
        return None

    rolling_vol = returns.rolling(window).std() * np.sqrt(252) * 100
    rolling_sharpe = (returns.rolling(window).mean() * 252 - RISK_FREE_RATE) / (returns.rolling(window).std() * np.sqrt(252))

    # Theme colors
    if use_professional_theme and PROFESSIONAL_THEME_AVAILABLE:
        vol_color = '#FF1744'
        vol_fill = 'rgba(229, 57, 53, 0.15)'
        sharpe_color = '#00BCD4'
        sharpe_fill = 'rgba(30, 136, 229, 0.15)'
        line_color = 'rgba(255, 255, 255, 0.5)'
        title_color = '#FFFFFF'
        text_color = '#FFFFFF'
        paper_bg = '#1a1d29'
        grid_color = 'rgba(255, 255, 255, 0.1)'
    else:
        vol_color = COLORS['danger']
        vol_fill = 'rgba(255, 0, 68, 0.2)'
        sharpe_color = COLORS['neon_blue']
        sharpe_fill = 'rgba(0, 212, 255, 0.2)'
        line_color = COLORS['text_muted']
        title_color = '#ffffff'
        text_color = '#ffffff'
        paper_bg = 'rgba(0, 0, 0, 0)'
        grid_color = 'rgba(99, 102, 241, 0.1)'

    fig = make_subplots(
        rows=2, cols=1,
        subplot_titles=('Rolling Volatility (60-Day)', 'Rolling Sharpe Ratio (60-Day)'),
        vertical_spacing=0.15
    )

    fig.add_trace(
        go.Scatter(
            x=rolling_vol.index,
            y=rolling_vol.values,
            fill='tozeroy',
            fillcolor=vol_fill,
            line=dict(color=vol_color, width=2, shape='spline'),
            name='Volatility'
        ),
        row=1, col=1
    )

    fig.add_trace(
        go.Scatter(
            x=rolling_sharpe.index,
            y=rolling_sharpe.values,
            fill='tozeroy',
            fillcolor=sharpe_fill,
            line=dict(color=sharpe_color, width=2, shape='spline'),
            name='Sharpe Ratio'
        ),
        row=2, col=1
    )

    fig.add_hline(y=0, line_dash="dash", line_color=line_color, row=2, col=1)

    fig.update_layout(
        height=550,
        showlegend=False,
        title=dict(text="üìä Rolling Risk Metrics", font=dict(size=16, color=title_color, family='Inter'), x=0.02, xanchor='left'),
        paper_bgcolor=paper_bg,
        plot_bgcolor=paper_bg,
        font=dict(family='Inter', color=text_color),
        margin=dict(l=60, r=30, t=60, b=40)
    )

    # Update axes styling
    fig.update_xaxes(showgrid=True, gridcolor=grid_color, tickfont=dict(size=10, color=text_color))
    fig.update_yaxes(showgrid=True, gridcolor=grid_color, tickfont=dict(size=10, color=text_color, family='JetBrains Mono'))

    # Update subplot titles
    for annotation in fig['layout']['annotations']:
        annotation['font'] = dict(size=12, color=title_color, family='Inter')

    if not use_professional_theme:
        apply_chart_theme(fig)
    return fig

def create_underwater_plot(returns):
    """Underwater drawdown plot - ENHANCED THEMING"""
    if not is_valid_series(returns) or len(returns) < 2:
        return None
    
    cumulative = (1 + returns).cumprod()
    running_max = cumulative.expanding().max()
    drawdown = ((cumulative - running_max) / running_max) * 100
    
    fig = go.Figure()
    
    fig.add_trace(go.Scatter(
        x=drawdown.index,
        y=drawdown.values,
        fill='tozeroy',
        fillcolor='rgba(255, 0, 68, 0.3)',
        line=dict(color=COLORS['danger'], width=2),
        name='Drawdown'
    ))
    
    fig.add_hline(y=0, line_dash="solid", line_color=COLORS['text_primary'], line_width=1)
    
    max_dd_idx = drawdown.idxmin()
    max_dd_val = drawdown.min()
    
    fig.add_annotation(
        x=max_dd_idx,
        y=max_dd_val,
        text=f"Max DD: {max_dd_val:.2f}%",
        showarrow=True,
        arrowhead=2,
        arrowcolor=COLORS['danger'],
        ax=0,
        ay=-40,
        bgcolor=COLORS['card_background'],
        bordercolor=COLORS['danger'],
        borderwidth=2
    )
    
    fig.update_layout(
        title="üåä Underwater Plot",
        xaxis_title="Date",
        yaxis_title="Drawdown (%)",
        height=500
    )
    
    apply_chart_theme(fig)
    return fig

def create_var_waterfall(returns, use_professional_theme=True):
    """VaR/CVaR waterfall chart - Professional Blue theme"""
    if not is_valid_series(returns) or len(returns) < 2:
        return None

    var_90 = calculate_var(returns, 0.90)
    var_95 = calculate_var(returns, 0.95)
    var_99 = calculate_var(returns, 0.99)
    cvar_95 = calculate_cvar(returns, 0.95)

    categories = ['VaR 90%', 'VaR 95%', 'VaR 99%', 'CVaR 95%']
    values = [var_90, var_95, var_99, cvar_95]

    # Theme colors - graduated risk scale
    if use_professional_theme and PROFESSIONAL_THEME_AVAILABLE:
        colors_list = ['#FFC400', '#F57C00', '#FF1744', '#FF1744']
        border_color = 'rgba(255, 255, 255, 0.5)'
        title_color = '#FFFFFF'
        text_color = '#FFFFFF'
        paper_bg = '#1a1d29'
        grid_color = 'rgba(255, 255, 255, 0.1)'
    else:
        colors_list = [COLORS['warning'], COLORS['orange'], COLORS['danger'], COLORS['danger']]
        border_color = COLORS['border']
        title_color = '#ffffff'
        text_color = '#ffffff'
        paper_bg = 'rgba(0, 0, 0, 0)'
        grid_color = 'rgba(99, 102, 241, 0.1)'

    fig = go.Figure()

    fig.add_trace(go.Bar(
        x=categories,
        y=values,
        marker=dict(
            color=colors_list,
            line=dict(color=border_color, width=1)
        ),
        text=[f"{v:.2f}%" for v in values],
        textposition='outside',
        textfont=dict(size=11, family='JetBrains Mono', color=text_color)
    ))

    fig.update_layout(
        title=dict(text="‚ö†Ô∏è Value at Risk Analysis", font=dict(size=16, color=title_color, family='Inter'), x=0.02, xanchor='left'),
        xaxis=dict(title="Risk Measure", showgrid=False, tickfont=dict(size=11, color=text_color)),
        yaxis=dict(title="Expected Loss (%)", showgrid=True, gridcolor=grid_color,
                   tickfont=dict(size=10, color=text_color, family='JetBrains Mono')),
        height=400,
        paper_bgcolor=paper_bg,
        plot_bgcolor=paper_bg,
        font=dict(family='Inter', color=text_color),
        margin=dict(l=60, r=30, t=60, b=50)
    )

    if not use_professional_theme:
        apply_chart_theme(fig)
    return fig

# v9.7 NEW FEATURE: VaR/CVaR on Return Distribution
def create_var_cvar_distribution(returns):
    """
    NEW IN v9.7: Visualize VaR and CVaR on the actual return distribution
    Shows histogram of returns with VaR and CVaR threshold lines
    """
    if not is_valid_series(returns) or len(returns) < 30:
        return None

    # Calculate risk metrics
    var_95 = calculate_var(returns, 0.95)
    cvar_95 = calculate_cvar(returns, 0.95)
    var_99 = calculate_var(returns, 0.99)

    if var_95 is None or cvar_95 is None:
        return None

    # Convert to decimal for distribution
    returns_pct = returns * 100

    fig = go.Figure()

    # Add histogram of returns
    fig.add_trace(go.Histogram(
        x=returns_pct,
        name='Return Distribution',
        nbinsx=50,
        marker=dict(
            color=COLORS['info'],
            opacity=0.7,
            line=dict(color=COLORS['border'], width=1)
        ),
        hovertemplate='Returns: %{x:.2f}%<br>Count: %{y}<extra></extra>'
    ))

    # Add VaR 95% line
    fig.add_vline(
        x=var_95,
        line_dash="dash",
        line_color=COLORS['warning'],
        line_width=3,
        annotation_text=f"VaR 95%: {var_95:.2f}%",
        annotation_position="top",
        annotation=dict(
            font=dict(size=12, color=COLORS['warning']),
            bgcolor='rgba(10, 25, 41, 0.8)',
            bordercolor=COLORS['warning'],
            borderwidth=2
        )
    )

    # Add CVaR 95% line
    fig.add_vline(
        x=cvar_95,
        line_dash="solid",
        line_color=COLORS['danger'],
        line_width=3,
        annotation_text=f"CVaR 95%: {cvar_95:.2f}%",
        annotation_position="bottom",
        annotation=dict(
            font=dict(size=12, color=COLORS['danger']),
            bgcolor='rgba(10, 25, 41, 0.8)',
            bordercolor=COLORS['danger'],
            borderwidth=2
        )
    )

    # Add VaR 99% line
    fig.add_vline(
        x=var_99,
        line_dash="dot",
        line_color=COLORS['danger'],
        line_width=2,
        annotation_text=f"VaR 99%: {var_99:.2f}%",
        annotation_position="top right",
        annotation=dict(
            font=dict(size=10, color=COLORS['danger']),
            bgcolor='rgba(10, 25, 41, 0.6)'
        )
    )

    # Shade the tail risk area (beyond CVaR)
    fig.add_vrect(
        x0=returns_pct.min(),
        x1=cvar_95,
        fillcolor=COLORS['danger'],
        opacity=0.15,
        layer="below",
        line_width=0,
        annotation_text="Tail Risk Zone",
        annotation_position="top left"
    )

    fig.update_layout(
        title="üìä v9.7: Return Distribution with VaR/CVaR Analysis",
        xaxis_title="Daily Returns (%)",
        yaxis_title="Frequency",
        height=500,
        showlegend=False,
        bargap=0.05
    )

    apply_chart_theme(fig)
    return fig

# v9.7 NEW FEATURE: Rolling VaR/CVaR Time Series
def create_rolling_var_cvar_chart(returns, window=60, use_professional_theme=True):
    """Rolling VaR and CVaR time series - Professional Blue theme"""
    if not is_valid_series(returns) or len(returns) < window:
        return None

    # Calculate rolling VaR and CVaR
    rolling_var_95 = []
    rolling_cvar_95 = []
    dates = []

    for i in range(window, len(returns)):
        window_returns = returns.iloc[i-window:i]
        var = calculate_var(window_returns, 0.95)
        cvar = calculate_cvar(window_returns, 0.95)

        if var is not None and cvar is not None:
            rolling_var_95.append(var)
            rolling_cvar_95.append(cvar)
            dates.append(returns.index[i])

    if not rolling_var_95:
        return None

    # Theme colors
    if use_professional_theme and PROFESSIONAL_THEME_AVAILABLE:
        var_color = '#FFC400'
        cvar_color = '#FF1744'
        line_color = 'rgba(255, 255, 255, 0.5)'
        title_color = '#FFFFFF'
        text_color = '#FFFFFF'
        paper_bg = '#1a1d29'
        grid_color = 'rgba(255, 255, 255, 0.1)'
        legend_bg = 'rgba(26, 29, 41, 0.9)'
    else:
        var_color = COLORS['orange']
        cvar_color = COLORS['danger']
        line_color = COLORS['text_muted']
        title_color = '#ffffff'
        text_color = '#ffffff'
        paper_bg = 'rgba(0, 0, 0, 0)'
        grid_color = 'rgba(99, 102, 241, 0.1)'
        legend_bg = 'rgba(0, 0, 0, 0)'

    fig = go.Figure()

    # Add VaR trace
    fig.add_trace(go.Scatter(
        x=dates,
        y=rolling_var_95,
        name='VaR 95%',
        line=dict(color=var_color, width=2, shape='spline'),
        mode='lines'
    ))

    # Add CVaR trace
    fig.add_trace(go.Scatter(
        x=dates,
        y=rolling_cvar_95,
        name='CVaR 95%',
        line=dict(color=cvar_color, width=2, dash='dash', shape='spline'),
        mode='lines'
    ))

    # Add zero line
    fig.add_hline(y=0, line_dash="dot", line_color=line_color, line_width=1)

    fig.update_layout(
        title=dict(text=f"üìä Rolling VaR & CVaR ({window}-Day)", font=dict(size=16, color=title_color, family='Inter'), x=0.02, xanchor='left'),
        xaxis=dict(title="Date", showgrid=True, gridcolor=grid_color, tickfont=dict(size=10, color=text_color)),
        yaxis=dict(title="Expected Loss (%)", showgrid=True, gridcolor=grid_color,
                   tickfont=dict(size=10, color=text_color, family='JetBrains Mono')),
        height=450,
        hovermode='x unified',
        paper_bgcolor=paper_bg,
        plot_bgcolor=paper_bg,
        font=dict(family='Inter', color=text_color),
        margin=dict(l=60, r=30, t=60, b=50),
        legend=dict(
            orientation="h",
            yanchor="bottom",
            y=1.02,
            xanchor="right",
            x=1,
            bgcolor=legend_bg,
            font=dict(size=11, color=text_color)
        )
    )

    if not use_professional_theme:
        apply_chart_theme(fig)
    return fig

def create_risk_contribution_sunburst(df):
    """Risk contribution sunburst - ENHANCED THEMING"""
    risk_data = []

    for _, row in df.iterrows():
        ticker = row.get('Ticker', 'Unknown')
        # Handle missing or zero Weight %
        weight = row.get('Weight %', 0)
        if pd.isna(weight) or weight <= 0:
            # Try to calculate weight from Total Value
            if 'Total Value' in df.columns:
                total_portfolio = df['Total Value'].sum()
                if total_portfolio > 0:
                    weight = (row.get('Total Value', 0) / total_portfolio) * 100
                else:
                    weight = 0
            else:
                weight = 0

        sector = row.get('Sector', 'Unknown')
        if pd.isna(sector) or sector == '':
            sector = 'Unknown'

        hist_data = fetch_historical_data(ticker, datetime.now() - timedelta(days=365), datetime.now())
        if hist_data is not None and len(hist_data) > 30:
            returns = hist_data['Close'].pct_change().dropna()
            vol = returns.std() * np.sqrt(252) * 100
            # Ensure positive risk contribution (use absolute value, minimum 0.01)
            risk_contribution = max(abs(weight * vol), 0.01) if weight > 0 else 0.01

            risk_data.append({
                'Ticker': ticker,
                'Sector': sector,
                'Weight': weight,
                'Volatility': vol,
                'Risk Contribution': risk_contribution
            })

    if not risk_data:
        return None

    risk_df = pd.DataFrame(risk_data)

    # Safety check: ensure Risk Contribution sum is positive
    total_risk = risk_df['Risk Contribution'].sum()
    if total_risk <= 0:
        return None

    try:
        fig = px.sunburst(
            risk_df,
            path=['Sector', 'Ticker'],
            values='Risk Contribution',
            color='Volatility',
            color_continuous_scale='RdYlGn_r',
            title="Risk Contribution Sunburst"
        )

        fig.update_layout(height=600)
        apply_chart_theme(fig)
        return fig
    except Exception as e:
        print(f"Sunburst chart failed: {e}")
        return None

def create_risk_reward_plot(df):
    """Risk-reward scatter plot - ENHANCED THEMING"""
    risk_reward_data = []
    
    for _, row in df.iterrows():
        ticker = row['Ticker']
        hist_data = fetch_historical_data(ticker, datetime.now() - timedelta(days=365), datetime.now())
        
        if hist_data is not None and len(hist_data) > 30:
            returns = hist_data['Close'].pct_change().dropna()
            annual_return = ((1 + returns.mean()) ** 252 - 1) * 100
            annual_vol = returns.std() * np.sqrt(252) * 100
            
            risk_reward_data.append({
                'Ticker': ticker,
                'Asset Name': row['Asset Name'],
                'Return': annual_return,
                'Risk': annual_vol,
                'Weight': row['Weight %'],
                'Sector': row['Sector']
            })
    
    if not risk_reward_data:
        return None
    
    rr_df = pd.DataFrame(risk_reward_data)
    
    fig = px.scatter(
        rr_df,
        x='Risk',
        y='Return',
        size='Weight',
        color='Sector',
        text='Ticker',
        hover_data=['Asset Name'],
        color_discrete_sequence=px.colors.qualitative.Set3
    )
    
    fig.update_traces(
        textposition='top center',
        marker=dict(line=dict(width=2, color=COLORS['border']))
    )
    
    fig.update_layout(
        title="üìà Risk-Reward Analysis",
        xaxis_title="Risk (Annual Volatility %)",
        yaxis_title="Expected Return (Annual %)",
        height=CHART_HEIGHT_STANDARD  # P1-4: Standardized height
    )
    
    apply_chart_theme(fig)
    return fig

def should_display_monthly_heatmap(df):
    """
    Validate if monthly heatmap should be displayed.
    Returns True only if there are at least 2 complete months of meaningful data.
    """
    try:
        end_date = datetime.now()
        start_date = end_date - timedelta(days=365)
        current_month_start = end_date.replace(day=1, hour=0, minute=0, second=0, microsecond=0)

        monthly_data_count = 0
        has_meaningful_data = False

        for _, row in df.iterrows():
            ticker = row['Ticker']
            hist_data = fetch_historical_data(ticker, start_date, end_date)

            if hist_data is not None and len(hist_data) > 0:
                monthly_data = hist_data['Close'].resample('M').last()
                monthly_returns = monthly_data.pct_change()

                # Count complete months (excluding current month)
                complete_months = []
                for month, ret in monthly_returns.items():
                    month_start = month.replace(day=1, hour=0, minute=0, second=0, microsecond=0)
                    if month_start < current_month_start and pd.notna(ret):
                        complete_months.append(ret)
                        if abs(ret) > 0.001:  # At least 0.1% variation
                            has_meaningful_data = True

                if len(complete_months) > monthly_data_count:
                    monthly_data_count = len(complete_months)

        # Require at least 2 complete months with some meaningful variation
        return monthly_data_count >= 2 and has_meaningful_data
    except:
        return False

def create_performance_heatmap(df, period='monthly', use_professional_theme=True):
    """Performance heatmap - Professional Blue theme"""
    try:
        portfolio_values = {}

        end_date = datetime.now()
        start_date = end_date - timedelta(days=365)
        current_month_start = end_date.replace(day=1, hour=0, minute=0, second=0, microsecond=0)

        for _, row in df.iterrows():
            ticker = row['Ticker']
            hist_data = fetch_historical_data(ticker, start_date, end_date)

            if hist_data is not None and len(hist_data) > 0:
                monthly_data = hist_data['Close'].resample('M').last()
                monthly_returns = monthly_data.pct_change() * 100

                for month, ret in monthly_returns.items():
                    # v9.7 FIX: More robust check for incomplete months
                    # Skip if this month is the current month or in the future
                    month_start = month.replace(day=1, hour=0, minute=0, second=0, microsecond=0)
                    if month_start >= current_month_start:
                        continue

                    month_str = month.strftime('%b %Y')
                    if month_str not in portfolio_values:
                        portfolio_values[month_str] = {}
                    if pd.notna(ret) and abs(ret) < 50:
                        portfolio_values[month_str][ticker] = ret

        if not portfolio_values:
            return None

        tickers = sorted(set(t for months in portfolio_values.values() for t in months))
        months_list = sorted(portfolio_values.keys(), key=lambda x: datetime.strptime(x, '%b %Y'))

        # v9.7 FIX: Double-check to remove any incomplete months that slipped through
        months = []
        for m in months_list:
            m_date = datetime.strptime(m, '%b %Y')
            if m_date < current_month_start:
                months.append(m)
        
        matrix = []
        for ticker in tickers:
            row = []
            for month in months:
                if ticker in portfolio_values[month]:
                    val = portfolio_values[month][ticker]
                    val = max(-50, min(50, val))
                    row.append(val)
                else:
                    row.append(0)
            matrix.append(row)

        # ===== FIX #6: Remove Empty Columns from Heatmap =====
        # Convert to numpy array for easier column operations
        matrix_array = np.array(matrix)

        # Find columns where all values are zero
        non_zero_cols = []
        filtered_months = []

        for i, month in enumerate(months):
            # Check if this column has any non-zero values
            if np.any(np.abs(matrix_array[:, i]) > 0.01):
                non_zero_cols.append(i)
                filtered_months.append(month)

        # Filter matrix to keep only non-zero columns
        if len(non_zero_cols) > 0:
            filtered_matrix = matrix_array[:, non_zero_cols].tolist()
            months = filtered_months
            matrix = filtered_matrix
            print(f"‚úÖ Filtered heatmap: kept {len(filtered_months)} non-empty months")

        # Theme colors
        if use_professional_theme and PROFESSIONAL_THEME_AVAILABLE:
            title_color = '#FFFFFF'
            text_color = '#FFFFFF'
            paper_bg = '#1a1d29'
            colorscale = 'Spectral_r'
        else:
            title_color = '#ffffff'
            text_color = '#ffffff'
            paper_bg = 'rgba(0, 0, 0, 0)'
            colorscale = 'Spectral_r'

        fig = go.Figure(data=go.Heatmap(
            z=matrix,
            x=months,
            y=tickers,
            colorscale=colorscale,
            zmid=0,
            zmin=-20,
            zmax=20,
            text=np.round(matrix, 1),
            texttemplate='%{text}%',
            textfont={"size": 11, "family": "JetBrains Mono", "color": "white"},
            colorbar=dict(title=dict(text="Return %", font=dict(family='JetBrains Mono', size=11, color='white')), tickfont=dict(family='JetBrains Mono', size=10, color='white'))
        ))

        fig.update_layout(
            title=dict(text="üî• Monthly Performance Heatmap", font=dict(size=16, color=title_color, family='Inter'), x=0.02, xanchor='left'),
            xaxis=dict(title="Month", tickfont=dict(size=10, color=text_color)),
            yaxis=dict(title="Asset", tickfont=dict(size=10, color=text_color)),
            height=600,
            paper_bgcolor=paper_bg,
            plot_bgcolor=paper_bg,
            font=dict(family='Inter', color=text_color),
            margin=dict(l=80, r=80, t=60, b=50)
        )

        if not use_professional_theme:
            apply_chart_theme(fig)
        return fig
    except Exception as e:
        st.error(f"Error: {str(e)}")
        return None

def create_portfolio_heatmap(df, use_professional_theme=True):
    """Portfolio treemap - Professional Blue theme"""
    df_viz = df[['Ticker', 'Asset Name', 'Weight %', 'Total Gain/Loss %', 'Sector']].copy()
    df_viz['Sector'] = df_viz['Sector'].fillna('Other')
    df_viz = df_viz.dropna()

    if df_viz.empty:
        return None

    # Theme colors
    if use_professional_theme and PROFESSIONAL_THEME_AVAILABLE:
        title_color = '#FFFFFF'
        text_color = '#FFFFFF'
        paper_bg = '#1a1d29'
        colorscale = [[0, '#ec4899'], [0.25, '#a855f7'], [0.5, '#1e293b'], [0.75, '#06b6d4'], [1, '#10b981']]
    else:
        title_color = '#ffffff'
        text_color = '#ffffff'
        paper_bg = 'rgba(0, 0, 0, 0)'
        colorscale = [[0, '#ec4899'], [0.25, '#a855f7'], [0.5, '#1e293b'], [0.75, '#06b6d4'], [1, '#10b981']]

    fig = px.treemap(
        df_viz,
        path=[px.Constant("Portfolio"), 'Sector', 'Ticker'],
        values='Weight %',
        color='Total Gain/Loss %',
        color_continuous_scale=colorscale,
        color_continuous_midpoint=0,
        hover_data={'Asset Name': True, 'Total Gain/Loss %': ':.2f'}
    )

    fig.update_layout(
        title=dict(text="üó∫Ô∏è Portfolio Heatmap", font=dict(size=16, color=title_color, family='Inter'), x=0.02, xanchor='left'),
        height=600,
        paper_bgcolor=paper_bg,
        font=dict(family='Inter', color=text_color),
        margin=dict(l=20, r=20, t=60, b=30)
    )

    fig.update_traces(textfont=dict(family='Inter', size=11))

    if not use_professional_theme:
        apply_chart_theme(fig)
    return fig

@st.cache_data(ttl=600)
def fetch_ticker_performance(ticker, start_date, end_date):
    try:
        data = fetch_historical_data(ticker, start_date, end_date)
        if data is not None and not data.empty:
            returns = data['Close'].pct_change().fillna(0)
            cumulative = (1 + returns).cumprod() - 1
            return cumulative * 100, data
        return None, None
    except:
        return None, None

def create_interactive_performance_chart(tickers, start_date, end_date, use_professional_theme=True):
    """Interactive performance chart - Professional Blue theme"""
    fig = go.Figure()

    # Theme colors
    if use_professional_theme and PROFESSIONAL_THEME_AVAILABLE:
        colors = PROFESSIONAL_CHART_COLORS
        line_color = 'rgba(255, 255, 255, 0.5)'
        title_color = '#FFFFFF'
        text_color = '#FFFFFF'
        paper_bg = '#1a1d29'
        grid_color = 'rgba(255, 255, 255, 0.1)'
        legend_bg = 'rgba(26, 29, 41, 0.9)'
    else:
        colors = [COLORS['neon_blue'], COLORS['electric_blue'], COLORS['teal'],
                  COLORS['success'], COLORS['warning'], COLORS['danger'],
                  COLORS['purple'], COLORS['pink'], COLORS['orange']]
        line_color = COLORS['text_muted']
        title_color = '#ffffff'
        text_color = '#ffffff'
        paper_bg = 'rgba(0, 0, 0, 0)'
        grid_color = 'rgba(99, 102, 241, 0.1)'
        legend_bg = 'rgba(0, 0, 0, 0)'

    for idx, ticker in enumerate(tickers):
        cumulative, data = fetch_ticker_performance(ticker, start_date, end_date)
        if cumulative is not None:
            fig.add_trace(go.Scatter(
                x=cumulative.index,
                y=cumulative.values,
                mode='lines',
                name=ticker,
                line=dict(width=2, color=colors[idx % len(colors)], shape='spline')
            ))

    if not fig.data:
        return None

    fig.update_layout(
        title=dict(text="üìà Performance Comparison", font=dict(size=16, color=title_color, family='Inter'), x=0.02, xanchor='left'),
        xaxis=dict(title="Date", showgrid=True, gridcolor=grid_color, tickfont=dict(size=10, color=text_color)),
        yaxis=dict(title="Cumulative Return (%)", showgrid=True, gridcolor=grid_color,
                   tickfont=dict(size=10, color=text_color, family='JetBrains Mono')),
        height=500,
        hovermode='x unified',
        paper_bgcolor=paper_bg,
        plot_bgcolor=paper_bg,
        font=dict(family='Inter', color=text_color),
        margin=dict(l=60, r=30, t=60, b=50),
        legend=dict(
            orientation="h",
            yanchor="bottom",
            y=1.02,
            xanchor="left",
            x=0,
            bgcolor=legend_bg,
            font=dict(size=11, color=text_color)
        )
    )

    fig.add_hline(y=0, line_dash="dash", line_color=line_color, line_width=1)

    if not use_professional_theme:
        apply_chart_theme(fig)
    return fig

def run_monte_carlo_simulation(returns, initial_value=100000, days=252, simulations=1000):
    if not is_valid_series(returns) or len(returns) < 30:
        return None
    
    daily_return = returns.mean()
    daily_vol = returns.std()
    
    simulation_results = []
    
    for _ in range(simulations):
        prices = [initial_value]
        for _ in range(days):
            price = prices[-1] * (1 + np.random.normal(daily_return, daily_vol))
            prices.append(price)
        simulation_results.append(prices)
    
    return np.array(simulation_results)

def create_monte_carlo_chart(simulation_results, initial_value=100000, use_professional_theme=True):
    if simulation_results is None:
        return None, None

    # Theme colors
    if use_professional_theme and PROFESSIONAL_THEME_AVAILABLE:
        sim_color = 'rgba(30, 136, 229, 0.1)'
        colors_pct = ['#FF1744', '#FFC400',
                      '#00BCD4', '#00ACC1', '#00E676']
        title_color = '#FFFFFF'
        text_color = '#FFFFFF'
        paper_bg = '#1a1d29'
        grid_color = 'rgba(255, 255, 255, 0.1)'
        legend_bg = 'rgba(26, 29, 41, 0.9)'
    else:
        sim_color = COLORS['electric_blue']
        colors_pct = [COLORS['danger'], COLORS['warning'], COLORS['info'],
                      COLORS['teal'], COLORS['success']]
        title_color = '#ffffff'
        text_color = '#ffffff'
        paper_bg = 'rgba(0, 0, 0, 0)'
        grid_color = 'rgba(99, 102, 241, 0.1)'
        legend_bg = 'rgba(0, 0, 0, 0)'

    fig = go.Figure()

    for i in range(min(100, len(simulation_results))):
        fig.add_trace(go.Scatter(
            y=simulation_results[i],
            mode='lines',
            line=dict(width=0.5, color=sim_color),
            opacity=0.1 if not use_professional_theme else 1,
            showlegend=False
        ))

    percentiles = [5, 25, 50, 75, 95]

    for p, color in zip(percentiles, colors_pct):
        values = np.percentile(simulation_results, p, axis=0)
        fig.add_trace(go.Scatter(
            y=values,
            mode='lines',
            line=dict(width=2.5, color=color, shape='spline'),
            name=f'{p}th Percentile'
        ))

    fig.update_layout(
        title=dict(text="üé≤ Monte Carlo Simulation", font=dict(size=16, color=title_color, family='Inter'), x=0.02, xanchor='left'),
        xaxis=dict(title="Trading Days", showgrid=True, gridcolor=grid_color, tickfont=dict(size=10, color=text_color)),
        yaxis=dict(title="Portfolio Value ($)", showgrid=True, gridcolor=grid_color,
                   tickfont=dict(size=10, color=text_color, family='JetBrains Mono')),
        height=450,
        paper_bgcolor=paper_bg,
        plot_bgcolor=paper_bg,
        font=dict(family='Inter', color=text_color),
        margin=dict(l=70, r=30, t=60, b=50),
        legend=dict(
            orientation="h",
            yanchor="bottom",
            y=1.02,
            xanchor="right",
            x=1,
            bgcolor=legend_bg,
            font=dict(size=10, color=text_color)
        )
    )

    if not use_professional_theme:
        apply_chart_theme(fig)
    
    final_values = simulation_results[:, -1]
    stats = {
        'mean': np.mean(final_values),
        'median': np.median(final_values),
        'percentile_5': np.percentile(final_values, 5),
        'percentile_95': np.percentile(final_values, 95),
        'prob_profit': (final_values > initial_value).mean() * 100,
        'prob_loss_10': (final_values < initial_value * 0.9).mean() * 100,
        'prob_gain_20': (final_values > initial_value * 1.2).mean() * 100
    }
    
    return fig, stats

def create_risk_parity_analysis(df):
    risk_contributions = []
    
    for _, row in df.iterrows():
        ticker = row['Ticker']
        weight = row['Weight %'] / 100
        
        hist_data = fetch_historical_data(ticker, datetime.now() - timedelta(days=365), datetime.now())
        if hist_data is not None and len(hist_data) > 30:
            returns = hist_data['Close'].pct_change().dropna()
            vol = returns.std() * np.sqrt(252)
            risk_contribution = weight * vol
            
            risk_contributions.append({
                'Ticker': ticker,
                'Weight %': row['Weight %'],
                'Volatility': vol * 100,
                'Risk Contribution': risk_contribution * 100
            })
    
    if not risk_contributions:
        return None
    
    rc_df = pd.DataFrame(risk_contributions)
    total_risk = rc_df['Risk Contribution'].sum()
    rc_df['Risk %'] = (rc_df['Risk Contribution'] / total_risk) * 100
    
    fig = go.Figure()
    
    fig.add_trace(go.Bar(
        name='Weight %',
        x=rc_df['Ticker'],
        y=rc_df['Weight %'],
        marker_color=COLORS['electric_blue']
    ))
    
    fig.add_trace(go.Bar(
        name='Risk Contribution %',
        x=rc_df['Ticker'],
        y=rc_df['Risk %'],
        marker_color=COLORS['danger']
    ))
    
    fig.update_layout(
        title="‚öñÔ∏è Risk Parity Analysis",
        xaxis_title="Asset",
        yaxis_title="Percentage",
        barmode='group',
        height=500
    )
    
    apply_chart_theme(fig)
    return fig

def create_drawdown_distribution(returns):
    """NEW: Drawdown distribution histogram"""
    if not is_valid_series(returns) or len(returns) < 2:
        return None

    cumulative = (1 + returns).cumprod()
    running_max = cumulative.expanding().max()
    drawdowns = ((cumulative - running_max) / running_max) * 100

    # Remove zeros
    drawdowns = drawdowns[drawdowns < 0]

    if len(drawdowns) == 0:
        return None

    fig = go.Figure()

    fig.add_trace(go.Histogram(
        x=drawdowns,
        nbinsx=50,
        marker=dict(
            color=COLORS['danger'],
            line=dict(color=COLORS['border'], width=1)
        ),
        name='Drawdowns',
        hovertemplate='Drawdown: %{x:.2f}%<br>Count: %{y}<extra></extra>'
    ))

    # Add vertical line for mean
    mean_dd = drawdowns.mean()
    fig.add_vline(
        x=mean_dd,
        line_dash="dash",
        line_color=COLORS['warning'],
        annotation_text=f"Mean: {mean_dd:.2f}%",
        annotation_position="top"
    )

    fig.update_layout(
        title="üìâ Drawdown Distribution",
        xaxis_title="Drawdown (%)",
        yaxis_title="Frequency",
        height=400,
        showlegend=False
    )

    apply_chart_theme(fig)
    return fig

def create_correlation_network(df, start_date, end_date):
    returns_data = {}
    
    for _, row in df.iterrows():
        ticker = row['Ticker']
        hist_data = fetch_historical_data(ticker, start_date, end_date)
        if hist_data is not None and len(hist_data) > 30:
            returns_data[ticker] = hist_data['Close'].pct_change().dropna()
    
    if len(returns_data) < 2:
        return None
    
    returns_df = pd.DataFrame(returns_data)
    corr_matrix = returns_df.corr()
    
    fig = go.Figure()
    
    G = nx.Graph()
    for ticker in corr_matrix.columns:
        G.add_node(ticker)
    
    threshold = 0.5
    for i, ticker1 in enumerate(corr_matrix.columns):
        for j, ticker2 in enumerate(corr_matrix.columns):
            if i < j:
                corr = corr_matrix.iloc[i, j]
                if abs(corr) > threshold:
                    G.add_edge(ticker1, ticker2, weight=abs(corr))
    
    pos = nx.spring_layout(G)
    
    for edge in G.edges():
        x0, y0 = pos[edge[0]]
        x1, y1 = pos[edge[1]]
        weight = G[edge[0]][edge[1]]['weight']
        
        fig.add_trace(go.Scatter(
            x=[x0, x1],
            y=[y0, y1],
            mode='lines',
            line=dict(width=weight*5, color=COLORS['electric_blue']),
            opacity=0.5,
            showlegend=False
        ))
    
    node_x = []
    node_y = []
    node_text = []
    
    for node in G.nodes():
        x, y = pos[node]
        node_x.append(x)
        node_y.append(y)
        node_text.append(node)
    
    fig.add_trace(go.Scatter(
        x=node_x,
        y=node_y,
        mode='markers+text',
        text=node_text,
        textposition='top center',
        marker=dict(
            size=20,
            color=COLORS['neon_blue'],
            line=dict(width=2, color=COLORS['border'])
        ),
        showlegend=False
    ))
    
    fig.update_layout(
        title="üîó Correlation Network",
        showlegend=False,
        height=600,
        xaxis=dict(showgrid=False, zeroline=False, showticklabels=False),
        yaxis=dict(showgrid=False, zeroline=False, showticklabels=False)
    )
    
    apply_chart_theme(fig)
    return fig

def create_efficient_frontier(df):
    """FIXED BROADCASTING ERROR - ENHANCED THEMING"""
    returns_data = {}
    expected_returns = []
    volatilities = []
    tickers = []
    
    for _, row in df.iterrows():
        ticker = row['Ticker']
        hist_data = fetch_historical_data(ticker, datetime.now() - timedelta(days=365), datetime.now())
        
        if hist_data is not None and len(hist_data) > 30:
            returns = hist_data['Close'].pct_change().dropna()
            annual_return = ((1 + returns.mean()) ** 252 - 1)
            annual_vol = returns.std() * np.sqrt(252)
            
            expected_returns.append(annual_return)
            volatilities.append(annual_vol)
            tickers.append(ticker)
            returns_data[ticker] = returns
    
    if len(expected_returns) < 2:
        return None
    
    returns_df = pd.DataFrame(returns_data)
    cov_matrix = returns_df.cov() * 252
    
    num_portfolios = 5000
    results = np.zeros((3, num_portfolios))
    
    np.random.seed(42)
    
    for i in range(num_portfolios):
        weights = np.random.random(len(tickers))
        weights /= np.sum(weights)
        
        portfolio_return = np.sum(weights * np.array(expected_returns))
        portfolio_vol = np.sqrt(np.dot(weights.T, np.dot(cov_matrix, weights)))
        sharpe = (portfolio_return - RISK_FREE_RATE) / portfolio_vol if portfolio_vol > 0 else 0
        
        results[0, i] = portfolio_return * 100
        results[1, i] = portfolio_vol * 100
        results[2, i] = sharpe
    
    fig = go.Figure()
    
    fig.add_trace(go.Scatter(
        x=results[1],
        y=results[0],
        mode='markers',
        marker=dict(
            size=5,
            color=results[2],
            colorscale='Viridis',
            showscale=True,
            colorbar=dict(title="Sharpe Ratio")
        ),
        name='Efficient Frontier'
    ))
    
    # FIXED: Properly align weights and returns
    current_weights = df[df['Ticker'].isin(tickers)]['Weight %'].values / 100
    aligned_returns = np.array(expected_returns[:len(current_weights)])
    aligned_cov = cov_matrix.iloc[:len(current_weights), :len(current_weights)]
    
    current_return = np.sum(current_weights * aligned_returns) * 100
    current_vol = np.sqrt(np.dot(current_weights.T, np.dot(aligned_cov, current_weights))) * 100
    
    fig.add_trace(go.Scatter(
        x=[current_vol],
        y=[current_return],
        mode='markers',
        marker=dict(size=20, color=COLORS['danger'], symbol='star'),
        name='Current Portfolio'
    ))
    
    fig.update_layout(
        title="üìä Efficient Frontier",
        xaxis_title="Risk (Volatility %)",
        yaxis_title="Return %",
        height=600,
        showlegend=True,  # FIX: Enable legend
        legend=dict(
            yanchor="top",
            y=0.99,
            xanchor="right",
            x=0.99,
            bgcolor="rgba(10, 25, 41, 0.8)",
            bordercolor=COLORS['border'],
            borderwidth=1
        )
    )

    apply_chart_theme(fig)
    return fig

# ============================================================================
# MARKET WATCH - ENHANCED
# ============================================================================

@st.cache_data(ttl=300)
def fetch_market_watch_data(tickers_dict):
    """v9.7 ENHANCED: Fetches market data with cleaned symbol display"""
    market_data = []

    for ticker, info in tickers_dict.items():
        try:
            stock = yf.Ticker(ticker)
            hist = stock.history(period="5d")

            if not hist.empty:
                # Convert timezone-aware index to timezone-naive
                if hist.index.tz is not None:
                    hist.index = hist.index.tz_localize(None)

                current = hist['Close'].iloc[-1]
                prev = hist['Close'].iloc[-2] if len(hist) > 1 else current
                change = ((current - prev) / prev) * 100

                five_day = ((current / hist['Close'].iloc[0]) - 1) * 100 if len(hist) >= 5 else 0

                volume = hist['Volume'].iloc[-1]
                avg_volume = hist['Volume'].mean()

                # v9.7 FIX: Clean up symbol for display (remove ^, =F, etc.)
                clean_symbol = ticker.replace('^', '').replace('=F', '').replace('-USD', '')
                # For commodities, show descriptive name instead
                if '=F' in ticker or ticker.endswith('=F'):
                    display_symbol = info.get('name', clean_symbol)
                elif ticker.startswith('^'):
                    display_symbol = info.get('name', clean_symbol)
                else:
                    display_symbol = ticker

                market_data.append({
                    'Symbol': display_symbol,
                    'Name': info.get('name', ticker),
                    'Category': info.get('category', info.get('region', '')),
                    'Last': current,
                    'Change %': change,
                    '5D %': five_day,
                    'Volume': volume,
                    'Avg Volume': avg_volume,
                    'Vol/Avg': volume / avg_volume if avg_volume > 0 else 0,
                    '_raw_ticker': ticker  # Store original ticker for formatting logic
                })
        except:
            continue

    return pd.DataFrame(market_data)

def create_dynamic_market_table(df, filters=None):
    if filters:
        if 'category' in filters and filters['category']:
            df = df[df['Category'] == filters['category']]

        if 'min_change' in filters and filters['min_change']:
            df = df[df['Change %'] >= filters['min_change']]

        if 'sort_by' in filters and filters['sort_by']:
            ascending = filters.get('ascending', False)
            df = df.sort_values(filters['sort_by'], ascending=ascending)

    display_df = df.copy()

    # FIX: Format treasury yields as percentages, not dollars
    # Treasury yield INDICES (^TNX, ^TYX, etc.) show yield values as percentages
    # Bond ETFs show prices as dollars
    def format_last_value(row):
        raw_ticker = row.get('_raw_ticker', '')
        # Yield indices starting with ^ and containing treasury/yield info
        is_yield_index = (raw_ticker.startswith('^') and
                         row.get('Category') == 'Government Bonds')

        if is_yield_index:
            # Treasury yields are already in percentage points (e.g., 4.5 = 4.5%)
            return f"{row['Last']:.2f}%"
        else:
            return format_currency(row['Last'])

    display_df['Last'] = display_df.apply(format_last_value, axis=1)
    display_df['Change %'] = display_df['Change %'].apply(lambda x: add_arrow_indicator(format_percentage(x)))
    display_df['5D %'] = display_df['5D %'].apply(lambda x: add_arrow_indicator(format_percentage(x)))
    display_df['Volume'] = display_df['Volume'].apply(lambda x: f"{x:,.0f}")
    display_df['Vol/Avg'] = display_df['Vol/Avg'].apply(lambda x: f"{x:.2f}x")

    # Remove internal column before displaying
    if '_raw_ticker' in display_df.columns:
        display_df = display_df.drop('_raw_ticker', axis=1)

    return display_df

# ============================================================================
# PORTFOLIO DEEP DIVE - ENHANCED
# ============================================================================

def create_sector_rotation_heatmap(df, start_date, end_date, use_professional_theme=True):
    """Sector rotation heatmap - Professional Blue theme"""
    sector_returns = {}

    # FIX: Make end_date_cutoff timezone-naive
    end_date_cutoff = pd.Timestamp(datetime.now().replace(day=1, hour=0, minute=0, second=0, microsecond=0))

    for _, row in df.iterrows():
        ticker = row['Ticker']
        sector = row['Sector']

        hist_data = fetch_historical_data(ticker, start_date, end_date)
        if hist_data is not None and len(hist_data) > 30:
            monthly_data = hist_data['Close'].resample('M').last()
            monthly_returns = monthly_data.pct_change() * 100

            # FIX: Convert index to timezone-naive before comparison
            monthly_returns.index = monthly_returns.index.tz_localize(None)
            monthly_returns = monthly_returns[monthly_returns.index < end_date_cutoff]
            
            if sector not in sector_returns:
                sector_returns[sector] = []
            
            sector_returns[sector].append(monthly_returns)
    
    if not sector_returns:
        return None
    
    sector_avg = {}
    for sector, returns_list in sector_returns.items():
        combined = pd.concat(returns_list, axis=1).mean(axis=1)
        sector_avg[sector] = combined
    
    sectors = list(sector_avg.keys())
    months = sector_avg[sectors[0]].index
    
    matrix = []
    for sector in sectors:
        matrix.append(sector_avg[sector].values)
    
    # Theme colors - Magenta-Cyan gradient (vibrant, LinkedIn-ready)
    if use_professional_theme and PROFESSIONAL_THEME_AVAILABLE:
        title_color = '#FFFFFF'
        text_color = '#FFFFFF'
        paper_bg = '#1a1d29'
        colorscale = 'Spectral_r'
    else:
        title_color = '#ffffff'
        text_color = '#ffffff'
        paper_bg = 'rgba(0, 0, 0, 0)'
        colorscale = 'Spectral_r'

    fig = go.Figure(data=go.Heatmap(
        z=matrix,
        x=[m.strftime('%b %Y') for m in months],
        y=sectors,
        colorscale=colorscale,
        zmid=0,
        text=np.round(matrix, 1),
        texttemplate='%{text}%',
        textfont={"size": 10, "family": "JetBrains Mono", "color": "white"},
        colorbar=dict(title=dict(text="Return %", font=dict(family='JetBrains Mono', size=11, color='white')), tickfont=dict(family='JetBrains Mono', size=10, color='white'))
    ))

    fig.update_layout(
        title=dict(text="üîÑ Sector Rotation Heatmap", font=dict(size=16, color=title_color, family='Inter'), x=0.02, xanchor='left'),
        xaxis=dict(title="Month", tickfont=dict(size=10, color=text_color)),
        yaxis=dict(title="Sector", tickfont=dict(size=10, color=text_color)),
        height=450,
        paper_bgcolor=paper_bg,
        plot_bgcolor=paper_bg,
        font=dict(family='Inter', color=text_color),
        margin=dict(l=100, r=80, t=60, b=50)
    )

    if not use_professional_theme:
        apply_chart_theme(fig)
    return fig

def create_holdings_attribution_waterfall(df, use_professional_theme=True):
    """Holdings attribution waterfall - Professional Blue theme"""
    top_contributors = df.nlargest(10, 'Total Gain/Loss $')

    tickers = top_contributors['Ticker'].tolist()
    contributions = top_contributors['Total Gain/Loss $'].tolist()

    # Theme colors
    if use_professional_theme and PROFESSIONAL_THEME_AVAILABLE:
        connector_color = 'rgba(255, 255, 255, 0.5)'
        success_color = '#00E676'
        danger_color = '#FF1744'
        total_color = '#00BCD4'
        title_color = '#FFFFFF'
        text_color = '#FFFFFF'
        paper_bg = '#1a1d29'
        grid_color = 'rgba(255, 255, 255, 0.1)'
    else:
        connector_color = COLORS['neon_blue']
        success_color = COLORS['success']
        danger_color = COLORS['danger']
        total_color = COLORS['electric_blue']
        title_color = '#ffffff'
        text_color = '#ffffff'
        paper_bg = 'rgba(0, 0, 0, 0)'
        grid_color = 'rgba(99, 102, 241, 0.1)'

    fig = go.Figure()

    fig.add_trace(go.Waterfall(
        name="Attribution",
        orientation="v",
        x=tickers,
        y=contributions,
        textfont=dict(size=10, family='JetBrains Mono', color=text_color),
        connector={"line": {"color": connector_color, "width": 2}},
        decreasing={"marker": {"color": danger_color}},
        increasing={"marker": {"color": success_color}},
        totals={"marker": {"color": total_color}}
    ))

    fig.update_layout(
        title=dict(text="üíß Holdings Attribution Waterfall", font=dict(size=16, color=title_color, family='Inter'), x=0.02, xanchor='left'),
        xaxis=dict(title="Ticker", tickfont=dict(size=10, color=text_color)),
        yaxis=dict(title="Contribution ($)", showgrid=True, gridcolor=grid_color,
                   tickfont=dict(size=10, color=text_color, family='JetBrains Mono')),
        height=400,
        paper_bgcolor=paper_bg,
        plot_bgcolor=paper_bg,
        font=dict(family='Inter', color=text_color),
        margin=dict(l=70, r=30, t=60, b=50)
    )

    if not use_professional_theme:
        apply_chart_theme(fig)
    return fig

def create_concentration_gauge(df, use_professional_theme=True):
    """Concentration gauge - Professional Blue or Dark theme"""
    top_5_weight = df.nlargest(5, 'Weight %')['Weight %'].sum()

    # Use dark theme if available
    if use_professional_theme and PROFESSIONAL_THEME_AVAILABLE:
        bar_color = '#00BCD4'
        success_color = '#69F0AE'  # Light green
        warning_color = '#FFD740'  # Light amber
        danger_color = '#FF5252'   # Light red
        title_color = '#FFFFFF'
        number_color = '#FFFFFF'
        paper_bg = '#1a1d29'
        delta_color = '#FFC400'
        threshold_color = '#FF1744'
        tick_color = 'rgba(255, 255, 255, 0.5)'
    else:
        bar_color = COLORS['neon_blue']
        success_color = COLORS['success']
        warning_color = COLORS['warning']
        danger_color = COLORS['danger']
        title_color = '#ffffff'
        number_color = '#ffffff'
        paper_bg = 'rgba(0, 0, 0, 0)'
        delta_color = COLORS['warning']
        threshold_color = 'red'
        tick_color = '#94a3b8'

    fig = go.Figure(go.Indicator(
        mode="gauge+number+delta",
        value=top_5_weight,
        title={'text': "Top 5 Concentration", 'font': {'color': title_color, 'size': 16, 'family': 'Inter'}},
        number={'font': {'color': number_color, 'size': 32, 'family': 'JetBrains Mono'}},
        delta={'reference': 50, 'increasing': {'color': delta_color}},
        gauge={
            'axis': {'range': [0, 100], 'tickfont': {'color': tick_color, 'size': 10}},
            'bar': {'color': bar_color, 'thickness': 0.75},
            'bgcolor': '#242838' if use_professional_theme else 'rgba(0,0,0,0)',
            'borderwidth': 0,
            'steps': [
                {'range': [0, 30], 'color': success_color},
                {'range': [30, 50], 'color': warning_color},
                {'range': [50, 100], 'color': danger_color}
            ],
            'threshold': {
                'line': {'color': threshold_color, 'width': 3},
                'thickness': 0.75,
                'value': 70
            }
        }
    ))

    fig.update_layout(
        height=350,
        paper_bgcolor=paper_bg,
        plot_bgcolor=paper_bg,
        font={'family': 'Inter, sans-serif'}
    )

    if not use_professional_theme:
        apply_chart_theme(fig)

    return fig

def create_concentration_analysis(df):
    """NEW: Enhanced concentration analysis with multiple visuals"""
    
    # Top 10 Holdings Bar Chart
    top_10 = df.nlargest(10, 'Weight %')
    
    fig = go.Figure()
    
    fig.add_trace(go.Bar(
        x=top_10['Weight %'],
        y=top_10['Ticker'],
        orientation='h',
        marker=dict(
            color=top_10['Weight %'],
            colorscale='Blues',
            line=dict(color=COLORS['border'], width=2)
        ),
        text=[f"{x:.1f}%" for x in top_10['Weight %']],
        textposition='auto'
    ))
    
    fig.update_layout(
        title="üìä Top 10 Holdings Concentration",
        xaxis_title="Weight (%)",
        yaxis_title="",
        height=500,
        showlegend=False
    )
    
    apply_chart_theme(fig)
    return fig

# ============================================================================
# MULTI-FACTOR ANALYSIS - ENHANCED
# ============================================================================

def create_factor_momentum_chart(factor_data, use_professional_theme=True):
    """Factor momentum chart - Professional Blue theme"""
    if factor_data is None or 'factor_returns' not in factor_data:
        return None

    factor_returns = factor_data['factor_returns']

    # Theme colors
    if use_professional_theme and PROFESSIONAL_THEME_AVAILABLE:
        colors = PROFESSIONAL_CHART_COLORS
        title_color = '#FFFFFF'
        text_color = '#FFFFFF'
        paper_bg = '#1a1d29'
        grid_color = 'rgba(255, 255, 255, 0.1)'
        legend_bg = 'rgba(26, 29, 41, 0.9)'
    else:
        colors = [COLORS['neon_blue'], COLORS['electric_blue'], COLORS['teal'],
                  COLORS['success'], COLORS['purple'], COLORS['pink']]
        title_color = '#ffffff'
        text_color = '#ffffff'
        paper_bg = 'rgba(0, 0, 0, 0)'
        grid_color = 'rgba(99, 102, 241, 0.1)'
        legend_bg = 'rgba(0, 0, 0, 0)'

    fig = go.Figure()

    for idx, factor in enumerate(FACTOR_DEFINITIONS.keys()):
        if factor in factor_returns.columns:
            cumulative = (1 + factor_returns[factor]).cumprod() - 1
            fig.add_trace(go.Scatter(
                x=cumulative.index,
                y=cumulative.values * 100,
                mode='lines',
                name=factor,
                line=dict(width=2, color=colors[idx % len(colors)], shape='spline')
            ))

    fig.update_layout(
        title=dict(text="üìà Factor Momentum", font=dict(size=16, color=title_color, family='Inter'), x=0.02, xanchor='left'),
        xaxis=dict(title="Date", showgrid=True, gridcolor=grid_color, tickfont=dict(size=10, color=text_color)),
        yaxis=dict(title="Cumulative Return (%)", showgrid=True, gridcolor=grid_color,
                   tickfont=dict(size=10, color=text_color, family='JetBrains Mono')),
        height=500,
        hovermode='x unified',
        paper_bgcolor=paper_bg,
        plot_bgcolor=paper_bg,
        font=dict(family='Inter', color=text_color),
        margin=dict(l=60, r=30, t=60, b=50),
        legend=dict(
            orientation="h",
            yanchor="bottom",
            y=1.02,
            xanchor="left",
            x=0,
            bgcolor=legend_bg,
            font=dict(size=11, color=text_color)
        )
    )

    if not use_professional_theme:
        apply_chart_theme(fig)
    return fig

def create_factor_exposure_radar(exposures):
    """Factor exposure radar - ENHANCED THEMING"""
    if exposures is None or 'exposures' not in exposures:
        return None
    
    exp = exposures['exposures']
    factors = [f for f in FACTOR_DEFINITIONS.keys() if f in exp.index]
    values = [exp[f] for f in factors]
    
    max_abs = max([abs(v) for v in values]) if values else 1
    normalized = [(v / max_abs) * 100 if max_abs > 0 else 0 for v in values]
    
    fig = go.Figure()
    
    fig.add_trace(go.Scatterpolar(
        r=normalized,
        theta=factors,
        fill='toself',
        fillcolor='rgba(0, 212, 255, 0.2)',
        line=dict(color=COLORS['neon_blue'], width=2),
        name='Factor Exposure'
    ))
    
    fig.update_layout(
        polar=dict(
            radialaxis=dict(
                visible=True,
                range=[0, 100],
                color=COLORS['text_secondary']
            ),
            bgcolor='rgba(10, 25, 41, 0.3)'
        ),
        title="üéØ Factor Exposure Radar",
        height=550
    )
    
    apply_chart_theme(fig)
    return fig

@st.cache_data(ttl=3600)
def calculate_factor_exposures(df, start_date, end_date):
    try:
        portfolio_returns = calculate_portfolio_returns(df, start_date, end_date)
        if not is_valid_series(portfolio_returns):
            return None
        
        factor_returns = {}
        for factor_name, factor_info in FACTOR_DEFINITIONS.items():
            benchmark = factor_info['benchmark']
            returns = calculate_benchmark_returns(benchmark, start_date, end_date)
            if is_valid_series(returns):
                factor_returns[factor_name] = returns
        
        if not factor_returns:
            return None
        
        common_dates = portfolio_returns.index
        for factor_name in factor_returns:
            common_dates = common_dates.intersection(factor_returns[factor_name].index)
        
        X = pd.DataFrame({name: returns.loc[common_dates] for name, returns in factor_returns.items()})
        y = portfolio_returns.loc[common_dates]
        
        X['Alpha'] = 1
        
        model = LinearRegression()
        model.fit(X, y)
        
        exposures = pd.Series(model.coef_, index=X.columns)
        r_squared = model.score(X, y)
        predicted_returns = model.predict(X)
        
        asset_exposures = {}
        for _, row in df.iterrows():
            ticker = row['Ticker']
            ticker_returns = calculate_benchmark_returns(ticker, start_date, end_date)
            if is_valid_series(ticker_returns):
                ticker_aligned = ticker_returns.loc[common_dates]
                
                asset_model = LinearRegression()
                asset_model.fit(X, ticker_aligned)
                
                asset_exposures[ticker] = pd.Series(asset_model.coef_, index=X.columns)
        
        return {
            'exposures': exposures,
            'r_squared': r_squared,
            'factor_returns': X,
            'portfolio_returns': y,
            'predicted_returns': predicted_returns,
            'asset_exposures': asset_exposures
        }
    except:
        return None

def create_factor_attribution_table(exposures, df):
    if exposures is None or 'asset_exposures' not in exposures:
        return None, None, None
    
    attribution_data = []
    
    for ticker, asset_exp in exposures['asset_exposures'].items():
        asset_row = df[df['Ticker'] == ticker]
        if asset_row.empty:
            continue
        
        weight = asset_row['Weight %'].values[0] / 100
        sector = asset_row['Sector'].values[0]
        
        for factor in FACTOR_DEFINITIONS.keys():
            if factor in asset_exp:
                contribution = weight * asset_exp[factor]
                attribution_data.append({
                    'Ticker': ticker,
                    'Sector': sector,
                    'Factor': factor,
                    'Weight': weight * 100,
                    'Factor Beta': asset_exp[factor],
                    'Contribution': contribution
                })
    
    if not attribution_data:
        return None, None, None
    
    attr_df = pd.DataFrame(attribution_data)
    
    factor_summary = attr_df.groupby('Factor').agg({
        'Contribution': 'sum'
    }).reset_index()
    factor_summary.columns = ['Factor', 'Total Contribution']
    
    sector_summary = attr_df.groupby(['Sector', 'Factor']).agg({
        'Contribution': 'sum'
    }).reset_index()
    
    return attr_df, factor_summary, sector_summary

# ============================================================================
# PERFORMANCE METRICS
# ============================================================================

def calculate_performance_metrics(df, portfolio_returns, benchmark_returns):
    if not is_valid_series(portfolio_returns):
        return None
    
    total_return = (1 + portfolio_returns).prod() - 1
    n_years = len(portfolio_returns) / 252
    annualized_return = (1 + total_return) ** (1/n_years) - 1 if n_years > 0 else 0
    annualized_vol = portfolio_returns.std() * np.sqrt(252)
    
    sharpe = calculate_sharpe_ratio(portfolio_returns)
    sortino = calculate_sortino_ratio(portfolio_returns)
    calmar = calculate_calmar_ratio(portfolio_returns)
    
    info_ratio = calculate_information_ratio(portfolio_returns, benchmark_returns)
    
    var_95 = calculate_var(portfolio_returns, 0.95)
    cvar_95 = calculate_cvar(portfolio_returns, 0.95)
    max_dd = calculate_max_drawdown(portfolio_returns)
    
    winning_days = (portfolio_returns > 0).sum()
    losing_days = (portfolio_returns < 0).sum()
    win_rate = winning_days / (winning_days + losing_days) * 100 if (winning_days + losing_days) > 0 else 0
    
    avg_win = portfolio_returns[portfolio_returns > 0].mean() * 100 if winning_days > 0 else 0
    avg_loss = portfolio_returns[portfolio_returns < 0].mean() * 100 if losing_days > 0 else 0
    
    best_day = portfolio_returns.max() * 100
    worst_day = portfolio_returns.min() * 100
    
    return {
        'Total Return': total_return * 100,
        'Annualized Return': annualized_return * 100,
        'Annualized Volatility': annualized_vol * 100,
        'Sharpe Ratio': sharpe,
        'Sortino Ratio': sortino,
        'Calmar Ratio': calmar,
        'Information Ratio': info_ratio,
        'VaR (95%)': var_95,
        'CVaR (95%)': cvar_95,
        'Max Drawdown': max_dd,
        'Win Rate': win_rate,
        'Avg Win': avg_win,
        'Avg Loss': avg_loss,
        'Best Day': best_day,
        'Worst Day': worst_day,
        'Winning Days': winning_days,
        'Losing Days': losing_days
    }

def create_performance_dashboard(metrics):
    fig = make_subplots(
        rows=2, cols=2,
        subplot_titles=('Returns Distribution', 'Risk Metrics', 
                       'Win/Loss Analysis', 'Risk-Adjusted Returns'),
        specs=[[{'type': 'bar'}, {'type': 'scatter'}],
               [{'type': 'pie'}, {'type': 'bar'}]]
    )
    
    fig.add_trace(
        go.Bar(x=['Total', 'Annualized'], 
               y=[metrics['Total Return'], metrics['Annualized Return']],
               marker_color=[COLORS['success'], COLORS['electric_blue']]),
        row=1, col=1
    )
    
    fig.add_trace(
        go.Scatter(x=['Volatility', 'VaR', 'CVaR', 'Max DD'],
                  y=[metrics['Annualized Volatility'], abs(metrics['VaR (95%)']), 
                     abs(metrics['CVaR (95%)']), abs(metrics['Max Drawdown'])],
                  mode='markers+lines',
                  marker=dict(size=15, color=COLORS['danger'])),
        row=1, col=2
    )
    
    fig.add_trace(
        go.Pie(labels=['Winning Days', 'Losing Days'],
               values=[metrics['Winning Days'], metrics['Losing Days']],
               marker=dict(colors=[COLORS['success'], COLORS['danger']])),
        row=2, col=1
    )
    
    fig.add_trace(
        go.Bar(x=['Sharpe', 'Sortino', 'Calmar', 'Info'],
               y=[metrics['Sharpe Ratio'], metrics['Sortino Ratio'], 
                  metrics['Calmar Ratio'], metrics['Information Ratio']],
               marker_color=COLORS['purple']),
        row=2, col=2
    )
    
    fig.update_layout(
        height=700,
        showlegend=False,
        title_text="üìä Performance Dashboard"
    )
    
    apply_chart_theme(fig)
    return fig

# ============================================================================
# VALUATION HOUSE VISUALIZATIONS - ENHANCED
# ============================================================================

def create_dcf_waterfall(dcf_results, method='FCFF', use_professional_theme=True):
    """Create waterfall chart showing DCF buildup - Professional Blue theme"""

    categories = ['PV of Cash Flows', 'PV of Terminal Value']
    values = [dcf_results['total_pv_cash_flows'], dcf_results['pv_terminal']]

    if method == 'FCFF':
        categories.append('Enterprise Value')
        categories.append('Less: Net Debt')
        categories.append('Equity Value')
        values.append(dcf_results['enterprise_value'])
        values.append(-dcf_results.get('net_debt', 0))
        values.append(dcf_results['equity_value'])

    # Theme colors
    if use_professional_theme and PROFESSIONAL_THEME_AVAILABLE:
        connector_color = 'rgba(255, 255, 255, 0.5)'
        success_color = '#00E676'
        danger_color = '#FF1744'
        title_color = '#FFFFFF'
        text_color = '#FFFFFF'
        paper_bg = '#1a1d29'
        grid_color = 'rgba(255, 255, 255, 0.1)'
    else:
        connector_color = COLORS['neon_blue']
        success_color = COLORS['success']
        danger_color = COLORS['danger']
        title_color = '#ffffff'
        text_color = '#ffffff'
        paper_bg = 'rgba(0, 0, 0, 0)'
        grid_color = 'rgba(99, 102, 241, 0.1)'

    fig = go.Figure(go.Waterfall(
        name="DCF Buildup",
        orientation="v",
        x=categories,
        y=values,
        textfont=dict(size=10, family='JetBrains Mono', color=text_color),
        connector={"line": {"color": connector_color, "width": 2}},
        decreasing={"marker": {"color": danger_color}},
        increasing={"marker": {"color": success_color}},
    ))

    fig.update_layout(
        title=dict(text=f"üíé {method} Valuation Buildup", font=dict(size=16, color=title_color, family='Inter'), x=0.02, xanchor='left'),
        xaxis=dict(tickfont=dict(size=10, color=text_color)),
        yaxis=dict(title="Value ($)", showgrid=True, gridcolor=grid_color,
                   tickfont=dict(size=10, color=text_color, family='JetBrains Mono')),
        height=450,
        paper_bgcolor=paper_bg,
        plot_bgcolor=paper_bg,
        font=dict(family='Inter', color=text_color),
        margin=dict(l=70, r=30, t=60, b=50)
    )

    if not use_professional_theme:
        apply_chart_theme(fig)
    return fig

def create_cash_flow_chart(projections, method='FCFF', use_professional_theme=True):
    """Create bar chart of projected cash flows - Professional Blue theme"""

    # Handle DCFProjections object or list
    if not isinstance(projections, list):
        # If projections is a DCFProjections object, convert it to list format
        if hasattr(projections, 'forecast_years') and hasattr(projections, 'final_projections'):
            proj_list = []
            for year in range(1, projections.forecast_years + 1):
                year_data = projections.final_projections.get(year, {}) if isinstance(projections.final_projections, dict) else {}
                proj_list.append({
                    'year': year,
                    'fcff': year_data.get('fcff', 0),
                    'fcfe': year_data.get('fcfe', 0)
                })
            projections = proj_list
        else:
            # Can't convert, return empty chart
            st.warning("‚ö†Ô∏è Projections data format not recognized. Cannot display cash flow chart.")
            return go.Figure()

    cf_key = 'fcff' if method == 'FCFF' else 'fcfe'

    years = [proj['year'] for proj in projections]
    cash_flows = [proj[cf_key] for proj in projections]

    # Theme colors
    if use_professional_theme and PROFESSIONAL_THEME_AVAILABLE:
        bar_color = '#00BCD4'
        border_color = 'rgba(30, 136, 229, 0.3)'
        title_color = '#FFFFFF'
        text_color = '#FFFFFF'
        paper_bg = '#1a1d29'
        grid_color = 'rgba(255, 255, 255, 0.1)'
    else:
        bar_color = COLORS['electric_blue']
        border_color = COLORS['border']
        title_color = '#ffffff'
        text_color = '#ffffff'
        paper_bg = 'rgba(0, 0, 0, 0)'
        grid_color = 'rgba(99, 102, 241, 0.1)'

    fig = go.Figure()

    fig.add_trace(go.Bar(
        x=years,
        y=cash_flows,
        marker_color=bar_color,
        name=method,
        marker=dict(line=dict(color=border_color, width=1)),
        textfont=dict(size=10, family='JetBrains Mono')
    ))

    fig.update_layout(
        title=dict(text=f"üìä Projected {method} by Year", font=dict(size=16, color=title_color, family='Inter'), x=0.02, xanchor='left'),
        xaxis=dict(title="Year", tickfont=dict(size=10, color=text_color)),
        yaxis=dict(title=f"{method} ($)", showgrid=True, gridcolor=grid_color,
                   tickfont=dict(size=10, color=text_color, family='JetBrains Mono')),
        height=350,
        paper_bgcolor=paper_bg,
        plot_bgcolor=paper_bg,
        font=dict(family='Inter', color=text_color),
        margin=dict(l=70, r=30, t=60, b=50)
    )

    if not use_professional_theme:
        apply_chart_theme(fig)
    return fig

def create_sensitivity_table(base_price, base_discount, base_terminal):
    """Create sensitivity analysis table - ENHANCED THEMING"""
    
    discount_rates = np.linspace(base_discount - 0.02, base_discount + 0.02, 5)
    terminal_growth_rates = np.linspace(base_terminal - 0.01, base_terminal + 0.01, 5)
    
    # This is simplified - in real implementation would recalculate DCF
    sensitivity_matrix = []
    for tr in terminal_growth_rates:
        row = []
        for dr in discount_rates:
            # Simplified sensitivity calculation
            adjustment = (1 - (dr - base_discount)) * (1 + (tr - base_terminal))
            value = base_price * adjustment
            row.append(value)
        sensitivity_matrix.append(row)
    
    fig = go.Figure(data=go.Heatmap(
        z=sensitivity_matrix,
        x=[f"{dr:.1%}" for dr in discount_rates],
        y=[f"{tg:.1%}" for tg in terminal_growth_rates],
        colorscale='Spectral_r',
        text=[[f"${v:.2f}" for v in row] for row in sensitivity_matrix],
        texttemplate='%{text}',
        textfont={"size": 10},
        colorbar=dict(title="Price")
    ))
    
    fig.update_layout(
        title="üéØ Sensitivity Analysis",
        xaxis_title="Discount Rate",
        yaxis_title="Terminal Growth Rate",
        height=400
    )
    
    apply_chart_theme(fig)
    return fig

# ============================================================================
# ATLAS v11.0 ADVANCED FEATURES
# ============================================================================

class InvestopediaIntegration:
    """
    Investopedia Paper Trading API Integration - TWO-STAGE AUTHENTICATION

    FIXED: Proper 2FA flow with Selenium
    - Stage 1: Login with email/password ‚Üí triggers 2FA email
    - Stage 2: Submit 2FA code after user receives it
    - Live portfolio scraping after authentication
    """

    def __init__(self, email="davenompozolo@gmail.com"):
        self.email = email
        self.driver = None
        self.authenticated = False

    def attempt_login(self, password):
        """
        Stage 1: Attempt login with email/password to trigger 2FA email

        Returns:
            dict: {
                'status': '2fa_required' | 'error' | 'success',
                'message': str
            }
        """
        try:
            from selenium import webdriver
            from selenium.webdriver.common.by import By
            from selenium.webdriver.support.ui import WebDriverWait
            from selenium.webdriver.support import expected_conditions as EC
            from selenium.common.exceptions import TimeoutException, NoSuchElementException

            # COLAB-OPTIMIZED: System ChromeDriver setup
            # Auto-install Chromium and ChromeDriver if not present
            import subprocess
            import os

            # Check if ChromeDriver is installed, install if missing
            if not os.path.exists('/usr/bin/chromedriver'):
                st.info("üì¶ Installing Chrome/ChromeDriver for Colab...")
                try:
                    subprocess.run(['apt-get', 'update'], check=True, capture_output=True)
                    subprocess.run(['apt-get', 'install', '-y', 'chromium-chromedriver'], check=True, capture_output=True)
                    subprocess.run(['cp', '/usr/lib/chromium-browser/chromedriver', '/usr/bin'], check=True, capture_output=True)
                    subprocess.run(['chmod', '+x', '/usr/bin/chromedriver'], check=True, capture_output=True)
                    st.success("‚úÖ ChromeDriver installed successfully!")
                except Exception as e:
                    st.warning(f"‚ö†Ô∏è ChromeDriver installation failed: {e}")

            # COLAB-OPTIMIZED: Minimal Chrome options for stability
            options = webdriver.ChromeOptions()
            options.add_argument('--headless')
            options.add_argument('--no-sandbox')
            options.add_argument('--disable-dev-shm-usage')
            options.add_argument('--disable-gpu')

            # Explicit binary location for Colab
            options.binary_location = '/usr/bin/chromium-browser'

            # Use system ChromeDriver (no webdriver-manager needed)
            self.driver = webdriver.Chrome(options=options)

            # Navigate to Investopedia login page
            self.driver.get("https://www.investopedia.com/simulator/trade/login")

            # Wait for login form to load
            try:
                WebDriverWait(self.driver, 10).until(
                    EC.presence_of_element_located((By.ID, "edit-email"))
                )
            except TimeoutException:
                # Try alternative selectors
                WebDriverWait(self.driver, 10).until(
                    EC.presence_of_element_located((By.NAME, "email"))
                )

            # Enter credentials
            email_field = self.driver.find_element(By.ID, "edit-email") if self.driver.find_elements(By.ID, "edit-email") else self.driver.find_element(By.NAME, "email")
            password_field = self.driver.find_element(By.ID, "edit-password") if self.driver.find_elements(By.ID, "edit-password") else self.driver.find_element(By.NAME, "password")

            email_field.clear()
            email_field.send_keys(self.email)
            password_field.clear()
            password_field.send_keys(password)

            # Click login button
            login_button = self.driver.find_element(By.ID, "edit-submit") if self.driver.find_elements(By.ID, "edit-submit") else self.driver.find_element(By.CSS_SELECTOR, "button[type='submit']")
            login_button.click()

            # Wait for response (check for 2FA prompt, error, or success)
            import time
            time.sleep(3)  # Brief wait for page to react

            # Check for 2FA prompt
            try:
                WebDriverWait(self.driver, 5).until(
                    EC.presence_of_element_located((By.ID, "edit-otp"))
                )
                # 2FA field appeared - success! Email has been sent
                return {
                    'status': '2fa_required',
                    'message': '‚úì Login successful! Check your email for the 2FA code.'
                }
            except TimeoutException:
                pass

            # Check for error message
            try:
                error_element = self.driver.find_element(By.CLASS_NAME, "messages--error")
                error_text = error_element.text
                self.driver.quit()
                self.driver = None
                return {
                    'status': 'error',
                    'message': f'Login failed: {error_text}'
                }
            except NoSuchElementException:
                pass

            # Check if already on portfolio page (no 2FA needed)
            if "portfolio" in self.driver.current_url.lower() or "trade" in self.driver.current_url.lower():
                self.authenticated = True
                return {
                    'status': 'success',
                    'message': 'Login successful (no 2FA required)'
                }

            # Unknown state
            current_url = self.driver.current_url
            self.driver.quit()
            self.driver = None
            return {
                'status': 'error',
                'message': f'Unexpected page state after login. Current URL: {current_url}'
            }

        except Exception as e:
            if self.driver:
                self.driver.quit()
                self.driver = None
            return {
                'status': 'error',
                'message': f'Login error: {str(e)}'
            }

    def submit_2fa_code(self, code):
        """
        Stage 2: Submit 2FA code to complete authentication

        Args:
            code (str): 6-digit 2FA code from user's email

        Returns:
            dict: {'status': 'success' | 'error', 'message': str}
        """
        try:
            from selenium.webdriver.common.by import By
            from selenium.webdriver.support.ui import WebDriverWait
            from selenium.webdriver.support import expected_conditions as EC
            from selenium.common.exceptions import TimeoutException, NoSuchElementException

            if not self.driver:
                return {
                    'status': 'error',
                    'message': 'No active login session. Please start login again.'
                }

            # Find 2FA code input field
            try:
                code_field = WebDriverWait(self.driver, 5).until(
                    EC.presence_of_element_located((By.ID, "edit-otp"))
                )
            except TimeoutException:
                # Try alternative selectors
                code_field = self.driver.find_element(By.NAME, "otp")

            # Enter 2FA code
            code_field.clear()
            code_field.send_keys(code)

            # Click submit button
            submit_button = self.driver.find_element(By.ID, "edit-submit") if self.driver.find_elements(By.ID, "edit-submit") else self.driver.find_element(By.CSS_SELECTOR, "button[type='submit']")
            submit_button.click()

            # Wait for result
            import time
            time.sleep(3)

            # Check for error message
            try:
                error = self.driver.find_element(By.CLASS_NAME, "messages--error")
                return {
                    'status': 'error',
                    'message': f'Invalid 2FA code: {error.text}'
                }
            except NoSuchElementException:
                pass

            # Check if redirected to portfolio/trade page (success)
            try:
                WebDriverWait(self.driver, 10).until(
                    lambda driver: "portfolio" in driver.current_url.lower() or "trade" in driver.current_url.lower()
                )
                self.authenticated = True
                return {
                    'status': 'success',
                    'message': '‚úì Authentication complete! You can now sync your portfolio.'
                }
            except TimeoutException:
                return {
                    'status': 'error',
                    'message': '2FA code accepted but failed to reach portfolio page'
                }

        except Exception as e:
            return {
                'status': 'error',
                'message': f'2FA submission error: {str(e)}'
            }

    def scrape_portfolio(self):
        """Scrape live portfolio data from Investopedia after successful authentication"""
        if not self.authenticated or not self.driver:
            st.warning("‚ö†Ô∏è Please authenticate first")
            return None

        try:
            from selenium.webdriver.common.by import By
            from selenium.webdriver.support.ui import WebDriverWait
            from selenium.webdriver.support import expected_conditions as EC
            from bs4 import BeautifulSoup

            # Navigate to portfolio page (if not already there)
            if "portfolio" not in self.driver.current_url:
                self.driver.get("https://www.investopedia.com/simulator/portfolio")

            # Wait for portfolio table to load
            WebDriverWait(self.driver, 10).until(
                EC.presence_of_element_located((By.CSS_SELECTOR, "table.portfolio-table"))
            )

            # Parse page HTML
            soup = BeautifulSoup(self.driver.page_source, 'html.parser')

            # Extract positions from table
            positions = []
            table = soup.find('table', class_='portfolio-table')

            if table:
                rows = table.find('tbody').find_all('tr')

                for row in rows:
                    cells = row.find_all('td')
                    if len(cells) >= 6:
                        position = {
                            'Ticker': cells[0].text.strip(),
                            'Shares': float(cells[1].text.strip().replace(',', '')),
                            'Avg Cost': float(cells[2].text.strip().replace('$', '').replace(',', '')),
                            'Current Price': float(cells[3].text.strip().replace('$', '').replace(',', '')),
                            'Total Value': float(cells[4].text.strip().replace('$', '').replace(',', '')),
                            'Gain/Loss': float(cells[5].text.strip().replace('$', '').replace(',', ''))
                        }
                        positions.append(position)

            # Cleanup driver
            self.driver.quit()
            self.driver = None

            if positions:
                st.success(f"‚úÖ Successfully scraped {len(positions)} positions from Investopedia")
                return pd.DataFrame(positions)
            else:
                st.info("üìä Portfolio is empty or no positions found")
                return pd.DataFrame()

        except Exception as e:
            st.error(f"‚ùå Portfolio scraping error: {str(e)}")
            if self.driver:
                self.driver.quit()
                self.driver = None
            return None

    def cleanup(self):
        """Cleanup driver resources"""
        if self.driver:
            self.driver.quit()
            self.driver = None


class StochasticEngine:
    """
    Advanced Stochastic Modeling using Geometric Brownian Motion
    - Monte Carlo simulations with 10,000+ paths
    - Correlated asset movements
    - VaR/CVaR risk metrics
    """

    def __init__(self, tickers, returns_data=None):
        self.tickers = tickers
        self.returns_data = returns_data
        self.mu = None
        self.cov = None

        if returns_data is not None:
            self.mu = returns_data.mean().values
            self.cov = returns_data.cov().values

    def geometric_brownian_motion(self, S0, mu, sigma, T, dt, n_paths):
        """
        Generate price paths using Geometric Brownian Motion

        dS_t = Œº * S_t * dt + œÉ * S_t * dW_t

        where:
        - S_t = stock price at time t
        - Œº = drift (expected return)
        - œÉ = volatility
        - dW_t = Wiener process (random walk)
        """
        n_steps = int(T / dt)
        paths = np.zeros((n_paths, n_steps))
        paths[:, 0] = S0

        for t in range(1, n_steps):
            Z = np.random.standard_normal(n_paths)
            paths[:, t] = paths[:, t-1] * np.exp(
                (mu - 0.5 * sigma**2) * dt + sigma * np.sqrt(dt) * Z
            )

        return paths

    def monte_carlo_simulation(self, weights, S0_values, n_scenarios=10000, T=252):
        """
        Run full portfolio Monte Carlo simulation

        Returns:
        - portfolio_paths: simulated portfolio values over time
        - returns_dist: distribution of portfolio returns
        - metrics: VaR 95%, CVaR 95%, Expected Return, Volatility
        """
        dt = 1 / 252  # Daily time step
        n_assets = len(self.tickers)
        n_steps = T

        # Generate correlated random numbers using Cholesky decomposition
        L = np.linalg.cholesky(self.cov)

        # Initialize paths for each asset
        asset_paths = np.zeros((n_scenarios, n_steps, n_assets))

        for i in range(n_assets):
            asset_paths[:, 0, i] = S0_values[i]

        # Simulate paths
        for t in range(1, n_steps):
            Z = np.random.standard_normal((n_scenarios, n_assets))
            Z_corr = Z @ L.T

            for i in range(n_assets):
                asset_paths[:, t, i] = asset_paths[:, t-1, i] * np.exp(
                    (self.mu[i] - 0.5 * self.cov[i, i]) * dt +
                    np.sqrt(self.cov[i, i] * dt) * Z_corr[:, i]
                )

        # Calculate portfolio values
        portfolio_paths = np.sum(asset_paths * weights, axis=2)

        # Calculate returns distribution
        final_returns = (portfolio_paths[:, -1] - portfolio_paths[:, 0]) / portfolio_paths[:, 0]

        # Calculate risk metrics
        var_95 = np.percentile(final_returns, 5)
        cvar_95 = final_returns[final_returns <= var_95].mean()
        expected_return = final_returns.mean()
        volatility = final_returns.std()

        metrics = {
            'VaR 95%': var_95,
            'CVaR 95%': cvar_95,
            'Expected Return': expected_return,
            'Volatility': volatility
        }

        return portfolio_paths, final_returns, metrics


class QuantOptimizer:
    """
    Advanced Portfolio Optimization using Multivariable Calculus
    - Analytical gradient calculation: ‚àÇSharpe/‚àÇw_i
    - SLSQP optimization with Jacobian matrix
    - Maximum Sharpe Ratio objective
    - Leverage constraints
    """

    def __init__(self, returns_data, risk_free_rate=0.04):
        self.returns = returns_data
        self.mu = returns_data.mean().values * 252  # Annualized
        self.cov = returns_data.cov().values * 252  # Annualized
        self.rf = risk_free_rate
        self.n_assets = len(self.mu)

    def portfolio_metrics(self, weights):
        """Calculate portfolio return and volatility"""
        ret = np.dot(weights, self.mu)
        vol = np.sqrt(np.dot(weights, np.dot(self.cov, weights)))
        return ret, vol

    def sharpe_ratio(self, weights):
        """Calculate Sharpe Ratio"""
        ret, vol = self.portfolio_metrics(weights)
        return (ret - self.rf) / vol if vol != 0 else 0

    def negative_sharpe(self, weights):
        """Negative Sharpe for minimization"""
        return -self.sharpe_ratio(weights)

    def sharpe_gradient(self, weights):
        """
        Analytical gradient of Sharpe Ratio

        ‚àÇSharpe/‚àÇw_i = (1/œÉ_p) * [‚àÇr_p/‚àÇw_i - Sharpe * ‚àÇœÉ_p/‚àÇw_i]

        where:
        - ‚àÇr_p/‚àÇw_i = Œº_i (partial derivative of return)
        - ‚àÇœÉ_p/‚àÇw_i = (Œ£*w)_i / œÉ_p (partial derivative of volatility)
        """
        ret, vol = self.portfolio_metrics(weights)

        if vol == 0:
            return np.zeros(self.n_assets)

        sharpe = self.sharpe_ratio(weights)

        # Volatility gradient: ‚àÇœÉ_p/‚àÇw_i = (Œ£*w)_i / œÉ_p
        vol_grad = np.dot(self.cov, weights) / vol

        # Return gradient: ‚àÇr_p/‚àÇw_i = Œº_i
        ret_grad = self.mu

        # Sharpe gradient: ‚àÇSharpe/‚àÇw_i = (1/œÉ_p) * [Œº_i - Sharpe * (Œ£*w)_i/œÉ_p]
        sharpe_grad = (1 / vol) * (ret_grad - sharpe * vol_grad)

        return -sharpe_grad  # Negative for minimization

    def optimize_max_sharpe(self, min_weight=0.01, max_weight=0.40):
        """
        Optimize portfolio using SLSQP with analytical Jacobian

        Constraints:
        - Sum of weights = 1
        - Min/max weight bounds
        """
        from scipy.optimize import minimize

        # Initial guess (equal weights)
        w0 = np.ones(self.n_assets) / self.n_assets

        # Constraints
        constraints = [
            {'type': 'eq', 'fun': lambda w: np.sum(w) - 1.0}  # Sum to 1
        ]

        # Bounds
        bounds = tuple((min_weight, max_weight) for _ in range(self.n_assets))

        # Optimize using SLSQP with analytical gradient
        result = minimize(
            fun=self.negative_sharpe,
            x0=w0,
            method='SLSQP',
            jac=self.sharpe_gradient,  # Analytical gradient
            bounds=bounds,
            constraints=constraints,
            options={'maxiter': 1000, 'ftol': 1e-9}
        )

        optimal_weights = result.x
        optimal_sharpe = self.sharpe_ratio(optimal_weights)

        return optimal_weights, optimal_sharpe, result

    def generate_rebalancing_plan(self, optimal_weights, portfolio_data, currency_symbol='$'):
        """
        Generate detailed rebalancing plan with BUY/SELL/HOLD actions.

        Args:
            optimal_weights: Optimal portfolio weights from optimization
            portfolio_data: Current portfolio DataFrame
            currency_symbol: Currency symbol for display

        Returns:
            tuple: (rebalancing_df, metrics_dict)
        """
        # Detect ticker column name
        ticker_column = 'Symbol' if 'Symbol' in portfolio_data.columns else 'Ticker'

        # Get tickers from returns data (this is what was optimized)
        optimized_tickers = list(self.returns.columns)

        # Filter portfolio data to only include optimized tickers
        portfolio_data = portfolio_data[portfolio_data[ticker_column].isin(optimized_tickers)].copy()

        # Calculate current portfolio value and weights
        if 'Quantity' in portfolio_data.columns and 'Current Price' in portfolio_data.columns:
            portfolio_data['Total Value'] = portfolio_data['Quantity'] * portfolio_data['Current Price']
        elif 'Total Value' not in portfolio_data.columns:
            # Fallback: use market value if available
            if 'Market Value' in portfolio_data.columns:
                portfolio_data['Total Value'] = portfolio_data['Market Value']
            else:
                # Cannot generate rebalancing plan without position values
                return None, None

        total_portfolio_value = portfolio_data['Total Value'].sum()
        portfolio_data['Current Weight'] = portfolio_data['Total Value'] / total_portfolio_value

        # Build rebalancing dataframe
        rebalancing_data = []
        total_buy_value = 0
        total_sell_value = 0

        for i, ticker in enumerate(optimized_tickers):
            # Get current position data
            ticker_data = portfolio_data[portfolio_data[ticker_column] == ticker]

            if ticker_data.empty:
                # New position to add
                current_weight = 0
                current_value = 0
                current_shares = 0
                current_price = 0  # Would need to fetch
            else:
                current_weight = ticker_data['Current Weight'].values[0]
                current_value = ticker_data['Total Value'].values[0]
                current_shares = ticker_data['Quantity'].values[0] if 'Quantity' in ticker_data.columns else 0
                current_price = ticker_data['Current Price'].values[0] if 'Current Price' in ticker_data.columns else 0

            # Optimal position
            optimal_weight = optimal_weights[i]
            optimal_value = optimal_weight * total_portfolio_value
            weight_diff = optimal_weight - current_weight

            # Calculate trade details
            if current_price > 0:
                optimal_shares = optimal_value / current_price
                shares_to_trade = optimal_shares - current_shares
                trade_value = shares_to_trade * current_price
            else:
                optimal_shares = 0
                shares_to_trade = 0
                trade_value = 0

            # Determine action (only flag if trade is meaningful > $100 or > 5 shares)
            if abs(trade_value) > 100 or abs(shares_to_trade) > 5:
                if shares_to_trade > 0:
                    action = 'BUY'
                    total_buy_value += abs(trade_value)
                else:
                    action = 'SELL'
                    total_sell_value += abs(trade_value)
            else:
                action = 'HOLD'

            rebalancing_data.append({
                'Ticker': ticker,
                'Current Weight (%)': current_weight * 100,
                'Optimal Weight (%)': optimal_weight * 100,
                'Weight Diff (%)': weight_diff * 100,
                'Current Shares': int(current_shares),
                'Target Shares': int(optimal_shares),
                'Shares to Trade': int(shares_to_trade),
                'Trade Value': trade_value,
                'Action': action,
                'Priority': abs(trade_value)  # For sorting
            })

        rebalancing_df = pd.DataFrame(rebalancing_data)
        rebalancing_df = rebalancing_df.sort_values('Priority', ascending=False)

        # Calculate metrics
        buy_trades = len(rebalancing_df[rebalancing_df['Action'] == 'BUY'])
        sell_trades = len(rebalancing_df[rebalancing_df['Action'] == 'SELL'])
        hold_positions = len(rebalancing_df[rebalancing_df['Action'] == 'HOLD'])

        # Estimate trading costs (assume 0.1% per trade)
        trading_cost = (total_buy_value + total_sell_value) * 0.001

        metrics = {
            'total_portfolio_value': total_portfolio_value,
            'buy_trades': buy_trades,
            'sell_trades': sell_trades,
            'hold_positions': hold_positions,
            'total_buy_value': total_buy_value,
            'total_sell_value': total_sell_value,
            'estimated_trading_cost': trading_cost,
            'total_trades': buy_trades + sell_trades,
            'turnover_pct': (total_buy_value + total_sell_value) / (2 * total_portfolio_value) * 100 if total_portfolio_value > 0 else 0
        }

        return rebalancing_df, metrics


class EnhancedDCFEngine:
    """
    Advanced DCF Valuation with WACC and FCF projections
    - WACC calculation using CAPM
    - 5-year FCF projections
    - Terminal value calculation
    - Sensitivity analysis
    """

    def __init__(self, ticker):
        self.ticker = ticker
        self.stock = yf.Ticker(ticker)
        self.info = self.stock.info

    def calculate_wacc(self, risk_free=0.04, market_return=0.10):
        """
        Calculate Weighted Average Cost of Capital

        WACC = (E/V) * Re + (D/V) * Rd * (1-T)

        where:
        - Re = Cost of Equity = Rf + Œ≤ * (Rm - Rf)  [CAPM]
        - Rd = Cost of Debt
        - E = Market value of equity
        - D = Market value of debt
        - V = E + D
        - T = Tax rate
        """
        info = self.info

        # Get values from info
        market_cap = info.get('marketCap', 0)
        total_debt = info.get('totalDebt', 0)
        beta = info.get('beta', 1.0)

        # Calculate cost of equity using CAPM
        re = risk_free + beta * (market_return - risk_free)

        # Cost of debt (simplified)
        interest_expense = info.get('interestExpense', 0)
        rd = abs(interest_expense) / total_debt if total_debt > 0 else 0.05

        # Tax rate
        tax_rate = info.get('effectiveTaxRate', 0.21)

        # Total value
        total_value = market_cap + total_debt

        if total_value == 0:
            return None

        # Calculate WACC
        wacc = (market_cap / total_value) * re + (total_debt / total_value) * rd * (1 - tax_rate)

        return {
            'WACC': wacc,
            'Cost of Equity': re,
            'Cost of Debt': rd,
            'Market Cap': market_cap,
            'Total Debt': total_debt,
            'Tax Rate': tax_rate,
            'Beta': beta
        }

    def calculate_enterprise_value(self, terminal_growth=0.03):
        """
        Calculate Enterprise Value using DCF

        EV = PV(FCF_1) + PV(FCF_2) + ... + PV(FCF_5) + PV(Terminal Value)

        Terminal Value = FCF_5 * (1 + g) / (WACC - g)
        """
        wacc_data = self.calculate_wacc()
        if wacc_data is None:
            return None

        wacc = wacc_data['WACC']

        # Get current free cash flow
        cash_flow = self.stock.cashflow
        if cash_flow.empty:
            return None

        fcf = cash_flow.loc['Free Cash Flow'].iloc[0] if 'Free Cash Flow' in cash_flow.index else 0

        if fcf <= 0:
            return None

        # Project 5 years of FCF (assuming 5% annual growth)
        fcf_growth = 0.05
        fcf_projections = []

        for year in range(1, 6):
            projected_fcf = fcf * ((1 + fcf_growth) ** year)
            pv_fcf = projected_fcf / ((1 + wacc) ** year)
            fcf_projections.append({
                'Year': year,
                'FCF': projected_fcf,
                'PV of FCF': pv_fcf
            })

        # Terminal value
        fcf_terminal = fcf_projections[-1]['FCF'] * (1 + terminal_growth)
        terminal_value = fcf_terminal / (wacc - terminal_growth)
        pv_terminal = terminal_value / ((1 + wacc) ** 5)

        # Enterprise Value
        pv_fcf_sum = sum([p['PV of FCF'] for p in fcf_projections])
        enterprise_value = pv_fcf_sum + pv_terminal

        # Equity value
        total_debt = wacc_data['Total Debt']
        cash = self.info.get('totalCash', 0)
        equity_value = enterprise_value - total_debt + cash

        # Shares outstanding
        shares_outstanding = self.info.get('sharesOutstanding', 1)
        fair_value_per_share = equity_value / shares_outstanding

        return {
            'FCF Projections': fcf_projections,
            'Terminal Value': terminal_value,
            'PV Terminal Value': pv_terminal,
            'Enterprise Value': enterprise_value,
            'Equity Value': equity_value,
            'Fair Value per Share': fair_value_per_share,
            'WACC': wacc
        }


class MultiSourceDataBroker:
    """
    Multi-Source Data Integration
    - Yahoo Finance (primary)
    - Alpha Vantage
    - Bloomberg (framework ready)
    """

    def __init__(self, alpha_vantage_key=None, bloomberg_available=False):
        self.alpha_vantage_key = alpha_vantage_key
        self.bloomberg_available = bloomberg_available

    def get_price_data(self, ticker, source='yahoo', period='1y'):
        """Get price data from specified source"""

        if source == 'yahoo':
            try:
                # Import ticker conversion utility
                from modules import convert_ee_ticker_to_yahoo

                # Convert Easy Equities ticker to Yahoo Finance format
                yahoo_ticker = convert_ee_ticker_to_yahoo(ticker)

                # Fetch data with converted ticker
                data = yf.download(yahoo_ticker, period=period, progress=False)

                # Add metadata
                if not data.empty:
                    data.attrs['original_ticker'] = ticker
                    data.attrs['yahoo_ticker'] = yahoo_ticker

                return data
            except Exception as e:
                st.error(f"Yahoo Finance error for {ticker}: {str(e)}")
                return None

        elif source == 'alpha_vantage' and self.alpha_vantage_key:
            try:
                import requests
                url = f"https://www.alphavantage.co/query?function=TIME_SERIES_DAILY_ADJUSTED&symbol={ticker}&apikey={self.alpha_vantage_key}&outputsize=full"
                response = requests.get(url)
                data = response.json()

                # Convert to DataFrame format similar to yfinance
                # (Placeholder - would need full implementation)
                st.info("Alpha Vantage integration ready")
                return None

            except Exception as e:
                st.error(f"Alpha Vantage error: {str(e)}")
                return None

        elif source == 'bloomberg' and self.bloomberg_available:
            # Placeholder for Bloomberg Terminal integration
            st.info("Bloomberg Terminal integration framework ready")
            return None

        else:
            st.warning(f"Source '{source}' not available")
            return None

    def get_multi_source_data(self, ticker, sources=['yahoo']):
        """Fetch data from multiple sources and aggregate"""
        data_dict = {}

        for source in sources:
            data = self.get_price_data(ticker, source=source)
            if data is not None:
                data_dict[source] = data

        return data_dict


# ============================================================================
# MAIN APP - EXCELLENCE EDITION
# ============================================================================

def main():
    # Ensure plotly.graph_objects is available in function scope
    import plotly.graph_objects as go

    # ============================================================================
    # SIDEBAR - RENDER IMMEDIATELY TO FORCE VISIBILITY
    # ============================================================================
    # ============================================================================
    # EQUITY TRACKING INITIALIZATION - CRITICAL FIX FOR LEVERAGE CALCULATIONS
    # ============================================================================
    # Initialize equity tracking from performance history if available
    if 'equity_capital' not in st.session_state:
        # Try to get equity from performance history first
        metrics = get_current_portfolio_metrics()
        if metrics and metrics.get('equity', 0) > 0:
            st.session_state['equity_capital'] = metrics['equity']
        else:
            st.session_state['equity_capital'] = 100000.0  # Default $100k

    if 'target_leverage' not in st.session_state:
        st.session_state['target_leverage'] = 1.0  # Default no leverage

    # ============================================================================
    # ATLAS TERMINAL HEADER - FIGMA REDESIGN (JetBrains Mono)
    # ============================================================================

    def render_atlas_header():
        """FIGMA REDESIGN: Clean header with JetBrains Mono typography."""
        # Single-line styles to fix Streamlit HTML parsing
        st.markdown("""<style>@import url('https://fonts.googleapis.com/css2?family=JetBrains+Mono:wght@300;400;500;600;700&display=swap');</style><div style="background: linear-gradient(135deg, rgba(34,211,238,0.04), rgba(21,25,50,0.95)); backdrop-filter: blur(24px); border-radius: 16px; border: 1px solid rgba(34,211,238,0.1); padding: 2rem 2.5rem; margin-bottom: 0.75rem; box-shadow: 0 4px 24px rgba(0,0,0,0.2); position: relative; overflow: hidden; display: flex; align-items: center; justify-content: space-between;"><div style="position: absolute; top: 0; left: 0; right: 0; height: 3px; background: linear-gradient(90deg, #22d3ee, #6366f1, #8b5cf6); opacity: 0.8;"></div><div style="display: flex; align-items: center; gap: 1.25rem;"><div style="width: 4rem; height: 4rem; background: linear-gradient(135deg, rgba(34,211,238,0.12), rgba(99,102,241,0.12)); border: 1px solid rgba(34,211,238,0.25); border-radius: 0.5rem; display: flex; align-items: center; justify-content: center;"><span style="font-family: 'JetBrains Mono', monospace; font-size: 2rem; font-weight: 700; color: #22d3ee;">A</span></div><div><div style="font-family: 'JetBrains Mono', monospace; font-size: 2.25rem; font-weight: 600; color: #22d3ee; margin: 0; letter-spacing: 0.05em; line-height: 1.2;">ATLAS TERMINAL</div></div></div><div style="text-align: right;"><div style="font-family: 'JetBrains Mono', monospace; font-size: 0.8rem; color: rgba(156, 163, 175, 0.7); margin: 0; line-height: 1.4;">Institutional Intelligence.</div><div style="font-family: 'JetBrains Mono', monospace; font-size: 0.8rem; color: rgba(156, 163, 175, 0.7); margin: 0; line-height: 1.4;">Personal Scale.</div></div></div>""", unsafe_allow_html=True)

    def render_data_source_cards():
        """FIGMA REDESIGN: Clickable cards for data source selection."""
        if 'portfolio_data_source_mode' not in st.session_state:
            st.session_state['portfolio_data_source_mode'] = "üìÅ Classic Mode (Excel Upload)"

        sources = [
            {"key": "üìÅ Classic Mode (Excel Upload)", "icon": "üìÅ", "title": "Classic Mode", "desc": "Upload Excel files"},
            {"key": "üîó Easy Equities (Live Sync)", "icon": "üîó", "title": "Easy Equities", "desc": "Live broker sync"},
            {"key": "ü¶ô Alpaca Markets (Live Sync)", "icon": "ü¶ô", "title": "Alpaca Markets", "desc": "Live broker sync"}
        ]

        cols = st.columns(3)
        for i, source in enumerate(sources):
            with cols[i]:
                is_selected = st.session_state['portfolio_data_source_mode'] == source['key']
                border_color = "rgba(34, 211, 238, 0.5)" if is_selected else "rgb(31, 41, 55)"
                bg_color = "rgba(34, 211, 238, 0.1)" if is_selected else "transparent"

                if st.button(f"{source['icon']} {source['title']}", key=f"src_{i}", use_container_width=True):
                    st.session_state['portfolio_data_source_mode'] = source['key']
                    st.rerun()

                st.markdown(f"""<div style="text-align: center; padding: 0.5rem; background: {bg_color}; border: 1px solid {border_color}; border-radius: 0.5rem; margin-top: -0.5rem;"><p style="font-family: 'JetBrains Mono', monospace; font-size: 0.7rem; color: rgb(156, 163, 175); margin: 0;">{source['desc']}</p></div>""", unsafe_allow_html=True)

        return st.session_state['portfolio_data_source_mode']

    # Call the header function
    render_atlas_header()

    # ============================================================================
    # CAPITAL SETTINGS - Auto-populated from session state (UI removed for cleaner homepage)
    # ============================================================================
    # Capital settings now auto-populated from performance history
    metrics = get_current_portfolio_metrics()
    if metrics and metrics.get('equity', 0) > 0:
        st.session_state['equity_capital'] = metrics['equity']
        st.session_state['target_leverage'] = metrics.get('leverage', 1.0)
    elif 'equity_capital' not in st.session_state:
        st.session_state['equity_capital'] = 100000.0
        st.session_state['target_leverage'] = 1.0

    # ============================================================================
    # PHASE 1B: VERTICAL SIDEBAR NAVIGATION
    # ============================================================================
    try:
        page = render_sidebar_navigation(default_page="Portfolio Home")
    except Exception as e:
        # Fallback sidebar if render_sidebar_navigation fails
        with st.sidebar:
            page = st.radio("Navigation", ["Portfolio Home", "Phoenix Parser", "Market Watch", "Stock Screener", "Valuation House"], label_visibility="collapsed")

    # ============================================================================
    # LEGACY HORIZONTAL NAVIGATION (DEPRECATED - PHASE 1B)
    # ============================================================================
    # Preserved for reference and potential rollback
    # Remove after successful testing of vertical sidebar

    # # Horizontal Navigation Menu (positioned at top for better hierarchy)
    # page = option_menu(
    #     menu_title=None,
    #     options=[
    #         "üî• Phoenix Parser",
    #         "üè† Portfolio Home",
    #         "üöÄ v10.0 Analytics",
    #         "üìä R Analytics",
    #         "üíæ Database",
    #         "üåç Market Watch",
    #         "üìà Risk Analysis",
    #         "üíé Performance Suite",
    #         "üî¨ Portfolio Deep Dive",
    #         "üìä Multi-Factor Analysis",
    #         "üí∞ Valuation House",
    #         "üé≤ Monte Carlo Engine",
    #         "üßÆ Quant Optimizer",
    #         "üìä Leverage Tracker",
    #         "üì° Investopedia Live",
    #         "‚ÑπÔ∏è About"
    #     ],
    #     icons=["fire", "house-fill", "rocket-takeoff-fill", "graph-up-arrow", "database-fill", "globe", "graph-up", "gem", "microscope", "bar-chart-fill", "cash-coin", "dice-5-fill", "calculator-fill", "graph-up", "broadcast", "info-circle-fill"],
    #     menu_icon="cast",
    #     default_index=0,
    #     orientation="horizontal",  # KEY: Horizontal layout
    #     styles={
    #         "container": {
    #             "padding": "0!important",
    #             "background-color": "rgba(10, 25, 41, 0.4)",
    #             "border-radius": "10px",
    #             "margin-bottom": "20px"
    #         },
    #         "icon": {
    #             "color": "#00d4ff",
    #             "font-size": "18px"
    #         },
    #         "nav-link": {
    #             "font-size": "14px",
    #             "text-align": "center",
    #             "margin": "0px",
    #             "padding": "12px 16px",
    #             "border-radius": "8px",
    #             "--hover-color": "rgba(0, 212, 255, 0.15)",
    #             "color": "#ffffff",
    #             "white-space": "nowrap"
    #         },
    #         "nav-link-selected": {
    #             "background-color": "#00d4ff",
    #             "color": "#000000",
    #             "font-weight": "600",
    #             "box-shadow": "0 4px 12px rgba(0, 212, 255, 0.3)"
    #         }
    #     }
    # )

    # ========================================================================
    # PHASE 2A: NAVIGATION ROUTING (Registry-Based)
    # ========================================================================
    # Map option_menu titles to registry keys
    PAGE_TITLE_TO_KEY = {
        "üî• Phoenix Parser": "phoenix_parser",
        "üè† Portfolio Home": "portfolio_home",
        "üöÄ v10.0 Analytics": "v10_analytics",
        "üìä R Analytics": "r_analytics",
        "üíæ Database": "database",
        "üåç Market Watch": "market_watch",
        "üìà Risk Analysis": "risk_analysis",
        "üíé Performance Suite": "performance_suite",
        "üî¨ Portfolio Deep Dive": "portfolio_deep_dive",
        "üìä Multi-Factor Analysis": "multi_factor_analysis",
        "üí∞ Valuation House": "valuation_house",
        "üé≤ Monte Carlo Engine": "monte_carlo_engine",
        "üåê Market Regime": "market_regime",
        "üßÆ Quant Optimizer": "quant_optimizer",
        "üìä Leverage Tracker": "leverage_tracker",
        "üì° Investopedia Live": "investopedia_live",
        "‚ÑπÔ∏è About": "about"
    }

    # Get page key from selected title
    selected_page_key = PAGE_TITLE_TO_KEY.get(page, "portfolio_home")

    # ============================================================================
    # SIDEBAR SETTINGS - Time Range and Benchmark controls
    # ============================================================================
    with st.sidebar:
        st.markdown("---")
        st.markdown("### ‚öôÔ∏è Settings")

        # Time Range Selector
        date_options = ["1D", "1W", "1M", "3M", "6M", "YTD", "1Y", "3Y", "5Y", "MAX"]
        selected_range = st.selectbox(
            "üìÖ Time Range",
            date_options,
            index=6,  # Default to "1Y"
            key="sidebar_time_range"
        )

        # Benchmark Selector
        benchmark_options = ["SPY", "QQQ", "DIA", "IWM", "VTI", "ACWI"]
        selected_benchmark = st.selectbox(
            "üéØ Benchmark",
            benchmark_options,
            index=0,  # Default to "SPY"
            key="sidebar_benchmark"
        )

        # Store in session state for use throughout app
        st.session_state['selected_range'] = selected_range
        st.session_state['selected_benchmark'] = selected_benchmark

    # Calculate date range based on selection
    if selected_range == "YTD":
        start_date = datetime(datetime.now().year, 1, 1)
        end_date = datetime.now()
    elif selected_range == "MAX":
        start_date = datetime(2000, 1, 1)
        end_date = datetime.now()
    else:
        days_map = {"1D": 1, "1W": 7, "1M": 30, "3M": 90, "6M": 180, "1Y": 365, "3Y": 1095, "5Y": 1825}
        days = days_map.get(selected_range, 365)
        end_date = datetime.now()
        start_date = end_date - timedelta(days=days)
    
    # ========================================================================
    # PHASE 2A: NAVIGATION V2 ROUTING (Experimental - can be toggled)
    # ========================================================================
    # Toggle between old monolithic routing and new modular navigation
    USE_NAVIGATION_V2 = st.sidebar.checkbox(
        "üß™ Use Navigation v2.0 (Experimental)",
        value=False,
        help="Enable new modular navigation system (Phase 2A)"
    )

    if USE_NAVIGATION_V2:
        # NEW: Registry-based routing
        st.info(f"üìç **Navigation v2.0 Active** - Routing to: `{selected_page_key}`")
        route_to_page(selected_page_key)

    else:
        # OLD: Monolithic if/elif routing (will be deprecated after Phase 2A testing)
        pass  # Fall through to old code below

    # ========================================================================
    # OLD NAVIGATION CODE (To be deprecated after Phase 2A complete)
    # ========================================================================
    if not USE_NAVIGATION_V2:  # Only run old code if v2 is disabled
        # ====================================================================
        # PHOENIX PARSER
        # ====================================================================
        if page == "üî• Phoenix Parser":
            st.markdown("## üî• PHOENIX MODE")

            # ===== FIGMA REDESIGN: Portfolio Data Source Cards =====
            st.markdown("### üìä Portfolio Data Source")
            portfolio_mode = render_data_source_cards()
            st.divider()

            # ===== CLASSIC MODE: Original Excel Upload (Existing Code) =====
            if portfolio_mode == "üìÅ Classic Mode (Excel Upload)":
                col1, col2 = st.columns(2)

                with col1:
                    st.markdown("### üìä Trade History")
                    trade_file = st.file_uploader("Upload Trade History", type=['xls', 'xlsx'], key="trade")
                
                    if trade_file:
                        with st.spinner("Parsing..."):
                            trade_df = parse_trade_history_file(trade_file)

                            if trade_df is not None:
                                # FIX #7: Add debug output to diagnose database save issues
                                with st.expander("üîç Debug Info - Trade File Columns", expanded=False):
                                    st.write("**Columns in uploaded file:**")
                                    st.write(list(trade_df.columns))
                                    st.write(f"**SQL_AVAILABLE:** {SQL_AVAILABLE}")
                                    if not SQL_AVAILABLE:
                                        st.warning("‚ö†Ô∏è Database not available - trades will save to cache file only")

                                save_trade_history(trade_df)
                                st.success(f"‚úÖ Parsed {len(trade_df)} trades!")

                                # CRITICAL FIX: Verify database save
                                if SQL_AVAILABLE:
                                    try:
                                        db = get_db()
                                        db_count = db.read("SELECT COUNT(*) as count FROM trades").iloc[0]['count']
                                        st.success(f"üíæ Database now contains {db_count} total trade records (persistent across sessions)")

                                        # Show last 5 trades from database to confirm
                                        last_trades = db.read("SELECT * FROM trades ORDER BY date DESC LIMIT 5")
                                        if len(last_trades) > 0:
                                            with st.expander("üîç Last 5 Trades in Database", expanded=False):
                                                st.dataframe(last_trades, use_container_width=True)
                                    except Exception as e:
                                        st.warning(f"‚ö†Ô∏è Could not verify database: {e}")

                                show_toast(f"Trade history imported: {len(trade_df)} trades parsed successfully", toast_type="success", duration=3000)
                                make_scrollable_table(trade_df.head(10), height=400, hide_index=True, use_container_width=True, column_config=None)

                                # Check for options that will be filtered
                                option_tickers = []
                                if 'Symbol' in trade_df.columns:
                                    unique_symbols = trade_df['Symbol'].unique()
                                    option_tickers = [ticker for ticker in unique_symbols if is_option_ticker(ticker)]

                                portfolio_df = calculate_portfolio_from_trades(trade_df)
                                if len(portfolio_df) > 0:
                                    save_portfolio_data(portfolio_df.to_dict('records'))
                                    st.success(f"üéâ Portfolio rebuilt! {len(portfolio_df)} positions")
                                    show_toast(f"üî• Phoenix reconstruction complete: {len(portfolio_df)} positions rebuilt", toast_type="success", duration=4000)

                                    # Show filtered options if any
                                    if option_tickers:
                                        with st.expander(f"üóëÔ∏è Filtered {len(option_tickers)} option symbols"):
                                            st.info("""
                                            **Options automatically excluded from equity portfolio:**

                                            These option positions are excluded from equity analysis:
                                            """)
                                            for opt in option_tickers:
                                                st.write(f"- {opt}")

                                    make_scrollable_table(portfolio_df, height=400, hide_index=True, use_container_width=True, column_config=None)
            
                with col2:
                    st.markdown("### üí∞ Account History")
                    account_file = st.file_uploader("Upload Account History", type=['xls', 'xlsx'], key="account")
                
                    if account_file:
                        with st.spinner("Parsing..."):
                            account_df = parse_account_history_file(account_file)
                        
                            if account_df is not None:
                                save_account_history(account_df)
                                st.success(f"‚úÖ Parsed {len(account_df)} records!")
                                show_toast(f"Account history imported: {len(account_df)} records processed", toast_type="success", duration=3000)
                                make_scrollable_table(account_df.head(10), height=400, hide_index=True, use_container_width=True, column_config=None)
                            
                                leverage_info_parsed = get_leverage_info()
                                if leverage_info_parsed:
                                    st.info(f"""
                                    üí° Leverage Detected:
                                    - Margin: ${leverage_info_parsed['margin_used']:,.2f}
                                    - Leverage: {leverage_info_parsed['leverage_ratio']:.2f}x
                                    """)

            # ===== EASY EQUITIES MODE: Live Portfolio Sync (NEW) =====
            elif portfolio_mode == "üîó Easy Equities (Live Sync)":
                st.subheader("üîó Sync Portfolio from Easy Equities")

                # Info box about security
                st.info(
                    "üîí **Secure Connection:** Your Easy Equities credentials are used once to fetch "
                    "portfolio data and are NOT stored. Data is synced in real-time from your account."
                )

                # Import Easy Equities sync module
                try:
                    from modules.easy_equities_sync import (
                        sync_easy_equities_portfolio,
                        get_account_summary,
                        list_available_accounts
                    )
                    EE_MODULE_AVAILABLE = True
                except ImportError as e:
                    EE_MODULE_AVAILABLE = False
                    st.error(f"‚ùå Easy Equities module not available: {e}")
                    st.info("Please ensure easy-equities-client is installed: `pip install easy-equities-client`")

                if EE_MODULE_AVAILABLE:
                    # Login form
                    with st.form("ee_login_form"):
                        col1, col2 = st.columns(2)

                        with col1:
                            ee_username = st.text_input(
                                "Easy Equities Username",
                                placeholder="Your EE username",
                                key="ee_username_input",
                                help="Your Easy Equities login username"
                            )

                        with col2:
                            ee_password = st.text_input(
                                "Easy Equities Password",
                                type="password",
                                placeholder="Your EE password",
                                key="ee_password_input",
                                help="Your Easy Equities password (not stored)"
                            )

                        # Account selection (optional)
                        show_account_selector = st.checkbox(
                            "Select specific account (optional)",
                            help="If you have multiple EE accounts (ZAR, USD, TFSA, etc.), you can choose which one to sync",
                            key="show_ee_account_selector"
                        )

                        account_index = 5  # Default to Demo ZAR for testing
                        selected_account_name = "First available account"

                        if show_account_selector and ee_username and ee_password:
                            try:
                                with st.spinner("Fetching your accounts..."):
                                    accounts = list_available_accounts(ee_username, ee_password)

                                account_options = [f"{acc['name']} (ID: {acc['id']})" for acc in accounts]
                                selected = st.selectbox(
                                    "Select Account to Sync",
                                    account_options,
                                    key="ee_account_selector"
                                )
                                account_index = account_options.index(selected)
                                selected_account_name = accounts[account_index]['name']

                            except Exception as e:
                                st.warning(f"‚ö†Ô∏è Could not fetch accounts: {str(e)}")
                                st.caption("Using default account selection")

                        # Sync button
                        submit_button = st.form_submit_button(
                            "üîÑ Sync Portfolio from Easy Equities",
                            use_container_width=True,
                            type="primary"
                        )

                    # Process sync when button clicked
                    if submit_button:
                        if not ee_username or not ee_password:
                            st.error("‚ùå Please enter both username and password")
                        else:
                            with st.spinner(f"üîÑ Syncing portfolio from Easy Equities ({selected_account_name})..."):
                                try:
                                    # Sync portfolio data
                                    df = sync_easy_equities_portfolio(
                                        username=ee_username,
                                        password=ee_password,
                                        account_index=account_index
                                    )

                                    # Store in session state (same format as Excel upload)
                                    st.session_state['portfolio_df'] = df
                                    st.session_state['portfolio_source'] = 'easy_equities'

                                    # CRITICAL FIX: Store currency in session_state for persistence
                                    # This ensures currency propagates to all ATLAS modules
                                    st.session_state['currency'] = df.attrs.get('currency', 'ZAR')
                                    st.session_state['currency_symbol'] = df.attrs.get('currency_symbol', 'R')

                                    # ========== AUTO-ENRICHMENT AND SNAPSHOT ==========
                                    # Import enrichment modules and enrich portfolio with Yahoo Finance data
                                    try:
                                        from modules.ee_enrichment import (
                                            enrich_portfolio,
                                            auto_snapshot_on_sync,
                                            get_snapshot_stats
                                        )

                                        # Auto-enrich portfolio with Yahoo Finance data
                                        with st.spinner("Enriching portfolio with Yahoo Finance data..."):
                                            enriched_df, enrichment_data = enrich_portfolio(df, period='1y')

                                            # Store enriched data in session state
                                            st.session_state['enriched_portfolio_df'] = enriched_df
                                            st.session_state['enrichment_data'] = enrichment_data

                                            enriched_count = enrichment_data.get('tickers_enriched', 0)
                                            total_count = enrichment_data.get('tickers_total', 0)

                                            st.success(f"Enriched {enriched_count}/{total_count} positions with Yahoo Finance data")

                                        # Auto-save daily snapshot
                                        snapshot_saved = auto_snapshot_on_sync(df, enriched_df)
                                        if snapshot_saved:
                                            stats = get_snapshot_stats()
                                            st.info(f"Daily snapshot saved ({stats.get('snapshot_count', 1)} days of history)")

                                    except ImportError as e:
                                        st.warning(f"Enrichment modules not available: {e}")
                                    except Exception as e:
                                        st.warning(f"Auto-enrichment skipped: {e}")
                                    # ========== END AUTO-ENRICHMENT ==========

                                    # Also save to portfolio data for persistence
                                    save_portfolio_data(df.to_dict('records'))

                                    # Get account summary for display
                                    summary = get_account_summary(ee_username, ee_password, account_index)

                                    # Success message
                                    st.success(
                                        f"‚úÖ Successfully synced **{len(df)}** positions from "
                                        f"**{summary['account_name']}** (Account: {summary['account_number']})"
                                    )

                                    show_toast(
                                        f"üéâ Easy Equities sync complete: {len(df)} positions imported!",
                                        toast_type="success",
                                        duration=4000
                                    )

                                    # Portfolio preview section
                                    st.markdown("---")
                                    st.subheader("üìä Synced Portfolio Preview")

                                    # Summary metrics in cards
                                    metric_col1, metric_col2, metric_col3, metric_col4 = st.columns(4)

                                    total_market_value = df['Market_Value'].sum()
                                    total_purchase_value = df['Purchase_Value'].sum()
                                    total_pnl = df['Unrealized_PnL'].sum()
                                    pnl_pct = (total_pnl / total_purchase_value * 100) if total_purchase_value > 0 else 0

                                    with metric_col1:
                                        st.metric(
                                            "Total Positions",
                                            f"{len(df)}",
                                            help="Number of holdings in portfolio"
                                        )

                                    with metric_col2:
                                        st.metric(
                                            "Market Value",
                                            f"R{total_market_value:,.2f}",
                                            help="Current total value of all holdings"
                                        )

                                    with metric_col3:
                                        st.metric(
                                            "Total Invested",
                                            f"R{total_purchase_value:,.2f}",
                                            help="Total amount invested (cost basis)"
                                        )

                                    with metric_col4:
                                        st.metric(
                                            "Total P&L",
                                            f"R{total_pnl:,.2f}",
                                            delta=f"{pnl_pct:+.2f}%",
                                            help="Unrealized profit/loss"
                                        )

                                    # Show dataframe preview
                                    st.markdown("##### Holdings Details")
                                    preview_df = df[[
                                        'Ticker', 'Name', 'Shares', 'Cost_Basis',
                                        'Current_Price', 'Market_Value', 'Unrealized_PnL', 'Unrealized_PnL_Pct'
                                    ]].copy()

                                    # Format columns for display
                                    preview_df['Shares'] = preview_df['Shares'].apply(lambda x: f"{x:.4f}")
                                    preview_df['Cost_Basis'] = preview_df['Cost_Basis'].apply(lambda x: f"R{x:.2f}")
                                    preview_df['Current_Price'] = preview_df['Current_Price'].apply(lambda x: f"R{x:.2f}")
                                    preview_df['Market_Value'] = preview_df['Market_Value'].apply(lambda x: f"R{x:,.2f}")
                                    preview_df['Unrealized_PnL'] = preview_df['Unrealized_PnL'].apply(lambda x: f"R{x:,.2f}")
                                    preview_df['Unrealized_PnL_Pct'] = preview_df['Unrealized_PnL_Pct'].apply(lambda x: f"{x:+.2f}%")

                                    make_scrollable_table(
                                        preview_df,
                                        height=400,
                                        hide_index=True,
                                        use_container_width=True,
                                        column_config=None
                                    )

                                    # Sync timestamp
                                    sync_time = df.attrs.get('sync_timestamp', pd.Timestamp.now())
                                    st.caption(f"üìÖ Last synced: {sync_time.strftime('%Y-%m-%d %H:%M:%S')} | Source: Easy Equities API")

                                    st.success("‚úÖ Portfolio data is now available for all ATLAS analysis modules!")

                                except Exception as e:
                                    st.error(f"‚ùå Sync failed: {str(e)}")
                                    st.info(
                                        "**Troubleshooting Steps:**\n\n"
                                        "1. Verify your Easy Equities credentials are correct\n"
                                        "2. Check that your selected account has holdings\n"
                                        "3. Ensure stable internet connection\n"
                                        "4. Try selecting a different account if you have multiple\n"
                                        "5. Check if Easy Equities platform is accessible"
                                    )

                                    # Show debug info in expander
                                    with st.expander("üîç Technical Error Details"):
                                        import traceback
                                        st.code(traceback.format_exc())

            # ===== ALPACA MARKETS MODE: Live Portfolio Sync (NEW) =====
            elif portfolio_mode == "ü¶ô Alpaca Markets (Live Sync)":
                st.markdown("### ü¶ô Alpaca Markets Live Portfolio Sync")
                st.info("Connect to your Alpaca broker account for real-time portfolio synchronization")

                # Import Alpaca integration module
                try:
                    from atlas_alpaca_integration import AlpacaAdapter
                    ALPACA_MODULE_AVAILABLE = True
                except ImportError as e:
                    ALPACA_MODULE_AVAILABLE = False
                    st.error(f"‚ùå Alpaca module not available: {e}")
                    st.info("Please ensure alpaca-py is installed: `pip install alpaca-py`")

                if ALPACA_MODULE_AVAILABLE:
                    # Check for stored credentials in secrets
                    try:
                        api_key = st.secrets.get("alpaca_key", "")
                        secret_key = st.secrets.get("alpaca_secret", "")
                        has_secrets = api_key and secret_key
                    except:
                        has_secrets = False

                    # Connection form
                    with st.form("alpaca_sync_form"):
                        st.markdown("#### üîê API Credentials")

                        col1, col2 = st.columns(2)

                        with col1:
                            if has_secrets:
                                st.info("‚úÖ Using credentials from secrets.toml")
                                api_key_input = api_key
                            else:
                                api_key_input = st.text_input(
                                    "API Key",
                                    type="password",
                                    placeholder="Your Alpaca API key",
                                    help="Get your API credentials from alpaca.markets/paper/dashboard/overview"
                                )

                        with col2:
                            if has_secrets:
                                secret_key_input = secret_key
                            else:
                                secret_key_input = st.text_input(
                                    "Secret Key",
                                    type="password",
                                    placeholder="Your Alpaca secret key",
                                    help="Keep your secret key secure - never share it"
                                )

                        # Paper vs Live trading toggle
                        use_paper = st.checkbox(
                            "üìù Use Paper Trading Account",
                            value=True,
                            help="Paper trading for testing, Live trading for real money"
                        )

                        # Sync button
                        sync_button = st.form_submit_button(
                            "üîÑ Sync Portfolio from Alpaca",
                            use_container_width=True,
                            type="primary"
                        )

                    # Process sync when button clicked
                    if sync_button:
                        # Use form inputs or secrets
                        final_api_key = api_key_input if not has_secrets else api_key
                        final_secret = secret_key_input if not has_secrets else secret_key

                        if not final_api_key or not final_secret:
                            st.error("‚ùå Please enter both API Key and Secret Key")
                        else:
                            account_type_display = "Paper Trading" if use_paper else "Live Trading"
                            with st.spinner(f"üîÑ Connecting to Alpaca {account_type_display} account..."):
                                try:
                                    # Create adapter and test connection
                                    adapter = AlpacaAdapter(final_api_key, final_secret, paper=use_paper)
                                    success, message = adapter.test_connection()

                                    if not success:
                                        st.error(f"‚ùå Connection failed: {message}")
                                    else:
                                        st.success(message)

                                        # Fetch portfolio positions
                                        with st.spinner("üìä Fetching portfolio positions..."):
                                            df = adapter.get_positions()

                                            if df.empty:
                                                st.warning("‚ö†Ô∏è No positions found in your Alpaca account")
                                                st.info("Add some positions in your Alpaca account and try syncing again")
                                            else:
                                                # Store in session state (same format as Easy Equities)
                                                st.session_state['portfolio_df'] = df
                                                st.session_state['portfolio_source'] = 'alpaca'
                                                st.session_state['alpaca_adapter'] = adapter

                                                # Store currency in session_state
                                                st.session_state['currency'] = 'USD'
                                                st.session_state['currency_symbol'] = '$'

                                                # Save to portfolio data for persistence
                                                save_portfolio_data(df.to_dict('records'))

                                                # Get account summary
                                                account = adapter.get_account_summary()

                                                # Success message
                                                st.success(
                                                    f"‚úÖ Successfully synced **{len(df)}** positions from "
                                                    f"**Alpaca {account['account_type']}** account"
                                                )

                                                show_toast(
                                                    f"üéâ Alpaca sync complete: {len(df)} positions imported!",
                                                    toast_type="success",
                                                    duration=4000
                                                )

                                                # Portfolio preview section
                                                st.markdown("---")
                                                st.subheader("üìä Synced Portfolio Preview")

                                                # Account summary metrics
                                                st.markdown("##### Account Summary")
                                                col1, col2, col3, col4 = st.columns(4)

                                                with col1:
                                                    st.metric(
                                                        "Portfolio Value",
                                                        f"${account.get('portfolio_value', 0):,.2f}",
                                                        help="Total equity value"
                                                    )

                                                with col2:
                                                    st.metric(
                                                        "Cash",
                                                        f"${account.get('cash', 0):,.2f}",
                                                        help="Available cash"
                                                    )

                                                with col3:
                                                    total_pnl = df['Unrealized_PnL'].sum()
                                                    total_value = df['Market_Value'].sum()
                                                    total_cost = df['Purchase_Value'].sum()
                                                    pnl_pct = (total_pnl / total_cost * 100) if total_cost > 0 else 0

                                                    st.metric(
                                                        "Total P&L",
                                                        f"${total_pnl:,.2f}",
                                                        delta=f"{pnl_pct:+.2f}%",
                                                        help="Unrealized profit/loss"
                                                    )

                                                with col4:
                                                    st.metric(
                                                        "Positions",
                                                        f"{len(df)}",
                                                        help="Number of holdings"
                                                    )

                                                # Show dataframe preview
                                                st.markdown("##### Holdings Details")
                                                preview_df = df[[
                                                    'Ticker', 'Shares', 'Avg_Cost',
                                                    'Current_Price', 'Market_Value', 'Unrealized_PnL', 'Unrealized_PnL_Pct'
                                                ]].copy()

                                                # Format columns for display
                                                preview_df['Shares'] = preview_df['Shares'].apply(lambda x: f"{x:.4f}")
                                                preview_df['Avg_Cost'] = preview_df['Avg_Cost'].apply(lambda x: f"${x:.2f}")
                                                preview_df['Current_Price'] = preview_df['Current_Price'].apply(lambda x: f"${x:.2f}")
                                                preview_df['Market_Value'] = preview_df['Market_Value'].apply(lambda x: f"${x:,.2f}")
                                                preview_df['Unrealized_PnL'] = preview_df['Unrealized_PnL'].apply(lambda x: f"${x:,.2f}")
                                                preview_df['Unrealized_PnL_Pct'] = preview_df['Unrealized_PnL_Pct'].apply(lambda x: f"{x:+.2f}%")

                                                make_scrollable_table(
                                                    preview_df,
                                                    height=400,
                                                    hide_index=True,
                                                    use_container_width=True,
                                                    column_config=None
                                                )

                                                # Sync timestamp
                                                st.caption(f"üìÖ Last synced: {pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')} | Source: Alpaca Markets API")

                                                st.success("‚úÖ Portfolio data is now available for all ATLAS analysis modules!")

                                except Exception as e:
                                    st.error(f"‚ùå Sync failed: {str(e)}")
                                    st.info(
                                        "**Troubleshooting Steps:**\n\n"
                                        "1. Verify your Alpaca API credentials are correct\n"
                                        "2. Check that you selected the correct account type (Paper vs Live)\n"
                                        "3. Ensure your account has positions\n"
                                        "4. Verify your API keys have proper permissions\n"
                                        "5. Check your internet connection"
                                    )

                                    # Show debug info in expander
                                    with st.expander("üîç Technical Error Details"):
                                        import traceback
                                        st.code(traceback.format_exc())

            # PHASE 4: Database Management Section
            st.markdown("---")
            st.markdown("### üíæ Database Management")

            col1, col2 = st.columns(2)

            with col1:
                st.markdown("#### üìä Database Status")

                if SQL_AVAILABLE:
                    try:
                        db = get_db()

                        # Check if portfolio exists in database
                        portfolio_db = db.get_portfolio()
                        portfolio_count = len(portfolio_db)

                        # Check if trades exist in database
                        trades_db = db.get_trades()
                        trades_count = len(trades_db)

                        st.success("‚úÖ Database Connected")

                        # Transform to premium cards
                        db_col1, db_col2 = st.columns(2)

                        with db_col1:
                            st.markdown(f'<div style="background: linear-gradient(135deg, rgba(139,92,246,0.08), rgba(21,25,50,0.95)); backdrop-filter: blur(24px); border-radius: 24px; border: 1px solid rgba(139,92,246,0.2); padding: 1.75rem 1.5rem; box-shadow: 0 4px 24px rgba(0,0,0,0.2); min-height: 200px; position: relative; overflow: hidden;"><div style="position: absolute; top: 0; left: 0; right: 0; height: 3px; background: linear-gradient(90deg, #8b5cf6, #a855f7); opacity: 0.8;"></div><div style="display: flex; align-items: center; gap: 0.4rem; margin-bottom: 0.875rem;"><span style="font-size: 1rem;">üìä</span><p style="font-size: 0.6rem; color: #94a3b8; text-transform: uppercase; letter-spacing: 0.08em; margin: 0; font-weight: 600;">PORTFOLIO POSITIONS</p></div><h3 style="font-size: 2.5rem; font-weight: 800; color: #a5b4fc; margin: 0.5rem 0 0.75rem 0; line-height: 1;">{portfolio_count}</h3><div style="display: inline-block; padding: 0.4rem 0.75rem; background: rgba(139,92,246,0.12); border-radius: 10px; border: 1px solid rgba(139,92,246,0.25);"><p style="font-size: 0.7rem; color: #d8b4fe; margin: 0; font-weight: 600;">Active Holdings</p></div></div>', unsafe_allow_html=True)

                        with db_col2:
                            st.markdown(f'<div style="background: linear-gradient(135deg, rgba(6,182,212,0.08), rgba(21,25,50,0.95)); backdrop-filter: blur(24px); border-radius: 24px; border: 1px solid rgba(6,182,212,0.2); padding: 1.75rem 1.5rem; box-shadow: 0 4px 24px rgba(0,0,0,0.2); min-height: 200px; position: relative; overflow: hidden;"><div style="position: absolute; top: 0; left: 0; right: 0; height: 3px; background: linear-gradient(90deg, #06b6d4, #3b82f6); opacity: 0.8;"></div><div style="display: flex; align-items: center; gap: 0.4rem; margin-bottom: 0.875rem;"><span style="font-size: 1rem;">üìú</span><p style="font-size: 0.6rem; color: #94a3b8; text-transform: uppercase; letter-spacing: 0.08em; margin: 0; font-weight: 600;">TRADE HISTORY RECORDS</p></div><h3 style="font-size: 2.5rem; font-weight: 800; color: #67e8f9; margin: 0.5rem 0 0.75rem 0; line-height: 1;">{trades_count}</h3><div style="display: inline-block; padding: 0.4rem 0.75rem; background: rgba(6,182,212,0.12); border-radius: 10px; border: 1px solid rgba(6,182,212,0.25);"><p style="font-size: 0.7rem; color: #a5f3fc; margin: 0; font-weight: 600;">Total Transactions</p></div></div>', unsafe_allow_html=True)

                        if portfolio_count > 0:
                            st.info(f"üí° Last updated: {portfolio_db['updated_at'].max() if 'updated_at' in portfolio_db.columns else 'Unknown'}")

                    except Exception as e:
                        st.error(f"‚ùå Database Error: {e}")
                else:
                    st.warning("‚ö†Ô∏è SQL database not available")
                    st.info("Portfolio data is saved to pickle cache only")

            with col2:
                st.markdown("#### üîÑ Manual Database Operations")

                # Manual save button
                if st.button("üíæ Save Current Portfolio to Database", type="primary"):
                    # Load current portfolio
                    portfolio_data = load_portfolio_data()

                    # ===== FIX #1: Robust validation =====
                    has_data = False

                    if portfolio_data is not None:
                        if isinstance(portfolio_data, pd.DataFrame):
                            has_data = not portfolio_data.empty
                        elif isinstance(portfolio_data, list):
                            has_data = len(portfolio_data) > 0

                    if not has_data:
                        st.error("‚ùå No portfolio data to save. Upload data via Phoenix Parser first.")
                    else:
                        # Convert to DataFrame if needed
                        if isinstance(portfolio_data, list):
                            df = pd.DataFrame(portfolio_data)
                        else:
                            df = portfolio_data

                        # DEBUG: Show what we're saving
                        st.info(f"üíæ Attempting to save {len(df)} positions...")

                        try:
                            import sqlite3
                            # datetime already imported globally at top of file

                            # Connect to database
                            conn = sqlite3.connect('atlas_portfolio.db', timeout=10)
                            cursor = conn.cursor()

                            # Create table if it doesn't exist
                            cursor.execute("""
                                CREATE TABLE IF NOT EXISTS portfolio_positions (
                                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                                    ticker TEXT NOT NULL,
                                    quantity REAL NOT NULL,
                                    avg_cost REAL NOT NULL,
                                    current_price REAL,
                                    total_value REAL,
                                    sector TEXT,
                                    last_updated TEXT
                                )
                            """)

                            # Clear existing positions
                            cursor.execute("DELETE FROM portfolio_positions")

                            # Save each position
                            saved_count = 0
                            for idx, row in df.iterrows():
                                try:
                                    # Handle different column name variations
                                    ticker = str(row.get('Ticker', row.get('Symbol', 'UNKNOWN')))
                                    quantity = float(row.get('Quantity', row.get('Shares', 0)))
                                    avg_cost = float(row.get('Avg Cost', row.get('Average Cost', row.get('Avg Price', 0))))
                                    current_price = float(row.get('Current Price', 0))
                                    total_value = float(row.get('Total Value', quantity * current_price if current_price else quantity * avg_cost))
                                    sector = str(row.get('Sector', 'Unknown'))

                                    cursor.execute("""
                                        INSERT INTO portfolio_positions
                                        (ticker, quantity, avg_cost, current_price, total_value, sector, last_updated)
                                        VALUES (?, ?, ?, ?, ?, ?, ?)
                                    """, (
                                        ticker,
                                        quantity,
                                        avg_cost,
                                        current_price,
                                        total_value,
                                        sector,
                                        datetime.now().strftime('%Y-%m-%d %H:%M:%S')
                                    ))
                                    saved_count += 1
                                except Exception as row_error:
                                    st.warning(f"‚ö†Ô∏è Skipped {row.get('Ticker', row.get('Symbol', 'unknown'))}: {row_error}")

                            conn.commit()
                            conn.close()

                            st.success(f"‚úÖ Successfully saved {saved_count} positions to database!")
                            st.balloons()

                        except Exception as e:
                            st.error(f"‚ùå Database save failed: {str(e)}")
                            import traceback
                            st.code(traceback.format_exc())

                # Debug database state button
                if st.button("üîç Debug Database State"):
                    try:
                        import sqlite3
                        conn = sqlite3.connect('atlas_portfolio.db')
                        result = pd.read_sql("SELECT * FROM portfolio_positions", conn)
                        st.write(f"**Database has {len(result)} positions**")
                        if len(result) > 0:
                            make_scrollable_table(result, height=400, hide_index=True, use_container_width=True)
                        else:
                            st.info("No positions found in database")
                        conn.close()
                    except Exception as e:
                        st.error(f"Error reading database: {e}")

                # Clear database button
                if st.button("üóëÔ∏è Clear Database (Keep Pickle Cache)"):
                    if SQL_AVAILABLE:
                        try:
                            db = get_db()
                            db.execute("DELETE FROM holdings")
                            st.success("‚úÖ Database cleared (pickle cache preserved)")
                            show_toast("Database cleared successfully", toast_type="info", duration=2000)
                        except Exception as e:
                            st.error(f"‚ùå Clear failed: {e}")
                    else:
                        st.error("‚ùå SQL database not available")

                st.info("""
                **‚ÑπÔ∏è Auto-Save:**
                Portfolio data is automatically saved to both:
                - üíæ SQL Database (persistent)
                - üì¶ Pickle Cache (backup)

                Use the manual save button to force a database update.
                """)

            # ===== FIX #8: LEVERAGE TRACKING FEATURE =====
            st.markdown("---")
            st.markdown('<h2 style="font-size: 1.5rem; font-weight: 700; color: #f8fafc; margin-bottom: 1.5rem;"><span style="font-size: 1.25rem;">üìä</span> <span style="background: linear-gradient(135deg, #00d4ff, #6366f1, #8b5cf6); -webkit-background-clip: text; -webkit-text-fill-color: transparent;">Leverage Tracking (Optional)</span></h2>', unsafe_allow_html=True)
            st.info("üìà Upload your Investopedia performance-history.xls file to enable leverage analysis")

            perf_history_file = st.file_uploader(
                "üìà Upload Performance History",
                type=['xls', 'xlsx', 'html'],
                help="Upload your Investopedia performance-history.xls file for leverage tracking",
                key="perf_history"
            )

            if perf_history_file is not None:
                try:
                    # Save uploaded file temporarily
                    import tempfile
                    with tempfile.NamedTemporaryFile(delete=False, suffix='.xls') as tmp_file:
                        tmp_file.write(perf_history_file.getvalue())
                        tmp_path = tmp_file.name

                    # Parse leverage data
                    from analytics.leverage_tracker import LeverageTracker

                    tracker = LeverageTracker(tmp_path)

                    if tracker.load_and_parse():
                        # Get current stats
                        stats = tracker.get_current_stats()

                        # Display current leverage
                        st.success("‚úÖ Performance history loaded!")

                        col1, col2, col3, col4 = st.columns(4)

                        # Preview Card 1: Current Leverage
                        with col1:
                            lev_color = '#10b981' if abs(stats['current_leverage'] - 1.7) < 0.3 else '#ef4444'
                            st.markdown(f'<div style="background: linear-gradient(135deg, rgba(99,102,241,0.08), rgba(21,25,50,0.95)); backdrop-filter: blur(24px); border-radius: 24px; border: 1px solid rgba(99,102,241,0.2); padding: 1.75rem 1.5rem; box-shadow: 0 4px 24px rgba(0,0,0,0.2); min-height: 200px; position: relative; overflow: hidden;"><div style="position: absolute; top: 0; left: 0; right: 0; height: 3px; background: linear-gradient(90deg, #6366f1, #8b5cf6); opacity: 0.8;"></div><div style="display: flex; align-items: center; gap: 0.4rem; margin-bottom: 0.875rem;"><span style="font-size: 1rem;">‚ö°</span><p style="font-size: 0.6rem; color: #94a3b8; text-transform: uppercase; letter-spacing: 0.08em; margin: 0; font-weight: 600;">CURRENT LEVERAGE</p></div><h3 style="font-size: 2.5rem; font-weight: 800; color: {lev_color}; margin: 0.5rem 0 0.75rem 0; line-height: 1;">{stats["current_leverage"]:.2f}x</h3><div style="display: inline-block; padding: 0.4rem 0.75rem; background: rgba(99,102,241,0.12); border-radius: 10px; border: 1px solid rgba(99,102,241,0.25);"><p style="font-size: 0.7rem; color: #a5b4fc; margin: 0; font-weight: 600;">Target: 1.7x</p></div></div>', unsafe_allow_html=True)

                        # Preview Card 2: Net Equity
                        with col2:
                            st.markdown(f'<div style="background: linear-gradient(135deg, rgba(16,185,129,0.08), rgba(21,25,50,0.95)); backdrop-filter: blur(24px); border-radius: 24px; border: 1px solid rgba(16,185,129,0.2); padding: 1.75rem 1.5rem; box-shadow: 0 4px 24px rgba(0,0,0,0.2); min-height: 200px; position: relative; overflow: hidden;"><div style="position: absolute; top: 0; left: 0; right: 0; height: 3px; background: linear-gradient(90deg, #10b981, #059669); opacity: 0.8;"></div><div style="display: flex; align-items: center; gap: 0.4rem; margin-bottom: 0.875rem;"><span style="font-size: 1rem;">üí∞</span><p style="font-size: 0.6rem; color: #94a3b8; text-transform: uppercase; letter-spacing: 0.08em; margin: 0; font-weight: 600;">NET EQUITY</p></div><h3 style="font-size: 2.5rem; font-weight: 800; color: #10b981; margin: 0.5rem 0 0.75rem 0; text-shadow: 0 0 24px rgba(16,185,129,0.5); line-height: 1;">${stats["current_equity"]:,.0f}</h3><div style="display: inline-block; padding: 0.4rem 0.75rem; background: rgba(16,185,129,0.12); border-radius: 10px; border: 1px solid rgba(16,185,129,0.25);"><p style="font-size: 0.7rem; color: #6ee7b7; margin: 0; font-weight: 600;">Your Capital</p></div></div>', unsafe_allow_html=True)

                        # Preview Card 3: Gross Exposure
                        with col3:
                            exposure_pct = ((stats['current_gross_exposure'] / stats['current_equity'] - 1) * 100) if stats['current_equity'] > 0 else 0
                            st.markdown(f'<div style="background: linear-gradient(135deg, rgba(6,182,212,0.08), rgba(21,25,50,0.95)); backdrop-filter: blur(24px); border-radius: 24px; border: 1px solid rgba(6,182,212,0.2); padding: 1.75rem 1.5rem; box-shadow: 0 4px 24px rgba(0,0,0,0.2); min-height: 200px; position: relative; overflow: hidden;"><div style="position: absolute; top: 0; left: 0; right: 0; height: 3px; background: linear-gradient(90deg, #06b6d4, #3b82f6); opacity: 0.8;"></div><div style="display: flex; align-items: center; gap: 0.4rem; margin-bottom: 0.875rem;"><span style="font-size: 1rem;">üìä</span><p style="font-size: 0.6rem; color: #94a3b8; text-transform: uppercase; letter-spacing: 0.08em; margin: 0; font-weight: 600;">GROSS EXPOSURE</p></div><h3 style="font-size: 2.5rem; font-weight: 800; color: #67e8f9; margin: 0.5rem 0 0.75rem 0; line-height: 1;">${stats["current_gross_exposure"]:,.0f}</h3><div style="display: inline-block; padding: 0.4rem 0.75rem; background: rgba(6,182,212,0.12); border-radius: 10px; border: 1px solid rgba(6,182,212,0.25);"><p style="font-size: 0.7rem; color: #a5f3fc; margin: 0; font-weight: 600;">+{exposure_pct:.0f}% vs Equity</p></div></div>', unsafe_allow_html=True)

                        # Preview Card 4: Avg Leverage
                        with col4:
                            st.markdown(f'<div style="background: linear-gradient(135deg, rgba(6,182,212,0.08), rgba(21,25,50,0.95)); backdrop-filter: blur(24px); border-radius: 24px; border: 1px solid rgba(6,182,212,0.2); padding: 1.75rem 1.5rem; box-shadow: 0 4px 24px rgba(0,0,0,0.2); min-height: 200px; position: relative; overflow: hidden;"><div style="position: absolute; top: 0; left: 0; right: 0; height: 3px; background: linear-gradient(90deg, #06b6d4, #3b82f6); opacity: 0.8;"></div><div style="display: flex; align-items: center; gap: 0.4rem; margin-bottom: 0.875rem;"><span style="font-size: 1rem;">üìä</span><p style="font-size: 0.6rem; color: #94a3b8; text-transform: uppercase; letter-spacing: 0.08em; margin: 0; font-weight: 600;">AVG LEVERAGE</p></div><h3 style="font-size: 2.5rem; font-weight: 800; color: #67e8f9; margin: 0.5rem 0 0.75rem 0; line-height: 1;">{stats["avg_leverage"]:.2f}x</h3><div style="display: inline-block; padding: 0.4rem 0.75rem; background: rgba(6,182,212,0.12); border-radius: 10px; border: 1px solid rgba(6,182,212,0.25);"><p style="font-size: 0.7rem; color: #a5f3fc; margin: 0; font-weight: 600;">Historical Avg</p></div></div>', unsafe_allow_html=True)

                        # Store in session state for other pages
                        st.session_state.leverage_tracker = tracker

                        # FIX #5: Auto-update equity capital from performance history
                        if 'current_equity' in stats:
                            st.session_state['equity_capital'] = stats['current_equity']
                            st.info(f"üí∞ Equity capital auto-set to ${stats['current_equity']:,.0f} from performance history")

                        # Show dashboard
                        with st.expander("üìä View Leverage Dashboard", expanded=True):
                            fig = tracker.create_leverage_dashboard()
                            st.plotly_chart(fig, use_container_width=True)

                        # Show calculation workings
                        with st.expander("üßÆ Calculation Workings"):
                            workings = tracker.create_workings_display()
                            st.markdown(workings)

                        show_toast("Leverage tracking enabled! Visit the Leverage Tracker page for full analysis", toast_type="success", duration=4000)
                    else:
                        st.error("‚ùå Could not parse performance history file")

                except Exception as e:
                    st.error(f"Error loading performance history: {e}")
                    import traceback
                    st.code(traceback.format_exc())

        # ========================================================================
        # v10.0 ANALYTICS - NEW ADVANCED FEATURES
        # ========================================================================
        elif page == "üöÄ v10.0 Analytics":
            st.markdown("## üöÄ ATLAS v10.0 ADVANCED ANALYTICS")
    
            if not V10_MODULES_AVAILABLE:
                st.error("‚ùå v10.0 modules not available. Please check installation.")
                st.stop()
            st.success("‚úÖ All v10.0 Advanced Modules Loaded")
    
            # Create tabs for different v10.0 features
            tabs = st.tabs([
                "üé≤ Monte Carlo",
                "üìä Risk Metrics",
                "üí∞ DCF Valuation",
                "üî• Phoenix Mode",
                "üìà Attribution",
                "üé® Enhanced Charts"
            ])
    
            # Tab 1: Monte Carlo Simulation
            with tabs[0]:
                st.markdown("### üé≤ Monte Carlo Portfolio Simulation")
    
                portfolio_data = load_portfolio_data()
                if portfolio_data is None or (isinstance(portfolio_data, pd.DataFrame) and portfolio_data.empty):
                    st.warning("‚ö†Ô∏è Upload portfolio data via Phoenix Parser first")
                else:
                    df = pd.DataFrame(portfolio_data)
    
                    # Auto-populate from performance history
                    metrics = get_current_portfolio_metrics()
                    default_value = int(metrics['equity']) if metrics else 100000

                    if metrics:
                        st.success(f"üìä Using current portfolio equity: {format_currency(metrics['equity'])}")

                    col1, col2 = st.columns(2)
                    with col1:
                        n_simulations = st.slider("Number of Simulations", 1000, 20000, 5000, 1000)
                        n_days = st.slider("Time Horizon (days)", 30, 365, 252)
                    with col2:
                        confidence_level = st.slider("Confidence Level", 0.90, 0.99, 0.95, 0.01)
                        initial_value = st.number_input("Portfolio Value ($)", value=default_value, step=10000, help="Auto-populated from performance history" if metrics else "Upload performance history to auto-populate")
    
                    if st.button("üé≤ Run Monte Carlo Simulation", type="primary"):
                        with st.spinner("Running simulations..."):
                            try:
                                # Get historical returns (placeholder - use actual data)
                                tickers = df['Ticker'].tolist() if 'Ticker' in df.columns else []
                                if len(tickers) > 0:
                                    returns = yf.download(tickers, period="1y", progress=False)['Close'].pct_change().dropna()
                                    weights = np.array([1/len(tickers)] * len(tickers))
    
                                    mc = MonteCarloSimulation(returns, weights, initial_value=initial_value)
                                    var_result = mc.calculate_var_cvar(n_simulations=n_simulations, n_days=n_days, confidence_level=confidence_level)
    
                                    # Display results
                                    col1, col2, col3 = st.columns(3)
                                    col1.metric("VaR", f"${var_result['var_dollar']:,.0f}", f"{var_result['var_pct']:.2f}%")
                                    col2.metric("CVaR", f"${var_result['cvar_dollar']:,.0f}", f"{var_result['cvar_pct']:.2f}%")
                                    col3.metric("Simulations", f"{n_simulations:,}")
    
                                    st.success(f"‚úÖ Simulation complete! {n_simulations:,} paths analyzed")
                                else:
                                    st.warning("No tickers found in portfolio")
                            except Exception as e:
                                st.error(f"Error: {str(e)}")
    
            # Tab 2: Advanced Risk Metrics
            with tabs[1]:
                st.markdown("### üìä Advanced Risk Metrics")
    
                portfolio_data = load_portfolio_data()
                if portfolio_data is None or (isinstance(portfolio_data, pd.DataFrame) and portfolio_data.empty):
                    st.warning("‚ö†Ô∏è Upload portfolio data via Phoenix Parser first")
                else:
                    df = pd.DataFrame(portfolio_data)
    
                    if st.button("üìä Calculate Risk Metrics", type="primary"):
                        with st.spinner("Calculating metrics..."):
                            try:
                                tickers = df['Ticker'].tolist() if 'Ticker' in df.columns else []
                                if len(tickers) > 0:
                                    returns_data = yf.download(tickers, period="1y", progress=False)['Close'].pct_change().dropna()
                                    portfolio_returns = returns_data.mean(axis=1)
    
                                    # Benchmark (SPY)
                                    spy = yf.download('SPY', period="1y", progress=False)['Close'].pct_change().dropna()
    
                                    risk = RiskAnalytics(portfolio_returns, spy)
                                    metrics = risk.comprehensive_metrics(risk_free_rate=0.03)
    
                                    # Display metrics
                                    col1, col2, col3, col4 = st.columns(4)
                                    col1.metric("Sharpe Ratio", f"{metrics['sharpe_ratio']:.3f}")
                                    col2.metric("Sortino Ratio", f"{metrics['sortino_ratio']:.3f}")
                                    col3.metric("Beta", f"{metrics['beta']:.3f}")
                                    col4.metric("Alpha", f"{metrics['alpha']:.2f}%")
    
                                    col1, col2, col3 = st.columns(3)
                                    col1.metric("Max Drawdown", f"{metrics['max_drawdown']:.2f}%")
                                    col2.metric("Annual Return", f"{metrics['annual_return']:.2f}%")
                                    col3.metric("Annual Volatility", f"{metrics['annual_volatility']:.2f}%")
    
                                    st.success("‚úÖ Risk metrics calculated successfully")
                                else:
                                    st.warning("No tickers found in portfolio")
                            except Exception as e:
                                st.error(f"Error: {str(e)}")
    
            # Tab 3: DCF Valuation
            with tabs[2]:
                st.markdown("### üí∞ DCF Intrinsic Value Calculator")
    
                ticker = st.text_input("Enter Ticker Symbol", value="AAPL")
    
                col1, col2, col3 = st.columns(3)
                with col1:
                    projection_years = st.slider("Projection Years", 3, 10, 5)
                with col2:
                    growth_rate = st.slider("Growth Rate (%)", 0, 20, 8) / 100
                with col3:
                    terminal_growth = st.slider("Terminal Growth (%)", 0, 5, 3) / 100
    
                if st.button("üí∞ Calculate DCF", type="primary"):
                    with st.spinner(f"Analyzing {ticker}..."):
                        try:
                            dcf = DCFValuation(ticker)
                            result = dcf.calculate_intrinsic_value(
                                projection_years=projection_years,
                                growth_rate=growth_rate,
                                terminal_growth_rate=terminal_growth
                            )
    
                            col1, col2, col3 = st.columns(3)
                            col1.metric("Intrinsic Value", f"${result['intrinsic_value']:.2f}")
                            col2.metric("Current Price", f"${result['current_price']:.2f}")
                            col3.metric("Upside/Downside", f"{result['upside_pct']:.1f}%")
    
                            if result['upside_pct'] > 20:
                                st.success("üü¢ Signal: UNDERVALUED")
                            elif result['upside_pct'] < -20:
                                st.error("üî¥ Signal: OVERVALUED")
                            else:
                                st.info("üü° Signal: FAIRLY VALUED")
    
                            st.metric("WACC", f"{result['wacc']*100:.2f}%")
                        except Exception as e:
                            st.error(f"Error: {str(e)}")
    
            # Tab 4: Phoenix Mode
            with tabs[3]:
                st.markdown("### üî• Phoenix Mode - Portfolio Reconstruction")
    
                st.markdown("Upload a CSV file with trade history:")
                st.code("Required columns: Date, Ticker, Action, Quantity, Price", language="text")
    
                uploaded_file = st.file_uploader("Upload Trade History CSV", type=['csv'])
    
                if uploaded_file:
                    with st.spinner("Reconstructing portfolio..."):
                        try:
                            phoenix = PhoenixMode()
                            trades = phoenix.load_trade_history(uploaded_file)
    
                            st.success(f"‚úÖ Loaded {len(trades)} trades")
                            make_scrollable_table(trades, height=400, hide_index=True, use_container_width=True)
    
                            # Get current prices (you'd fetch these from API)
                            tickers = trades['Ticker'].unique()
                            current_prices = {}
                            for ticker in tickers:
                                try:
                                    price = yf.Ticker(ticker).history(period='1d')['Close'].iloc[-1]
                                    current_prices[ticker] = price
                                except:
                                    current_prices[ticker] = 0
    
                            portfolio = phoenix.reconstruct_portfolio(current_prices)
    
                            col1, col2, col3, col4 = st.columns(4)
                            col1.metric("Positions", portfolio['total_positions'])
                            col2.metric("Total Cost", f"${portfolio['total_cost']:,.2f}")
                            col3.metric("Current Value", f"${portfolio['current_value']:,.2f}")
                            col4.metric("Total P&L", f"${portfolio['total_pnl']:,.2f}", f"{portfolio['total_return_pct']:.2f}%")
    
                            summary = phoenix.get_portfolio_summary(current_prices)
                            make_scrollable_table(summary, height=400, hide_index=True, use_container_width=True)
    
                        except Exception as e:
                            st.error(f"Error: {str(e)}")
    
            # Tab 5: Performance Attribution
            with tabs[4]:
                st.markdown("### üìà Performance Attribution Analysis")
    
                portfolio_data = load_portfolio_data()
                if portfolio_data is None or (isinstance(portfolio_data, pd.DataFrame) and portfolio_data.empty):
                    st.warning("‚ö†Ô∏è Upload portfolio data via Phoenix Parser first")
                else:
                    df = pd.DataFrame(portfolio_data)
    
                    if st.button("üìà Calculate Attribution", type="primary"):
                        with st.spinner("Analyzing..."):
                            try:
                                # Prepare data
                                weights = {}
                                total_value = df['Total Value'].sum() if 'Total Value' in df.columns else 1
    
                                for _, row in df.iterrows():
                                    ticker = row['Ticker']
                                    value = row['Total Value'] if 'Total Value' in df.columns else 1
                                    weights[ticker] = value / total_value
    
                                # ===== FIX #4: Get returns, sectors, and include weights =====
                                asset_data_list = []
                                for ticker in weights.keys():
                                    try:
                                        stock = yf.Ticker(ticker)
                                        hist = stock.history(period='1mo')
                                        ret = (hist['Close'].iloc[-1] / hist['Close'].iloc[0] - 1)
                                        sector = stock.info.get('sector', 'Unknown')
                                        # ‚úÖ Include actual weight in asset data
                                        asset_data_list.append({
                                            'ticker': ticker,
                                            'sector': sector,
                                            'return': ret,
                                            'weight': weights[ticker] * 100  # Convert to percentage
                                        })
                                    except:
                                        pass
    
                                if len(asset_data_list) > 0:
                                    asset_data = pd.DataFrame(asset_data_list)
                                    attribution = PerformanceAttribution(weights, asset_data)
    
                                    st.markdown("#### Stock-Level Contribution")
                                    stock_contrib = attribution.stock_contribution()
                                    make_scrollable_table(stock_contrib, height=400, hide_index=True, use_container_width=True)
    
                                    st.markdown("#### Sector-Level Attribution (Brinson-Fachler Model)")
                                    sector_contrib = attribution.sector_attribution()
                                    make_scrollable_table(sector_contrib, height=400, hide_index=True, use_container_width=True)
    
                                    # ===== FIX #5: Calculate and Display Skill Scores =====
                                    if 'Allocation Effect' in sector_contrib.columns and 'Selection Effect' in sector_contrib.columns:
                                        st.markdown("---")

                                        # Calculate total effects
                                        total_allocation = sector_contrib['Allocation Effect'].sum()
                                        total_selection = sector_contrib['Selection Effect'].sum()
                                        total_interaction = sector_contrib['Interaction Effect'].sum() if 'Interaction Effect' in sector_contrib.columns else 0
                                        total_active_return = total_allocation + total_selection + total_interaction

                                        # Skill scoring: 0-10 scale where 5 = neutral (0% effect)
                                        allocation_score = max(0, min(10, 5 + total_allocation))
                                        selection_score = max(0, min(10, 5 + total_selection))

                                        # Determine colors and status
                                        alloc_color = '#00ff9d' if total_allocation > 0 else '#ff006b'
                                        select_color = '#00ff9d' if total_selection > 0 else '#ff006b'
                                        active_color = '#00ff9d' if total_active_return > 0 else '#ff006b'

                                        alloc_status = '‚úì Strong sector rotation' if total_allocation > 1 else '‚óã Neutral' if total_allocation > -1 else '‚úó Poor allocation'
                                        select_status = '‚úì Strong stock picks' if total_selection > 1 else '‚óã Neutral' if total_selection > -1 else '‚úó Poor selection'

                                        # Determine primary skill
                                        if allocation_score > selection_score + 2:
                                            primary_skill = "Sector Timing (Allocation)"
                                            recommendation = "Focus on sector rotation strategies. Consider using sector ETFs."
                                        elif selection_score > allocation_score + 2:
                                            primary_skill = "Stock Picking (Selection)"
                                            recommendation = "Focus on fundamental analysis. Your stock picks add value."
                                        else:
                                            primary_skill = "Balanced"
                                            recommendation = "Continue current strategy - both skills are comparable."

                                        # Glassmorphism styled skill assessment card
                                        skill_html = f"""
<div style="background: rgba(26, 35, 50, 0.7); backdrop-filter: blur(10px); -webkit-backdrop-filter: blur(10px); border: 1px solid rgba(0, 212, 255, 0.2); border-radius: 12px; padding: 24px; margin: 20px 0; font-family: 'Inter', -apple-system, BlinkMacSystemFont, sans-serif;">
<h3 style="font-family: 'Inter', sans-serif; font-size: 1.2rem; font-weight: 700; color: #00d4ff; text-transform: uppercase; letter-spacing: 0.1em; margin: 0 0 20px 0; text-shadow: 0 0 10px rgba(0, 212, 255, 0.3);">üéØ Portfolio Management Skill Assessment</h3>
<div style="display: grid; grid-template-columns: 1fr 1fr 1fr; gap: 16px;">
<div style="background: rgba(10, 15, 26, 0.6); border: 1px solid rgba(0, 212, 255, 0.15); border-radius: 8px; padding: 16px;">
<div style="font-family: 'Inter', sans-serif; font-size: 0.7rem; font-weight: 600; color: #8890a0; text-transform: uppercase; letter-spacing: 0.1em; margin-bottom: 8px;">ALLOCATION SKILL</div>
<div style="font-family: 'JetBrains Mono', monospace; font-size: 2rem; font-weight: 700; color: {alloc_color}; text-shadow: 0 0 15px {alloc_color}40;">{allocation_score:.1f}/10</div>
<div style="font-family: 'Inter', sans-serif; font-size: 0.85rem; color: #c0c8d0; margin-top: 6px;">Effect: {total_allocation:+.2f}%</div>
<div style="font-family: 'Inter', sans-serif; font-size: 0.7rem; color: {alloc_color}; margin-top: 6px;">{alloc_status}</div>
</div>
<div style="background: rgba(10, 15, 26, 0.6); border: 1px solid rgba(0, 212, 255, 0.15); border-radius: 8px; padding: 16px;">
<div style="font-family: 'Inter', sans-serif; font-size: 0.7rem; font-weight: 600; color: #8890a0; text-transform: uppercase; letter-spacing: 0.1em; margin-bottom: 8px;">SELECTION SKILL</div>
<div style="font-family: 'JetBrains Mono', monospace; font-size: 2rem; font-weight: 700; color: {select_color}; text-shadow: 0 0 15px {select_color}40;">{selection_score:.1f}/10</div>
<div style="font-family: 'Inter', sans-serif; font-size: 0.85rem; color: #c0c8d0; margin-top: 6px;">Effect: {total_selection:+.2f}%</div>
<div style="font-family: 'Inter', sans-serif; font-size: 0.7rem; color: {select_color}; margin-top: 6px;">{select_status}</div>
</div>
<div style="background: rgba(10, 15, 26, 0.6); border: 1px solid rgba(0, 212, 255, 0.15); border-radius: 8px; padding: 16px;">
<div style="font-family: 'Inter', sans-serif; font-size: 0.7rem; font-weight: 600; color: #8890a0; text-transform: uppercase; letter-spacing: 0.1em; margin-bottom: 8px;">TOTAL ACTIVE RETURN</div>
<div style="font-family: 'JetBrains Mono', monospace; font-size: 2rem; font-weight: 700; color: {active_color}; text-shadow: 0 0 15px {active_color}40;">{total_active_return:+.2f}%</div>
<div style="font-family: 'Inter', sans-serif; font-size: 0.85rem; color: #c0c8d0; margin-top: 6px;">Interaction: {total_interaction:+.2f}%</div>
<div style="font-family: 'Inter', sans-serif; font-size: 0.7rem; color: {active_color}; margin-top: 6px;">{'‚úì Outperforming' if total_active_return > 0 else '‚úó Underperforming'}</div>
</div>
</div>
<div style="background: linear-gradient(90deg, rgba(0, 212, 255, 0.1) 0%, transparent 100%); border-left: 3px solid #00d4ff; padding: 12px 16px; margin-top: 20px; border-radius: 4px;">
<div style="font-family: 'Inter', sans-serif; font-size: 0.75rem; font-weight: 700; color: #00d4ff; text-transform: uppercase; letter-spacing: 0.1em; margin-bottom: 4px;">üí° Primary Strength: {primary_skill}</div>
<div style="font-family: 'Inter', sans-serif; font-size: 0.85rem; color: #c0c8d0;">{recommendation}</div>
</div>
</div>
"""
                                        st.markdown(skill_html, unsafe_allow_html=True)
    
                                    st.success("‚úÖ Attribution analysis complete")
                                else:
                                    st.warning("Could not fetch data for analysis")
                            except Exception as e:
                                st.error(f"Error: {str(e)}")
    
            # ===== FIX #9: Enhanced Charts Quality =====
            # Tab 6: Truly Enhanced Charts
            with tabs[5]:
                # ===== FIX #2: Import required modules for this tab =====
                try:
                    import plotly.express as px
                    import plotly.graph_objects as go
                    import numpy as np
                    from scipy import stats
                except ImportError as e:
                    st.error(f"‚ùå Missing dependency: {e}")
                    st.code("pip install plotly scipy numpy")
                    st.stop()
    
                st.markdown("### üé® Enhanced Plotly Visualizations")
                st.markdown("Professional-grade charts with Bloomberg Terminal quality")
    
                portfolio_data = load_portfolio_data()
    
                if portfolio_data is None or (isinstance(portfolio_data, pd.DataFrame) and portfolio_data.empty):
                    st.warning("‚ö†Ô∏è Upload portfolio data via Phoenix Parser first")
                else:
                    df = pd.DataFrame(portfolio_data) if isinstance(portfolio_data, list) else portfolio_data
    
                    # ===== CHART 1: Advanced Portfolio Allocation =====
                    st.markdown("#### üìä Portfolio Allocation")
    
                    weights = {}
                    total_value = df['Total Value'].sum() if 'Total Value' in df.columns else 1
    
                    for _, row in df.iterrows():
                        ticker = row['Ticker']
                        value = row['Total Value'] if 'Total Value' in df.columns else 1
                        weights[ticker] = value / total_value
    
                    # Create sunburst chart (more advanced than donut)
                    allocation_data = []
                    for ticker, weight in weights.items():
                        ticker_data = df[df['Ticker'] == ticker].iloc[0]
                        sector = ticker_data.get('Sector', 'Unknown')
    
                        allocation_data.append({
                            'Ticker': ticker,
                            'Sector': sector,
                            'Weight': weight * 100,
                            'Value': weight * total_value
                        })
    
                    allocation_df = pd.DataFrame(allocation_data)
    
                    fig_allocation = px.sunburst(
                        allocation_df,
                        path=['Sector', 'Ticker'],
                        values='Weight',
                        color='Weight',
                        color_continuous_scale='Viridis',
                        title='Portfolio Allocation by Sector & Ticker'
                    )
    
                    fig_allocation.update_layout(
                        paper_bgcolor='rgba(0,0,0,0)',
                        plot_bgcolor='rgba(10,25,41,0.3)',
                        font=dict(color='white', size=12),
                        height=600
                    )
    
                    st.plotly_chart(fig_allocation, use_container_width=True)
    
                    # ===== CHART 2: Returns Distribution with Statistics =====
                    st.markdown("#### üìà Returns Distribution Analysis")
    
                    tickers = df['Ticker'].tolist() if 'Ticker' in df.columns else []
    
                    if len(tickers) > 0:
                        try:
                            # Fetch 1 year of data
                            hist_data = yf.download(tickers, period="1y", progress=False)['Close']
    
                            if isinstance(hist_data, pd.Series):
                                hist_data = hist_data.to_frame()
    
                            # Calculate daily returns
                            returns = hist_data.pct_change().dropna()
    
                            # Calculate portfolio returns (weighted average)
                            portfolio_returns = pd.Series(0, index=returns.index)
                            for ticker, weight in weights.items():
                                if ticker in returns.columns:
                                    portfolio_returns += returns[ticker] * weight
    
                            # Create distribution plot with annotations
                            from scipy import stats
    
                            fig_dist = go.Figure()
    
                            # Histogram
                            fig_dist.add_trace(go.Histogram(
                                x=portfolio_returns * 100,
                                name='Daily Returns',
                                nbinsx=50,
                                marker_color='rgba(0, 212, 255, 0.6)',
                                showlegend=False
                            ))
    
                            # Add normal distribution overlay
                            mu = portfolio_returns.mean() * 100
                            sigma = portfolio_returns.std() * 100
                            x_range = np.linspace(portfolio_returns.min() * 100,
                                                portfolio_returns.max() * 100, 100)
                            y_range = stats.norm.pdf(x_range, mu, sigma) * len(portfolio_returns) * \
                                    (portfolio_returns.max() - portfolio_returns.min()) * 100 / 50
    
                            fig_dist.add_trace(go.Scatter(
                                x=x_range,
                                y=y_range,
                                mode='lines',
                                name='Normal Distribution',
                                line=dict(color='#00ff9d', width=2, dash='dash')
                            ))
    
                            # Add statistics annotations
                            fig_dist.add_annotation(
                                x=0.02, y=0.98,
                                xref='paper', yref='paper',
                                text=f'<b>Statistics</b><br>Mean: {mu:.3f}%<br>Std Dev: {sigma:.3f}%<br>' + \
                                    f'Skew: {portfolio_returns.skew():.3f}<br>Kurtosis: {portfolio_returns.kurtosis():.3f}',
                                showarrow=False,
                                align='left',
                                bgcolor='rgba(10,25,41,0.8)',
                                bordercolor='#00d4ff',
                                borderwidth=1,
                                font=dict(color='white', size=11)
                            )
    
                            fig_dist.update_layout(
                                title='Portfolio Returns Distribution (1 Year)',
                                xaxis_title='Daily Return (%)',
                                yaxis_title='Frequency',
                                paper_bgcolor='rgba(0,0,0,0)',
                                plot_bgcolor='rgba(10,25,41,0.3)',
                                font=dict(color='white'),
                                height=500
                            )
    
                            st.plotly_chart(fig_dist, use_container_width=True)
    
                            # ===== CHART 3: Correlation Network Graph =====
                            st.markdown("#### üîó Correlation Network")
    
                            if len(tickers) > 1:
                                corr_matrix = returns.corr()
    
                                # Create network graph
                                fig_network = go.Figure()
    
                                # Add nodes
                                for i, ticker in enumerate(tickers):
                                    fig_network.add_trace(go.Scatter(
                                        x=[i],
                                        y=[0],
                                        mode='markers+text',
                                        marker=dict(size=30, color='#00d4ff'),
                                        text=[ticker],
                                        textposition='top center',
                                        name=ticker,
                                        showlegend=False
                                    ))
    
                                # Add edges for strong correlations (>0.5)
                                for i, ticker1 in enumerate(tickers):
                                    for j, ticker2 in enumerate(tickers):
                                        if i < j and ticker1 in corr_matrix.columns and ticker2 in corr_matrix.columns:
                                            if abs(corr_matrix.loc[ticker1, ticker2]) > 0.5:
                                                corr_val = corr_matrix.loc[ticker1, ticker2]
                                                color = '#00ff9d' if corr_val > 0 else '#ff0055'
    
                                                fig_network.add_trace(go.Scatter(
                                                    x=[i, j],
                                                    y=[0, 0],
                                                    mode='lines',
                                                    line=dict(
                                                        color=color,
                                                        width=abs(corr_val) * 3
                                                    ),
                                                    showlegend=False,
                                                    hovertext=f'{ticker1}-{ticker2}: {corr_val:.2f}'
                                                ))
    
                                fig_network.update_layout(
                                    title='Asset Correlation Network (|r| > 0.5)',
                                    xaxis=dict(visible=False),
                                    yaxis=dict(visible=False),
                                    paper_bgcolor='rgba(0,0,0,0)',
                                    plot_bgcolor='rgba(10,25,41,0.3)',
                                    height=400
                                )
    
                                st.plotly_chart(fig_network, use_container_width=True)
    
                            # ===== CHART 4: Rolling Metrics =====
                            st.markdown("#### üìâ Rolling Sharpe Ratio (90-Day)")
    
                            rolling_sharpe = (portfolio_returns.rolling(90).mean() /
                                            portfolio_returns.rolling(90).std() * np.sqrt(252))
    
                            fig_sharpe = go.Figure()
    
                            fig_sharpe.add_trace(go.Scatter(
                                x=rolling_sharpe.index,
                                y=rolling_sharpe,
                                mode='lines',
                                fill='tozeroy',
                                line=dict(color='#00d4ff', width=2),
                                fillcolor='rgba(0, 212, 255, 0.2)',
                                name='Rolling Sharpe'
                            ))
    
                            # Add reference line at Sharpe = 1
                            fig_sharpe.add_hline(
                                y=1,
                                line_dash="dash",
                                line_color="#00ff9d",
                                annotation_text="Sharpe = 1 (Good)"
                            )
    
                            fig_sharpe.update_layout(
                                title='Rolling 90-Day Sharpe Ratio',
                                xaxis_title='Date',
                                yaxis_title='Sharpe Ratio',
                                paper_bgcolor='rgba(0,0,0,0)',
                                plot_bgcolor='rgba(10,25,41,0.3)',
                                font=dict(color='white'),
                                height=400
                            )
    
                            st.plotly_chart(fig_sharpe, use_container_width=True)
    
                            st.success("‚úÖ All enhanced charts generated successfully")
    
                        except Exception as e:
                            st.error(f"Error generating charts: {str(e)}")
                            import traceback
                            st.code(traceback.format_exc())
    
        # ========================================================================
        # R ANALYTICS - ADVANCED QUANT MODELS (v11.0)
        # ========================================================================
        elif page == "üìä R Analytics":
            st.markdown("## üìä R ANALYTICS - ADVANCED QUANTITATIVE MODELS")
    
            if not R_AVAILABLE:
                st.error("‚ùå R Analytics Requires Manual Setup")
    
                st.markdown("""
                ### üìã R Analytics Setup Instructions
    
                R analytics requires packages that cannot be installed from within the app.
                You must install these dependencies **before** running the application.
    
                ---
    
                #### üîß For Google Colab Users:
    
                1. Create a new code cell **ABOVE** your Streamlit app cell
                2. Run this code:
    
                ```python
                # Install R and packages (takes 3-5 minutes)
                !apt-get update -qq
                !apt-get install -y r-base r-base-dev
                !R -e "install.packages(c('rugarch', 'copula', 'xts'), repos='https://cloud.r-project.org')"
                !pip install rpy2
                ```
    
                3. Wait for installation to complete
                4. Restart your Streamlit app
                5. R Analytics will then be available
    
                ---
    
                #### üíª For Local Deployment (Linux/MacOS):
    
                ```bash
                # Install R
                sudo apt-get update
                sudo apt-get install -y r-base r-base-dev
    
                # Install R packages
                R -e "install.packages(c('rugarch', 'copula', 'xts'), repos='https://cloud.r-project.org')"
    
                # Install Python bridge
                pip install rpy2
                ```
    
                ---
    
                #### ü™ü For Windows:
    
                1. Download and install R from: https://cran.r-project.org/bin/windows/base/
                2. Open R console and run:
                   ```r
                   install.packages(c('rugarch', 'copula', 'xts'))
                   ```
                3. Install rpy2:
                   ```bash
                   pip install rpy2
                   ```
    
                ---
                """)
    
                # Add status check
                st.markdown("### üîç Package Status Check")
    
                col1, col2, col3 = st.columns(3)
    
                with col1:
                    try:
                        import rpy2
                        st.success("‚úÖ rpy2 installed")
                    except ImportError:
                        st.error("‚ùå rpy2 missing")
                        st.caption("Run: `pip install rpy2`")
    
                with col2:
                    try:
                        from rpy2.robjects.packages import importr
                        importr('rugarch')
                        st.success("‚úÖ rugarch available")
                    except:
                        st.error("‚ùå rugarch missing")
                        st.caption("Install in R")
    
                with col3:
                    try:
                        from rpy2.robjects.packages import importr
                        importr('copula')
                        st.success("‚úÖ copula available")
                    except:
                        st.error("‚ùå copula missing")
                        st.caption("Install in R")
    
                return
    
            # Initialize R analytics
            try:
                r = get_r()
                st.success("‚úÖ R Analytics Engine Ready")
            except Exception as e:
                st.error(f"Error initializing R: {str(e)}")
                return
    
            # Create tabs
            tabs = st.tabs(["üìà GARCH Volatility", "üîó Copula Analysis", "üé≤ Custom R Code"])
    
            # Tab 1: GARCH Volatility Modeling
            with tabs[0]:
                st.markdown("### üìà GARCH Volatility Forecasting")
                st.markdown("Fit GARCH models to estimate conditional volatility and forecast future volatility")
    
                portfolio_data = load_portfolio_data()
                if portfolio_data is None or (isinstance(portfolio_data, pd.DataFrame) and portfolio_data.empty):
                    st.warning("‚ö†Ô∏è Upload portfolio data via Phoenix Parser first")
                else:
                    df = pd.DataFrame(portfolio_data)
    
                    # Ticker selection
                    ticker = st.selectbox("Select Ticker", df['Ticker'].tolist() if 'Ticker' in df.columns else [])
    
                    col1, col2 = st.columns(2)
                    with col1:
                        model_type = st.selectbox("GARCH Model", ["sGARCH", "eGARCH", "gjrGARCH"])
                    with col2:
                        forecast_days = st.number_input("Forecast Horizon (days)", 1, 30, 10)
    
                    if st.button("üéØ Fit GARCH Model", type="primary"):
                        with st.spinner(f"Fitting {model_type} model to {ticker}..."):
                            try:
                                # Get historical data
                                stock_data = yf.download(ticker, period="1y", progress=False)
                                returns = stock_data['Close'].pct_change().dropna()
    
                                # Fit GARCH model using R
                                result = r.garch_volatility(returns, model=model_type)
    
                                # Display metrics
                                col1, col2, col3 = st.columns(3)
                                col1.metric("Current Volatility", f"{result['last_volatility']*100:.2f}%")
                                col2.metric("Mean Volatility", f"{result['mean_volatility']*100:.2f}%")
                                col3.metric("Model Type", result['model'])
    
                                # Plot volatility
                                import plotly.graph_objects as go
                                fig = go.Figure()
                                fig.add_trace(go.Scatter(
                                    y=result['volatility'] * 100,
                                    mode='lines',
                                    name=f'{model_type} Volatility',
                                    line=dict(color='#00d4ff', width=2)
                                ))
                                fig.update_layout(
                                    title=f"{ticker} - Conditional Volatility ({model_type})",
                                    xaxis_title="Time",
                                    yaxis_title="Volatility (%)",
                                    height=400,
                                    template='plotly_dark',
                                    paper_bgcolor='rgba(0,0,0,0)',
                                    plot_bgcolor='rgba(10,25,41,0.3)'
                                )
                                st.plotly_chart(fig, use_container_width=True)
    
                                st.success(f"‚úÖ {model_type} model fitted successfully to {ticker}")
    
                            except Exception as e:
                                st.error(f"Error: {str(e)}")
                                st.info("Make sure rugarch package is installed in R: install.packages('rugarch')")
    
            # Tab 2: Copula Dependency Analysis
            with tabs[1]:
                st.markdown("### üîó Copula Dependency Analysis")
                st.markdown("Model the dependency structure between assets using copula functions")
    
                portfolio_data = load_portfolio_data()
                if portfolio_data is None or (isinstance(portfolio_data, pd.DataFrame) and portfolio_data.empty):
                    st.warning("‚ö†Ô∏è Upload portfolio data via Phoenix Parser first")
                else:
                    df = pd.DataFrame(portfolio_data)
    
                    # Multi-select tickers
                    all_tickers = df['Ticker'].tolist() if 'Ticker' in df.columns else []
                    selected_tickers = st.multiselect(
                        "Select Assets (min 2)",
                        all_tickers,
                        default=all_tickers[:min(3, len(all_tickers))]
                    )
    
                    copula_type = st.selectbox("Copula Type", ["t", "normal", "clayton", "gumbel"])
    
                    if len(selected_tickers) >= 2:
                        if st.button("üîó Fit Copula", type="primary"):
                            with st.spinner(f"Fitting {copula_type} copula..."):
                                try:
                                    # Get returns data
                                    returns_data = yf.download(selected_tickers, period="1y", progress=False)['Close'].pct_change().dropna()
    
                                    # Fit copula
                                    result = r.copula_dependency(returns_data, copula_type=copula_type)
    
                                    st.success(f"‚úÖ {copula_type.upper()} Copula fitted successfully")
    
                                    col1, col2 = st.columns(2)
                                    col1.metric("Copula Type", result['copula_type'].upper())
                                    col2.metric("Number of Assets", result['n_assets'])
    
                                    st.markdown("#### Copula Parameters")
                                    st.write(result['parameters'])
    
                                    # Correlation heatmap
                                    corr_matrix = returns_data.corr()
                                    import plotly.express as px
                                    fig = px.imshow(
                                        corr_matrix,
                                        labels=dict(color="Correlation"),
                                        x=corr_matrix.columns,
                                        y=corr_matrix.columns,
                                        color_continuous_scale='Spectral_r',
                                        zmin=-1, zmax=1
                                    )
                                    fig.update_layout(
                                        title="Asset Correlation Matrix",
                                        height=500,
                                        template='plotly_dark',
                                        paper_bgcolor='rgba(0,0,0,0)',
                                        plot_bgcolor='rgba(10,25,41,0.3)'
                                    )
                                    st.plotly_chart(fig, use_container_width=True)
    
                                except Exception as e:
                                    st.error(f"Error: {str(e)}")
                                    st.info("Make sure copula package is installed in R: install.packages('copula')")
                    else:
                        st.info("Please select at least 2 assets for copula analysis")
    
            # Tab 3: Custom R Code Execution
            with tabs[2]:
                st.markdown("### üé≤ Custom R Code Executor")
                st.markdown("Run custom R analytics with your portfolio data")
    
                st.markdown("**Portfolio data available as `df` variable in R**")
    
                r_code = st.text_area(
                    "R Code",
                    value="""# Example: Calculate correlation matrix
    cor(df)
    
    # Example: Summary statistics
    summary(df)""",
                    height=200
                )
    
                if st.button("‚ñ∂Ô∏è Run R Code", type="primary"):
                    portfolio_data = load_portfolio_data()
    
                    if portfolio_data is None or (isinstance(portfolio_data, pd.DataFrame) and portfolio_data.empty):
                        st.warning("‚ö†Ô∏è No portfolio data available")
                    else:
                        with st.spinner("Executing R code..."):
                            try:
                                df = pd.DataFrame(portfolio_data)
    
                                # Get returns for analysis
                                tickers = df['Ticker'].tolist() if 'Ticker' in df.columns else []
                                if len(tickers) > 0:
                                    returns_data = yf.download(tickers, period="1y", progress=False)['Close'].pct_change().dropna()
    
                                    # Execute custom R code
                                    result = r.run_custom_analysis(r_code, data=returns_data)
    
                                    st.success("‚úÖ R code executed successfully")
    
                                    st.markdown("#### Results:")
                                    st.write(result)
                                else:
                                    st.warning("No tickers found in portfolio")
    
                            except Exception as e:
                                st.error(f"Error executing R code: {str(e)}")
                                st.code(str(e))
    
        # ========================================================================
        # DATABASE PAGE - PROFESSIONAL SQL INTERFACE
        # ========================================================================
        elif page == "üíæ Database":
            st.markdown("## üíæ DATABASE MANAGEMENT")
    
            if not SQL_AVAILABLE:
                st.error("‚ùå SQL database not available")
                st.info("""
                **To enable database features:**
                1. Install SQLAlchemy: `pip install sqlalchemy`
                2. Database will be automatically created at: `data/atlas.db`
                3. Restart the application
                """)
                return
    
            try:
                db = get_db()
                st.success("‚úÖ Database Connected")
            except Exception as e:
                st.error(f"Error connecting to database: {str(e)}")
                return
    
            # Create 4 tabs as per Phase 5 specs
            tabs = st.tabs(["üìä Quick Stats", "üîç Custom Query", "üíæ Saved Queries", "‚ÑπÔ∏è Database Info"])
    
            # ====================================================================
            # TAB 1: QUICK STATS
            # ====================================================================
            with tabs[0]:
                st.markdown("### üìä Quick Stats & Overview")
    
                # Database metrics
                col1, col2, col3, col4 = st.columns(4)
    
                try:
                    # CRITICAL FIX: Query database directly, not pickle cache
                    portfolio_count = len(db.get_portfolio())
    
                    # Query trades table directly from database
                    try:
                        trades_result = db.read("SELECT COUNT(*) as count FROM trades")
                        trades_count = trades_result.iloc[0]['count'] if len(trades_result) > 0 else 0
                    except:
                        trades_count = 0
    
                    # Calculate additional metrics
                    if portfolio_count > 0:
                        portfolio_df = db.get_portfolio()
                        total_value = (portfolio_df['quantity'] * portfolio_df['current_price'].fillna(portfolio_df['avg_cost'])).sum()
                        total_cost = (portfolio_df['quantity'] * portfolio_df['avg_cost']).sum()
                    else:
                        total_value = 0
                        total_cost = 0
    
                    with col1:
                        st.markdown(f'<div style="background: linear-gradient(135deg, rgba(139,92,246,0.08), rgba(21,25,50,0.95)); backdrop-filter: blur(24px); border-radius: 24px; border: 1px solid rgba(139,92,246,0.2); padding: 1.75rem 1.5rem; box-shadow: 0 4px 24px rgba(0,0,0,0.2); min-height: 200px; position: relative; overflow: hidden;"><div style="position: absolute; top: 0; left: 0; right: 0; height: 3px; background: linear-gradient(90deg, #8b5cf6, #a855f7); opacity: 0.8;"></div><div style="display: flex; align-items: center; gap: 0.4rem; margin-bottom: 0.875rem;"><span style="font-size: 1rem;">üìä</span><p style="font-size: 0.6rem; color: #94a3b8; text-transform: uppercase; letter-spacing: 0.08em; margin: 0; font-weight: 600;">PORTFOLIO POSITIONS</p></div><h3 style="font-size: 2.5rem; font-weight: 800; color: #a5b4fc; margin: 0.5rem 0 0.75rem 0; line-height: 1;">{portfolio_count}</h3><div style="display: inline-block; padding: 0.4rem 0.75rem; background: rgba(139,92,246,0.12); border-radius: 10px; border: 1px solid rgba(139,92,246,0.25);"><p style="font-size: 0.7rem; color: #d8b4fe; margin: 0; font-weight: 600;">Active Holdings</p></div></div>', unsafe_allow_html=True)

                    with col2:
                        st.markdown(f'<div style="background: linear-gradient(135deg, rgba(6,182,212,0.08), rgba(21,25,50,0.95)); backdrop-filter: blur(24px); border-radius: 24px; border: 1px solid rgba(6,182,212,0.2); padding: 1.75rem 1.5rem; box-shadow: 0 4px 24px rgba(0,0,0,0.2); min-height: 200px; position: relative; overflow: hidden;"><div style="position: absolute; top: 0; left: 0; right: 0; height: 3px; background: linear-gradient(90deg, #06b6d4, #3b82f6); opacity: 0.8;"></div><div style="display: flex; align-items: center; gap: 0.4rem; margin-bottom: 0.875rem;"><span style="font-size: 1rem;">üìú</span><p style="font-size: 0.6rem; color: #94a3b8; text-transform: uppercase; letter-spacing: 0.08em; margin: 0; font-weight: 600;">TRADE RECORDS</p></div><h3 style="font-size: 2.5rem; font-weight: 800; color: #67e8f9; margin: 0.5rem 0 0.75rem 0; line-height: 1;">{trades_count}</h3><div style="display: inline-block; padding: 0.4rem 0.75rem; background: rgba(6,182,212,0.12); border-radius: 10px; border: 1px solid rgba(6,182,212,0.25);"><p style="font-size: 0.7rem; color: #a5f3fc; margin: 0; font-weight: 600;">Total Transactions</p></div></div>', unsafe_allow_html=True)

                    with col3:
                        st.markdown(f'<div style="background: linear-gradient(135deg, rgba(16,185,129,0.08), rgba(21,25,50,0.95)); backdrop-filter: blur(24px); border-radius: 24px; border: 1px solid rgba(16,185,129,0.2); padding: 1.75rem 1.5rem; box-shadow: 0 4px 24px rgba(0,0,0,0.2); min-height: 200px; position: relative; overflow: hidden;"><div style="position: absolute; top: 0; left: 0; right: 0; height: 3px; background: linear-gradient(90deg, #10b981, #059669); opacity: 0.8;"></div><div style="display: flex; align-items: center; gap: 0.4rem; margin-bottom: 0.875rem;"><span style="font-size: 1rem;">üí∞</span><p style="font-size: 0.6rem; color: #94a3b8; text-transform: uppercase; letter-spacing: 0.08em; margin: 0; font-weight: 600;">TOTAL VALUE</p></div><h3 style="font-size: 2.5rem; font-weight: 800; color: #10b981; margin: 0.5rem 0 0.75rem 0; text-shadow: 0 0 24px rgba(16,185,129,0.5); line-height: 1;">${total_value:,.0f}</h3><div style="display: inline-block; padding: 0.4rem 0.75rem; background: rgba(16,185,129,0.12); border-radius: 10px; border: 1px solid rgba(16,185,129,0.25);"><p style="font-size: 0.7rem; color: #6ee7b7; margin: 0; font-weight: 600;">Portfolio Value</p></div></div>', unsafe_allow_html=True)

                    with col4:
                        pl = total_value - total_cost
                        pl_pct = (pl / total_cost * 100) if total_cost > 0 else 0
                        pl_color = '#10b981' if pl > 0 else '#ef4444'
                        pl_glow = '0 0 24px rgba(16,185,129,0.5)' if pl > 0 else '0 0 24px rgba(239,68,68,0.5)'
                        pl_status = f'{pl_pct:+.2f}%'
                        st.markdown(f'<div style="background: linear-gradient(135deg, rgba(245,158,11,0.08), rgba(21,25,50,0.95)); backdrop-filter: blur(24px); border-radius: 24px; border: 1px solid rgba(245,158,11,0.2); padding: 1.75rem 1.5rem; box-shadow: 0 4px 24px rgba(0,0,0,0.2); min-height: 200px; position: relative; overflow: hidden;"><div style="position: absolute; top: 0; left: 0; right: 0; height: 3px; background: linear-gradient(90deg, #f59e0b, #d97706); opacity: 0.8;"></div><div style="display: flex; align-items: center; gap: 0.4rem; margin-bottom: 0.875rem;"><span style="font-size: 1rem;">üìä</span><p style="font-size: 0.6rem; color: #94a3b8; text-transform: uppercase; letter-spacing: 0.08em; margin: 0; font-weight: 600;">TOTAL P&L</p></div><h3 style="font-size: 2.5rem; font-weight: 800; color: {pl_color}; margin: 0.5rem 0 0.75rem 0; text-shadow: {pl_glow}; line-height: 1;">${pl:,.0f}</h3><div style="display: inline-block; padding: 0.4rem 0.75rem; background: rgba(245,158,11,0.12); border-radius: 10px; border: 1px solid rgba(245,158,11,0.25);"><p style="font-size: 0.7rem; color: #fcd34d; margin: 0; font-weight: 600;">{pl_status}</p></div></div>', unsafe_allow_html=True)
    
                except Exception as e:
                    st.error(f"Error calculating stats: {e}")
    
                st.markdown("---")
    
                # Recent activity
                st.markdown("#### üìà Recent Activity")
    
                col1, col2 = st.columns(2)
    
                with col1:
                    st.markdown("##### Current Portfolio Holdings")
                    try:
                        portfolio = db.get_portfolio()
                        if len(portfolio) > 0:
                            display_df = portfolio[['ticker', 'quantity', 'avg_cost', 'current_price']].copy()
                            display_df['value'] = display_df['quantity'] * display_df['current_price'].fillna(display_df['avg_cost'])
                            display_df = display_df.sort_values('value', ascending=False)
                            make_scrollable_table(display_df, height=400, hide_index=True, use_container_width=True)
                        else:
                            st.info("No positions in database")
                    except Exception as e:
                        st.error(f"Error: {e}")
    
                with col2:
                    st.markdown("##### Recent Trades")
                    try:
                        # CRITICAL FIX: Query database directly, not pickle
                        trades = db.read("SELECT * FROM trades ORDER BY date DESC LIMIT 10")
                        if len(trades) > 0:
                            display_trades = trades[['date', 'ticker', 'action', 'quantity', 'price']]
                            make_scrollable_table(display_trades, height=400, hide_index=True, use_container_width=True)
                            st.caption(f"üíæ Showing {len(trades)} most recent trades from database")
                        else:
                            st.info("No trades in database yet. Upload trade history in Phoenix Parser.")
                    except Exception as e:
                        st.error(f"Error querying database: {e}")
    
                st.markdown("---")
    
                # Performance summary
                st.markdown("#### üéØ Performance Summary")
    
                try:
                    portfolio = db.get_portfolio()
                    if len(portfolio) > 0:
                        # Calculate metrics
                        portfolio['position_value'] = portfolio['quantity'] * portfolio['current_price'].fillna(portfolio['avg_cost'])
                        portfolio['cost_basis'] = portfolio['quantity'] * portfolio['avg_cost']
                        portfolio['unrealized_pl'] = portfolio['position_value'] - portfolio['cost_basis']
                        portfolio['pl_pct'] = (portfolio['unrealized_pl'] / portfolio['cost_basis'] * 100).round(2)
    
                        # Sort by P&L percentage
                        portfolio_sorted = portfolio.sort_values('pl_pct', ascending=False)
    
                        # Top performers
                        col1, col2 = st.columns(2)
    
                        with col1:
                            st.markdown("##### üü¢ Top Performers")
                            top_performers = portfolio_sorted.head(3)
                            for _, row in top_performers.iterrows():
                                st.metric(
                                    row['ticker'],
                                    f"${row['position_value']:,.2f}",
                                    f"{row['pl_pct']:+.2f}%"
                                )
    
                        with col2:
                            st.markdown("##### üî¥ Bottom Performers")
                            bottom_performers = portfolio_sorted.tail(3)
                            for _, row in bottom_performers.iterrows():
                                st.metric(
                                    row['ticker'],
                                    f"${row['position_value']:,.2f}",
                                    f"{row['pl_pct']:+.2f}%"
                                )
                    else:
                        st.info("No portfolio data available for performance analysis")
    
                except Exception as e:
                    st.error(f"Error calculating performance: {e}")
    
            # ====================================================================
            # TAB 2: CUSTOM QUERY
            # ====================================================================
            with tabs[1]:
                st.markdown("### üîç Custom SQL Query")
                st.markdown("Execute custom SQL queries against the ATLAS database")
    
                # Query templates
                st.markdown("#### üìù Query Templates")
    
                col1, col2, col3 = st.columns(3)
    
                with col1:
                    if st.button("üìä All Holdings", use_container_width=True):
                        st.session_state['sql_query'] = "SELECT * FROM holdings ORDER BY ticker"
    
                with col2:
                    if st.button("üìà All Trades", use_container_width=True):
                        st.session_state['sql_query'] = "SELECT * FROM trades ORDER BY date DESC LIMIT 20"
    
                with col3:
                    if st.button("üí∞ Portfolio Value", use_container_width=True):
                        st.session_state['sql_query'] = """SELECT
        ticker,
        quantity,
        avg_cost,
        current_price,
        (quantity * COALESCE(current_price, avg_cost)) as position_value,
        (quantity * avg_cost) as cost_basis,
        ((quantity * COALESCE(current_price, avg_cost)) - (quantity * avg_cost)) as unrealized_pl
    FROM holdings
    ORDER BY position_value DESC"""
    
                st.markdown("---")
    
                # SQL editor
                default_query = st.session_state.get('sql_query', "SELECT * FROM holdings LIMIT 10")
    
                sql_query = st.text_area(
                    "SQL Query",
                    value=default_query,
                    height=200,
                    help="Write your SQL query here. Tables: holdings, trades, prices, analytics_cache"
                )
    
                col1, col2 = st.columns([1, 4])
    
                with col1:
                    execute_button = st.button("‚ñ∂Ô∏è Execute Query", type="primary", use_container_width=True)
    
                with col2:
                    st.info("**Available tables:** holdings, trades, prices, analytics_cache")
    
                if execute_button:
                    with st.spinner("Executing query..."):
                        try:
                            result_df = db.read(sql_query)
    
                            st.success(f"‚úÖ Query executed successfully - {len(result_df)} rows returned")
    
                            # Display results
                            st.markdown("#### Results:")
                            make_scrollable_table(result_df, height=600, hide_index=True, use_container_width=True)
    
                            # Export option
                            csv = result_df.to_csv(index=False).encode('utf-8')
                            st.download_button(
                                label="üì• Download as CSV",
                                data=csv,
                                file_name=f"query_results_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
                                mime="text/csv"
                            )
    
                        except Exception as e:
                            st.error(f"‚ùå Query failed: {str(e)}")
                            st.code(str(e))
    
                st.markdown("---")
    
                # Quick reference
                with st.expander("üìö SQL Quick Reference"):
                    st.markdown("""
                    **Common SQL Commands:**
                    - `SELECT * FROM table_name` - Get all records
                    - `WHERE column = value` - Filter results
                    - `ORDER BY column DESC` - Sort results
                    - `LIMIT 10` - Limit number of results
                    - `COUNT(*)` - Count rows
                    - `SUM(column)` - Sum values
                    - `AVG(column)` - Average values
                    - `GROUP BY column` - Group results
    
                    **Examples:**
                    ```sql
                    -- Get trades for a specific ticker
                    SELECT * FROM trades WHERE ticker = 'AAPL' ORDER BY date DESC
    
                    -- Calculate total invested per ticker
                    SELECT ticker, SUM(quantity * price) as total_invested
                    FROM trades
                    WHERE action = 'BUY'
                    GROUP BY ticker
    
                    -- Get portfolio summary
                    SELECT
                        COUNT(*) as num_positions,
                        SUM(quantity * avg_cost) as total_cost
                    FROM holdings
                    ```
                    """)
    
            # ====================================================================
            # TAB 3: SAVED QUERIES
            # ====================================================================
            with tabs[2]:
                st.markdown("### üíæ Saved Queries")
                st.markdown("Save and manage frequently used queries")
    
                # Initialize saved queries in session state
                if 'saved_queries' not in st.session_state:
                    st.session_state['saved_queries'] = {
                        'Portfolio Summary': "SELECT ticker, quantity, avg_cost, current_price FROM holdings ORDER BY ticker",
                        'Recent Trades': "SELECT date, ticker, action, quantity, price FROM trades ORDER BY date DESC LIMIT 20",
                        'Trade Volume by Ticker': "SELECT ticker, COUNT(*) as trade_count, SUM(quantity) as total_shares FROM trades GROUP BY ticker ORDER BY trade_count DESC",
                        'Buy vs Sell Summary': "SELECT action, COUNT(*) as trade_count, SUM(quantity * price) as total_value FROM trades GROUP BY action"
                    }
    
                # Add new query
                with st.expander("‚ûï Save New Query"):
                    new_query_name = st.text_input("Query Name")
                    new_query_sql = st.text_area("SQL Query", height=150)
    
                    if st.button("üíæ Save Query"):
                        if new_query_name and new_query_sql:
                            st.session_state['saved_queries'][new_query_name] = new_query_sql
                            st.success(f"‚úÖ Query '{new_query_name}' saved!")
                        else:
                            st.warning("Please provide both name and query")
    
                st.markdown("---")
    
                # Display saved queries
                st.markdown("#### üìã Your Saved Queries")
    
                for query_name, query_sql in st.session_state['saved_queries'].items():
                    with st.expander(f"üìå {query_name}"):
                        st.code(query_sql, language='sql')
    
                        col1, col2, col3 = st.columns(3)
    
                        with col1:
                            if st.button(f"‚ñ∂Ô∏è Run", key=f"run_{query_name}"):
                                try:
                                    result = db.read(query_sql)
                                    st.success(f"‚úÖ {len(result)} rows")
                                    make_scrollable_table(result, height=400, hide_index=True, use_container_width=True)
                                except Exception as e:
                                    st.error(f"Error: {e}")
    
                        with col2:
                            if st.button(f"üìã Copy", key=f"copy_{query_name}"):
                                st.session_state['sql_query'] = query_sql
                                st.info("Query copied to Custom Query tab")
    
                        with col3:
                            if st.button(f"üóëÔ∏è Delete", key=f"delete_{query_name}"):
                                if query_name in st.session_state['saved_queries']:
                                    del st.session_state['saved_queries'][query_name]
                                    st.rerun()
    
            # ====================================================================
            # TAB 4: DATABASE INFO
            # ====================================================================
            with tabs[3]:
                st.markdown("### ‚ÑπÔ∏è Database Information")
    
                # Database location
                st.markdown("#### üìÅ Database Location")
                db_path = "data/atlas.db"
                st.code(db_path)
    
                st.markdown("---")
    
                # Table schemas
                st.markdown("#### üìä Table Schemas")
    
                tables = [
                    {
                        'name': 'holdings',
                        'description': 'Current portfolio positions',
                        'columns': [
                            ('id', 'INTEGER', 'Primary key'),
                            ('portfolio_id', 'INTEGER', 'Portfolio identifier'),
                            ('ticker', 'TEXT', 'Stock ticker symbol'),
                            ('quantity', 'REAL', 'Number of shares'),
                            ('avg_cost', 'REAL', 'Average cost per share'),
                            ('current_price', 'REAL', 'Current market price'),
                            ('updated_at', 'TIMESTAMP', 'Last update time')
                        ]
                    },
                    {
                        'name': 'trades',
                        'description': 'Trade history',
                        'columns': [
                            ('id', 'INTEGER', 'Primary key'),
                            ('date', 'DATE', 'Trade date'),
                            ('ticker', 'TEXT', 'Stock ticker symbol'),
                            ('action', 'TEXT', 'BUY or SELL'),
                            ('quantity', 'REAL', 'Number of shares'),
                            ('price', 'REAL', 'Execution price'),
                            ('created_at', 'TIMESTAMP', 'Record creation time')
                        ]
                    },
                    {
                        'name': 'prices',
                        'description': 'Historical price data',
                        'columns': [
                            ('id', 'INTEGER', 'Primary key'),
                            ('date', 'DATE', 'Price date'),
                            ('ticker', 'TEXT', 'Stock ticker symbol'),
                            ('open_price', 'REAL', 'Opening price'),
                            ('high_price', 'REAL', 'High price'),
                            ('low_price', 'REAL', 'Low price'),
                            ('close_price', 'REAL', 'Closing price'),
                            ('volume', 'REAL', 'Trading volume'),
                            ('updated_at', 'TIMESTAMP', 'Last update time')
                        ]
                    },
                    {
                        'name': 'analytics_cache',
                        'description': 'Cached analysis results',
                        'columns': [
                            ('id', 'INTEGER', 'Primary key'),
                            ('analysis_type', 'TEXT', 'Type of analysis'),
                            ('parameters', 'TEXT', 'Analysis parameters (JSON)'),
                            ('result', 'TEXT', 'Analysis result (JSON)'),
                            ('created_at', 'TIMESTAMP', 'Cache creation time')
                        ]
                    }
                ]
    
                for table in tables:
                    with st.expander(f"üìã {table['name']} - {table['description']}"):
                        # Create DataFrame for columns
                        schema_df = pd.DataFrame(table['columns'], columns=['Column', 'Type', 'Description'])
                        make_scrollable_table(schema_df, height=400, hide_index=True, use_container_width=True)
    
                        # Show row count
                        try:
                            count_result = db.read(f"SELECT COUNT(*) as count FROM {table['name']}")
                            row_count = count_result.iloc[0]['count']
                            st.info(f"üìä Current rows: {row_count}")
                        except:
                            st.info("üìä Table not yet created")
    
                st.markdown("---")
    
                # Database statistics
                st.markdown("#### üìà Database Statistics")
    
                try:
                    col1, col2 = st.columns(2)
    
                    with col1:
                        # Get total records across all tables
                        total_holdings = len(db.read("SELECT * FROM holdings"))
                        total_trades = len(db.read("SELECT * FROM trades"))
    
                        st.metric("Total Holdings Records", total_holdings)
                        st.metric("Total Trade Records", total_trades)
    
                    with col2:
                        # Calculate database size (if possible)
                        import os
                        if os.path.exists('data/atlas.db'):
                            db_size = os.path.getsize('data/atlas.db') / 1024  # KB
                            st.metric("Database Size", f"{db_size:.2f} KB")
    
                        # Last update time
                        portfolio = db.get_portfolio()
                        if len(portfolio) > 0 and 'updated_at' in portfolio.columns:
                            last_update = portfolio['updated_at'].max()
                            st.metric("Last Portfolio Update", str(last_update))
    
                except Exception as e:
                    st.error(f"Error calculating statistics: {e}")
    
                st.markdown("---")
    
                # Database maintenance
                st.markdown("#### üõ†Ô∏è Database Maintenance")
    
                col1, col2 = st.columns(2)
    
                with col1:
                    if st.button("üîÑ Vacuum Database", help="Optimize database and reclaim space"):
                        try:
                            db.execute("VACUUM")
                            st.success("‚úÖ Database vacuumed successfully")
                        except Exception as e:
                            st.error(f"Error: {e}")
    
                with col2:
                    if st.button("üìä Analyze Tables", help="Update table statistics"):
                        try:
                            db.execute("ANALYZE")
                            st.success("‚úÖ Tables analyzed successfully")
                        except Exception as e:
                            st.error(f"Error: {e}")
    
                st.warning("‚ö†Ô∏è Maintenance operations may take a few seconds for large databases")
    
        # ========================================================================
        # PORTFOLIO HOME - ENHANCED WITH CONTRIBUTORS/DETRACTORS
        # ========================================================================
        elif page == "üè† Portfolio Home":
            from ui.pages.portfolio_home import render_portfolio_home
            render_portfolio_home(start_date, end_date)

        # ========================================================================
        # MARKET WATCH - COMPLETE REVAMP (DEPRECATED - Replaced by ATLAS Market Watch at line ~21255)
        # ========================================================================
        # OLD MARKET WATCH DISABLED - Now using ATLAS Market Watch with institutional features
        # See atlas_app.py line 21255 for new implementation
        elif page == "üåç Market Watch (OLD - DISABLED)":
            st.markdown("## üåç MARKET WATCH - EXCELLENCE EDITION")
            st.markdown("*Your comprehensive window into global markets, crypto, bonds, and credit conditions*")
    
            st.markdown("---")
    
            # LIVE TICKER SEARCH
            st.markdown("### üîç Live Ticker Search")
            search_col1, search_col2 = st.columns([3, 1])
    
            with search_col1:
                search_query = st.text_input(
                    "Search any ticker or add to watchlist",
                    placeholder="Enter ticker symbol (e.g., AAPL, TSLA, BTC-USD)...",
                    key="ticker_search",
                    label_visibility="collapsed"
                )
    
            with search_col2:
                search_button = st.button("üîç Search", use_container_width=True, type="primary")
    
            # Display search results
            if (search_query and search_button) or (search_query and len(search_query) >= 2):
                with st.spinner(f"Searching for '{search_query}'..."):
                    results = search_yahoo_finance(search_query)
    
                    if results:
                        result = results[0]
                        st.success(f"‚úÖ Found: **{result['symbol']}** - {result['name']}")
    
                        # Display quick info
                        info_col1, info_col2, info_col3, info_col4 = st.columns(4)
                        with info_col1:
                            st.markdown(f'<div style="background: linear-gradient(135deg, rgba(139,92,246,0.08), rgba(21,25,50,0.95)); backdrop-filter: blur(24px); border-radius: 24px; border: 1px solid rgba(139,92,246,0.2); padding: 1.75rem 1.5rem; box-shadow: 0 4px 24px rgba(0,0,0,0.2); min-height: 200px; position: relative; overflow: hidden;"><div style="position: absolute; top: 0; left: 0; right: 0; height: 3px; background: linear-gradient(90deg, #8b5cf6, #a855f7); opacity: 0.8;"></div><div style="display: flex; align-items: center; gap: 0.4rem; margin-bottom: 0.875rem;"><span style="font-size: 1rem;">üè∑Ô∏è</span><p style="font-size: 0.6rem; color: #94a3b8; text-transform: uppercase; letter-spacing: 0.08em; margin: 0; font-weight: 600;">TYPE</p></div><h3 style="font-size: 2.5rem; font-weight: 800; color: #a5b4fc; margin: 0.5rem 0 0.75rem 0; line-height: 1;">{result["type"]}</h3><div style="display: inline-block; padding: 0.4rem 0.75rem; background: rgba(139,92,246,0.12); border-radius: 10px; border: 1px solid rgba(139,92,246,0.25);"><p style="font-size: 0.7rem; color: #d8b4fe; margin: 0; font-weight: 600;">Asset Class</p></div></div>', unsafe_allow_html=True)
                        with info_col2:
                            st.markdown(f'<div style="background: linear-gradient(135deg, rgba(6,182,212,0.08), rgba(21,25,50,0.95)); backdrop-filter: blur(24px); border-radius: 24px; border: 1px solid rgba(6,182,212,0.2); padding: 1.75rem 1.5rem; box-shadow: 0 4px 24px rgba(0,0,0,0.2); min-height: 200px; position: relative; overflow: hidden;"><div style="position: absolute; top: 0; left: 0; right: 0; height: 3px; background: linear-gradient(90deg, #06b6d4, #3b82f6); opacity: 0.8;"></div><div style="display: flex; align-items: center; gap: 0.4rem; margin-bottom: 0.875rem;"><span style="font-size: 1rem;">üèõÔ∏è</span><p style="font-size: 0.6rem; color: #94a3b8; text-transform: uppercase; letter-spacing: 0.08em; margin: 0; font-weight: 600;">EXCHANGE</p></div><h3 style="font-size: 2.5rem; font-weight: 800; color: #67e8f9; margin: 0.5rem 0 0.75rem 0; line-height: 1;">{result["exchange"]}</h3><div style="display: inline-block; padding: 0.4rem 0.75rem; background: rgba(6,182,212,0.12); border-radius: 10px; border: 1px solid rgba(6,182,212,0.25);"><p style="font-size: 0.7rem; color: #a5f3fc; margin: 0; font-weight: 600;">Trading Venue</p></div></div>', unsafe_allow_html=True)
                        with info_col3:
                            if result['market_cap'] > 0:
                                mkt_cap_val = result['market_cap']/1e9
                                mkt_cap_tier = 'Large Cap' if mkt_cap_val > 10 else ('Mid Cap' if mkt_cap_val > 2 else 'Small Cap')
                                st.markdown(f'<div style="background: linear-gradient(135deg, rgba(16,185,129,0.08), rgba(21,25,50,0.95)); backdrop-filter: blur(24px); border-radius: 24px; border: 1px solid rgba(16,185,129,0.2); padding: 1.75rem 1.5rem; box-shadow: 0 4px 24px rgba(0,0,0,0.2); min-height: 200px; position: relative; overflow: hidden;"><div style="position: absolute; top: 0; left: 0; right: 0; height: 3px; background: linear-gradient(90deg, #10b981, #059669); opacity: 0.8;"></div><div style="display: flex; align-items: center; gap: 0.4rem; margin-bottom: 0.875rem;"><span style="font-size: 1rem;">üí∞</span><p style="font-size: 0.6rem; color: #94a3b8; text-transform: uppercase; letter-spacing: 0.08em; margin: 0; font-weight: 600;">MARKET CAP</p></div><h3 style="font-size: 2.5rem; font-weight: 800; color: #10b981; margin: 0.5rem 0 0.75rem 0; text-shadow: 0 0 24px rgba(16,185,129,0.5); line-height: 1;">${mkt_cap_val:.1f}B</h3><div style="display: inline-block; padding: 0.4rem 0.75rem; background: rgba(16,185,129,0.12); border-radius: 10px; border: 1px solid rgba(16,185,129,0.25);"><p style="font-size: 0.7rem; color: #6ee7b7; margin: 0; font-weight: 600;">{mkt_cap_tier}</p></div></div>', unsafe_allow_html=True)
                            else:
                                st.markdown(f'<div style="background: linear-gradient(135deg, rgba(245,158,11,0.08), rgba(21,25,50,0.95)); backdrop-filter: blur(24px); border-radius: 24px; border: 1px solid rgba(245,158,11,0.2); padding: 1.75rem 1.5rem; box-shadow: 0 4px 24px rgba(0,0,0,0.2); min-height: 200px; position: relative; overflow: hidden;"><div style="position: absolute; top: 0; left: 0; right: 0; height: 3px; background: linear-gradient(90deg, #f59e0b, #d97706); opacity: 0.8;"></div><div style="display: flex; align-items: center; gap: 0.4rem; margin-bottom: 0.875rem;"><span style="font-size: 1rem;">üí±</span><p style="font-size: 0.6rem; color: #94a3b8; text-transform: uppercase; letter-spacing: 0.08em; margin: 0; font-weight: 600;">CURRENCY</p></div><h3 style="font-size: 2.5rem; font-weight: 800; color: #fbbf24; margin: 0.5rem 0 0.75rem 0; line-height: 1;">{result["currency"]}</h3><div style="display: inline-block; padding: 0.4rem 0.75rem; background: rgba(245,158,11,0.12); border-radius: 10px; border: 1px solid rgba(245,158,11,0.25);"><p style="font-size: 0.7rem; color: #fcd34d; margin: 0; font-weight: 600;">Base Currency</p></div></div>', unsafe_allow_html=True)
                        with info_col4:
                            # Add to watchlist button
                            if st.button(f"‚≠ê Add to Watchlist", key=f"add_{result['symbol']}"):
                                if add_to_watchlist(result['symbol'], result['name'], result['type']):
                                    st.success(f"‚úÖ Added {result['symbol']} to watchlist!")
                                    st.rerun()
                                else:
                                    st.warning(f"‚ö†Ô∏è {result['symbol']} already in watchlist")
                    else:
                        st.error(f"‚ùå No results found for '{search_query}'. Try a different ticker symbol.")
    
            st.markdown("---")
            st.markdown("### üîç Filters & Settings")
            col1, col2, col3, col4 = st.columns(4)
            
            with col1:
                filter_change = st.slider("Min Change %", -10.0, 10.0, -10.0)
            with col2:
                sort_by = st.selectbox("Sort By", ["Change %", "5D %", "Volume"])
            with col3:
                refresh = st.button("üîÑ Refresh Data")
                if refresh:
                    current_time = datetime.now().strftime("%H:%M:%S")
                    show_toast(f"Market data refreshed - updated at {current_time}", toast_type="info", duration=3000)
            with col4:
                auto_refresh = st.checkbox("Auto-Refresh (5min)")
    
            st.markdown("---")
    
            # EXPANDED TABS
            tab0, tab1, tab2, tab3, tab4, tab5, tab6, tab7 = st.tabs([
                "‚≠ê My Watchlist",
                "üìà Indices",
                "üí∞ Crypto",
                "üè¶ ETFs",
                "‚ö° Commodities",
                "üìä Stocks",
                "üíµ Bonds & Rates",
                "üéØ Credit Spreads"
            ])
    
            # PERSONAL WATCHLIST TAB
            with tab0:
                st.markdown("#### ‚≠ê Personal Watchlist")
    
                watchlist = get_watchlist()
    
                if not watchlist:
                    st.info("üìù Your watchlist is empty. Use the search bar above to add tickers!")
                else:
                    st.success(f"‚úÖ Tracking {len(watchlist)} securities")
    
                    # Fetch live data for watchlist
                    watchlist_data = []
    
                    with st.spinner("Loading watchlist prices..."):
                        from modules import convert_ee_ticker_to_yahoo

                        for item in watchlist:
                            try:
                                # Convert ticker format
                                yahoo_ticker = convert_ee_ticker_to_yahoo(item['ticker'])
                                ticker = yf.Ticker(yahoo_ticker)
                                hist = ticker.history(period='5d')
    
                                if not hist.empty:
                                    current_price = hist['Close'].iloc[-1]
                                    prev_close = hist['Close'].iloc[-2] if len(hist) > 1 else current_price
                                    change = current_price - prev_close
                                    change_pct = (change / prev_close * 100) if prev_close > 0 else 0
    
                                    # Get 5-day change
                                    if len(hist) >= 5:
                                        five_day_change = ((current_price - hist['Close'].iloc[0]) / hist['Close'].iloc[0] * 100)
                                    else:
                                        five_day_change = 0
    
                                    watchlist_data.append({
                                        'Ticker': item['ticker'],
                                        'Name': item['name'],
                                        'Type': item['type'],
                                        'Price': f"${current_price:.2f}",
                                        'Change': f"${change:+.2f}",
                                        'Change %': change_pct,
                                        '5D %': five_day_change,
                                        'Added': item['added_date']
                                    })
                            except:
                                # If data fetch fails, still show the item
                                watchlist_data.append({
                                    'Ticker': item['ticker'],
                                    'Name': item['name'],
                                    'Type': item['type'],
                                    'Price': 'N/A',
                                    'Change': 'N/A',
                                    'Change %': 0,
                                    '5D %': 0,
                                    'Added': item['added_date']
                                })
    
                    if watchlist_data:
                        watchlist_df = pd.DataFrame(watchlist_data)
                        make_scrollable_table(watchlist_df, height=600, hide_index=True, use_container_width=True)
    
                        # Remove from watchlist
                        st.markdown("---")
                        st.markdown("##### üóëÔ∏è Manage Watchlist")
    
                        remove_col1, remove_col2 = st.columns([3, 1])
    
                        with remove_col1:
                            ticker_to_remove = st.selectbox(
                                "Select ticker to remove",
                                options=[item['ticker'] for item in watchlist],
                                key="remove_ticker_select"
                            )
    
                        with remove_col2:
                            if st.button("üóëÔ∏è Remove", use_container_width=True, type="secondary"):
                                remove_from_watchlist(ticker_to_remove)
                                st.success(f"‚úÖ Removed {ticker_to_remove} from watchlist")
                                st.rerun()
    
            with tab1:
                st.markdown("#### üåç Global Indices")
    
                # Advanced filters for indices
                index_regions = st.multiselect(
                    "Filter by Region",
                    ["US", "Europe", "Asia-Pacific", "Americas", "Middle East & Africa", "UK", "Germany", "France",
                     "Japan", "Hong Kong", "China", "India", "Canada", "Brazil", "Australia"],
                    default=["US", "Europe", "Asia-Pacific"],
                    key="index_region_filter"
                )
    
                with st.spinner("Loading indices..."):
                    indices_df = fetch_market_watch_data(GLOBAL_INDICES)
                    if not indices_df.empty:
                        # Apply region filter
                        if index_regions and 'Region' in indices_df.columns:
                            indices_df = indices_df[indices_df['Region'].isin(index_regions)]
                        # Apply change filter
                        indices_df = indices_df[indices_df['Change %'] >= filter_change]
                        display_df = create_dynamic_market_table(indices_df, {'sort_by': sort_by, 'ascending': False})
                        make_scrollable_table(display_df, height=600, hide_index=True, use_container_width=True, column_config=None)
                    else:
                        st.warning("No data available")
            
            with tab2:
                st.markdown("#### ü™ô Cryptocurrency Markets")
    
                # Advanced filters for crypto
                col_crypto1, col_crypto2 = st.columns(2)
                with col_crypto1:
                    crypto_market_caps = st.multiselect(
                        "Filter by Market Cap",
                        ["Large", "Mid", "Small"],
                        default=["Large", "Mid"],
                        key="crypto_mcap_filter"
                    )
                with col_crypto2:
                    crypto_categories = st.multiselect(
                        "Filter by Type",
                        ["Crypto", "Stablecoin"],
                        default=["Crypto", "Stablecoin"],
                        key="crypto_cat_filter"
                    )
    
                with st.spinner("Loading crypto..."):
                    crypto_df = fetch_market_watch_data(CRYPTOCURRENCIES)
                    if not crypto_df.empty:
                        # Apply market cap filter
                        if crypto_market_caps and 'Market Cap' in crypto_df.columns:
                            crypto_df = crypto_df[crypto_df['Market Cap'].isin(crypto_market_caps)]
                        # Apply category filter
                        if crypto_categories and 'Category' in crypto_df.columns:
                            crypto_df = crypto_df[crypto_df['Category'].isin(crypto_categories)]
                        # Apply change filter
                        crypto_df = crypto_df[crypto_df['Change %'] >= filter_change]
                        display_df = create_dynamic_market_table(crypto_df, {'sort_by': sort_by, 'ascending': False})
                        make_scrollable_table(display_df, height=600, hide_index=True, use_container_width=True, column_config=None)
                    else:
                        st.warning("No data available")
            
            with tab3:
                st.markdown("#### üì¶ Exchange-Traded Funds")
    
                # Comprehensive ETF category filters
                etf_categories = st.multiselect(
                    "Filter by Category",
                    ["Broad Market", "Mid Cap", "Small Cap", "Sector", "Real Estate", "Thematic",
                     "International", "Bonds", "Commodities", "Factor", "Leveraged", "Inverse", "Volatility"],
                    default=["Broad Market", "Sector", "Thematic", "International"],
                    key="etf_cat_filter"
                )
    
                with st.spinner("Loading ETFs..."):
                    etf_df = fetch_market_watch_data(POPULAR_ETFS)
                    if not etf_df.empty:
                        if etf_categories:
                            etf_df = etf_df[etf_df['Category'].isin(etf_categories)]
                        # Apply change filter
                        etf_df = etf_df[etf_df['Change %'] >= filter_change]
                        display_df = create_dynamic_market_table(etf_df, {'sort_by': sort_by, 'ascending': False})
                        make_scrollable_table(display_df, height=600, hide_index=True, use_container_width=True, column_config=None)
                    else:
                        st.warning("No data available")
            
            with tab4:
                st.markdown("#### ‚õΩ Commodity Markets")
    
                # Commodity category filters
                commodity_cats = st.multiselect(
                    "Filter by Type",
                    ["Precious Metals", "Energy", "Industrial Metals", "Agriculture", "Livestock"],
                    default=["Precious Metals", "Energy", "Agriculture"],
                    key="commodity_cat_filter"
                )
    
                with st.spinner("Loading commodities..."):
                    comm_df = fetch_market_watch_data(COMMODITIES)
                    if not comm_df.empty:
                        if commodity_cats:
                            comm_df = comm_df[comm_df['Category'].isin(commodity_cats)]
                        # Apply change filter
                        comm_df = comm_df[comm_df['Change %'] >= filter_change]
                        display_df = create_dynamic_market_table(comm_df, {'sort_by': sort_by, 'ascending': False})
                        make_scrollable_table(display_df, height=600, hide_index=True, use_container_width=True, column_config=None)
                    else:
                        st.warning("No data available")
            
            with tab5:
                st.markdown("#### üìà Popular Stocks")
    
                # Comprehensive stock category filters
                stock_categories = st.multiselect(
                    "Filter by Category",
                    ["Mega Cap Tech", "Tech", "Semiconductors", "Software", "E-Commerce", "Payments", "Crypto",
                     "Financials", "Insurance", "Healthcare", "Biotech", "Medical Devices",
                     "Consumer", "Retail", "Automotive", "Travel", "Delivery",
                     "Energy", "Oil Services", "Industrials", "Aerospace", "Transportation", "Airlines",
                     "Materials", "Chemicals", "Mining", "Utilities", "REITs",
                     "Telecom", "Media", "Gaming", "Rideshare", "International"],
                    default=["Mega Cap Tech", "Semiconductors", "Software", "Financials", "Healthcare"],
                    key="stock_cat_filter"
                )
    
                with st.spinner("Loading stocks..."):
                    stocks_df = fetch_market_watch_data(POPULAR_STOCKS)
                    if not stocks_df.empty:
                        if stock_categories:
                            stocks_df = stocks_df[stocks_df['Category'].isin(stock_categories)]
                        # Apply change filter
                        stocks_df = stocks_df[stocks_df['Change %'] >= filter_change]
                        display_df = create_dynamic_market_table(stocks_df, {'sort_by': sort_by, 'ascending': False})
                        make_scrollable_table(display_df, height=600, hide_index=True, use_container_width=True, column_config=None)
                    else:
                        st.warning("No data available")
            
            with tab6:
                st.markdown("#### üíµ Global Bond Yields & Yield Curves")
                st.info("üìä **Key Insight:** Monitor yield curves for recession signals, inflation expectations, and relative value across markets")
    
                # Country/Region selector for yield curves
                selected_curve = st.selectbox(
                    "Select Yield Curve",
                    ["US Treasuries", "UK Gilts", "German Bunds", "SA Government Bonds"],
                    index=0,
                    help="Compare government bond yields across major economies"
                )
    
                # Display yield curve based on selection
                if selected_curve == "US Treasuries":
                    result = create_yield_curve()
                    if result:
                        yield_curve, maturities, spot_rates, data_source = result
    
                        # Display combined spot + forward curve
                        st.plotly_chart(yield_curve, use_container_width=True)
    
                        # Show data source indicator
                        freshness_color = {
                            "FRED API": "üü¢",
                            "Yahoo Finance": "üü°",
                            "Fallback Data": "üî¥"
                        }.get(data_source, "üü°")
    
                        st.caption(f"**Data Freshness:** {ATLASFormatter.format_timestamp()} ‚Ä¢ {freshness_color} {data_source}")
                        st.info("üí° **Blue line** = Spot yields | **Green dashed** = Implied forward rates showing market expectations")
    
                        # Calculate and display spread
                        treasuries_10y = yf.Ticker("^TNX")
                        treasuries_2y = yf.Ticker("^FVX")
                        try:
                            hist_10y = treasuries_10y.history(period="1d")
                            hist_2y = treasuries_2y.history(period="1d")
                            if not hist_10y.empty and not hist_2y.empty:
                                spread_10y_2y = hist_10y['Close'].iloc[-1] - hist_2y['Close'].iloc[-1]
                                if spread_10y_2y > 0:
                                    st.success(f"‚úÖ 10Y-5Y Spread: **+{spread_10y_2y:.2f}%** (Normal - Positive slope)")
                                else:
                                    st.error(f"‚ö†Ô∏è 10Y-5Y Spread: **{spread_10y_2y:.2f}%** (INVERTED - Potential recession signal)")
                        except:
                            pass
    
                elif selected_curve == "UK Gilts":
                    with st.spinner("Fetching UK Gilt yields..."):
                        maturities, yields = fetch_uk_gilt_yields()
    
                    fig_gilts = create_yield_curve_with_forwards(maturities, yields, "UK Gilt Yield Curve with Forward Rates", color='#FF6B6B')
                    st.plotly_chart(fig_gilts, use_container_width=True)
                    st.caption(f"**Data Freshness:** {ATLASFormatter.format_timestamp()} ‚Ä¢ Live data from Yahoo Finance")
                    st.info("üí° **Red line** = Spot yields | **Green dashed** = Implied forward rates showing market expectations")
    
                elif selected_curve == "German Bunds":
                    with st.spinner("Fetching German Bund yields..."):
                        maturities, yields = fetch_german_bund_yields()
    
                    fig_bunds = create_yield_curve_with_forwards(maturities, yields, "German Bund Yield Curve with Forward Rates", color='#FFD700')
                    st.plotly_chart(fig_bunds, use_container_width=True)
                    st.caption(f"**Data Freshness:** {ATLASFormatter.format_timestamp()} ‚Ä¢ Live data from Yahoo Finance")
                    st.info("üí° **Gold line** = Spot yields | **Green dashed** = Implied forward rates showing market expectations")
    
                elif selected_curve == "SA Government Bonds":
                    with st.spinner("Fetching SA Government Bond yields..."):
                        maturities, yields = fetch_sa_government_bond_yields()
    
                    fig_sagov = create_yield_curve_with_forwards(maturities, yields, "SA Government Bond Yield Curve with Forward Rates", color='#00D4FF')
                    st.plotly_chart(fig_sagov, use_container_width=True)
                    st.caption(f"**Data Freshness:** {ATLASFormatter.format_timestamp()} ‚Ä¢ South African government bond yields")
                    st.info("üí° **Cyan line** = Spot yields | **Green dashed** = Implied forward rates showing market expectations")
    
                st.markdown("---")
    
                with st.spinner("Loading bonds..."):
                    bonds_df = fetch_market_watch_data(BOND_YIELDS)
                    if not bonds_df.empty:
                        display_df = create_dynamic_market_table(bonds_df, {'sort_by': sort_by, 'ascending': False})
                        make_scrollable_table(display_df, height=400, hide_index=True, use_container_width=True, column_config=None)
                    else:
                        st.warning("No data available")
            
            with tab7:
                st.markdown("#### üéØ Credit Spreads & Conditions")
                st.info("üí° **Key Insight:** Widening spreads signal deteriorating credit conditions and rising risk premiums")
                
                with st.spinner("Loading credit spreads..."):
                    credit_df = fetch_market_watch_data(CREDIT_SPREADS)
                    if not credit_df.empty:
                        display_df = create_dynamic_market_table(credit_df, {'sort_by': sort_by, 'ascending': False})
                        make_scrollable_table(display_df, height=400, hide_index=True, use_container_width=True, column_config=None)
                        
                        st.markdown("---")
                        st.markdown("#### üìä Credit Market Interpretation")
                        st.markdown("""
                        **Investment Grade (LQD):** Corporate bonds rated BBB- or higher
                        **High Yield (HYG):** "Junk" bonds with higher risk and return potential
                        **Emerging Markets (EMB):** Sovereign and corporate debt from developing economies
                        **TIPS (TIP):** Treasury Inflation-Protected Securities
                        **MBS (MBB):** Mortgage-Backed Securities
                        """)
                    else:
                        st.warning("No data available")
        
        # Continue with remaining pages in next message...
        # (Risk Analysis, Performance Suite, Portfolio Deep Dive, Multi-Factor, Valuation House, About)
        
        # ========================================================================
        # RISK ANALYSIS - WORLD CLASS
        # ========================================================================
        elif page == "üìà Risk Analysis":

            from ui.pages.risk_analysis import render_risk_analysis

            render_risk_analysis(start_date, end_date, selected_benchmark)



        # Continue with remaining pages...
        # ========================================================================
        # PERFORMANCE SUITE
        # ========================================================================
        elif page == "üíé Performance Suite":

            from ui.pages.performance_suite import render_performance_suite

            render_performance_suite(start_date, end_date, selected_benchmark)



        # ========================================================================
        # PORTFOLIO DEEP DIVE - ENHANCED
        # ========================================================================
        elif page == "üî¨ Portfolio Deep Dive":

            from ui.pages.portfolio_deep_dive import render_portfolio_deep_dive

            render_portfolio_deep_dive(start_date, end_date)



        # ========================================================================
        # MULTI-FACTOR ANALYSIS - ENHANCED
        # ========================================================================
        elif page == "üìä Multi-Factor Analysis":

            from ui.pages.multi_factor_analysis import render_multi_factor_analysis

            render_multi_factor_analysis(start_date, end_date)



        # ========================================================================
        # VALUATION HOUSE - ENHANCED WITH SMART ASSUMPTIONS
        # ========================================================================
        elif page == "üí∞ Valuation House":

            from ui.pages.valuation_house import render_valuation_house

            render_valuation_house(start_date, end_date)



        # ========================================================================
        # MONTE CARLO ENGINE (v11.0)
        # ========================================================================
        elif page == "üé≤ Monte Carlo Engine":

            from ui.pages.monte_carlo import render_monte_carlo

            render_monte_carlo()



        # ========================================================================
        # MARKET WATCH (ATLAS Market Watch Integration)
        # ========================================================================
        elif page == "üåç Market Watch":

            from ui.pages.market_watch import render_market_watch

            render_market_watch()



        # ========================================================================
        # MARKET REGIME DETECTOR (Phase 2)
        # ========================================================================
        elif page == "üåê Market Regime":

            from ui.pages.market_regime import render_market_regime

            render_market_regime()




        # ========================================================================
        # QUANT OPTIMIZER (v11.0)
        # ========================================================================
        elif page == "üßÆ Quant Optimizer":

            from ui.pages.quant_optimizer import render_quant_optimizer

            render_quant_optimizer(start_date, end_date, selected_benchmark)



        # ========================================================================
        # LEVERAGE TRACKER (v11.0) - NEW FEATURE
        # ========================================================================
        elif page == "üìä Leverage Tracker":
            st.markdown('<h1 style="font-size: 2.5rem; font-weight: 800; color: #f8fafc; margin-bottom: 0.5rem;"><span style="font-size: 2rem;">üìä</span> <span style="background: linear-gradient(135deg, #00d4ff, #6366f1, #8b5cf6); -webkit-background-clip: text; -webkit-text-fill-color: transparent;">LEVERAGE TRACKING & ANALYSIS</span></h1>', unsafe_allow_html=True)
            st.markdown("**Track how leverage has affected your returns over time**")
    
            # FIX #6: Removed duplicate upload - keep uploads centralized in Phoenix Parser
            # Check if leverage tracker exists in session state
            if 'leverage_tracker' not in st.session_state:
                st.warning("‚ö†Ô∏è No performance history loaded")
                st.info("""
                **To use Leverage Tracking:**
    
                1. Go to üî• **Phoenix Parser** (in sidebar navigation)
                2. Scroll to "üìä Leverage Tracking" section
                3. Upload your Investopedia performance-history.xls file
                4. Return to this page to view full analysis
    
                The performance history upload is centralized in Phoenix Parser to keep all data uploads in one place.
                """)
    
                # Show helpful navigation hint
                st.markdown("---")
                st.caption("üí° Tip: Use the sidebar navigation to quickly switch between pages")
    
                return  # Exit early if no tracker
            else:
                # Display leverage analysis
                tracker = st.session_state.leverage_tracker
                stats = tracker.get_current_stats()
    
                # Header metrics
                st.markdown('<h2 style="font-size: 1.5rem; font-weight: 700; color: #f8fafc; margin-bottom: 1.5rem;"><span style="font-size: 1.25rem;">üìä</span> <span style="background: linear-gradient(135deg, #00d4ff, #6366f1, #8b5cf6); -webkit-background-clip: text; -webkit-text-fill-color: transparent;">Current Statistics</span></h2>', unsafe_allow_html=True)

                col1, col2, col3, col4, col5 = st.columns(5)

                # Card 1: Current Leverage
                with col1:
                    lev_color = '#10b981' if abs(stats['current_leverage'] - 1.7) < 0.3 else '#ef4444'
                    st.markdown(f'<div style="background: linear-gradient(135deg, rgba(99,102,241,0.08), rgba(21,25,50,0.95)); backdrop-filter: blur(24px); border-radius: 24px; border: 1px solid rgba(99,102,241,0.2); padding: 1.75rem 1.5rem; box-shadow: 0 4px 24px rgba(0,0,0,0.2); min-height: 200px; position: relative; overflow: hidden;"><div style="position: absolute; top: 0; left: 0; right: 0; height: 3px; background: linear-gradient(90deg, #6366f1, #8b5cf6); opacity: 0.8;"></div><div style="display: flex; align-items: center; gap: 0.4rem; margin-bottom: 0.875rem;"><span style="font-size: 1rem;">‚ö°</span><p style="font-size: 0.6rem; color: #94a3b8; text-transform: uppercase; letter-spacing: 0.08em; margin: 0; font-weight: 600;">CURRENT LEVERAGE</p></div><h3 style="font-size: 2.5rem; font-weight: 800; color: {lev_color}; margin: 0.5rem 0 0.75rem 0; line-height: 1;">{stats["current_leverage"]:.2f}x</h3><div style="display: inline-block; padding: 0.4rem 0.75rem; background: rgba(99,102,241,0.12); border-radius: 10px; border: 1px solid rgba(99,102,241,0.25);"><p style="font-size: 0.7rem; color: #a5b4fc; margin: 0; font-weight: 600;">Target: 1.7x</p></div></div>', unsafe_allow_html=True)
    
                # Card 2: Net Equity
                with col2:
                    st.markdown(f'<div style="background: linear-gradient(135deg, rgba(16,185,129,0.08), rgba(21,25,50,0.95)); backdrop-filter: blur(24px); border-radius: 24px; border: 1px solid rgba(16,185,129,0.2); padding: 1.75rem 1.5rem; box-shadow: 0 4px 24px rgba(0,0,0,0.2); min-height: 200px; position: relative; overflow: hidden;"><div style="position: absolute; top: 0; left: 0; right: 0; height: 3px; background: linear-gradient(90deg, #10b981, #059669); opacity: 0.8;"></div><div style="display: flex; align-items: center; gap: 0.4rem; margin-bottom: 0.875rem;"><span style="font-size: 1rem;">üí∞</span><p style="font-size: 0.6rem; color: #94a3b8; text-transform: uppercase; letter-spacing: 0.08em; margin: 0; font-weight: 600;">NET EQUITY</p></div><h3 style="font-size: 2.5rem; font-weight: 800; color: #10b981; margin: 0.5rem 0 0.75rem 0; text-shadow: 0 0 24px rgba(16,185,129,0.5); line-height: 1;">${stats["current_equity"]:,.0f}</h3><div style="display: inline-block; padding: 0.4rem 0.75rem; background: rgba(16,185,129,0.12); border-radius: 10px; border: 1px solid rgba(16,185,129,0.25);"><p style="font-size: 0.7rem; color: #6ee7b7; margin: 0; font-weight: 600;">Your Capital</p></div></div>', unsafe_allow_html=True)
    
                # Card 3: Gross Exposure
                with col3:
                    exposure_pct = ((stats['current_gross_exposure'] / stats['current_equity'] - 1) * 100) if stats['current_equity'] > 0 else 0
                    st.markdown(f'<div style="background: linear-gradient(135deg, rgba(6,182,212,0.08), rgba(21,25,50,0.95)); backdrop-filter: blur(24px); border-radius: 24px; border: 1px solid rgba(6,182,212,0.2); padding: 1.75rem 1.5rem; box-shadow: 0 4px 24px rgba(0,0,0,0.2); min-height: 200px; position: relative; overflow: hidden;"><div style="position: absolute; top: 0; left: 0; right: 0; height: 3px; background: linear-gradient(90deg, #06b6d4, #3b82f6); opacity: 0.8;"></div><div style="display: flex; align-items: center; gap: 0.4rem; margin-bottom: 0.875rem;"><span style="font-size: 1rem;">üìä</span><p style="font-size: 0.6rem; color: #94a3b8; text-transform: uppercase; letter-spacing: 0.08em; margin: 0; font-weight: 600;">GROSS EXPOSURE</p></div><h3 style="font-size: 2.5rem; font-weight: 800; color: #67e8f9; margin: 0.5rem 0 0.75rem 0; line-height: 1;">${stats["current_gross_exposure"]:,.0f}</h3><div style="display: inline-block; padding: 0.4rem 0.75rem; background: rgba(6,182,212,0.12); border-radius: 10px; border: 1px solid rgba(6,182,212,0.25);"><p style="font-size: 0.7rem; color: #a5f3fc; margin: 0; font-weight: 600;">+{exposure_pct:.0f}% vs Equity</p></div></div>', unsafe_allow_html=True)
    
                # Card 4: YTD Equity Return
                with col4:
                    ytd_color = '#10b981' if stats['ytd_equity_return'] >= 0 else '#ef4444'
                    ytd_glow = '0 0 24px rgba(16,185,129,0.5)' if stats['ytd_equity_return'] >= 0 else '0 0 24px rgba(239,68,68,0.5)'
                    st.markdown(f'<div style="background: linear-gradient(135deg, rgba(139,92,246,0.08), rgba(21,25,50,0.95)); backdrop-filter: blur(24px); border-radius: 24px; border: 1px solid rgba(139,92,246,0.2); padding: 1.75rem 1.5rem; box-shadow: 0 4px 24px rgba(0,0,0,0.2); min-height: 200px; position: relative; overflow: hidden;"><div style="position: absolute; top: 0; left: 0; right: 0; height: 3px; background: linear-gradient(90deg, #8b5cf6, #a855f7); opacity: 0.8;"></div><div style="display: flex; align-items: center; gap: 0.4rem; margin-bottom: 0.875rem;"><span style="font-size: 1rem;">üìà</span><p style="font-size: 0.6rem; color: #94a3b8; text-transform: uppercase; letter-spacing: 0.08em; margin: 0; font-weight: 600;">YTD EQUITY RETURN</p></div><h3 style="font-size: 2.5rem; font-weight: 800; color: {ytd_color}; margin: 0.5rem 0 0.75rem 0; text-shadow: {ytd_glow}; line-height: 1;">{stats["ytd_equity_return"]:+.1f}%</h3><div style="display: inline-block; padding: 0.4rem 0.75rem; background: rgba(139,92,246,0.12); border-radius: 10px; border: 1px solid rgba(139,92,246,0.25);"><p style="font-size: 0.7rem; color: #d8b4fe; margin: 0; font-weight: 600;">On Your Capital</p></div></div>', unsafe_allow_html=True)
    
                # Card 5: YTD Gross Return
                with col5:
                    gross_color = '#10b981' if stats['ytd_gross_return'] >= 0 else '#ef4444'
                    gross_glow = '0 0 24px rgba(16,185,129,0.5)' if stats['ytd_gross_return'] >= 0 else '0 0 24px rgba(239,68,68,0.5)'
                    st.markdown(f'<div style="background: linear-gradient(135deg, rgba(99,102,241,0.08), rgba(21,25,50,0.95)); backdrop-filter: blur(24px); border-radius: 24px; border: 1px solid rgba(99,102,241,0.2); padding: 1.75rem 1.5rem; box-shadow: 0 4px 24px rgba(0,0,0,0.2); min-height: 200px; position: relative; overflow: hidden;"><div style="position: absolute; top: 0; left: 0; right: 0; height: 3px; background: linear-gradient(90deg, #6366f1, #8b5cf6); opacity: 0.8;"></div><div style="display: flex; align-items: center; gap: 0.4rem; margin-bottom: 0.875rem;"><span style="font-size: 1rem;">üíé</span><p style="font-size: 0.6rem; color: #94a3b8; text-transform: uppercase; letter-spacing: 0.08em; margin: 0; font-weight: 600;">YTD GROSS RETURN</p></div><h3 style="font-size: 2.5rem; font-weight: 800; color: {gross_color}; margin: 0.5rem 0 0.75rem 0; text-shadow: {gross_glow}; line-height: 1;">{stats["ytd_gross_return"]:+.1f}%</h3><div style="display: inline-block; padding: 0.4rem 0.75rem; background: rgba(99,102,241,0.12); border-radius: 10px; border: 1px solid rgba(99,102,241,0.25);"><p style="font-size: 0.7rem; color: #a5b4fc; margin: 0; font-weight: 600;">Portfolio Perf</p></div></div>', unsafe_allow_html=True)
    
                # Additional stats row
                st.markdown("<br>", unsafe_allow_html=True)
                col1, col2, col3 = st.columns(3)

                # Card 6: Average Leverage
                with col1:
                    st.markdown(f'<div style="background: linear-gradient(135deg, rgba(6,182,212,0.08), rgba(21,25,50,0.95)); backdrop-filter: blur(24px); border-radius: 24px; border: 1px solid rgba(6,182,212,0.2); padding: 1.75rem 1.5rem; box-shadow: 0 4px 24px rgba(0,0,0,0.2); min-height: 200px; position: relative; overflow: hidden;"><div style="position: absolute; top: 0; left: 0; right: 0; height: 3px; background: linear-gradient(90deg, #06b6d4, #3b82f6); opacity: 0.8;"></div><div style="display: flex; align-items: center; gap: 0.4rem; margin-bottom: 0.875rem;"><span style="font-size: 1rem;">üìä</span><p style="font-size: 0.6rem; color: #94a3b8; text-transform: uppercase; letter-spacing: 0.08em; margin: 0; font-weight: 600;">AVERAGE LEVERAGE</p></div><h3 style="font-size: 2.5rem; font-weight: 800; color: #67e8f9; margin: 0.5rem 0 0.75rem 0; line-height: 1;">{stats["avg_leverage"]:.2f}x</h3><div style="display: inline-block; padding: 0.4rem 0.75rem; background: rgba(6,182,212,0.12); border-radius: 10px; border: 1px solid rgba(6,182,212,0.25);"><p style="font-size: 0.7rem; color: #a5f3fc; margin: 0; font-weight: 600;">Historical Avg</p></div></div>', unsafe_allow_html=True)
    
                # Card 7: Max Leverage
                with col2:
                    st.markdown(f'<div style="background: linear-gradient(135deg, rgba(239,68,68,0.08), rgba(21,25,50,0.95)); backdrop-filter: blur(24px); border-radius: 24px; border: 1px solid rgba(239,68,68,0.2); padding: 1.75rem 1.5rem; box-shadow: 0 4px 24px rgba(0,0,0,0.2); min-height: 200px; position: relative; overflow: hidden;"><div style="position: absolute; top: 0; left: 0; right: 0; height: 3px; background: linear-gradient(90deg, #ef4444, #dc2626); opacity: 0.8;"></div><div style="display: flex; align-items: center; gap: 0.4rem; margin-bottom: 0.875rem;"><span style="font-size: 1rem;">‚ö†Ô∏è</span><p style="font-size: 0.6rem; color: #94a3b8; text-transform: uppercase; letter-spacing: 0.08em; margin: 0; font-weight: 600;">MAX LEVERAGE</p></div><h3 style="font-size: 2.5rem; font-weight: 800; color: #ef4444; margin: 0.5rem 0 0.75rem 0; text-shadow: 0 0 24px rgba(239,68,68,0.5); line-height: 1;">{stats["max_leverage"]:.2f}x</h3><div style="display: inline-block; padding: 0.4rem 0.75rem; background: rgba(239,68,68,0.12); border-radius: 10px; border: 1px solid rgba(239,68,68,0.25);"><p style="font-size: 0.7rem; color: #fca5a5; margin: 0; font-weight: 600;">Peak Risk</p></div></div>', unsafe_allow_html=True)
    
                # Card 8: Min Leverage
                with col3:
                    st.markdown(f'<div style="background: linear-gradient(135deg, rgba(16,185,129,0.08), rgba(21,25,50,0.95)); backdrop-filter: blur(24px); border-radius: 24px; border: 1px solid rgba(16,185,129,0.2); padding: 1.75rem 1.5rem; box-shadow: 0 4px 24px rgba(0,0,0,0.2); min-height: 200px; position: relative; overflow: hidden;"><div style="position: absolute; top: 0; left: 0; right: 0; height: 3px; background: linear-gradient(90deg, #10b981, #059669); opacity: 0.8;"></div><div style="display: flex; align-items: center; gap: 0.4rem; margin-bottom: 0.875rem;"><span style="font-size: 1rem;">‚úÖ</span><p style="font-size: 0.6rem; color: #94a3b8; text-transform: uppercase; letter-spacing: 0.08em; margin: 0; font-weight: 600;">MIN LEVERAGE</p></div><h3 style="font-size: 2.5rem; font-weight: 800; color: #10b981; margin: 0.5rem 0 0.75rem 0; text-shadow: 0 0 24px rgba(16,185,129,0.5); line-height: 1;">{stats["min_leverage"]:.2f}x</h3><div style="display: inline-block; padding: 0.4rem 0.75rem; background: rgba(16,185,129,0.12); border-radius: 10px; border: 1px solid rgba(16,185,129,0.25);"><p style="font-size: 0.7rem; color: #6ee7b7; margin: 0; font-weight: 600;">Conservative</p></div></div>', unsafe_allow_html=True)
    
                # Dashboard
                st.markdown("---")
                st.markdown('<h2 style="font-size: 1.5rem; font-weight: 700; color: #f8fafc; margin-bottom: 1.5rem;"><span style="font-size: 1.25rem;">üìä</span> <span style="background: linear-gradient(135deg, #00d4ff, #6366f1, #8b5cf6); -webkit-background-clip: text; -webkit-text-fill-color: transparent;">6-Chart Leverage Dashboard</span></h2>', unsafe_allow_html=True)
    
                fig = tracker.create_leverage_dashboard()
                st.plotly_chart(fig, use_container_width=True)
    
                # Workings
                st.markdown("---")
                st.markdown('<h2 style="font-size: 1.5rem; font-weight: 700; color: #f8fafc; margin-bottom: 1.5rem;"><span style="font-size: 1.25rem;">üßÆ</span> <span style="background: linear-gradient(135deg, #00d4ff, #6366f1, #8b5cf6); -webkit-background-clip: text; -webkit-text-fill-color: transparent;">Calculation Workings</span></h2>', unsafe_allow_html=True)
                st.markdown("**See exactly how leverage is calculated**")
    
                workings = tracker.create_workings_display()
                st.markdown(workings)
    
                # Historical data table
                st.markdown("---")
                st.markdown('<h2 style="font-size: 1.5rem; font-weight: 700; color: #f8fafc; margin-bottom: 1.5rem;"><span style="font-size: 1.25rem;">üìã</span> <span style="background: linear-gradient(135deg, #00d4ff, #6366f1, #8b5cf6); -webkit-background-clip: text; -webkit-text-fill-color: transparent;">Historical Data Table</span></h2>', unsafe_allow_html=True)
    
                display_df = tracker.leverage_history[[
                    'Date', 'Net Equity', 'Gross Exposure', 'Leverage Ratio',
                    'Equity Return (%)', 'Gross Return (%)', 'Leverage Impact (%)'
                ]].copy()
    
                # Format for display
                display_df['Date'] = display_df['Date'].dt.strftime('%Y-%m-%d')
                display_df['Net Equity'] = display_df['Net Equity'].apply(lambda x: f"${x:,.0f}")
                display_df['Gross Exposure'] = display_df['Gross Exposure'].apply(lambda x: f"${x:,.0f}")
                display_df['Leverage Ratio'] = display_df['Leverage Ratio'].apply(lambda x: f"{x:.2f}x")
    
                for col in ['Equity Return (%)', 'Gross Return (%)', 'Leverage Impact (%)']:
                    display_df[col] = display_df[col].apply(lambda x: f"{x:.2f}%" if pd.notna(x) else "")
    
                make_scrollable_table(display_df, height=400, hide_index=True, use_container_width=True)
    
                # Export options
                st.markdown("---")
                st.markdown('<h2 style="font-size: 1.5rem; font-weight: 700; color: #f8fafc; margin-bottom: 1.5rem;"><span style="font-size: 1.25rem;">üíæ</span> <span style="background: linear-gradient(135deg, #00d4ff, #6366f1, #8b5cf6); -webkit-background-clip: text; -webkit-text-fill-color: transparent;">Export Options</span></h2>', unsafe_allow_html=True)
    
                col1, col2 = st.columns(2)
    
                with col1:
                    if st.button("üì• Download Full Data (CSV)"):
                        csv = tracker.leverage_history.to_csv(index=False)
                        st.download_button(
                            label="Download CSV",
                            data=csv,
                            file_name="leverage_history.csv",
                            mime="text/csv"
                        )
    
                with col2:
                    if st.button("üîÑ Clear Leverage Data"):
                        del st.session_state.leverage_tracker
                        st.success("‚úÖ Leverage data cleared. Upload a new file to continue.")
                        st.experimental_rerun()
    
        # ========================================================================
        # INVESTOPEDIA LIVE (v11.0) - FIXED TWO-STAGE AUTH
        # ========================================================================
        elif page == "üì° Investopedia Live":
            st.markdown("### üì° Investopedia Paper Trading Integration")
            st.markdown("**Live Portfolio Sync with Investopedia Simulator**")
    
            # ===== FIX #6: Check for Selenium availability =====
            try:
                from selenium import webdriver
                SELENIUM_AVAILABLE = True
            except ImportError:
                SELENIUM_AVAILABLE = False
    
            if not SELENIUM_AVAILABLE:
                st.error("‚ùå Selenium Not Installed")
    
                st.markdown("""
                ### üì¶ Selenium Installation Required
    
                Investopedia integration requires Selenium for web automation.
    
                ---
    
                #### üîß For Google Colab:
    
                Run this in a code cell **before** starting the app:
    
                ```python
                # Install Selenium and ChromeDriver
                !pip install selenium
                !apt-get update
                !apt-get install -y chromium-chromedriver
                !cp /usr/lib/chromium-browser/chromedriver /usr/bin
                ```
    
                Then restart your Streamlit app.
    
                ---
    
                #### üíª For Local Deployment:
    
                ```bash
                # Install Selenium
                pip install selenium webdriver-manager
    
                # For Chrome (recommended)
                # Download ChromeDriver from: https://chromedriver.chromium.org/
                # Or use webdriver-manager to auto-download
                ```
    
                ---
    
                #### üìã Requirements:
    
                - ‚úÖ `selenium` package (Python)
                - ‚úÖ Chrome/Chromium browser
                - ‚úÖ ChromeDriver (matching Chrome version)
    
                ---
                """)
    
                # Add status check
                st.markdown("### üîç Package Status Check")
    
                col1, col2 = st.columns(2)
    
                with col1:
                    try:
                        from selenium import webdriver
                        st.success("‚úÖ selenium installed")
                    except ImportError:
                        st.error("‚ùå selenium missing")
                        st.caption("Run: `pip install selenium`")
    
                with col2:
                    try:
                        import subprocess
                        result = subprocess.run(['which', 'chromedriver'], capture_output=True)
                        if result.returncode == 0:
                            st.success("‚úÖ chromedriver found")
                        else:
                            st.error("‚ùå chromedriver missing")
                            st.caption("Install ChromeDriver")
                    except:
                        st.error("‚ùå chromedriver missing")
                        st.caption("Install ChromeDriver")
    
                st.stop()
    
            # Initialize authentication state
            if 'investopedia_auth_state' not in st.session_state:
                st.session_state.investopedia_auth_state = 'initial'  # initial, awaiting_2fa, authenticated
    
            # Authentication section
            st.markdown("#### üîê Authentication")
    
            # STAGE 1: Initial Login (Email + Password)
            if st.session_state.investopedia_auth_state == 'initial':
                st.info("**Step 1 of 2:** Enter your credentials to trigger 2FA email")
    
                col1, col2 = st.columns(2)
                with col1:
                    email = st.text_input("Email", value="davenompozolo@gmail.com", key="inv_email")
                with col2:
                    password = st.text_input("Password", type="password", key="inv_password")
    
                if st.button("üîì Attempt Login", type="primary"):
                    if password:
                        with st.spinner("Attempting login to Investopedia..."):
                            integration = InvestopediaIntegration(email=email)
                            result = integration.attempt_login(password)
    
                            if result['status'] == 'error':
                                st.error(f"‚ùå {result['message']}")
    
                            elif result['status'] == '2fa_required':
                                # Store integration object for Stage 2
                                st.session_state['investopedia_integration'] = integration
                                st.session_state.investopedia_auth_state = 'awaiting_2fa'
                                st.success(result['message'])
                                st.info("‚è≥ **Step 2 of 2:** Check your email and enter the 2FA code below")
                                st.rerun()
    
                            elif result['status'] == 'success':
                                st.session_state['investopedia_integration'] = integration
                                st.session_state.investopedia_auth_state = 'authenticated'
                                st.success(result['message'])
                                st.balloons()
                                st.rerun()
                    else:
                        st.warning("‚ö†Ô∏è Please enter your password")
    
            # STAGE 2: 2FA Code Submission
            elif st.session_state.investopedia_auth_state == 'awaiting_2fa':
                st.success("‚úì Login attempt successful! 2FA code has been sent to your email.")
                st.info("‚è≥ **Step 2 of 2:** Enter the 6-digit code from your email")
    
                twofa_code = st.text_input("2FA Code", placeholder="Enter 6-digit code", max_chars=6, key="inv_2fa")
    
                col1, col2 = st.columns([3, 1])
                with col1:
                    if st.button("‚úÖ Submit 2FA Code", type="primary"):
                        if twofa_code and len(twofa_code) == 6:
                            with st.spinner("Submitting 2FA code..."):
                                integration = st.session_state.get('investopedia_integration')
    
                                if integration:
                                    result = integration.submit_2fa_code(twofa_code)
    
                                    if result['status'] == 'success':
                                        st.session_state.investopedia_auth_state = 'authenticated'
                                        st.success(result['message'])
                                        st.balloons()
                                        st.rerun()
                                    else:
                                        st.error(f"‚ùå {result['message']}")
                                else:
                                    st.error("‚ùå No active login session. Please restart login.")
                                    st.session_state.investopedia_auth_state = 'initial'
                                    st.rerun()
                        else:
                            st.warning("‚ö†Ô∏è Please enter a valid 6-digit code")
    
                with col2:
                    if st.button("üîô Start Over"):
                        # Cleanup and restart
                        if 'investopedia_integration' in st.session_state:
                            integration = st.session_state['investopedia_integration']
                            integration.cleanup()
                        st.session_state.investopedia_auth_state = 'initial'
                        st.rerun()
    
            # STAGE 3: Authenticated - Portfolio Sync
            elif st.session_state.investopedia_auth_state == 'authenticated':
                st.success("‚úÖ **Authenticated with Investopedia!**")
    
                col1, col2 = st.columns([3, 1])
                with col1:
                    st.markdown("You can now sync your portfolio from Investopedia Simulator")
                with col2:
                    if st.button("üîì Logout"):
                        # Cleanup and reset
                        if 'investopedia_integration' in st.session_state:
                            integration = st.session_state['investopedia_integration']
                            integration.cleanup()
                        st.session_state.investopedia_auth_state = 'initial'
                        st.session_state.pop('investopedia_integration', None)
                        st.rerun()
    
                st.markdown("---")
                st.markdown("#### üìä Portfolio Sync")
    
                if st.button("üîÑ Sync Portfolio from Investopedia", type="primary"):
                    with st.spinner("Fetching portfolio data..."):
                        integration = st.session_state.get('investopedia_integration')
    
                        if integration:
                            portfolio_df = integration.scrape_portfolio()
    
                            if portfolio_df is not None and not portfolio_df.empty:
                                st.success(f"‚úÖ Portfolio synced successfully! Found {len(portfolio_df)} positions")
                                make_scrollable_table(portfolio_df, height=600, hide_index=True, use_container_width=True)
    
                                # Save to session state for use in other ATLAS modules
                                st.session_state['portfolio_data'] = portfolio_df
                                st.info("üí° Portfolio saved! You can now use it in other ATLAS features")
    
                                # Reset auth state after successful sync
                                st.session_state.investopedia_auth_state = 'initial'
                                st.session_state.pop('investopedia_integration', None)
                            else:
                                st.warning("‚ö†Ô∏è No portfolio data found or portfolio is empty")
                                # Reset auth state
                                st.session_state.investopedia_auth_state = 'initial'
                                st.session_state.pop('investopedia_integration', None)
                        else:
                            st.error("‚ùå Authentication session lost. Please login again.")
                            st.session_state.investopedia_auth_state = 'initial'
                            st.rerun()
    
            # Info section
            st.markdown("---")
            st.markdown("#### ‚ÑπÔ∏è About Investopedia Integration")
            st.markdown("""
            **Features:**
            - üîê **Two-stage authentication** with proper 2FA flow
            - üìß Email-based 2FA code delivery
            - üìä Live portfolio data scraping
            - üîÑ Real-time sync with Investopedia Simulator
            - üîí Secure Selenium-based browser automation
    
            **How to use:**
            1. **Step 1:** Enter your email and password
            2. **Step 2:** Click "Attempt Login" - this will trigger Investopedia to send you a 2FA code
            3. **Step 3:** Check your email for the 6-digit code
            4. **Step 4:** Enter the code and click "Submit 2FA Code"
            5. **Step 5:** Once authenticated, click "Sync Portfolio" to fetch your positions
            6. Synced data is automatically available in other ATLAS modules
    
            **Fixed Issues:**
            - ‚úÖ No more Status 403 errors
            - ‚úÖ Honest authentication flow (actually logs in to Investopedia)
            - ‚úÖ Proper 2FA handling (email ‚Üí code ‚Üí submit)
            - ‚úÖ Clear step-by-step progress indicators
    
            **Note:** This feature uses Selenium to automate browser interactions with Investopedia.
            Your credentials are only used for authentication and are not stored.
            """)
    
        # ========================================================================
        # ABOUT
        # ========================================================================
        elif page == "‚ÑπÔ∏è About":
            st.markdown("### ‚ÑπÔ∏è ATLAS Terminal v9.7 ULTIMATE EDITION")
            st.success("""
            **ATLAS v9.7 ULTIMATE EDITION** üöÄüíé‚ú®
    
            **üìÖ RELEASE DATE: November 14, 2025**
            **üî• STATUS: Production Ready & Verified**
    
            **üöÄ NEW IN v9.7 (Latest Release):**
            ‚úÖ Enhanced Performance - Optimized data loading and caching
            ‚úÖ Advanced Risk Metrics - VaR, CVaR, Maximum Drawdown
            ‚úÖ Improved Error Handling - Graceful fallbacks for data fetching
            ‚úÖ Better Data Validation - Enhanced portfolio integrity checks
            ‚úÖ Version Display - Clear versioning throughout interface
            ‚úÖ Code Structure - Modular, maintainable, production-ready
            ‚úÖ Extended Market Coverage - Additional asset classes
    
            **PREVIOUS ENHANCEMENTS (v9.3-v9.6):**
            ‚úÖ Enhanced Home Page (Top Contributors/Detractors + Better Layout)
            ‚úÖ Market Watch COMPLETE REVAMP (Crypto, Bonds, Spreads, 100+ Assets)
            ‚úÖ ALL Charts Seamlessly Themed (No More Black Boxes!)
            ‚úÖ Portfolio Deep Dive Enhanced (Better Concentration Analysis)
            ‚úÖ Valuation House: Smart Assumptions Mode (AI-Generated)
            ‚úÖ Valuation House: Fixed D&A/CapEx Scaling with Revenue
            ‚úÖ Fixed Nov 2024 Columns in All Heatmaps
            ‚úÖ Multi-Factor Analysis (Perfect - No Changes Needed!)
    
            **COMPLETE MODULE LIST:**
            1. **Phoenix Parser** - Exceptional data parsing
            2. **Portfolio Home** - Enhanced dashboard with contributors/detractors
            3. **Market Watch** - Comprehensive: Indices, Crypto, Bonds, Spreads, ETFs, Stocks, Commodities
            4. **Risk Analysis** - World-class metrics & visualizations
            5. **Performance Suite** - Comprehensive analytics
            6. **Portfolio Deep Dive** - Enhanced concentration analysis
            7. **Multi-Factor Analysis** - Advanced attribution (kept perfect!)
            8. **Valuation House** - Smart Assumptions + Enhanced DCF
    
            **KEY FEATURES:**
            - ü§ñ Smart Assumptions for DCF valuations
            - üåç Expanded Market Watch (150+ assets)
            - üìä Seamless chart theming throughout
            - üéØ Enhanced Home Page dashboard
            - üíé Fixed D&A/CapEx scaling
            - üîí Production-ready error handling
            - ‚ö° Optimized performance
            - ‚ú® All original features preserved and enhanced
    
            **VERSION HISTORY:**
            - v9.7 (Nov 2025): Performance, risk metrics, error handling
            - v9.6 (Oct 2025): Valuation House integration
            - v9.5 (Sep 2025): Modular methods expansion
            - v9.4 (Sep 2025): Professional grade enhancements
            - v9.3 (Aug 2025): Excellence edition features
    
            Total: **The Ultimate Investment Analysis Platform - PRODUCTION READY!** üöÄüíé
            """)
    
            # SYSTEM NOTIFICATIONS DEMO
            # ============================================================
            st.divider()
            st.subheader("üß™ System Notifications Demo")
            st.caption("Test the toast notification system with different message types")
    
            col1, col2, col3, col4 = st.columns(4)
    
            with col1:
                if st.button("‚úì Success", use_container_width=True, key="demo_success"):
                    show_toast("Portfolio optimization completed successfully!", toast_type="success", duration=3000)
    
            with col2:
                if st.button("‚úï Error", use_container_width=True, key="demo_error"):
                    show_toast("Failed to connect to market data API", toast_type="error", duration=4000)
    
            with col3:
                if st.button("‚ö† Warning", use_container_width=True, key="demo_warning"):
                    show_toast("Portfolio VaR exceeds risk threshold", toast_type="warning", duration=4000)
    
            with col4:
                if st.button("‚Ñπ Info", use_container_width=True, key="demo_info"):
                    show_toast("Market data updated - last refresh: 14:23:45", toast_type="info", duration=3000)
    
            st.markdown("")  # Spacing
    
            # Sequential demo button
            if st.button("üé¨ Play All Notifications", use_container_width=True, key="demo_sequential"):
                show_toast("Starting system check...", toast_type="info", duration=2000)
                import time
                time.sleep(0.3)
                show_toast("‚úì Market data connection established", toast_type="success", duration=2000)
                time.sleep(0.3)
                show_toast("‚ö†Ô∏è High volatility detected in portfolio", toast_type="warning", duration=2000)
            time.sleep(0.3)
            show_toast("System check complete!", toast_type="success", duration=3000)

if __name__ == "__main__":
    main()
